// modules are defined as an array
// [ module function, map of requires ]
//
// map of requires is short require name -> numeric require
//
// anything defined in a previous bundle is accessed via the
// orig method which is the require for previous bundles

(function(modules, entry, mainEntry, parcelRequireName, globalName) {
  /* eslint-disable no-undef */
  var globalObject =
    typeof globalThis !== 'undefined'
      ? globalThis
      : typeof self !== 'undefined'
      ? self
      : typeof window !== 'undefined'
      ? window
      : typeof global !== 'undefined'
      ? global
      : {};
  /* eslint-enable no-undef */

  // Save the require from previous bundle to this closure if any
  var previousRequire =
    typeof globalObject[parcelRequireName] === 'function' &&
    globalObject[parcelRequireName];

  var cache = previousRequire.cache || {};
  // Do not use `require` to prevent Webpack from trying to bundle this call
  var nodeRequire =
    typeof module !== 'undefined' &&
    typeof module.require === 'function' &&
    module.require.bind(module);

  function newRequire(name, jumped) {
    if (!cache[name]) {
      if (!modules[name]) {
        // if we cannot find the module within our internal map or
        // cache jump to the current global require ie. the last bundle
        // that was added to the page.
        var currentRequire =
          typeof globalObject[parcelRequireName] === 'function' &&
          globalObject[parcelRequireName];
        if (!jumped && currentRequire) {
          return currentRequire(name, true);
        }

        // If there are other bundles on this page the require from the
        // previous one is saved to 'previousRequire'. Repeat this as
        // many times as there are bundles until the module is found or
        // we exhaust the require chain.
        if (previousRequire) {
          return previousRequire(name, true);
        }

        // Try the node require function if it exists.
        if (nodeRequire && typeof name === 'string') {
          return nodeRequire(name);
        }

        var err = new Error("Cannot find module '" + name + "'");
        err.code = 'MODULE_NOT_FOUND';
        throw err;
      }

      localRequire.resolve = resolve;
      localRequire.cache = {};

      var module = (cache[name] = new newRequire.Module(name));

      modules[name][0].call(
        module.exports,
        localRequire,
        module,
        module.exports,
        this
      );
    }

    return cache[name].exports;

    function localRequire(x) {
      return newRequire(localRequire.resolve(x));
    }

    function resolve(x) {
      return modules[name][1][x] || x;
    }
  }

  function Module(moduleName) {
    this.id = moduleName;
    this.bundle = newRequire;
    this.exports = {};
  }

  newRequire.isParcelRequire = true;
  newRequire.Module = Module;
  newRequire.modules = modules;
  newRequire.cache = cache;
  newRequire.parent = previousRequire;
  newRequire.register = function(id, exports) {
    modules[id] = [
      function(require, module) {
        module.exports = exports;
      },
      {},
    ];
  };

  Object.defineProperty(newRequire, 'root', {
    get: function() {
      return globalObject[parcelRequireName];
    },
  });

  globalObject[parcelRequireName] = newRequire;

  for (var i = 0; i < entry.length; i++) {
    newRequire(entry[i]);
  }

  if (mainEntry) {
    // Expose entry point to Node, AMD or browser globals
    // Based on https://github.com/ForbesLindesay/umd/blob/master/template.js
    var mainExports = newRequire(mainEntry);

    // CommonJS
    if (typeof exports === 'object' && typeof module !== 'undefined') {
      module.exports = mainExports;

      // RequireJS
    } else if (typeof define === 'function' && define.amd) {
      define(function() {
        return mainExports;
      });

      // <script>
    } else if (globalName) {
      this[globalName] = mainExports;
    }
  }
})({"5mFkr":[function(require,module,exports) {
var HMR_HOST = null;
var HMR_PORT = null;
var HMR_SECURE = false;
var HMR_ENV_HASH = "69f74e7f31319ffd";
module.bundle.HMR_BUNDLE_ID = "032419a86a345035";
"use strict";
function _createForOfIteratorHelper(o, allowArrayLike) {
    var it;
    if (typeof Symbol === "undefined" || o[Symbol.iterator] == null) {
        if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === "number") {
            if (it) o = it;
            var i = 0;
            var F = function F1() {
            };
            return {
                s: F,
                n: function n() {
                    if (i >= o.length) return {
                        done: true
                    };
                    return {
                        done: false,
                        value: o[i++]
                    };
                },
                e: function e(_e) {
                    throw _e;
                },
                f: F
            };
        }
        throw new TypeError("Invalid attempt to iterate non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.");
    }
    var normalCompletion = true, didErr = false, err;
    return {
        s: function s() {
            it = o[Symbol.iterator]();
        },
        n: function n() {
            var step = it.next();
            normalCompletion = step.done;
            return step;
        },
        e: function e(_e2) {
            didErr = true;
            err = _e2;
        },
        f: function f() {
            try {
                if (!normalCompletion && it.return != null) it.return();
            } finally{
                if (didErr) throw err;
            }
        }
    };
}
function _unsupportedIterableToArray(o, minLen) {
    if (!o) return;
    if (typeof o === "string") return _arrayLikeToArray(o, minLen);
    var n = Object.prototype.toString.call(o).slice(8, -1);
    if (n === "Object" && o.constructor) n = o.constructor.name;
    if (n === "Map" || n === "Set") return Array.from(o);
    if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen);
}
function _arrayLikeToArray(arr, len) {
    if (len == null || len > arr.length) len = arr.length;
    for(var i = 0, arr2 = new Array(len); i < len; i++)arr2[i] = arr[i];
    return arr2;
}
/* global HMR_HOST, HMR_PORT, HMR_ENV_HASH, HMR_SECURE */ /*::
import type {
  HMRAsset,
  HMRMessage,
} from '@parcel/reporter-dev-server/src/HMRServer.js';
interface ParcelRequire {
  (string): mixed;
  cache: {|[string]: ParcelModule|};
  hotData: mixed;
  Module: any;
  parent: ?ParcelRequire;
  isParcelRequire: true;
  modules: {|[string]: [Function, {|[string]: string|}]|};
  HMR_BUNDLE_ID: string;
  root: ParcelRequire;
}
interface ParcelModule {
  hot: {|
    data: mixed,
    accept(cb: (Function) => void): void,
    dispose(cb: (mixed) => void): void,
    // accept(deps: Array<string> | string, cb: (Function) => void): void,
    // decline(): void,
    _acceptCallbacks: Array<(Function) => void>,
    _disposeCallbacks: Array<(mixed) => void>,
  |};
}
declare var module: {bundle: ParcelRequire, ...};
declare var HMR_HOST: string;
declare var HMR_PORT: string;
declare var HMR_ENV_HASH: string;
declare var HMR_SECURE: boolean;
*/ var OVERLAY_ID = '__parcel__error__overlay__';
var OldModule = module.bundle.Module;
function Module(moduleName) {
    OldModule.call(this, moduleName);
    this.hot = {
        data: module.bundle.hotData,
        _acceptCallbacks: [],
        _disposeCallbacks: [],
        accept: function accept(fn) {
            this._acceptCallbacks.push(fn || function() {
            });
        },
        dispose: function dispose(fn) {
            this._disposeCallbacks.push(fn);
        }
    };
    module.bundle.hotData = undefined;
}
module.bundle.Module = Module;
var checkedAssets, acceptedAssets, assetsToAccept;
function getHostname() {
    return HMR_HOST || (location.protocol.indexOf('http') === 0 ? location.hostname : 'localhost');
}
function getPort() {
    return HMR_PORT || location.port;
} // eslint-disable-next-line no-redeclare
var parent = module.bundle.parent;
if ((!parent || !parent.isParcelRequire) && typeof WebSocket !== 'undefined') {
    var hostname = getHostname();
    var port = getPort();
    var protocol = HMR_SECURE || location.protocol == 'https:' && !/localhost|127.0.0.1|0.0.0.0/.test(hostname) ? 'wss' : 'ws';
    var ws = new WebSocket(protocol + '://' + hostname + (port ? ':' + port : '') + '/'); // $FlowFixMe
    ws.onmessage = function(event) {
        checkedAssets = {
        };
        acceptedAssets = {
        };
        assetsToAccept = [];
        var data = JSON.parse(event.data);
        if (data.type === 'update') {
            // Remove error overlay if there is one
            removeErrorOverlay();
            var assets = data.assets.filter(function(asset) {
                return asset.envHash === HMR_ENV_HASH;
            }); // Handle HMR Update
            var handled = assets.every(function(asset) {
                return asset.type === 'css' || asset.type === 'js' && hmrAcceptCheck(module.bundle.root, asset.id, asset.depsByBundle);
            });
            if (handled) {
                console.clear();
                assets.forEach(function(asset) {
                    hmrApply(module.bundle.root, asset);
                });
                for(var i = 0; i < assetsToAccept.length; i++){
                    var id = assetsToAccept[i][1];
                    if (!acceptedAssets[id]) hmrAcceptRun(assetsToAccept[i][0], id);
                }
            } else window.location.reload();
        }
        if (data.type === 'error') {
            // Log parcel errors to console
            var _iterator = _createForOfIteratorHelper(data.diagnostics.ansi), _step;
            try {
                for(_iterator.s(); !(_step = _iterator.n()).done;){
                    var ansiDiagnostic = _step.value;
                    var stack = ansiDiagnostic.codeframe ? ansiDiagnostic.codeframe : ansiDiagnostic.stack;
                    console.error('🚨 [parcel]: ' + ansiDiagnostic.message + '\n' + stack + '\n\n' + ansiDiagnostic.hints.join('\n'));
                } // Render the fancy html overlay
            } catch (err) {
                _iterator.e(err);
            } finally{
                _iterator.f();
            }
            removeErrorOverlay();
            var overlay = createErrorOverlay(data.diagnostics.html); // $FlowFixMe
            document.body.appendChild(overlay);
        }
    };
    ws.onerror = function(e) {
        console.error(e.message);
    };
    ws.onclose = function() {
        console.warn('[parcel] 🚨 Connection to the HMR server was lost');
    };
}
function removeErrorOverlay() {
    var overlay = document.getElementById(OVERLAY_ID);
    if (overlay) {
        overlay.remove();
        console.log('[parcel] ✨ Error resolved');
    }
}
function createErrorOverlay(diagnostics) {
    var overlay = document.createElement('div');
    overlay.id = OVERLAY_ID;
    var errorHTML = '<div style="background: black; opacity: 0.85; font-size: 16px; color: white; position: fixed; height: 100%; width: 100%; top: 0px; left: 0px; padding: 30px; font-family: Menlo, Consolas, monospace; z-index: 9999;">';
    var _iterator2 = _createForOfIteratorHelper(diagnostics), _step2;
    try {
        for(_iterator2.s(); !(_step2 = _iterator2.n()).done;){
            var diagnostic = _step2.value;
            var stack = diagnostic.codeframe ? diagnostic.codeframe : diagnostic.stack;
            errorHTML += "\n      <div>\n        <div style=\"font-size: 18px; font-weight: bold; margin-top: 20px;\">\n          \uD83D\uDEA8 ".concat(diagnostic.message, "\n        </div>\n        <pre>\n          ").concat(stack, "\n        </pre>\n        <div>\n          ").concat(diagnostic.hints.map(function(hint) {
                return '<div>' + hint + '</div>';
            }).join(''), "\n        </div>\n      </div>\n    ");
        }
    } catch (err) {
        _iterator2.e(err);
    } finally{
        _iterator2.f();
    }
    errorHTML += '</div>';
    overlay.innerHTML = errorHTML;
    return overlay;
}
function getParents(bundle, id) /*: Array<[ParcelRequire, string]> */ {
    var modules = bundle.modules;
    if (!modules) return [];
    var parents = [];
    var k, d, dep;
    for(k in modules)for(d in modules[k][1]){
        dep = modules[k][1][d];
        if (dep === id || Array.isArray(dep) && dep[dep.length - 1] === id) parents.push([
            bundle,
            k
        ]);
    }
    if (bundle.parent) parents = parents.concat(getParents(bundle.parent, id));
    return parents;
}
function updateLink(link) {
    var newLink = link.cloneNode();
    newLink.onload = function() {
        if (link.parentNode !== null) // $FlowFixMe
        link.parentNode.removeChild(link);
    };
    newLink.setAttribute('href', link.getAttribute('href').split('?')[0] + '?' + Date.now()); // $FlowFixMe
    link.parentNode.insertBefore(newLink, link.nextSibling);
}
var cssTimeout = null;
function reloadCSS() {
    if (cssTimeout) return;
    cssTimeout = setTimeout(function() {
        var links = document.querySelectorAll('link[rel="stylesheet"]');
        for(var i = 0; i < links.length; i++){
            // $FlowFixMe[incompatible-type]
            var href = links[i].getAttribute('href');
            var hostname = getHostname();
            var servedFromHMRServer = hostname === 'localhost' ? new RegExp('^(https?:\\/\\/(0.0.0.0|127.0.0.1)|localhost):' + getPort()).test(href) : href.indexOf(hostname + ':' + getPort());
            var absolute = /^https?:\/\//i.test(href) && href.indexOf(window.location.origin) !== 0 && !servedFromHMRServer;
            if (!absolute) updateLink(links[i]);
        }
        cssTimeout = null;
    }, 50);
}
function hmrApply(bundle, asset) {
    var modules = bundle.modules;
    if (!modules) return;
    if (asset.type === 'css') {
        reloadCSS();
        return;
    }
    var deps = asset.depsByBundle[bundle.HMR_BUNDLE_ID];
    if (deps) {
        var fn = new Function('require', 'module', 'exports', asset.output);
        modules[asset.id] = [
            fn,
            deps
        ];
    } else if (bundle.parent) hmrApply(bundle.parent, asset);
}
function hmrAcceptCheck(bundle, id, depsByBundle) {
    var modules = bundle.modules;
    if (!modules) return;
    if (depsByBundle && !depsByBundle[bundle.HMR_BUNDLE_ID]) {
        // If we reached the root bundle without finding where the asset should go,
        // there's nothing to do. Mark as "accepted" so we don't reload the page.
        if (!bundle.parent) return true;
        return hmrAcceptCheck(bundle.parent, id, depsByBundle);
    }
    if (checkedAssets[id]) return;
    checkedAssets[id] = true;
    var cached = bundle.cache[id];
    assetsToAccept.push([
        bundle,
        id
    ]);
    if (cached && cached.hot && cached.hot._acceptCallbacks.length) return true;
    return getParents(module.bundle.root, id).some(function(v) {
        return hmrAcceptCheck(v[0], v[1], null);
    });
}
function hmrAcceptRun(bundle, id) {
    var cached = bundle.cache[id];
    bundle.hotData = {
    };
    if (cached && cached.hot) cached.hot.data = bundle.hotData;
    if (cached && cached.hot && cached.hot._disposeCallbacks.length) cached.hot._disposeCallbacks.forEach(function(cb) {
        cb(bundle.hotData);
    });
    delete bundle.cache[id];
    bundle(id);
    cached = bundle.cache[id];
    if (cached && cached.hot && cached.hot._acceptCallbacks.length) cached.hot._acceptCallbacks.forEach(function(cb) {
        var assetsToAlsoAccept = cb(function() {
            return getParents(module.bundle.root, id);
        });
        if (assetsToAlsoAccept && assetsToAccept.length) // $FlowFixMe[method-unbinding]
        assetsToAccept.push.apply(assetsToAccept, assetsToAlsoAccept);
    });
    acceptedAssets[id] = true;
}

},{}],"davKm":[function(require,module,exports) {
var _pixiJs = require("pixi.js");
var _tone = require("tone");
const { innerWidth: width , innerHeight: height  } = window;
let keyDown;
const cursorRadius = 50;
const cursorDiameter = cursorRadius * 2;
const speed = 10;
const margin = 20;
let direction = {
    x: 0,
    y: 0
};
let position = {
    x: width / 2 - cursorRadius / 2,
    y: height / 2 - cursorRadius / 2
};
const maxWidth = width - cursorDiameter - margin;
const maxHeight = height - cursorDiameter - margin;
const synth = new _tone.MembraneSynth().toDestination();
synth.volume.value = -10;
const down = ({ code  })=>{
    switch(code){
        case 'ArrowLeft':
        case 'KeyA':
            direction.x = -1 * speed;
            break;
        case 'ArrowRight':
        case 'KeyD':
            direction.x = 1 * speed;
            break;
        case 'ArrowUp':
        case 'KeyW':
            direction.y = -1 * speed;
            break;
        case 'ArrowDown':
        case 'KeyS':
            direction.y = 1 * speed;
            break;
        default:
            keyDown = code;
            break;
    }
};
const up = ({ code  })=>{
    keyDown = undefined;
    switch(code){
        case 'ArrowLeft':
        case 'KeyA':
        case 'ArrowRight':
        case 'KeyD':
            direction.x = 0;
            break;
        case 'ArrowUp':
        case 'KeyW':
        case 'ArrowDown':
        case 'KeyS':
            direction.y = 0;
            break;
        default:
            keyDown = code;
            break;
    }
};
document.addEventListener('keydown', down);
document.addEventListener('keypress', down);
document.addEventListener('keyup', up);
let app = new _pixiJs.Application({
    width: width - margin,
    height: height - margin
});
document.body.appendChild(app.view);
const cursorGraphic = new _pixiJs.Graphics();
// Draw cursor
cursorGraphic.beginFill('0xff2222');
cursorGraphic.drawCircle(position.x, position.y, cursorRadius);
cursorGraphic.endFill();
const renderer = _pixiJs.autoDetectRenderer();
const texture = app.renderer.generateTexture(cursorGraphic);
const cursor = new _pixiJs.Sprite(texture);
app.stage.addChild(cursor);
const basicStyle = new _pixiJs.TextStyle({
    fontSize: 18,
    fill: [
        '#ffffff'
    ]
});
const basicText = new _pixiJs.Text(`KeyDown: ${keyDown}`, basicStyle);
basicText.x = 20;
basicText.y = 20;
app.stage.addChild(basicText);
let elapsed = 0;
let bonking = false;
const bonk = ()=>{
    if (bonking) return;
    bonking = true;
    synth.triggerAttackRelease('c4', '8n');
    setTimeout(()=>bonking = false
    , 100);
};
app.ticker.add((delta)=>{
    elapsed += delta;
    position.x = position.x + direction.x;
    position.y = position.y + direction.y;
    console.log(position, direction);
    if (position.x < 0) {
        position.x = 0;
        bonk();
    }
    if (position.x > maxWidth) {
        position.x = maxWidth;
        bonk();
    }
    if (position.y < 0) {
        position.y = 0;
        bonk();
    }
    if (position.y > maxHeight) {
        position.y = maxHeight;
        bonk();
    }
    cursor.x = position.x;
    cursor.y = position.y;
    basicText.text = `KeyDown: ${keyDown ? keyDown : ''}`;
});

},{"pixi.js":"3ZUrV","tone":"itYag"}],"3ZUrV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "utils", ()=>_utils
);
parcelHelpers.export(exports, "VERSION", ()=>VERSION
);
parcelHelpers.export(exports, "filters", ()=>filters
);
/*!
 * pixi.js - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * pixi.js is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _polyfill = require("@pixi/polyfill");
var _utils = require("@pixi/utils");
var _accessibility = require("@pixi/accessibility");
var _interaction = require("@pixi/interaction");
var _app = require("@pixi/app");
var _core = require("@pixi/core");
var _extract = require("@pixi/extract");
var _loaders = require("@pixi/loaders");
var _compressedTextures = require("@pixi/compressed-textures");
var _particleContainer = require("@pixi/particle-container");
var _prepare = require("@pixi/prepare");
var _spritesheet = require("@pixi/spritesheet");
var _spriteTiling = require("@pixi/sprite-tiling");
var _textBitmap = require("@pixi/text-bitmap");
var _ticker = require("@pixi/ticker");
var _filterAlpha = require("@pixi/filter-alpha");
var _filterBlur = require("@pixi/filter-blur");
var _filterColorMatrix = require("@pixi/filter-color-matrix");
var _filterDisplacement = require("@pixi/filter-displacement");
var _filterFxaa = require("@pixi/filter-fxaa");
var _filterNoise = require("@pixi/filter-noise");
var _mixinCacheAsBitmap = require("@pixi/mixin-cache-as-bitmap");
var _mixinGetChildByName = require("@pixi/mixin-get-child-by-name");
var _mixinGetGlobalPosition = require("@pixi/mixin-get-global-position");
parcelHelpers.exportAll(_accessibility, exports);
parcelHelpers.exportAll(_interaction, exports);
parcelHelpers.exportAll(_app, exports);
parcelHelpers.exportAll(_core, exports);
parcelHelpers.exportAll(_extract, exports);
parcelHelpers.exportAll(_loaders, exports);
parcelHelpers.exportAll(_compressedTextures, exports);
parcelHelpers.exportAll(_particleContainer, exports);
parcelHelpers.exportAll(_prepare, exports);
parcelHelpers.exportAll(_spritesheet, exports);
parcelHelpers.exportAll(_spriteTiling, exports);
parcelHelpers.exportAll(_textBitmap, exports);
parcelHelpers.exportAll(_ticker, exports);
var _constants = require("@pixi/constants");
parcelHelpers.exportAll(_constants, exports);
var _display = require("@pixi/display");
parcelHelpers.exportAll(_display, exports);
var _graphics = require("@pixi/graphics");
parcelHelpers.exportAll(_graphics, exports);
var _math = require("@pixi/math");
parcelHelpers.exportAll(_math, exports);
var _mesh = require("@pixi/mesh");
parcelHelpers.exportAll(_mesh, exports);
var _meshExtras = require("@pixi/mesh-extras");
parcelHelpers.exportAll(_meshExtras, exports);
var _runner = require("@pixi/runner");
parcelHelpers.exportAll(_runner, exports);
var _sprite = require("@pixi/sprite");
parcelHelpers.exportAll(_sprite, exports);
var _spriteAnimated = require("@pixi/sprite-animated");
parcelHelpers.exportAll(_spriteAnimated, exports);
var _text = require("@pixi/text");
parcelHelpers.exportAll(_text, exports);
var _settings = require("@pixi/settings");
parcelHelpers.exportAll(_settings, exports);
// Install renderer plugins
_core.Renderer.registerPlugin('accessibility', _accessibility.AccessibilityManager);
_core.Renderer.registerPlugin('extract', _extract.Extract);
_core.Renderer.registerPlugin('interaction', _interaction.InteractionManager);
_core.Renderer.registerPlugin('particle', _particleContainer.ParticleRenderer);
_core.Renderer.registerPlugin('prepare', _prepare.Prepare);
_core.Renderer.registerPlugin('batch', _core.BatchRenderer);
_core.Renderer.registerPlugin('tilingSprite', _spriteTiling.TilingSpriteRenderer);
// Install loader plugins
_loaders.Loader.registerPlugin(_textBitmap.BitmapFontLoader);
_loaders.Loader.registerPlugin(_compressedTextures.CompressedTextureLoader);
_loaders.Loader.registerPlugin(_compressedTextures.DDSLoader);
_loaders.Loader.registerPlugin(_compressedTextures.KTXLoader);
_loaders.Loader.registerPlugin(_spritesheet.SpritesheetLoader);
// Install application plugins
_app.Application.registerPlugin(_ticker.TickerPlugin);
_app.Application.registerPlugin(_loaders.AppLoaderPlugin);
/**
 * String of the current PIXI version.
 *
 * @static
 * @constant
 * @memberof PIXI
 * @name VERSION
 * @type {string}
 */ var VERSION = '6.1.3';
/**
 * @namespace PIXI
 */ /**
 * This namespace contains WebGL-only display filters that can be applied
 * to DisplayObjects using the {@link PIXI.DisplayObject#filters filters} property.
 *
 * Since PixiJS only had a handful of built-in filters, additional filters
 * can be downloaded {@link https://github.com/pixijs/pixi-filters here} from the
 * PixiJS Filters repository.
 *
 * All filters must extend {@link PIXI.Filter}.
 *
 * @example
 * // Create a new application
 * const app = new PIXI.Application();
 *
 * // Draw a green rectangle
 * const rect = new PIXI.Graphics()
 *     .beginFill(0x00ff00)
 *     .drawRect(40, 40, 200, 200);
 *
 * // Add a blur filter
 * rect.filters = [new PIXI.filters.BlurFilter()];
 *
 * // Display rectangle
 * app.stage.addChild(rect);
 * document.body.appendChild(app.view);
 * @namespace PIXI.filters
 */ var filters = {
    AlphaFilter: _filterAlpha.AlphaFilter,
    BlurFilter: _filterBlur.BlurFilter,
    BlurFilterPass: _filterBlur.BlurFilterPass,
    ColorMatrixFilter: _filterColorMatrix.ColorMatrixFilter,
    DisplacementFilter: _filterDisplacement.DisplacementFilter,
    FXAAFilter: _filterFxaa.FXAAFilter,
    NoiseFilter: _filterNoise.NoiseFilter
};

},{"@pixi/polyfill":"a0Eht","@pixi/utils":"joR65","@pixi/accessibility":"5A0wu","@pixi/interaction":"351da","@pixi/app":"bGbnz","@pixi/core":"d0INm","@pixi/extract":"8UvLW","@pixi/loaders":"1PTMa","@pixi/compressed-textures":"9HMtg","@pixi/particle-container":"j2a6m","@pixi/prepare":"gZ0OT","@pixi/spritesheet":"9ABv3","@pixi/sprite-tiling":"29NuY","@pixi/text-bitmap":"h5Lr7","@pixi/ticker":"5j6Uq","@pixi/filter-alpha":"ck9sM","@pixi/filter-blur":"7vdNI","@pixi/filter-color-matrix":"cz6Dl","@pixi/filter-displacement":"eENq5","@pixi/filter-fxaa":"5UHC7","@pixi/filter-noise":"fRToZ","@pixi/mixin-cache-as-bitmap":"fYfiT","@pixi/mixin-get-child-by-name":"1wORs","@pixi/mixin-get-global-position":"4IZbg","@pixi/constants":"lqjFh","@pixi/display":"hQqz5","@pixi/graphics":"eq7Pq","@pixi/math":"1qR3C","@pixi/mesh":"a96bk","@pixi/mesh-extras":"dJlOc","@pixi/runner":"9dm4Q","@pixi/sprite":"aeiZG","@pixi/sprite-animated":"3JjHI","@pixi/text":"fmwBo","@pixi/settings":"habh9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"a0Eht":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
/*!
 * @pixi/polyfill - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/polyfill is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _promisePolyfill = require("promise-polyfill");
var _promisePolyfillDefault = parcelHelpers.interopDefault(_promisePolyfill);
var _objectAssign = require("object-assign");
var _objectAssignDefault = parcelHelpers.interopDefault(_objectAssign);
// Support for IE 9 - 11 which does not include Promises
if (!self.Promise) self.Promise = _promisePolyfillDefault.default;
// References:
if (!Object.assign) Object.assign = _objectAssignDefault.default;
// References:
// http://paulirish.com/2011/requestanimationframe-for-smart-animating/
// https://gist.github.com/1579671
// http://updates.html5rocks.com/2012/05/requestAnimationFrame-API-now-with-sub-millisecond-precision
// https://gist.github.com/timhall/4078614
// https://github.com/Financial-Times/polyfill-service/tree/master/polyfills/requestAnimationFrame
// Expected to be used with Browserfiy
// Browserify automatically detects the use of `global` and passes the
// correct reference of `global`, `self`, and finally `window`
var ONE_FRAME_TIME = 16;
// Date.now
if (!(Date.now && Date.prototype.getTime)) Date.now = function now() {
    return new Date().getTime();
};
// performance.now
if (!(self.performance && self.performance.now)) {
    var startTime_1 = Date.now();
    if (!self.performance) self.performance = {
    };
    self.performance.now = function() {
        return Date.now() - startTime_1;
    };
}
// requestAnimationFrame
var lastTime = Date.now();
var vendors = [
    'ms',
    'moz',
    'webkit',
    'o'
];
for(var x = 0; x < vendors.length && !self.requestAnimationFrame; ++x){
    var p = vendors[x];
    self.requestAnimationFrame = self[p + "RequestAnimationFrame"];
    self.cancelAnimationFrame = self[p + "CancelAnimationFrame"] || self[p + "CancelRequestAnimationFrame"];
}
if (!self.requestAnimationFrame) self.requestAnimationFrame = function(callback) {
    if (typeof callback !== 'function') throw new TypeError(callback + "is not a function");
    var currentTime = Date.now();
    var delay = ONE_FRAME_TIME + lastTime - currentTime;
    if (delay < 0) delay = 0;
    lastTime = currentTime;
    return self.setTimeout(function() {
        lastTime = Date.now();
        callback(performance.now());
    }, delay);
};
if (!self.cancelAnimationFrame) self.cancelAnimationFrame = function(id) {
    return clearTimeout(id);
};
// References:
// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/sign
if (!Math.sign) Math.sign = function mathSign(x1) {
    x1 = Number(x1);
    if (x1 === 0 || isNaN(x1)) return x1;
    return x1 > 0 ? 1 : -1;
};
// References:
// https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Number/isInteger
if (!Number.isInteger) Number.isInteger = function numberIsInteger(value) {
    return typeof value === 'number' && isFinite(value) && Math.floor(value) === value;
};
if (!self.ArrayBuffer) self.ArrayBuffer = Array;
if (!self.Float32Array) self.Float32Array = Array;
if (!self.Uint32Array) self.Uint32Array = Array;
if (!self.Uint16Array) self.Uint16Array = Array;
if (!self.Uint8Array) self.Uint8Array = Array;
if (!self.Int32Array) self.Int32Array = Array;

},{"promise-polyfill":"hp9Zv","object-assign":"jzTFF","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hp9Zv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _finally = require("./finally");
var _finallyDefault = parcelHelpers.interopDefault(_finally);
var _allSettled = require("./allSettled");
var _allSettledDefault = parcelHelpers.interopDefault(_allSettled);
// Store setTimeout reference so promise-polyfill will be unaffected by
// other code modifying setTimeout (like sinon.useFakeTimers())
var setTimeoutFunc = setTimeout;
function isArray(x) {
    return Boolean(x && typeof x.length !== 'undefined');
}
function noop() {
}
// Polyfill for Function.prototype.bind
function bind(fn, thisArg) {
    return function() {
        fn.apply(thisArg, arguments);
    };
}
/**
 * @constructor
 * @param {Function} fn
 */ function Promise1(fn) {
    if (!(this instanceof Promise1)) throw new TypeError('Promises must be constructed via new');
    if (typeof fn !== 'function') throw new TypeError('not a function');
    /** @type {!number} */ this._state = 0;
    /** @type {!boolean} */ this._handled = false;
    /** @type {Promise|undefined} */ this._value = undefined;
    /** @type {!Array<!Function>} */ this._deferreds = [];
    doResolve(fn, this);
}
function handle(self, deferred) {
    while(self._state === 3)self = self._value;
    if (self._state === 0) {
        self._deferreds.push(deferred);
        return;
    }
    self._handled = true;
    Promise1._immediateFn(function() {
        var cb = self._state === 1 ? deferred.onFulfilled : deferred.onRejected;
        if (cb === null) {
            (self._state === 1 ? resolve : reject)(deferred.promise, self._value);
            return;
        }
        var ret;
        try {
            ret = cb(self._value);
        } catch (e) {
            reject(deferred.promise, e);
            return;
        }
        resolve(deferred.promise, ret);
    });
}
function resolve(self, newValue) {
    try {
        // Promise Resolution Procedure: https://github.com/promises-aplus/promises-spec#the-promise-resolution-procedure
        if (newValue === self) throw new TypeError('A promise cannot be resolved with itself.');
        if (newValue && (typeof newValue === 'object' || typeof newValue === 'function')) {
            var then = newValue.then;
            if (newValue instanceof Promise1) {
                self._state = 3;
                self._value = newValue;
                finale(self);
                return;
            } else if (typeof then === 'function') {
                doResolve(bind(then, newValue), self);
                return;
            }
        }
        self._state = 1;
        self._value = newValue;
        finale(self);
    } catch (e) {
        reject(self, e);
    }
}
function reject(self, newValue) {
    self._state = 2;
    self._value = newValue;
    finale(self);
}
function finale(self) {
    if (self._state === 2 && self._deferreds.length === 0) Promise1._immediateFn(function() {
        if (!self._handled) Promise1._unhandledRejectionFn(self._value);
    });
    for(var i = 0, len = self._deferreds.length; i < len; i++)handle(self, self._deferreds[i]);
    self._deferreds = null;
}
/**
 * @constructor
 */ function Handler(onFulfilled, onRejected, promise) {
    this.onFulfilled = typeof onFulfilled === 'function' ? onFulfilled : null;
    this.onRejected = typeof onRejected === 'function' ? onRejected : null;
    this.promise = promise;
}
/**
 * Take a potentially misbehaving resolver function and make sure
 * onFulfilled and onRejected are only called once.
 *
 * Makes no guarantees about asynchrony.
 */ function doResolve(fn, self) {
    var done = false;
    try {
        fn(function(value) {
            if (done) return;
            done = true;
            resolve(self, value);
        }, function(reason) {
            if (done) return;
            done = true;
            reject(self, reason);
        });
    } catch (ex) {
        if (done) return;
        done = true;
        reject(self, ex);
    }
}
Promise1.prototype['catch'] = function(onRejected) {
    return this.then(null, onRejected);
};
Promise1.prototype.then = function(onFulfilled, onRejected) {
    // @ts-ignore
    var prom = new this.constructor(noop);
    handle(this, new Handler(onFulfilled, onRejected, prom));
    return prom;
};
Promise1.prototype['finally'] = _finallyDefault.default;
Promise1.all = function(arr) {
    return new Promise1(function(resolve1, reject1) {
        if (!isArray(arr)) return reject1(new TypeError('Promise.all accepts an array'));
        var args = Array.prototype.slice.call(arr);
        if (args.length === 0) return resolve1([]);
        var remaining = args.length;
        function res(i, val) {
            try {
                if (val && (typeof val === 'object' || typeof val === 'function')) {
                    var then = val.then;
                    if (typeof then === 'function') {
                        then.call(val, function(val1) {
                            res(i, val1);
                        }, reject1);
                        return;
                    }
                }
                args[i] = val;
                if ((--remaining) === 0) resolve1(args);
            } catch (ex) {
                reject1(ex);
            }
        }
        for(var i = 0; i < args.length; i++)res(i, args[i]);
    });
};
Promise1.allSettled = _allSettledDefault.default;
Promise1.resolve = function(value) {
    if (value && typeof value === 'object' && value.constructor === Promise1) return value;
    return new Promise1(function(resolve1) {
        resolve1(value);
    });
};
Promise1.reject = function(value) {
    return new Promise1(function(resolve1, reject1) {
        reject1(value);
    });
};
Promise1.race = function(arr) {
    return new Promise1(function(resolve1, reject1) {
        if (!isArray(arr)) return reject1(new TypeError('Promise.race accepts an array'));
        for(var i = 0, len = arr.length; i < len; i++)Promise1.resolve(arr[i]).then(resolve1, reject1);
    });
};
// Use polyfill for setImmediate for performance gains
Promise1._immediateFn = // @ts-ignore
typeof setImmediate === 'function' && function(fn) {
    // @ts-ignore
    setImmediate(fn);
} || function(fn) {
    setTimeoutFunc(fn, 0);
};
Promise1._unhandledRejectionFn = function _unhandledRejectionFn(err) {
    if (typeof console !== 'undefined' && console) console.warn('Possible Unhandled Promise Rejection:', err); // eslint-disable-line no-console
};
exports.default = Promise1;

},{"./finally":"ia9dJ","./allSettled":"32hJP","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ia9dJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * @this {Promise}
 */ function finallyConstructor(callback) {
    var constructor = this.constructor;
    return this.then(function(value) {
        // @ts-ignore
        return constructor.resolve(callback()).then(function() {
            return value;
        });
    }, function(reason) {
        // @ts-ignore
        return constructor.resolve(callback()).then(function() {
            // @ts-ignore
            return constructor.reject(reason);
        });
    });
}
exports.default = finallyConstructor;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3feM1":[function(require,module,exports) {
exports.interopDefault = function(a) {
    return a && a.__esModule ? a : {
        default: a
    };
};
exports.defineInteropFlag = function(a) {
    Object.defineProperty(a, '__esModule', {
        value: true
    });
};
exports.exportAll = function(source, dest) {
    Object.keys(source).forEach(function(key) {
        if (key === 'default' || key === '__esModule') return;
        // Skip duplicate re-exports when they have the same value.
        if (key in dest && dest[key] === source[key]) return;
        Object.defineProperty(dest, key, {
            enumerable: true,
            get: function() {
                return source[key];
            }
        });
    });
    return dest;
};
exports.export = function(dest, destName, get) {
    Object.defineProperty(dest, destName, {
        enumerable: true,
        get: get
    });
};

},{}],"32hJP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
function allSettled(arr) {
    var P = this;
    return new P(function(resolve, reject) {
        if (!(arr && typeof arr.length !== 'undefined')) return reject(new TypeError(typeof arr + ' ' + arr + ' is not iterable(cannot read property Symbol(Symbol.iterator))'));
        var args = Array.prototype.slice.call(arr);
        if (args.length === 0) return resolve([]);
        var remaining = args.length;
        function res(i, val) {
            if (val && (typeof val === 'object' || typeof val === 'function')) {
                var then = val.then;
                if (typeof then === 'function') {
                    then.call(val, function(val1) {
                        res(i, val1);
                    }, function(e) {
                        args[i] = {
                            status: 'rejected',
                            reason: e
                        };
                        if ((--remaining) === 0) resolve(args);
                    });
                    return;
                }
            }
            args[i] = {
                status: 'fulfilled',
                value: val
            };
            if ((--remaining) === 0) resolve(args);
        }
        for(var i = 0; i < args.length; i++)res(i, args[i]);
    });
}
exports.default = allSettled;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jzTFF":[function(require,module,exports) {
/*
object-assign
(c) Sindre Sorhus
@license MIT
*/ 'use strict';
/* eslint-disable no-unused-vars */ var getOwnPropertySymbols = Object.getOwnPropertySymbols;
var hasOwnProperty = Object.prototype.hasOwnProperty;
var propIsEnumerable = Object.prototype.propertyIsEnumerable;
function toObject(val) {
    if (val === null || val === undefined) throw new TypeError('Object.assign cannot be called with null or undefined');
    return Object(val);
}
function shouldUseNative() {
    try {
        if (!Object.assign) return false;
        // Detect buggy property enumeration order in older V8 versions.
        // https://bugs.chromium.org/p/v8/issues/detail?id=4118
        var test1 = "abc"; // eslint-disable-line no-new-wrappers
        test1[5] = 'de';
        if (Object.getOwnPropertyNames(test1)[0] === '5') return false;
        // https://bugs.chromium.org/p/v8/issues/detail?id=3056
        var test2 = {
        };
        for(var i = 0; i < 10; i++)test2['_' + String.fromCharCode(i)] = i;
        var order2 = Object.getOwnPropertyNames(test2).map(function(n) {
            return test2[n];
        });
        if (order2.join('') !== '0123456789') return false;
        // https://bugs.chromium.org/p/v8/issues/detail?id=3056
        var test3 = {
        };
        'abcdefghijklmnopqrst'.split('').forEach(function(letter) {
            test3[letter] = letter;
        });
        if (Object.keys(Object.assign({
        }, test3)).join('') !== 'abcdefghijklmnopqrst') return false;
        return true;
    } catch (err) {
        // We don't expect any of the above to throw, but better to be safe.
        return false;
    }
}
module.exports = shouldUseNative() ? Object.assign : function(target, source) {
    var from;
    var to = toObject(target);
    var symbols;
    for(var s = 1; s < arguments.length; s++){
        from = Object(arguments[s]);
        for(var key in from)if (hasOwnProperty.call(from, key)) to[key] = from[key];
        if (getOwnPropertySymbols) {
            symbols = getOwnPropertySymbols(from);
            for(var i = 0; i < symbols.length; i++)if (propIsEnumerable.call(from, symbols[i])) to[symbols[i]] = from[symbols[i]];
        }
    }
    return to;
};

},{}],"joR65":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isMobile", ()=>_settings.isMobile
);
parcelHelpers.export(exports, "EventEmitter", ()=>_eventemitter3Default.default
);
parcelHelpers.export(exports, "earcut", ()=>_earcutDefault.default
);
parcelHelpers.export(exports, "BaseTextureCache", ()=>BaseTextureCache
);
parcelHelpers.export(exports, "CanvasRenderTarget", ()=>CanvasRenderTarget
);
parcelHelpers.export(exports, "DATA_URI", ()=>DATA_URI
);
parcelHelpers.export(exports, "ProgramCache", ()=>ProgramCache
);
parcelHelpers.export(exports, "TextureCache", ()=>TextureCache
);
parcelHelpers.export(exports, "clearTextureCache", ()=>clearTextureCache
);
parcelHelpers.export(exports, "correctBlendMode", ()=>correctBlendMode
);
parcelHelpers.export(exports, "createIndicesForQuads", ()=>createIndicesForQuads
);
parcelHelpers.export(exports, "decomposeDataUri", ()=>decomposeDataUri
);
parcelHelpers.export(exports, "deprecation", ()=>deprecation
);
parcelHelpers.export(exports, "destroyTextureCache", ()=>destroyTextureCache
);
parcelHelpers.export(exports, "determineCrossOrigin", ()=>determineCrossOrigin
);
parcelHelpers.export(exports, "getBufferType", ()=>getBufferType
);
parcelHelpers.export(exports, "getResolutionOfUrl", ()=>getResolutionOfUrl
);
parcelHelpers.export(exports, "hex2rgb", ()=>hex2rgb
);
parcelHelpers.export(exports, "hex2string", ()=>hex2string
);
parcelHelpers.export(exports, "interleaveTypedArrays", ()=>interleaveTypedArrays
);
parcelHelpers.export(exports, "isPow2", ()=>isPow2
);
parcelHelpers.export(exports, "isWebGLSupported", ()=>isWebGLSupported
);
parcelHelpers.export(exports, "log2", ()=>log2
);
parcelHelpers.export(exports, "nextPow2", ()=>nextPow2
);
parcelHelpers.export(exports, "premultiplyBlendMode", ()=>premultiplyBlendMode
);
parcelHelpers.export(exports, "premultiplyRgba", ()=>premultiplyRgba
);
parcelHelpers.export(exports, "premultiplyTint", ()=>premultiplyTint
);
parcelHelpers.export(exports, "premultiplyTintToRgba", ()=>premultiplyTintToRgba
);
parcelHelpers.export(exports, "removeItems", ()=>removeItems
);
parcelHelpers.export(exports, "rgb2hex", ()=>rgb2hex
);
parcelHelpers.export(exports, "sayHello", ()=>sayHello
);
parcelHelpers.export(exports, "sign", ()=>sign
);
parcelHelpers.export(exports, "skipHello", ()=>skipHello
);
parcelHelpers.export(exports, "string2hex", ()=>string2hex
);
parcelHelpers.export(exports, "trimCanvas", ()=>trimCanvas
);
parcelHelpers.export(exports, "uid", ()=>uid
);
parcelHelpers.export(exports, "url", ()=>url
);
/*!
 * @pixi/utils - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/utils is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _settings = require("@pixi/settings");
var _url = require("url");
var _constants = require("@pixi/constants");
var _eventemitter3 = require("eventemitter3");
var _eventemitter3Default = parcelHelpers.interopDefault(_eventemitter3);
var _earcut = require("earcut");
var _earcutDefault = parcelHelpers.interopDefault(_earcut);
/**
 * This file contains redeclared types for Node `url` and `querystring` modules. These modules
 * don't provide their own typings but instead are a part of the full Node typings. The purpose of
 * this file is to redeclare the required types to avoid having the whole Node types as a
 * dependency.
 */ var url = {
    parse: _url.parse,
    format: _url.format,
    resolve: _url.resolve
};
/**
 * The prefix that denotes a URL is for a retina asset.
 *
 * @static
 * @name RETINA_PREFIX
 * @memberof PIXI.settings
 * @type {RegExp}
 * @default /@([0-9\.]+)x/
 * @example `@2x`
 */ _settings.settings.RETINA_PREFIX = /@([0-9\.]+)x/;
/**
 * Should the `failIfMajorPerformanceCaveat` flag be enabled as a context option used in the `isWebGLSupported` function.
 * If set to true, a WebGL renderer can fail to be created if the browser thinks there could be performance issues when
 * using WebGL.
 *
 * In PixiJS v6 this has changed from true to false by default, to allow WebGL to work in as many scenarios as possible.
 * However, some users may have a poor experience, for example, if a user has a gpu or driver version blacklisted by the
 * browser.
 *
 * If your application requires high performance rendering, you may wish to set this to false.
 * We recommend one of two options if you decide to set this flag to false:
 *
 * 1: Use the `pixi.js-legacy` package, which includes a Canvas renderer as a fallback in case high performance WebGL is
 *    not supported.
 *
 * 2: Call `isWebGLSupported` (which if found in the PIXI.utils package) in your code before attempting to create a PixiJS
 *    renderer, and show an error message to the user if the function returns false, explaining that their device & browser
 *    combination does not support high performance WebGL.
 *    This is a much better strategy than trying to create a PixiJS renderer and finding it then fails.
 *
 * @static
 * @name FAIL_IF_MAJOR_PERFORMANCE_CAVEAT
 * @memberof PIXI.settings
 * @type {boolean}
 * @default false
 */ _settings.settings.FAIL_IF_MAJOR_PERFORMANCE_CAVEAT = false;
var saidHello = false;
var VERSION = '6.1.3';
/**
 * Skips the hello message of renderers that are created after this is run.
 *
 * @function skipHello
 * @memberof PIXI.utils
 */ function skipHello() {
    saidHello = true;
}
/**
 * Logs out the version and renderer information for this running instance of PIXI.
 * If you don't want to see this message you can run `PIXI.utils.skipHello()` before
 * creating your renderer. Keep in mind that doing that will forever make you a jerk face.
 *
 * @static
 * @function sayHello
 * @memberof PIXI.utils
 * @param {string} type - The string renderer type to log.
 */ function sayHello(type) {
    var _a;
    if (saidHello) return;
    if (navigator.userAgent.toLowerCase().indexOf('chrome') > -1) {
        var args = [
            "\n %c %c %c PixiJS " + VERSION + " - \u2730 " + type + " \u2730  %c  %c  http://www.pixijs.com/  %c %c \u2665%c\u2665%c\u2665 \n\n",
            'background: #ff66a5; padding:5px 0;',
            'background: #ff66a5; padding:5px 0;',
            'color: #ff66a5; background: #030307; padding:5px 0;',
            'background: #ff66a5; padding:5px 0;',
            'background: #ffc3dc; padding:5px 0;',
            'background: #ff66a5; padding:5px 0;',
            'color: #ff2424; background: #fff; padding:5px 0;',
            'color: #ff2424; background: #fff; padding:5px 0;',
            'color: #ff2424; background: #fff; padding:5px 0;'
        ];
        (_a = self.console).log.apply(_a, args);
    } else if (self.console) self.console.log("PixiJS " + VERSION + " - " + type + " - http://www.pixijs.com/");
    saidHello = true;
}
var supported;
/**
 * Helper for checking for WebGL support.
 *
 * @memberof PIXI.utils
 * @function isWebGLSupported
 * @return {boolean} Is WebGL supported.
 */ function isWebGLSupported() {
    if (typeof supported === 'undefined') supported = (function supported1() {
        var contextOptions = {
            stencil: true,
            failIfMajorPerformanceCaveat: _settings.settings.FAIL_IF_MAJOR_PERFORMANCE_CAVEAT
        };
        try {
            if (!self.WebGLRenderingContext) return false;
            var canvas = document.createElement('canvas');
            var gl = canvas.getContext('webgl', contextOptions) || canvas.getContext('experimental-webgl', contextOptions);
            var success = !!(gl && gl.getContextAttributes().stencil);
            if (gl) {
                var loseContext = gl.getExtension('WEBGL_lose_context');
                if (loseContext) loseContext.loseContext();
            }
            gl = null;
            return success;
        } catch (e) {
            return false;
        }
    })();
    return supported;
}
var aliceblue = "#f0f8ff";
var antiquewhite = "#faebd7";
var aqua = "#00ffff";
var aquamarine = "#7fffd4";
var azure = "#f0ffff";
var beige = "#f5f5dc";
var bisque = "#ffe4c4";
var black = "#000000";
var blanchedalmond = "#ffebcd";
var blue = "#0000ff";
var blueviolet = "#8a2be2";
var brown = "#a52a2a";
var burlywood = "#deb887";
var cadetblue = "#5f9ea0";
var chartreuse = "#7fff00";
var chocolate = "#d2691e";
var coral = "#ff7f50";
var cornflowerblue = "#6495ed";
var cornsilk = "#fff8dc";
var crimson = "#dc143c";
var cyan = "#00ffff";
var darkblue = "#00008b";
var darkcyan = "#008b8b";
var darkgoldenrod = "#b8860b";
var darkgray = "#a9a9a9";
var darkgreen = "#006400";
var darkgrey = "#a9a9a9";
var darkkhaki = "#bdb76b";
var darkmagenta = "#8b008b";
var darkolivegreen = "#556b2f";
var darkorange = "#ff8c00";
var darkorchid = "#9932cc";
var darkred = "#8b0000";
var darksalmon = "#e9967a";
var darkseagreen = "#8fbc8f";
var darkslateblue = "#483d8b";
var darkslategray = "#2f4f4f";
var darkslategrey = "#2f4f4f";
var darkturquoise = "#00ced1";
var darkviolet = "#9400d3";
var deeppink = "#ff1493";
var deepskyblue = "#00bfff";
var dimgray = "#696969";
var dimgrey = "#696969";
var dodgerblue = "#1e90ff";
var firebrick = "#b22222";
var floralwhite = "#fffaf0";
var forestgreen = "#228b22";
var fuchsia = "#ff00ff";
var gainsboro = "#dcdcdc";
var ghostwhite = "#f8f8ff";
var goldenrod = "#daa520";
var gold = "#ffd700";
var gray = "#808080";
var green = "#008000";
var greenyellow = "#adff2f";
var grey = "#808080";
var honeydew = "#f0fff0";
var hotpink = "#ff69b4";
var indianred = "#cd5c5c";
var indigo = "#4b0082";
var ivory = "#fffff0";
var khaki = "#f0e68c";
var lavenderblush = "#fff0f5";
var lavender = "#e6e6fa";
var lawngreen = "#7cfc00";
var lemonchiffon = "#fffacd";
var lightblue = "#add8e6";
var lightcoral = "#f08080";
var lightcyan = "#e0ffff";
var lightgoldenrodyellow = "#fafad2";
var lightgray = "#d3d3d3";
var lightgreen = "#90ee90";
var lightgrey = "#d3d3d3";
var lightpink = "#ffb6c1";
var lightsalmon = "#ffa07a";
var lightseagreen = "#20b2aa";
var lightskyblue = "#87cefa";
var lightslategray = "#778899";
var lightslategrey = "#778899";
var lightsteelblue = "#b0c4de";
var lightyellow = "#ffffe0";
var lime = "#00ff00";
var limegreen = "#32cd32";
var linen = "#faf0e6";
var magenta = "#ff00ff";
var maroon = "#800000";
var mediumaquamarine = "#66cdaa";
var mediumblue = "#0000cd";
var mediumorchid = "#ba55d3";
var mediumpurple = "#9370db";
var mediumseagreen = "#3cb371";
var mediumslateblue = "#7b68ee";
var mediumspringgreen = "#00fa9a";
var mediumturquoise = "#48d1cc";
var mediumvioletred = "#c71585";
var midnightblue = "#191970";
var mintcream = "#f5fffa";
var mistyrose = "#ffe4e1";
var moccasin = "#ffe4b5";
var navajowhite = "#ffdead";
var navy = "#000080";
var oldlace = "#fdf5e6";
var olive = "#808000";
var olivedrab = "#6b8e23";
var orange = "#ffa500";
var orangered = "#ff4500";
var orchid = "#da70d6";
var palegoldenrod = "#eee8aa";
var palegreen = "#98fb98";
var paleturquoise = "#afeeee";
var palevioletred = "#db7093";
var papayawhip = "#ffefd5";
var peachpuff = "#ffdab9";
var peru = "#cd853f";
var pink = "#ffc0cb";
var plum = "#dda0dd";
var powderblue = "#b0e0e6";
var purple = "#800080";
var rebeccapurple = "#663399";
var red = "#ff0000";
var rosybrown = "#bc8f8f";
var royalblue = "#4169e1";
var saddlebrown = "#8b4513";
var salmon = "#fa8072";
var sandybrown = "#f4a460";
var seagreen = "#2e8b57";
var seashell = "#fff5ee";
var sienna = "#a0522d";
var silver = "#c0c0c0";
var skyblue = "#87ceeb";
var slateblue = "#6a5acd";
var slategray = "#708090";
var slategrey = "#708090";
var snow = "#fffafa";
var springgreen = "#00ff7f";
var steelblue = "#4682b4";
var tan = "#d2b48c";
var teal = "#008080";
var thistle = "#d8bfd8";
var tomato = "#ff6347";
var turquoise = "#40e0d0";
var violet = "#ee82ee";
var wheat = "#f5deb3";
var white = "#ffffff";
var whitesmoke = "#f5f5f5";
var yellow = "#ffff00";
var yellowgreen = "#9acd32";
var cssColorNames = {
    aliceblue: aliceblue,
    antiquewhite: antiquewhite,
    aqua: aqua,
    aquamarine: aquamarine,
    azure: azure,
    beige: beige,
    bisque: bisque,
    black: black,
    blanchedalmond: blanchedalmond,
    blue: blue,
    blueviolet: blueviolet,
    brown: brown,
    burlywood: burlywood,
    cadetblue: cadetblue,
    chartreuse: chartreuse,
    chocolate: chocolate,
    coral: coral,
    cornflowerblue: cornflowerblue,
    cornsilk: cornsilk,
    crimson: crimson,
    cyan: cyan,
    darkblue: darkblue,
    darkcyan: darkcyan,
    darkgoldenrod: darkgoldenrod,
    darkgray: darkgray,
    darkgreen: darkgreen,
    darkgrey: darkgrey,
    darkkhaki: darkkhaki,
    darkmagenta: darkmagenta,
    darkolivegreen: darkolivegreen,
    darkorange: darkorange,
    darkorchid: darkorchid,
    darkred: darkred,
    darksalmon: darksalmon,
    darkseagreen: darkseagreen,
    darkslateblue: darkslateblue,
    darkslategray: darkslategray,
    darkslategrey: darkslategrey,
    darkturquoise: darkturquoise,
    darkviolet: darkviolet,
    deeppink: deeppink,
    deepskyblue: deepskyblue,
    dimgray: dimgray,
    dimgrey: dimgrey,
    dodgerblue: dodgerblue,
    firebrick: firebrick,
    floralwhite: floralwhite,
    forestgreen: forestgreen,
    fuchsia: fuchsia,
    gainsboro: gainsboro,
    ghostwhite: ghostwhite,
    goldenrod: goldenrod,
    gold: gold,
    gray: gray,
    green: green,
    greenyellow: greenyellow,
    grey: grey,
    honeydew: honeydew,
    hotpink: hotpink,
    indianred: indianred,
    indigo: indigo,
    ivory: ivory,
    khaki: khaki,
    lavenderblush: lavenderblush,
    lavender: lavender,
    lawngreen: lawngreen,
    lemonchiffon: lemonchiffon,
    lightblue: lightblue,
    lightcoral: lightcoral,
    lightcyan: lightcyan,
    lightgoldenrodyellow: lightgoldenrodyellow,
    lightgray: lightgray,
    lightgreen: lightgreen,
    lightgrey: lightgrey,
    lightpink: lightpink,
    lightsalmon: lightsalmon,
    lightseagreen: lightseagreen,
    lightskyblue: lightskyblue,
    lightslategray: lightslategray,
    lightslategrey: lightslategrey,
    lightsteelblue: lightsteelblue,
    lightyellow: lightyellow,
    lime: lime,
    limegreen: limegreen,
    linen: linen,
    magenta: magenta,
    maroon: maroon,
    mediumaquamarine: mediumaquamarine,
    mediumblue: mediumblue,
    mediumorchid: mediumorchid,
    mediumpurple: mediumpurple,
    mediumseagreen: mediumseagreen,
    mediumslateblue: mediumslateblue,
    mediumspringgreen: mediumspringgreen,
    mediumturquoise: mediumturquoise,
    mediumvioletred: mediumvioletred,
    midnightblue: midnightblue,
    mintcream: mintcream,
    mistyrose: mistyrose,
    moccasin: moccasin,
    navajowhite: navajowhite,
    navy: navy,
    oldlace: oldlace,
    olive: olive,
    olivedrab: olivedrab,
    orange: orange,
    orangered: orangered,
    orchid: orchid,
    palegoldenrod: palegoldenrod,
    palegreen: palegreen,
    paleturquoise: paleturquoise,
    palevioletred: palevioletred,
    papayawhip: papayawhip,
    peachpuff: peachpuff,
    peru: peru,
    pink: pink,
    plum: plum,
    powderblue: powderblue,
    purple: purple,
    rebeccapurple: rebeccapurple,
    red: red,
    rosybrown: rosybrown,
    royalblue: royalblue,
    saddlebrown: saddlebrown,
    salmon: salmon,
    sandybrown: sandybrown,
    seagreen: seagreen,
    seashell: seashell,
    sienna: sienna,
    silver: silver,
    skyblue: skyblue,
    slateblue: slateblue,
    slategray: slategray,
    slategrey: slategrey,
    snow: snow,
    springgreen: springgreen,
    steelblue: steelblue,
    tan: tan,
    teal: teal,
    thistle: thistle,
    tomato: tomato,
    turquoise: turquoise,
    violet: violet,
    wheat: wheat,
    white: white,
    whitesmoke: whitesmoke,
    yellow: yellow,
    yellowgreen: yellowgreen
};
/**
 * Converts a hexadecimal color number to an [R, G, B] array of normalized floats (numbers from 0.0 to 1.0).
 *
 * @example
 * PIXI.utils.hex2rgb(0xffffff); // returns [1, 1, 1]
 * @memberof PIXI.utils
 * @function hex2rgb
 * @param {number} hex - The hexadecimal number to convert
 * @param  {number[]} [out=[]] - If supplied, this array will be used rather than returning a new one
 * @return {number[]} An array representing the [R, G, B] of the color where all values are floats.
 */ function hex2rgb(hex, out) {
    if (out === void 0) out = [];
    out[0] = (hex >> 16 & 255) / 255;
    out[1] = (hex >> 8 & 255) / 255;
    out[2] = (hex & 255) / 255;
    return out;
}
/**
 * Converts a hexadecimal color number to a string.
 *
 * @example
 * PIXI.utils.hex2string(0xffffff); // returns "#ffffff"
 * @memberof PIXI.utils
 * @function hex2string
 * @param {number} hex - Number in hex (e.g., `0xffffff`)
 * @return {string} The string color (e.g., `"#ffffff"`).
 */ function hex2string(hex) {
    var hexString = hex.toString(16);
    hexString = '000000'.substr(0, 6 - hexString.length) + hexString;
    return "#" + hexString;
}
/**
 * Converts a string to a hexadecimal color number.
 * It can handle:
 *  hex strings starting with #: "#ffffff"
 *  hex strings starting with 0x: "0xffffff"
 *  hex strings without prefix: "ffffff"
 *  css colors: "black"
 *
 * @example
 * PIXI.utils.string2hex("#ffffff"); // returns 0xffffff
 * @memberof PIXI.utils
 * @function string2hex
 * @param {string} string - The string color (e.g., `"#ffffff"`)
 * @return {number} Number in hexadecimal.
 */ function string2hex(string) {
    if (typeof string === 'string') {
        string = cssColorNames[string.toLowerCase()] || string;
        if (string[0] === '#') string = string.substr(1);
    }
    return parseInt(string, 16);
}
/**
 * Converts a color as an [R, G, B] array of normalized floats to a hexadecimal number.
 *
 * @example
 * PIXI.utils.rgb2hex([1, 1, 1]); // returns 0xffffff
 * @memberof PIXI.utils
 * @function rgb2hex
 * @param {number[]} rgb - Array of numbers where all values are normalized floats from 0.0 to 1.0.
 * @return {number} Number in hexadecimal.
 */ function rgb2hex(rgb) {
    return (rgb[0] * 255 << 16) + (rgb[1] * 255 << 8) + (rgb[2] * 255 | 0);
}
/**
 * Corrects PixiJS blend, takes premultiplied alpha into account
 *
 * @memberof PIXI.utils
 * @function mapPremultipliedBlendModes
 * @private
 * @return {Array<number[]>} Mapped modes.
 */ function mapPremultipliedBlendModes() {
    var pm = [];
    var npm = [];
    for(var i = 0; i < 32; i++){
        pm[i] = i;
        npm[i] = i;
    }
    pm[_constants.BLEND_MODES.NORMAL_NPM] = _constants.BLEND_MODES.NORMAL;
    pm[_constants.BLEND_MODES.ADD_NPM] = _constants.BLEND_MODES.ADD;
    pm[_constants.BLEND_MODES.SCREEN_NPM] = _constants.BLEND_MODES.SCREEN;
    npm[_constants.BLEND_MODES.NORMAL] = _constants.BLEND_MODES.NORMAL_NPM;
    npm[_constants.BLEND_MODES.ADD] = _constants.BLEND_MODES.ADD_NPM;
    npm[_constants.BLEND_MODES.SCREEN] = _constants.BLEND_MODES.SCREEN_NPM;
    var array = [];
    array.push(npm);
    array.push(pm);
    return array;
}
/**
 * maps premultiply flag and blendMode to adjusted blendMode
 * @memberof PIXI.utils
 * @const premultiplyBlendMode
 * @type {Array<number[]>}
 */ var premultiplyBlendMode = mapPremultipliedBlendModes();
/**
 * changes blendMode according to texture format
 *
 * @memberof PIXI.utils
 * @function correctBlendMode
 * @param {number} blendMode - supposed blend mode
 * @param {boolean} premultiplied - whether source is premultiplied
 * @returns {number} true blend mode for this texture
 */ function correctBlendMode(blendMode, premultiplied) {
    return premultiplyBlendMode[premultiplied ? 1 : 0][blendMode];
}
/**
 * combines rgb and alpha to out array
 *
 * @memberof PIXI.utils
 * @function premultiplyRgba
 * @param {Float32Array|number[]} rgb - input rgb
 * @param {number} alpha - alpha param
 * @param {Float32Array} [out] - output
 * @param {boolean} [premultiply=true] - do premultiply it
 * @returns {Float32Array} vec4 rgba
 */ function premultiplyRgba(rgb, alpha, out, premultiply) {
    out = out || new Float32Array(4);
    if (premultiply || premultiply === undefined) {
        out[0] = rgb[0] * alpha;
        out[1] = rgb[1] * alpha;
        out[2] = rgb[2] * alpha;
    } else {
        out[0] = rgb[0];
        out[1] = rgb[1];
        out[2] = rgb[2];
    }
    out[3] = alpha;
    return out;
}
/**
 * premultiplies tint
 *
 * @memberof PIXI.utils
 * @function premultiplyTint
 * @param {number} tint - integer RGB
 * @param {number} alpha - floating point alpha (0.0-1.0)
 * @returns {number} tint multiplied by alpha
 */ function premultiplyTint(tint, alpha) {
    if (alpha === 1) return (alpha * 255 << 24) + tint;
    if (alpha === 0) return 0;
    var R = tint >> 16 & 255;
    var G = tint >> 8 & 255;
    var B = tint & 255;
    R = R * alpha + 0.5 | 0;
    G = G * alpha + 0.5 | 0;
    B = B * alpha + 0.5 | 0;
    return (alpha * 255 << 24) + (R << 16) + (G << 8) + B;
}
/**
 * converts integer tint and float alpha to vec4 form, premultiplies by default
 *
 * @memberof PIXI.utils
 * @function premultiplyTintToRgba
 * @param {number} tint - input tint
 * @param {number} alpha - alpha param
 * @param {Float32Array} [out] - output
 * @param {boolean} [premultiply=true] - do premultiply it
 * @returns {Float32Array} vec4 rgba
 */ function premultiplyTintToRgba(tint, alpha, out, premultiply) {
    out = out || new Float32Array(4);
    out[0] = (tint >> 16 & 255) / 255;
    out[1] = (tint >> 8 & 255) / 255;
    out[2] = (tint & 255) / 255;
    if (premultiply || premultiply === undefined) {
        out[0] *= alpha;
        out[1] *= alpha;
        out[2] *= alpha;
    }
    out[3] = alpha;
    return out;
}
/**
 * Generic Mask Stack data structure
 *
 * @memberof PIXI.utils
 * @function createIndicesForQuads
 * @param {number} size - Number of quads
 * @param {Uint16Array|Uint32Array} [outBuffer] - Buffer for output, length has to be `6 * size`
 * @return {Uint16Array|Uint32Array} - Resulting index buffer
 */ function createIndicesForQuads(size, outBuffer) {
    if (outBuffer === void 0) outBuffer = null;
    // the total number of indices in our array, there are 6 points per quad.
    var totalIndices = size * 6;
    outBuffer = outBuffer || new Uint16Array(totalIndices);
    if (outBuffer.length !== totalIndices) throw new Error("Out buffer length is incorrect, got " + outBuffer.length + " and expected " + totalIndices);
    // fill the indices with the quads to draw
    for(var i = 0, j = 0; i < totalIndices; i += 6, j += 4){
        outBuffer[i + 0] = j + 0;
        outBuffer[i + 1] = j + 1;
        outBuffer[i + 2] = j + 2;
        outBuffer[i + 3] = j + 0;
        outBuffer[i + 4] = j + 2;
        outBuffer[i + 5] = j + 3;
    }
    return outBuffer;
}
function getBufferType(array) {
    if (array.BYTES_PER_ELEMENT === 4) {
        if (array instanceof Float32Array) return 'Float32Array';
        else if (array instanceof Uint32Array) return 'Uint32Array';
        return 'Int32Array';
    } else if (array.BYTES_PER_ELEMENT === 2) {
        if (array instanceof Uint16Array) return 'Uint16Array';
    } else if (array.BYTES_PER_ELEMENT === 1) {
        if (array instanceof Uint8Array) return 'Uint8Array';
    }
    // TODO map out the rest of the array elements!
    return null;
}
/* eslint-disable object-shorthand */ var map = {
    Float32Array: Float32Array,
    Uint32Array: Uint32Array,
    Int32Array: Int32Array,
    Uint8Array: Uint8Array
};
function interleaveTypedArrays(arrays, sizes) {
    var outSize = 0;
    var stride = 0;
    var views = {
    };
    for(var i = 0; i < arrays.length; i++){
        stride += sizes[i];
        outSize += arrays[i].length;
    }
    var buffer = new ArrayBuffer(outSize * 4);
    var out = null;
    var littleOffset = 0;
    for(var i = 0; i < arrays.length; i++){
        var size = sizes[i];
        var array = arrays[i];
        /*
        @todo This is unsafe casting but consistent with how the code worked previously. Should it stay this way
              or should and `getBufferTypeUnsafe` function be exposed that throws an Error if unsupported type is passed?
         */ var type = getBufferType(array);
        if (!views[type]) views[type] = new map[type](buffer);
        out = views[type];
        for(var j = 0; j < array.length; j++){
            var indexStart = (j / size | 0) * stride + littleOffset;
            var index = j % size;
            out[indexStart + index] = array[j];
        }
        littleOffset += size;
    }
    return new Float32Array(buffer);
}
// Taken from the bit-twiddle package
/**
 * Rounds to next power of two.
 *
 * @function nextPow2
 * @memberof PIXI.utils
 * @param {number} v - input value
 * @return {number}
 */ function nextPow2(v) {
    v += v === 0 ? 1 : 0;
    --v;
    v |= v >>> 1;
    v |= v >>> 2;
    v |= v >>> 4;
    v |= v >>> 8;
    v |= v >>> 16;
    return v + 1;
}
/**
 * Checks if a number is a power of two.
 *
 * @function isPow2
 * @memberof PIXI.utils
 * @param {number} v - input value
 * @return {boolean} `true` if value is power of two
 */ function isPow2(v) {
    return !(v & v - 1) && !!v;
}
/**
 * Computes ceil of log base 2
 *
 * @function log2
 * @memberof PIXI.utils
 * @param {number} v - input value
 * @return {number} logarithm base 2
 */ function log2(v) {
    var r = (v > 65535 ? 1 : 0) << 4;
    v >>>= r;
    var shift = (v > 255 ? 1 : 0) << 3;
    v >>>= shift;
    r |= shift;
    shift = (v > 15 ? 1 : 0) << 2;
    v >>>= shift;
    r |= shift;
    shift = (v > 3 ? 1 : 0) << 1;
    v >>>= shift;
    r |= shift;
    return r | v >> 1;
}
/**
 * Remove items from a javascript array without generating garbage
 *
 * @function removeItems
 * @memberof PIXI.utils
 * @param {Array<any>} arr - Array to remove elements from
 * @param {number} startIdx - starting index
 * @param {number} removeCount - how many to remove
 */ function removeItems(arr, startIdx, removeCount) {
    var length = arr.length;
    var i;
    if (startIdx >= length || removeCount === 0) return;
    removeCount = startIdx + removeCount > length ? length - startIdx : removeCount;
    var len = length - removeCount;
    for(i = startIdx; i < len; ++i)arr[i] = arr[i + removeCount];
    arr.length = len;
}
/**
 * Returns sign of number
 *
 * @memberof PIXI.utils
 * @function sign
 * @param {number} n - the number to check the sign of
 * @returns {number} 0 if `n` is 0, -1 if `n` is negative, 1 if `n` is positive
 */ function sign(n) {
    if (n === 0) return 0;
    return n < 0 ? -1 : 1;
}
var nextUid = 0;
/**
 * Gets the next unique identifier
 *
 * @memberof PIXI.utils
 * @function uid
 * @return {number} The next unique identifier to use.
 */ function uid() {
    return ++nextUid;
}
// A map of warning messages already fired
var warnings = {
};
/**
 * Helper for warning developers about deprecated features & settings.
 * A stack track for warnings is given; useful for tracking-down where
 * deprecated methods/properties/classes are being used within the code.
 *
 * @memberof PIXI.utils
 * @function deprecation
 * @param {string} version - The version where the feature became deprecated
 * @param {string} message - Message should include what is deprecated, where, and the new solution
 * @param {number} [ignoreDepth=3] - The number of steps to ignore at the top of the error stack
 *        this is mostly to ignore internal deprecation calls.
 */ function deprecation(version, message, ignoreDepth) {
    if (ignoreDepth === void 0) ignoreDepth = 3;
    // Ignore duplicat
    if (warnings[message]) return;
    /* eslint-disable no-console */ var stack = new Error().stack;
    // Handle IE < 10 and Safari < 6
    if (typeof stack === 'undefined') console.warn('PixiJS Deprecation Warning: ', message + "\nDeprecated since v" + version);
    else {
        // chop off the stack trace which includes PixiJS internal calls
        stack = stack.split('\n').splice(ignoreDepth).join('\n');
        if (console.groupCollapsed) {
            console.groupCollapsed('%cPixiJS Deprecation Warning: %c%s', 'color:#614108;background:#fffbe6', 'font-weight:normal;color:#614108;background:#fffbe6', message + "\nDeprecated since v" + version);
            console.warn(stack);
            console.groupEnd();
        } else {
            console.warn('PixiJS Deprecation Warning: ', message + "\nDeprecated since v" + version);
            console.warn(stack);
        }
    }
    /* eslint-enable no-console */ warnings[message] = true;
}
/**
 * @todo Describe property usage
 *
 * @static
 * @name ProgramCache
 * @memberof PIXI.utils
 * @type {Object}
 */ var ProgramCache = {
};
/**
 * @todo Describe property usage
 *
 * @static
 * @name TextureCache
 * @memberof PIXI.utils
 * @type {Object}
 */ var TextureCache = Object.create(null);
/**
 * @todo Describe property usage
 *
 * @static
 * @name BaseTextureCache
 * @memberof PIXI.utils
 * @type {Object}
 */ var BaseTextureCache = Object.create(null);
/**
 * Destroys all texture in the cache
 *
 * @memberof PIXI.utils
 * @function destroyTextureCache
 */ function destroyTextureCache() {
    var key;
    for(key in TextureCache)TextureCache[key].destroy();
    for(key in BaseTextureCache)BaseTextureCache[key].destroy();
}
/**
 * Removes all textures from cache, but does not destroy them
 *
 * @memberof PIXI.utils
 * @function clearTextureCache
 */ function clearTextureCache() {
    var key;
    for(key in TextureCache)delete TextureCache[key];
    for(key in BaseTextureCache)delete BaseTextureCache[key];
}
/**
 * Creates a Canvas element of the given size to be used as a target for rendering to.
 *
 * @class
 * @memberof PIXI.utils
 */ var CanvasRenderTarget = function() {
    /**
     * @param width - the width for the newly created canvas
     * @param height - the height for the newly created canvas
     * @param {number} [resolution=PIXI.settings.RESOLUTION] - The resolution / device pixel ratio of the canvas
     */ function CanvasRenderTarget1(width, height, resolution) {
        this.canvas = document.createElement('canvas');
        this.context = this.canvas.getContext('2d');
        this.resolution = resolution || _settings.settings.RESOLUTION;
        this.resize(width, height);
    }
    /**
     * Clears the canvas that was created by the CanvasRenderTarget class.
     *
     * @private
     */ CanvasRenderTarget1.prototype.clear = function() {
        this.context.setTransform(1, 0, 0, 1, 0, 0);
        this.context.clearRect(0, 0, this.canvas.width, this.canvas.height);
    };
    /**
     * Resizes the canvas to the specified width and height.
     *
     * @param desiredWidth - the desired width of the canvas
     * @param desiredHeight - the desired height of the canvas
     */ CanvasRenderTarget1.prototype.resize = function(desiredWidth, desiredHeight) {
        this.canvas.width = Math.round(desiredWidth * this.resolution);
        this.canvas.height = Math.round(desiredHeight * this.resolution);
    };
    /** Destroys this canvas. */ CanvasRenderTarget1.prototype.destroy = function() {
        this.context = null;
        this.canvas = null;
    };
    Object.defineProperty(CanvasRenderTarget1.prototype, "width", {
        /**
         * The width of the canvas buffer in pixels.
         *
         * @member {number}
         */ get: function() {
            return this.canvas.width;
        },
        set: function(val) {
            this.canvas.width = Math.round(val);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(CanvasRenderTarget1.prototype, "height", {
        /**
         * The height of the canvas buffer in pixels.
         *
         * @member {number}
         */ get: function() {
            return this.canvas.height;
        },
        set: function(val) {
            this.canvas.height = Math.round(val);
        },
        enumerable: false,
        configurable: true
    });
    return CanvasRenderTarget1;
}();
/**
 * Trim transparent borders from a canvas
 *
 * @memberof PIXI.utils
 * @function trimCanvas
 * @param {HTMLCanvasElement} canvas - the canvas to trim
 * @returns {object} Trim data
 */ function trimCanvas(canvas) {
    // https://gist.github.com/remy/784508
    var width = canvas.width;
    var height = canvas.height;
    var context = canvas.getContext('2d');
    var imageData = context.getImageData(0, 0, width, height);
    var pixels = imageData.data;
    var len = pixels.length;
    var bound = {
        top: null,
        left: null,
        right: null,
        bottom: null
    };
    var data = null;
    var i;
    var x;
    var y;
    for(i = 0; i < len; i += 4)if (pixels[i + 3] !== 0) {
        x = i / 4 % width;
        y = ~~(i / 4 / width);
        if (bound.top === null) bound.top = y;
        if (bound.left === null) bound.left = x;
        else if (x < bound.left) bound.left = x;
        if (bound.right === null) bound.right = x + 1;
        else if (bound.right < x) bound.right = x + 1;
        if (bound.bottom === null) bound.bottom = y;
        else if (bound.bottom < y) bound.bottom = y;
    }
    if (bound.top !== null) {
        width = bound.right - bound.left;
        height = bound.bottom - bound.top + 1;
        data = context.getImageData(bound.left, bound.top, width, height);
    }
    return {
        height: height,
        width: width,
        data: data
    };
}
/**
 * Regexp for data URI.
 * Based on: {@link https://github.com/ragingwind/data-uri-regex}
 *
 * @static
 * @constant {RegExp|string} DATA_URI
 * @memberof PIXI
 * @example data:image/png;base64
 */ var DATA_URI = /^\s*data:(?:([\w-]+)\/([\w+.-]+))?(?:;charset=([\w-]+))?(?:;(base64))?,(.*)/i;
/**
 * @memberof PIXI.utils
 * @interface DecomposedDataUri
 */ /**
 * type, eg. `image`
 * @memberof PIXI.utils.DecomposedDataUri#
 * @member {string} mediaType
 */ /**
 * Sub type, eg. `png`
 * @memberof PIXI.utils.DecomposedDataUri#
 * @member {string} subType
 */ /**
 * @memberof PIXI.utils.DecomposedDataUri#
 * @member {string} charset
 */ /**
 * Data encoding, eg. `base64`
 * @memberof PIXI.utils.DecomposedDataUri#
 * @member {string} encoding
 */ /**
 * The actual data
 * @memberof PIXI.utils.DecomposedDataUri#
 * @member {string} data
 */ /**
 * Split a data URI into components. Returns undefined if
 * parameter `dataUri` is not a valid data URI.
 *
 * @memberof PIXI.utils
 * @function decomposeDataUri
 * @param {string} dataUri - the data URI to check
 * @return {PIXI.utils.DecomposedDataUri|undefined} The decomposed data uri or undefined
 */ function decomposeDataUri(dataUri) {
    var dataUriMatch = DATA_URI.exec(dataUri);
    if (dataUriMatch) return {
        mediaType: dataUriMatch[1] ? dataUriMatch[1].toLowerCase() : undefined,
        subType: dataUriMatch[2] ? dataUriMatch[2].toLowerCase() : undefined,
        charset: dataUriMatch[3] ? dataUriMatch[3].toLowerCase() : undefined,
        encoding: dataUriMatch[4] ? dataUriMatch[4].toLowerCase() : undefined,
        data: dataUriMatch[5]
    };
    return undefined;
}
var tempAnchor;
/**
 * Sets the `crossOrigin` property for this resource based on if the url
 * for this resource is cross-origin. If crossOrigin was manually set, this
 * function does nothing.
 * Nipped from the resource loader!
 *
 * @ignore
 * @param {string} url - The url to test.
 * @param {object} [loc=window.location] - The location object to test against.
 * @return {string} The crossOrigin value to use (or empty string for none).
 */ function determineCrossOrigin(url$1, loc) {
    if (loc === void 0) loc = self.location;
    // data: and javascript: urls are considered same-origin
    if (url$1.indexOf('data:') === 0) return '';
    // default is window.location
    loc = loc || self.location;
    if (!tempAnchor) tempAnchor = document.createElement('a');
    // let the browser determine the full href for the url of this resource and then
    // parse with the node url lib, we can't use the properties of the anchor element
    // because they don't work in IE9 :(
    tempAnchor.href = url$1;
    var parsedUrl = url.parse(tempAnchor.href);
    var samePort = !parsedUrl.port && loc.port === '' || parsedUrl.port === loc.port;
    // if cross origin
    if (parsedUrl.hostname !== loc.hostname || !samePort || parsedUrl.protocol !== loc.protocol) return 'anonymous';
    return '';
}
/**
 * get the resolution / device pixel ratio of an asset by looking for the prefix
 * used by spritesheets and image urls
 *
 * @memberof PIXI.utils
 * @function getResolutionOfUrl
 * @param {string} url - the image path
 * @param {number} [defaultValue=1] - the defaultValue if no filename prefix is set.
 * @return {number} resolution / device pixel ratio of an asset
 */ function getResolutionOfUrl(url1, defaultValue) {
    var resolution = _settings.settings.RETINA_PREFIX.exec(url1);
    if (resolution) return parseFloat(resolution[1]);
    return defaultValue !== undefined ? defaultValue : 1;
}

},{"@pixi/settings":"habh9","eventemitter3":"gTdcb","earcut":"gwhW7","url":"4B2Rd","@pixi/constants":"lqjFh","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"habh9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isMobile", ()=>isMobile
);
parcelHelpers.export(exports, "settings", ()=>settings
);
/*!
 * @pixi/settings - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/settings is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _ismobilejs = require("ismobilejs");
var _ismobilejsDefault = parcelHelpers.interopDefault(_ismobilejs);
// The ESM/CJS versions of ismobilejs only
var isMobile = _ismobilejsDefault.default(self.navigator);
/**
 * The maximum recommended texture units to use.
 * In theory the bigger the better, and for desktop we'll use as many as we can.
 * But some mobile devices slow down if there is to many branches in the shader.
 * So in practice there seems to be a sweet spot size that varies depending on the device.
 *
 * In v4, all mobile devices were limited to 4 texture units because for this.
 * In v5, we allow all texture units to be used on modern Apple or Android devices.
 *
 * @private
 * @param {number} max
 * @returns {number}
 */ function maxRecommendedTextures(max) {
    var allowMax = true;
    if (isMobile.tablet || isMobile.phone) {
        if (isMobile.apple.device) {
            var match = navigator.userAgent.match(/OS (\d+)_(\d+)?/);
            if (match) {
                var majorVersion = parseInt(match[1], 10);
                // Limit texture units on devices below iOS 11, which will be older hardware
                if (majorVersion < 11) allowMax = false;
            }
        }
        if (isMobile.android.device) {
            var match = navigator.userAgent.match(/Android\s([0-9.]*)/);
            if (match) {
                var majorVersion = parseInt(match[1], 10);
                // Limit texture units on devices below Android 7 (Nougat), which will be older hardware
                if (majorVersion < 7) allowMax = false;
            }
        }
    }
    return allowMax ? max : 4;
}
/**
 * Uploading the same buffer multiple times in a single frame can cause performance issues.
 * Apparent on iOS so only check for that at the moment
 * This check may become more complex if this issue pops up elsewhere.
 *
 * @private
 * @returns {boolean}
 */ function canUploadSameBuffer() {
    return !isMobile.apple.device;
}
/*!
 * @pixi/constants - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/constants is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ /**
 * Different types of environments for WebGL.
 *
 * @static
 * @memberof PIXI
 * @name ENV
 * @enum {number}
 * @property {number} WEBGL_LEGACY - Used for older v1 WebGL devices. PixiJS will aim to ensure compatibility
 *  with older / less advanced devices. If you experience unexplained flickering prefer this environment.
 * @property {number} WEBGL - Version 1 of WebGL
 * @property {number} WEBGL2 - Version 2 of WebGL
 */ var ENV;
(function(ENV1) {
    ENV1[ENV1["WEBGL_LEGACY"] = 0] = "WEBGL_LEGACY";
    ENV1[ENV1["WEBGL"] = 1] = "WEBGL";
    ENV1[ENV1["WEBGL2"] = 2] = "WEBGL2";
})(ENV || (ENV = {
}));
/**
 * Constant to identify the Renderer Type.
 *
 * @static
 * @memberof PIXI
 * @name RENDERER_TYPE
 * @enum {number}
 * @property {number} UNKNOWN - Unknown render type.
 * @property {number} WEBGL - WebGL render type.
 * @property {number} CANVAS - Canvas render type.
 */ var RENDERER_TYPE;
(function(RENDERER_TYPE1) {
    RENDERER_TYPE1[RENDERER_TYPE1["UNKNOWN"] = 0] = "UNKNOWN";
    RENDERER_TYPE1[RENDERER_TYPE1["WEBGL"] = 1] = "WEBGL";
    RENDERER_TYPE1[RENDERER_TYPE1["CANVAS"] = 2] = "CANVAS";
})(RENDERER_TYPE || (RENDERER_TYPE = {
}));
/**
 * Bitwise OR of masks that indicate the buffers to be cleared.
 *
 * @static
 * @memberof PIXI
 * @name BUFFER_BITS
 * @enum {number}
 * @property {number} COLOR - Indicates the buffers currently enabled for color writing.
 * @property {number} DEPTH - Indicates the depth buffer.
 * @property {number} STENCIL - Indicates the stencil buffer.
 */ var BUFFER_BITS;
(function(BUFFER_BITS1) {
    BUFFER_BITS1[BUFFER_BITS1["COLOR"] = 16384] = "COLOR";
    BUFFER_BITS1[BUFFER_BITS1["DEPTH"] = 256] = "DEPTH";
    BUFFER_BITS1[BUFFER_BITS1["STENCIL"] = 1024] = "STENCIL";
})(BUFFER_BITS || (BUFFER_BITS = {
}));
/**
 * Various blend modes supported by PIXI.
 *
 * IMPORTANT - The WebGL renderer only supports the NORMAL, ADD, MULTIPLY and SCREEN blend modes.
 * Anything else will silently act like NORMAL.
 *
 * @memberof PIXI
 * @name BLEND_MODES
 * @enum {number}
 * @property {number} NORMAL
 * @property {number} ADD
 * @property {number} MULTIPLY
 * @property {number} SCREEN
 * @property {number} OVERLAY
 * @property {number} DARKEN
 * @property {number} LIGHTEN
 * @property {number} COLOR_DODGE
 * @property {number} COLOR_BURN
 * @property {number} HARD_LIGHT
 * @property {number} SOFT_LIGHT
 * @property {number} DIFFERENCE
 * @property {number} EXCLUSION
 * @property {number} HUE
 * @property {number} SATURATION
 * @property {number} COLOR
 * @property {number} LUMINOSITY
 * @property {number} NORMAL_NPM
 * @property {number} ADD_NPM
 * @property {number} SCREEN_NPM
 * @property {number} NONE
 * @property {number} SRC_IN
 * @property {number} SRC_OUT
 * @property {number} SRC_ATOP
 * @property {number} DST_OVER
 * @property {number} DST_IN
 * @property {number} DST_OUT
 * @property {number} DST_ATOP
 * @property {number} SUBTRACT
 * @property {number} SRC_OVER
 * @property {number} ERASE
 * @property {number} XOR
 */ var BLEND_MODES;
(function(BLEND_MODES1) {
    BLEND_MODES1[BLEND_MODES1["NORMAL"] = 0] = "NORMAL";
    BLEND_MODES1[BLEND_MODES1["ADD"] = 1] = "ADD";
    BLEND_MODES1[BLEND_MODES1["MULTIPLY"] = 2] = "MULTIPLY";
    BLEND_MODES1[BLEND_MODES1["SCREEN"] = 3] = "SCREEN";
    BLEND_MODES1[BLEND_MODES1["OVERLAY"] = 4] = "OVERLAY";
    BLEND_MODES1[BLEND_MODES1["DARKEN"] = 5] = "DARKEN";
    BLEND_MODES1[BLEND_MODES1["LIGHTEN"] = 6] = "LIGHTEN";
    BLEND_MODES1[BLEND_MODES1["COLOR_DODGE"] = 7] = "COLOR_DODGE";
    BLEND_MODES1[BLEND_MODES1["COLOR_BURN"] = 8] = "COLOR_BURN";
    BLEND_MODES1[BLEND_MODES1["HARD_LIGHT"] = 9] = "HARD_LIGHT";
    BLEND_MODES1[BLEND_MODES1["SOFT_LIGHT"] = 10] = "SOFT_LIGHT";
    BLEND_MODES1[BLEND_MODES1["DIFFERENCE"] = 11] = "DIFFERENCE";
    BLEND_MODES1[BLEND_MODES1["EXCLUSION"] = 12] = "EXCLUSION";
    BLEND_MODES1[BLEND_MODES1["HUE"] = 13] = "HUE";
    BLEND_MODES1[BLEND_MODES1["SATURATION"] = 14] = "SATURATION";
    BLEND_MODES1[BLEND_MODES1["COLOR"] = 15] = "COLOR";
    BLEND_MODES1[BLEND_MODES1["LUMINOSITY"] = 16] = "LUMINOSITY";
    BLEND_MODES1[BLEND_MODES1["NORMAL_NPM"] = 17] = "NORMAL_NPM";
    BLEND_MODES1[BLEND_MODES1["ADD_NPM"] = 18] = "ADD_NPM";
    BLEND_MODES1[BLEND_MODES1["SCREEN_NPM"] = 19] = "SCREEN_NPM";
    BLEND_MODES1[BLEND_MODES1["NONE"] = 20] = "NONE";
    BLEND_MODES1[BLEND_MODES1["SRC_OVER"] = 0] = "SRC_OVER";
    BLEND_MODES1[BLEND_MODES1["SRC_IN"] = 21] = "SRC_IN";
    BLEND_MODES1[BLEND_MODES1["SRC_OUT"] = 22] = "SRC_OUT";
    BLEND_MODES1[BLEND_MODES1["SRC_ATOP"] = 23] = "SRC_ATOP";
    BLEND_MODES1[BLEND_MODES1["DST_OVER"] = 24] = "DST_OVER";
    BLEND_MODES1[BLEND_MODES1["DST_IN"] = 25] = "DST_IN";
    BLEND_MODES1[BLEND_MODES1["DST_OUT"] = 26] = "DST_OUT";
    BLEND_MODES1[BLEND_MODES1["DST_ATOP"] = 27] = "DST_ATOP";
    BLEND_MODES1[BLEND_MODES1["ERASE"] = 26] = "ERASE";
    BLEND_MODES1[BLEND_MODES1["SUBTRACT"] = 28] = "SUBTRACT";
    BLEND_MODES1[BLEND_MODES1["XOR"] = 29] = "XOR";
})(BLEND_MODES || (BLEND_MODES = {
}));
/**
 * Various webgl draw modes. These can be used to specify which GL drawMode to use
 * under certain situations and renderers.
 *
 * @memberof PIXI
 * @static
 * @name DRAW_MODES
 * @enum {number}
 * @property {number} POINTS
 * @property {number} LINES
 * @property {number} LINE_LOOP
 * @property {number} LINE_STRIP
 * @property {number} TRIANGLES
 * @property {number} TRIANGLE_STRIP
 * @property {number} TRIANGLE_FAN
 */ var DRAW_MODES;
(function(DRAW_MODES1) {
    DRAW_MODES1[DRAW_MODES1["POINTS"] = 0] = "POINTS";
    DRAW_MODES1[DRAW_MODES1["LINES"] = 1] = "LINES";
    DRAW_MODES1[DRAW_MODES1["LINE_LOOP"] = 2] = "LINE_LOOP";
    DRAW_MODES1[DRAW_MODES1["LINE_STRIP"] = 3] = "LINE_STRIP";
    DRAW_MODES1[DRAW_MODES1["TRIANGLES"] = 4] = "TRIANGLES";
    DRAW_MODES1[DRAW_MODES1["TRIANGLE_STRIP"] = 5] = "TRIANGLE_STRIP";
    DRAW_MODES1[DRAW_MODES1["TRIANGLE_FAN"] = 6] = "TRIANGLE_FAN";
})(DRAW_MODES || (DRAW_MODES = {
}));
/**
 * Various GL texture/resources formats.
 *
 * @memberof PIXI
 * @static
 * @name FORMATS
 * @enum {number}
 * @property {number} RGBA=6408
 * @property {number} RGB=6407
 * @property {number} RG=33319
 * @property {number} RED=6403
 * @property {number} RGBA_INTEGER=36249
 * @property {number} RGB_INTEGER=36248
 * @property {number} RG_INTEGER=33320
 * @property {number} RED_INTEGER=36244
 * @property {number} ALPHA=6406
 * @property {number} LUMINANCE=6409
 * @property {number} LUMINANCE_ALPHA=6410
 * @property {number} DEPTH_COMPONENT=6402
 * @property {number} DEPTH_STENCIL=34041
 */ var FORMATS;
(function(FORMATS1) {
    FORMATS1[FORMATS1["RGBA"] = 6408] = "RGBA";
    FORMATS1[FORMATS1["RGB"] = 6407] = "RGB";
    FORMATS1[FORMATS1["RG"] = 33319] = "RG";
    FORMATS1[FORMATS1["RED"] = 6403] = "RED";
    FORMATS1[FORMATS1["RGBA_INTEGER"] = 36249] = "RGBA_INTEGER";
    FORMATS1[FORMATS1["RGB_INTEGER"] = 36248] = "RGB_INTEGER";
    FORMATS1[FORMATS1["RG_INTEGER"] = 33320] = "RG_INTEGER";
    FORMATS1[FORMATS1["RED_INTEGER"] = 36244] = "RED_INTEGER";
    FORMATS1[FORMATS1["ALPHA"] = 6406] = "ALPHA";
    FORMATS1[FORMATS1["LUMINANCE"] = 6409] = "LUMINANCE";
    FORMATS1[FORMATS1["LUMINANCE_ALPHA"] = 6410] = "LUMINANCE_ALPHA";
    FORMATS1[FORMATS1["DEPTH_COMPONENT"] = 6402] = "DEPTH_COMPONENT";
    FORMATS1[FORMATS1["DEPTH_STENCIL"] = 34041] = "DEPTH_STENCIL";
})(FORMATS || (FORMATS = {
}));
/**
 * Various GL target types.
 *
 * @memberof PIXI
 * @static
 * @name TARGETS
 * @enum {number}
 * @property {number} TEXTURE_2D=3553
 * @property {number} TEXTURE_CUBE_MAP=34067
 * @property {number} TEXTURE_2D_ARRAY=35866
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_X=34069
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_X=34070
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_Y=34071
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_Y=34072
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_Z=34073
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_Z=34074
 */ var TARGETS;
(function(TARGETS1) {
    TARGETS1[TARGETS1["TEXTURE_2D"] = 3553] = "TEXTURE_2D";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP"] = 34067] = "TEXTURE_CUBE_MAP";
    TARGETS1[TARGETS1["TEXTURE_2D_ARRAY"] = 35866] = "TEXTURE_2D_ARRAY";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_X"] = 34069] = "TEXTURE_CUBE_MAP_POSITIVE_X";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_X"] = 34070] = "TEXTURE_CUBE_MAP_NEGATIVE_X";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_Y"] = 34071] = "TEXTURE_CUBE_MAP_POSITIVE_Y";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_Y"] = 34072] = "TEXTURE_CUBE_MAP_NEGATIVE_Y";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_Z"] = 34073] = "TEXTURE_CUBE_MAP_POSITIVE_Z";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_Z"] = 34074] = "TEXTURE_CUBE_MAP_NEGATIVE_Z";
})(TARGETS || (TARGETS = {
}));
/**
 * Various GL data format types.
 *
 * @memberof PIXI
 * @static
 * @name TYPES
 * @enum {number}
 * @property {number} UNSIGNED_BYTE=5121
 * @property {number} UNSIGNED_SHORT=5123
 * @property {number} UNSIGNED_SHORT_5_6_5=33635
 * @property {number} UNSIGNED_SHORT_4_4_4_4=32819
 * @property {number} UNSIGNED_SHORT_5_5_5_1=32820
 * @property {number} UNSIGNED_INT=5125
 * @property {number} UNSIGNED_INT_10F_11F_11F_REV=35899
 * @property {number} UNSIGNED_INT_2_10_10_10_REV=33640
 * @property {number} UNSIGNED_INT_24_8=34042
 * @property {number} UNSIGNED_INT_5_9_9_9_REV=35902
 * @property {number} BYTE=5120
 * @property {number} SHORT=5122
 * @property {number} INT=5124
 * @property {number} FLOAT=5126
 * @property {number} FLOAT_32_UNSIGNED_INT_24_8_REV=36269
 * @property {number} HALF_FLOAT=36193
 */ var TYPES;
(function(TYPES1) {
    TYPES1[TYPES1["UNSIGNED_BYTE"] = 5121] = "UNSIGNED_BYTE";
    TYPES1[TYPES1["UNSIGNED_SHORT"] = 5123] = "UNSIGNED_SHORT";
    TYPES1[TYPES1["UNSIGNED_SHORT_5_6_5"] = 33635] = "UNSIGNED_SHORT_5_6_5";
    TYPES1[TYPES1["UNSIGNED_SHORT_4_4_4_4"] = 32819] = "UNSIGNED_SHORT_4_4_4_4";
    TYPES1[TYPES1["UNSIGNED_SHORT_5_5_5_1"] = 32820] = "UNSIGNED_SHORT_5_5_5_1";
    TYPES1[TYPES1["UNSIGNED_INT"] = 5125] = "UNSIGNED_INT";
    TYPES1[TYPES1["UNSIGNED_INT_10F_11F_11F_REV"] = 35899] = "UNSIGNED_INT_10F_11F_11F_REV";
    TYPES1[TYPES1["UNSIGNED_INT_2_10_10_10_REV"] = 33640] = "UNSIGNED_INT_2_10_10_10_REV";
    TYPES1[TYPES1["UNSIGNED_INT_24_8"] = 34042] = "UNSIGNED_INT_24_8";
    TYPES1[TYPES1["UNSIGNED_INT_5_9_9_9_REV"] = 35902] = "UNSIGNED_INT_5_9_9_9_REV";
    TYPES1[TYPES1["BYTE"] = 5120] = "BYTE";
    TYPES1[TYPES1["SHORT"] = 5122] = "SHORT";
    TYPES1[TYPES1["INT"] = 5124] = "INT";
    TYPES1[TYPES1["FLOAT"] = 5126] = "FLOAT";
    TYPES1[TYPES1["FLOAT_32_UNSIGNED_INT_24_8_REV"] = 36269] = "FLOAT_32_UNSIGNED_INT_24_8_REV";
    TYPES1[TYPES1["HALF_FLOAT"] = 36193] = "HALF_FLOAT";
})(TYPES || (TYPES = {
}));
/**
 * Various sampler types. Correspond to `sampler`, `isampler`, `usampler` GLSL types respectively.
 * WebGL1 works only with FLOAT.
 *
 * @memberof PIXI
 * @static
 * @name SAMPLER_TYPES
 * @enum {number}
 * @property {number} FLOAT=0
 * @property {number} INT=1
 * @property {number} UINT=2
 */ var SAMPLER_TYPES;
(function(SAMPLER_TYPES1) {
    SAMPLER_TYPES1[SAMPLER_TYPES1["FLOAT"] = 0] = "FLOAT";
    SAMPLER_TYPES1[SAMPLER_TYPES1["INT"] = 1] = "INT";
    SAMPLER_TYPES1[SAMPLER_TYPES1["UINT"] = 2] = "UINT";
})(SAMPLER_TYPES || (SAMPLER_TYPES = {
}));
/**
 * The scale modes that are supported by pixi.
 *
 * The {@link PIXI.settings.SCALE_MODE} scale mode affects the default scaling mode of future operations.
 * It can be re-assigned to either LINEAR or NEAREST, depending upon suitability.
 *
 * @memberof PIXI
 * @static
 * @name SCALE_MODES
 * @enum {number}
 * @property {number} LINEAR Smooth scaling
 * @property {number} NEAREST Pixelating scaling
 */ var SCALE_MODES;
(function(SCALE_MODES1) {
    SCALE_MODES1[SCALE_MODES1["NEAREST"] = 0] = "NEAREST";
    SCALE_MODES1[SCALE_MODES1["LINEAR"] = 1] = "LINEAR";
})(SCALE_MODES || (SCALE_MODES = {
}));
/**
 * The wrap modes that are supported by pixi.
 *
 * The {@link PIXI.settings.WRAP_MODE} wrap mode affects the default wrapping mode of future operations.
 * It can be re-assigned to either CLAMP or REPEAT, depending upon suitability.
 * If the texture is non power of two then clamp will be used regardless as WebGL can
 * only use REPEAT if the texture is po2.
 *
 * This property only affects WebGL.
 *
 * @name WRAP_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} CLAMP - The textures uvs are clamped
 * @property {number} REPEAT - The texture uvs tile and repeat
 * @property {number} MIRRORED_REPEAT - The texture uvs tile and repeat with mirroring
 */ var WRAP_MODES;
(function(WRAP_MODES1) {
    WRAP_MODES1[WRAP_MODES1["CLAMP"] = 33071] = "CLAMP";
    WRAP_MODES1[WRAP_MODES1["REPEAT"] = 10497] = "REPEAT";
    WRAP_MODES1[WRAP_MODES1["MIRRORED_REPEAT"] = 33648] = "MIRRORED_REPEAT";
})(WRAP_MODES || (WRAP_MODES = {
}));
/**
 * Mipmap filtering modes that are supported by pixi.
 *
 * The {@link PIXI.settings.MIPMAP_TEXTURES} affects default texture filtering.
 * Mipmaps are generated for a baseTexture if its `mipmap` field is `ON`,
 * or its `POW2` and texture dimensions are powers of 2.
 * Due to platform restriction, `ON` option will work like `POW2` for webgl-1.
 *
 * This property only affects WebGL.
 *
 * @name MIPMAP_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} OFF - No mipmaps
 * @property {number} POW2 - Generate mipmaps if texture dimensions are pow2
 * @property {number} ON - Always generate mipmaps
 * @property {number} ON_MANUAL - Use mipmaps, but do not auto-generate them; this is used with a resource
 *   that supports buffering each level-of-detail.
 */ var MIPMAP_MODES;
(function(MIPMAP_MODES1) {
    MIPMAP_MODES1[MIPMAP_MODES1["OFF"] = 0] = "OFF";
    MIPMAP_MODES1[MIPMAP_MODES1["POW2"] = 1] = "POW2";
    MIPMAP_MODES1[MIPMAP_MODES1["ON"] = 2] = "ON";
    MIPMAP_MODES1[MIPMAP_MODES1["ON_MANUAL"] = 3] = "ON_MANUAL";
})(MIPMAP_MODES || (MIPMAP_MODES = {
}));
/**
 * How to treat textures with premultiplied alpha
 *
 * @name ALPHA_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NO_PREMULTIPLIED_ALPHA - Source is not premultiplied, leave it like that.
 *  Option for compressed and data textures that are created from typed arrays.
 * @property {number} PREMULTIPLY_ON_UPLOAD - Source is not premultiplied, premultiply on upload.
 *  Default option, used for all loaded images.
 * @property {number} PREMULTIPLIED_ALPHA - Source is already premultiplied
 *  Example: spine atlases with `_pma` suffix.
 * @property {number} NPM - Alias for NO_PREMULTIPLIED_ALPHA.
 * @property {number} UNPACK - Default option, alias for PREMULTIPLY_ON_UPLOAD.
 * @property {number} PMA - Alias for PREMULTIPLIED_ALPHA.
 */ var ALPHA_MODES;
(function(ALPHA_MODES1) {
    ALPHA_MODES1[ALPHA_MODES1["NPM"] = 0] = "NPM";
    ALPHA_MODES1[ALPHA_MODES1["UNPACK"] = 1] = "UNPACK";
    ALPHA_MODES1[ALPHA_MODES1["PMA"] = 2] = "PMA";
    ALPHA_MODES1[ALPHA_MODES1["NO_PREMULTIPLIED_ALPHA"] = 0] = "NO_PREMULTIPLIED_ALPHA";
    ALPHA_MODES1[ALPHA_MODES1["PREMULTIPLY_ON_UPLOAD"] = 1] = "PREMULTIPLY_ON_UPLOAD";
    ALPHA_MODES1[ALPHA_MODES1["PREMULTIPLY_ALPHA"] = 2] = "PREMULTIPLY_ALPHA";
})(ALPHA_MODES || (ALPHA_MODES = {
}));
/**
 * Configure whether filter textures are cleared after binding.
 *
 * Filter textures need not be cleared if the filter does not use pixel blending. {@link CLEAR_MODES.BLIT} will detect
 * this and skip clearing as an optimization.
 *
 * @name CLEAR_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} BLEND - Do not clear the filter texture. The filter's output will blend on top of the output texture.
 * @property {number} CLEAR - Always clear the filter texture.
 * @property {number} BLIT - Clear only if {@link FilterSystem.forceClear} is set or if the filter uses pixel blending.
 * @property {number} NO - Alias for BLEND, same as `false` in earlier versions
 * @property {number} YES - Alias for CLEAR, same as `true` in earlier versions
 * @property {number} AUTO - Alias for BLIT
 */ var CLEAR_MODES;
(function(CLEAR_MODES1) {
    CLEAR_MODES1[CLEAR_MODES1["NO"] = 0] = "NO";
    CLEAR_MODES1[CLEAR_MODES1["YES"] = 1] = "YES";
    CLEAR_MODES1[CLEAR_MODES1["AUTO"] = 2] = "AUTO";
    CLEAR_MODES1[CLEAR_MODES1["BLEND"] = 0] = "BLEND";
    CLEAR_MODES1[CLEAR_MODES1["CLEAR"] = 1] = "CLEAR";
    CLEAR_MODES1[CLEAR_MODES1["BLIT"] = 2] = "BLIT";
})(CLEAR_MODES || (CLEAR_MODES = {
}));
/**
 * The gc modes that are supported by pixi.
 *
 * The {@link PIXI.settings.GC_MODE} Garbage Collection mode for PixiJS textures is AUTO
 * If set to GC_MODE, the renderer will occasionally check textures usage. If they are not
 * used for a specified period of time they will be removed from the GPU. They will of course
 * be uploaded again when they are required. This is a silent behind the scenes process that
 * should ensure that the GPU does not  get filled up.
 *
 * Handy for mobile devices!
 * This property only affects WebGL.
 *
 * @name GC_MODES
 * @enum {number}
 * @static
 * @memberof PIXI
 * @property {number} AUTO - Garbage collection will happen periodically automatically
 * @property {number} MANUAL - Garbage collection will need to be called manually
 */ var GC_MODES;
(function(GC_MODES1) {
    GC_MODES1[GC_MODES1["AUTO"] = 0] = "AUTO";
    GC_MODES1[GC_MODES1["MANUAL"] = 1] = "MANUAL";
})(GC_MODES || (GC_MODES = {
}));
/**
 * Constants that specify float precision in shaders.
 *
 * @name PRECISION
 * @memberof PIXI
 * @constant
 * @static
 * @enum {string}
 * @property {string} LOW='lowp'
 * @property {string} MEDIUM='mediump'
 * @property {string} HIGH='highp'
 */ var PRECISION;
(function(PRECISION1) {
    PRECISION1["LOW"] = "lowp";
    PRECISION1["MEDIUM"] = "mediump";
    PRECISION1["HIGH"] = "highp";
})(PRECISION || (PRECISION = {
}));
/**
 * Constants for mask implementations.
 * We use `type` suffix because it leads to very different behaviours
 *
 * @name MASK_TYPES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NONE - Mask is ignored
 * @property {number} SCISSOR - Scissor mask, rectangle on screen, cheap
 * @property {number} STENCIL - Stencil mask, 1-bit, medium, works only if renderer supports stencil
 * @property {number} SPRITE - Mask that uses SpriteMaskFilter, uses temporary RenderTexture
 */ var MASK_TYPES;
(function(MASK_TYPES1) {
    MASK_TYPES1[MASK_TYPES1["NONE"] = 0] = "NONE";
    MASK_TYPES1[MASK_TYPES1["SCISSOR"] = 1] = "SCISSOR";
    MASK_TYPES1[MASK_TYPES1["STENCIL"] = 2] = "STENCIL";
    MASK_TYPES1[MASK_TYPES1["SPRITE"] = 3] = "SPRITE";
})(MASK_TYPES || (MASK_TYPES = {
}));
/**
 * Constants for multi-sampling antialiasing.
 *
 * @see PIXI.Framebuffer#multisample
 *
 * @name MSAA_QUALITY
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NONE - No multisampling for this renderTexture
 * @property {number} LOW - Try 2 samples
 * @property {number} MEDIUM - Try 4 samples
 * @property {number} HIGH - Try 8 samples
 */ var MSAA_QUALITY;
(function(MSAA_QUALITY1) {
    MSAA_QUALITY1[MSAA_QUALITY1["NONE"] = 0] = "NONE";
    MSAA_QUALITY1[MSAA_QUALITY1["LOW"] = 2] = "LOW";
    MSAA_QUALITY1[MSAA_QUALITY1["MEDIUM"] = 4] = "MEDIUM";
    MSAA_QUALITY1[MSAA_QUALITY1["HIGH"] = 8] = "HIGH";
})(MSAA_QUALITY || (MSAA_QUALITY = {
}));
/**
 * Constants for various buffer types in Pixi
 *
 * @see PIXI.BUFFER_TYPE
 *
 * @name BUFFER_TYPE
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} ELEMENT_ARRAY_BUFFER - buffer type for using as an index buffer
 * @property {number} ARRAY_BUFFER - buffer type for using attribute data
 * @property {number} UNIFORM_BUFFER - the buffer type is for uniform buffer objects
 */ var BUFFER_TYPE;
(function(BUFFER_TYPE1) {
    BUFFER_TYPE1[BUFFER_TYPE1["ELEMENT_ARRAY_BUFFER"] = 34963] = "ELEMENT_ARRAY_BUFFER";
    BUFFER_TYPE1[BUFFER_TYPE1["ARRAY_BUFFER"] = 34962] = "ARRAY_BUFFER";
    // NOT YET SUPPORTED
    BUFFER_TYPE1[BUFFER_TYPE1["UNIFORM_BUFFER"] = 35345] = "UNIFORM_BUFFER";
})(BUFFER_TYPE || (BUFFER_TYPE = {
}));
/**
 * User's customizable globals for overriding the default PIXI settings, such
 * as a renderer's default resolution, framerate, float precision, etc.
 * @example
 * // Use the native window resolution as the default resolution
 * // will support high-density displays when rendering
 * PIXI.settings.RESOLUTION = window.devicePixelRatio;
 *
 * // Disable interpolation when scaling, will make texture be pixelated
 * PIXI.settings.SCALE_MODE = PIXI.SCALE_MODES.NEAREST;
 * @namespace PIXI.settings
 */ var settings = {
    /**
     * If set to true WebGL will attempt make textures mimpaped by default.
     * Mipmapping will only succeed if the base texture uploaded has power of two dimensions.
     *
     * @static
     * @name MIPMAP_TEXTURES
     * @memberof PIXI.settings
     * @type {PIXI.MIPMAP_MODES}
     * @default PIXI.MIPMAP_MODES.POW2
     */ MIPMAP_TEXTURES: MIPMAP_MODES.POW2,
    /**
     * Default anisotropic filtering level of textures.
     * Usually from 0 to 16
     *
     * @static
     * @name ANISOTROPIC_LEVEL
     * @memberof PIXI.settings
     * @type {number}
     * @default 0
     */ ANISOTROPIC_LEVEL: 0,
    /**
     * Default resolution / device pixel ratio of the renderer.
     *
     * @static
     * @name RESOLUTION
     * @memberof PIXI.settings
     * @type {number}
     * @default 1
     */ RESOLUTION: 1,
    /**
     * Default filter resolution.
     *
     * @static
     * @name FILTER_RESOLUTION
     * @memberof PIXI.settings
     * @type {number}
     * @default 1
     */ FILTER_RESOLUTION: 1,
    /**
     * Default filter samples.
     *
     * @static
     * @name FILTER_MULTISAMPLE
     * @memberof PIXI.settings
     * @type {PIXI.MSAA_QUALITY}
     * @default PIXI.MSAA_QUALITY.NONE
     */ FILTER_MULTISAMPLE: MSAA_QUALITY.NONE,
    /**
     * The maximum textures that this device supports.
     *
     * @static
     * @name SPRITE_MAX_TEXTURES
     * @memberof PIXI.settings
     * @type {number}
     * @default 32
     */ SPRITE_MAX_TEXTURES: maxRecommendedTextures(32),
    // TODO: maybe change to SPRITE.BATCH_SIZE: 2000
    // TODO: maybe add PARTICLE.BATCH_SIZE: 15000
    /**
     * The default sprite batch size.
     *
     * The default aims to balance desktop and mobile devices.
     *
     * @static
     * @name SPRITE_BATCH_SIZE
     * @memberof PIXI.settings
     * @type {number}
     * @default 4096
     */ SPRITE_BATCH_SIZE: 4096,
    /**
     * The default render options if none are supplied to {@link PIXI.Renderer}
     * or {@link PIXI.CanvasRenderer}.
     *
     * @static
     * @name RENDER_OPTIONS
     * @memberof PIXI.settings
     * @type {object}
     * @property {HTMLCanvasElement} view=null
     * @property {boolean} antialias=false
     * @property {boolean} autoDensity=false
     * @property {boolean} useContextAlpha=true
     * @property {number} backgroundColor=0x000000
     * @property {number} backgroundAlpha=1
     * @property {boolean} clearBeforeRender=true
     * @property {boolean} preserveDrawingBuffer=false
     * @property {number} width=800
     * @property {number} height=600
     * @property {boolean} legacy=false
     */ RENDER_OPTIONS: {
        view: null,
        antialias: false,
        autoDensity: false,
        backgroundColor: 0,
        backgroundAlpha: 1,
        useContextAlpha: true,
        clearBeforeRender: true,
        preserveDrawingBuffer: false,
        width: 800,
        height: 600,
        legacy: false
    },
    /**
     * Default Garbage Collection mode.
     *
     * @static
     * @name GC_MODE
     * @memberof PIXI.settings
     * @type {PIXI.GC_MODES}
     * @default PIXI.GC_MODES.AUTO
     */ GC_MODE: GC_MODES.AUTO,
    /**
     * Default Garbage Collection max idle.
     *
     * @static
     * @name GC_MAX_IDLE
     * @memberof PIXI.settings
     * @type {number}
     * @default 3600
     */ GC_MAX_IDLE: 3600,
    /**
     * Default Garbage Collection maximum check count.
     *
     * @static
     * @name GC_MAX_CHECK_COUNT
     * @memberof PIXI.settings
     * @type {number}
     * @default 600
     */ GC_MAX_CHECK_COUNT: 600,
    /**
     * Default wrap modes that are supported by pixi.
     *
     * @static
     * @name WRAP_MODE
     * @memberof PIXI.settings
     * @type {PIXI.WRAP_MODES}
     * @default PIXI.WRAP_MODES.CLAMP
     */ WRAP_MODE: WRAP_MODES.CLAMP,
    /**
     * Default scale mode for textures.
     *
     * @static
     * @name SCALE_MODE
     * @memberof PIXI.settings
     * @type {PIXI.SCALE_MODES}
     * @default PIXI.SCALE_MODES.LINEAR
     */ SCALE_MODE: SCALE_MODES.LINEAR,
    /**
     * Default specify float precision in vertex shader.
     *
     * @static
     * @name PRECISION_VERTEX
     * @memberof PIXI.settings
     * @type {PIXI.PRECISION}
     * @default PIXI.PRECISION.HIGH
     */ PRECISION_VERTEX: PRECISION.HIGH,
    /**
     * Default specify float precision in fragment shader.
     * iOS is best set at highp due to https://github.com/pixijs/pixi.js/issues/3742
     *
     * @static
     * @name PRECISION_FRAGMENT
     * @memberof PIXI.settings
     * @type {PIXI.PRECISION}
     * @default PIXI.PRECISION.MEDIUM
     */ PRECISION_FRAGMENT: isMobile.apple.device ? PRECISION.HIGH : PRECISION.MEDIUM,
    /**
     * Can we upload the same buffer in a single frame?
     *
     * @static
     * @name CAN_UPLOAD_SAME_BUFFER
     * @memberof PIXI.settings
     * @type {boolean}
     */ CAN_UPLOAD_SAME_BUFFER: canUploadSameBuffer(),
    /**
     * Enables bitmap creation before image load. This feature is experimental.
     *
     * @static
     * @name CREATE_IMAGE_BITMAP
     * @memberof PIXI.settings
     * @type {boolean}
     * @default false
     */ CREATE_IMAGE_BITMAP: false,
    /**
     * If true PixiJS will Math.floor() x/y values when rendering, stopping pixel interpolation.
     * Advantages can include sharper image quality (like text) and faster rendering on canvas.
     * The main disadvantage is movement of objects may appear less smooth.
     *
     * @static
     * @constant
     * @memberof PIXI.settings
     * @type {boolean}
     * @default false
     */ ROUND_PIXELS: false
};

},{"ismobilejs":"fSs83","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fSs83":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "default", ()=>_isMobileDefault.default
);
var _isMobile = require("./isMobile");
parcelHelpers.exportAll(_isMobile, exports);
var _isMobileDefault = parcelHelpers.interopDefault(_isMobile);

},{"./isMobile":"gsy56","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gsy56":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var appleIphone = /iPhone/i;
var appleIpod = /iPod/i;
var appleTablet = /iPad/i;
var appleUniversal = /\biOS-universal(?:.+)Mac\b/i;
var androidPhone = /\bAndroid(?:.+)Mobile\b/i;
var androidTablet = /Android/i;
var amazonPhone = /(?:SD4930UR|\bSilk(?:.+)Mobile\b)/i;
var amazonTablet = /Silk/i;
var windowsPhone = /Windows Phone/i;
var windowsTablet = /\bWindows(?:.+)ARM\b/i;
var otherBlackBerry = /BlackBerry/i;
var otherBlackBerry10 = /BB10/i;
var otherOpera = /Opera Mini/i;
var otherChrome = /\b(CriOS|Chrome)(?:.+)Mobile/i;
var otherFirefox = /Mobile(?:.+)Firefox\b/i;
var isAppleTabletOnIos13 = function(navigator) {
    return typeof navigator !== 'undefined' && navigator.platform === 'MacIntel' && typeof navigator.maxTouchPoints === 'number' && navigator.maxTouchPoints > 1 && typeof MSStream === 'undefined';
};
function createMatch(userAgent) {
    return function(regex) {
        return regex.test(userAgent);
    };
}
function isMobile(param) {
    var nav = {
        userAgent: '',
        platform: '',
        maxTouchPoints: 0
    };
    if (!param && typeof navigator !== 'undefined') nav = {
        userAgent: navigator.userAgent,
        platform: navigator.platform,
        maxTouchPoints: navigator.maxTouchPoints || 0
    };
    else if (typeof param === 'string') nav.userAgent = param;
    else if (param && param.userAgent) nav = {
        userAgent: param.userAgent,
        platform: param.platform,
        maxTouchPoints: param.maxTouchPoints || 0
    };
    var userAgent = nav.userAgent;
    var tmp = userAgent.split('[FBAN');
    if (typeof tmp[1] !== 'undefined') userAgent = tmp[0];
    tmp = userAgent.split('Twitter');
    if (typeof tmp[1] !== 'undefined') userAgent = tmp[0];
    var match = createMatch(userAgent);
    var result = {
        apple: {
            phone: match(appleIphone) && !match(windowsPhone),
            ipod: match(appleIpod),
            tablet: !match(appleIphone) && (match(appleTablet) || isAppleTabletOnIos13(nav)) && !match(windowsPhone),
            universal: match(appleUniversal),
            device: (match(appleIphone) || match(appleIpod) || match(appleTablet) || match(appleUniversal) || isAppleTabletOnIos13(nav)) && !match(windowsPhone)
        },
        amazon: {
            phone: match(amazonPhone),
            tablet: !match(amazonPhone) && match(amazonTablet),
            device: match(amazonPhone) || match(amazonTablet)
        },
        android: {
            phone: !match(windowsPhone) && match(amazonPhone) || !match(windowsPhone) && match(androidPhone),
            tablet: !match(windowsPhone) && !match(amazonPhone) && !match(androidPhone) && (match(amazonTablet) || match(androidTablet)),
            device: !match(windowsPhone) && (match(amazonPhone) || match(amazonTablet) || match(androidPhone) || match(androidTablet)) || match(/\bokhttp\b/i)
        },
        windows: {
            phone: match(windowsPhone),
            tablet: match(windowsTablet),
            device: match(windowsPhone) || match(windowsTablet)
        },
        other: {
            blackberry: match(otherBlackBerry),
            blackberry10: match(otherBlackBerry10),
            opera: match(otherOpera),
            firefox: match(otherFirefox),
            chrome: match(otherChrome),
            device: match(otherBlackBerry) || match(otherBlackBerry10) || match(otherOpera) || match(otherFirefox) || match(otherChrome)
        },
        any: false,
        phone: false,
        tablet: false
    };
    result.any = result.apple.device || result.android.device || result.windows.device || result.other.device;
    result.phone = result.apple.phone || result.android.phone || result.windows.phone;
    result.tablet = result.apple.tablet || result.android.tablet || result.windows.tablet;
    return result;
}
exports.default = isMobile;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gTdcb":[function(require,module,exports) {
'use strict';
var has = Object.prototype.hasOwnProperty, prefix = '~';
/**
 * Constructor to create a storage for our `EE` objects.
 * An `Events` instance is a plain object whose properties are event names.
 *
 * @constructor
 * @private
 */ function Events() {
}
//
// We try to not inherit from `Object.prototype`. In some engines creating an
// instance in this way is faster than calling `Object.create(null)` directly.
// If `Object.create(null)` is not supported we prefix the event names with a
// character to make sure that the built-in object properties are not
// overridden or used as an attack vector.
//
if (Object.create) {
    Events.prototype = Object.create(null);
    //
    // This hack is needed because the `__proto__` property is still inherited in
    // some old browsers like Android 4, iPhone 5.1, Opera 11 and Safari 5.
    //
    if (!new Events().__proto__) prefix = false;
}
/**
 * Representation of a single event listener.
 *
 * @param {Function} fn The listener function.
 * @param {*} context The context to invoke the listener with.
 * @param {Boolean} [once=false] Specify if the listener is a one-time listener.
 * @constructor
 * @private
 */ function EE(fn, context, once) {
    this.fn = fn;
    this.context = context;
    this.once = once || false;
}
/**
 * Add a listener for a given event.
 *
 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
 * @param {(String|Symbol)} event The event name.
 * @param {Function} fn The listener function.
 * @param {*} context The context to invoke the listener with.
 * @param {Boolean} once Specify if the listener is a one-time listener.
 * @returns {EventEmitter}
 * @private
 */ function addListener(emitter, event, fn, context, once) {
    if (typeof fn !== 'function') throw new TypeError('The listener must be a function');
    var listener = new EE(fn, context || emitter, once), evt = prefix ? prefix + event : event;
    if (!emitter._events[evt]) emitter._events[evt] = listener, emitter._eventsCount++;
    else if (!emitter._events[evt].fn) emitter._events[evt].push(listener);
    else emitter._events[evt] = [
        emitter._events[evt],
        listener
    ];
    return emitter;
}
/**
 * Clear event by name.
 *
 * @param {EventEmitter} emitter Reference to the `EventEmitter` instance.
 * @param {(String|Symbol)} evt The Event name.
 * @private
 */ function clearEvent(emitter, evt) {
    if ((--emitter._eventsCount) === 0) emitter._events = new Events();
    else delete emitter._events[evt];
}
/**
 * Minimal `EventEmitter` interface that is molded against the Node.js
 * `EventEmitter` interface.
 *
 * @constructor
 * @public
 */ function EventEmitter() {
    this._events = new Events();
    this._eventsCount = 0;
}
/**
 * Return an array listing the events for which the emitter has registered
 * listeners.
 *
 * @returns {Array}
 * @public
 */ EventEmitter.prototype.eventNames = function eventNames() {
    var names = [], events, name;
    if (this._eventsCount === 0) return names;
    for(name in events = this._events)if (has.call(events, name)) names.push(prefix ? name.slice(1) : name);
    if (Object.getOwnPropertySymbols) return names.concat(Object.getOwnPropertySymbols(events));
    return names;
};
/**
 * Return the listeners registered for a given event.
 *
 * @param {(String|Symbol)} event The event name.
 * @returns {Array} The registered listeners.
 * @public
 */ EventEmitter.prototype.listeners = function listeners(event) {
    var evt = prefix ? prefix + event : event, handlers = this._events[evt];
    if (!handlers) return [];
    if (handlers.fn) return [
        handlers.fn
    ];
    for(var i = 0, l = handlers.length, ee = new Array(l); i < l; i++)ee[i] = handlers[i].fn;
    return ee;
};
/**
 * Return the number of listeners listening to a given event.
 *
 * @param {(String|Symbol)} event The event name.
 * @returns {Number} The number of listeners.
 * @public
 */ EventEmitter.prototype.listenerCount = function listenerCount(event) {
    var evt = prefix ? prefix + event : event, listeners1 = this._events[evt];
    if (!listeners1) return 0;
    if (listeners1.fn) return 1;
    return listeners1.length;
};
/**
 * Calls each of the listeners registered for a given event.
 *
 * @param {(String|Symbol)} event The event name.
 * @returns {Boolean} `true` if the event had listeners, else `false`.
 * @public
 */ EventEmitter.prototype.emit = function emit(event, a1, a2, a3, a4, a5) {
    var evt = prefix ? prefix + event : event;
    if (!this._events[evt]) return false;
    var listeners1 = this._events[evt], len = arguments.length, args, i;
    if (listeners1.fn) {
        if (listeners1.once) this.removeListener(event, listeners1.fn, undefined, true);
        switch(len){
            case 1:
                return listeners1.fn.call(listeners1.context), true;
            case 2:
                return listeners1.fn.call(listeners1.context, a1), true;
            case 3:
                return listeners1.fn.call(listeners1.context, a1, a2), true;
            case 4:
                return listeners1.fn.call(listeners1.context, a1, a2, a3), true;
            case 5:
                return listeners1.fn.call(listeners1.context, a1, a2, a3, a4), true;
            case 6:
                return listeners1.fn.call(listeners1.context, a1, a2, a3, a4, a5), true;
        }
        for(i = 1, args = new Array(len - 1); i < len; i++)args[i - 1] = arguments[i];
        listeners1.fn.apply(listeners1.context, args);
    } else {
        var length = listeners1.length, j;
        for(i = 0; i < length; i++){
            if (listeners1[i].once) this.removeListener(event, listeners1[i].fn, undefined, true);
            switch(len){
                case 1:
                    listeners1[i].fn.call(listeners1[i].context);
                    break;
                case 2:
                    listeners1[i].fn.call(listeners1[i].context, a1);
                    break;
                case 3:
                    listeners1[i].fn.call(listeners1[i].context, a1, a2);
                    break;
                case 4:
                    listeners1[i].fn.call(listeners1[i].context, a1, a2, a3);
                    break;
                default:
                    if (!args) for(j = 1, args = new Array(len - 1); j < len; j++)args[j - 1] = arguments[j];
                    listeners1[i].fn.apply(listeners1[i].context, args);
            }
        }
    }
    return true;
};
/**
 * Add a listener for a given event.
 *
 * @param {(String|Symbol)} event The event name.
 * @param {Function} fn The listener function.
 * @param {*} [context=this] The context to invoke the listener with.
 * @returns {EventEmitter} `this`.
 * @public
 */ EventEmitter.prototype.on = function on(event, fn, context) {
    return addListener(this, event, fn, context, false);
};
/**
 * Add a one-time listener for a given event.
 *
 * @param {(String|Symbol)} event The event name.
 * @param {Function} fn The listener function.
 * @param {*} [context=this] The context to invoke the listener with.
 * @returns {EventEmitter} `this`.
 * @public
 */ EventEmitter.prototype.once = function once(event, fn, context) {
    return addListener(this, event, fn, context, true);
};
/**
 * Remove the listeners of a given event.
 *
 * @param {(String|Symbol)} event The event name.
 * @param {Function} fn Only remove the listeners that match this function.
 * @param {*} context Only remove the listeners that have this context.
 * @param {Boolean} once Only remove one-time listeners.
 * @returns {EventEmitter} `this`.
 * @public
 */ EventEmitter.prototype.removeListener = function removeListener(event, fn, context, once1) {
    var evt = prefix ? prefix + event : event;
    if (!this._events[evt]) return this;
    if (!fn) {
        clearEvent(this, evt);
        return this;
    }
    var listeners1 = this._events[evt];
    if (listeners1.fn) {
        if (listeners1.fn === fn && (!once1 || listeners1.once) && (!context || listeners1.context === context)) clearEvent(this, evt);
    } else {
        for(var i = 0, events = [], length = listeners1.length; i < length; i++)if (listeners1[i].fn !== fn || once1 && !listeners1[i].once || context && listeners1[i].context !== context) events.push(listeners1[i]);
        //
        // Reset the array, or remove it completely if we have no more listeners.
        //
        if (events.length) this._events[evt] = events.length === 1 ? events[0] : events;
        else clearEvent(this, evt);
    }
    return this;
};
/**
 * Remove all listeners, or those of the specified event.
 *
 * @param {(String|Symbol)} [event] The event name.
 * @returns {EventEmitter} `this`.
 * @public
 */ EventEmitter.prototype.removeAllListeners = function removeAllListeners(event) {
    var evt;
    if (event) {
        evt = prefix ? prefix + event : event;
        if (this._events[evt]) clearEvent(this, evt);
    } else {
        this._events = new Events();
        this._eventsCount = 0;
    }
    return this;
};
//
// Alias methods names because people roll like that.
//
EventEmitter.prototype.off = EventEmitter.prototype.removeListener;
EventEmitter.prototype.addListener = EventEmitter.prototype.on;
//
// Expose the prefix.
//
EventEmitter.prefixed = prefix;
//
// Allow `EventEmitter` to be imported as module namespace.
//
EventEmitter.EventEmitter = EventEmitter;
//
// Expose the module.
//
if ('undefined' !== typeof module) module.exports = EventEmitter;

},{}],"gwhW7":[function(require,module,exports) {
'use strict';
module.exports = earcut;
module.exports.default = earcut;
function earcut(data, holeIndices, dim) {
    dim = dim || 2;
    var hasHoles = holeIndices && holeIndices.length, outerLen = hasHoles ? holeIndices[0] * dim : data.length, outerNode = linkedList(data, 0, outerLen, dim, true), triangles = [];
    if (!outerNode || outerNode.next === outerNode.prev) return triangles;
    var minX, minY, maxX, maxY, x, y, invSize;
    if (hasHoles) outerNode = eliminateHoles(data, holeIndices, outerNode, dim);
    // if the shape is not too simple, we'll use z-order curve hash later; calculate polygon bbox
    if (data.length > 80 * dim) {
        minX = maxX = data[0];
        minY = maxY = data[1];
        for(var i = dim; i < outerLen; i += dim){
            x = data[i];
            y = data[i + 1];
            if (x < minX) minX = x;
            if (y < minY) minY = y;
            if (x > maxX) maxX = x;
            if (y > maxY) maxY = y;
        }
        // minX, minY and invSize are later used to transform coords into integers for z-order calculation
        invSize = Math.max(maxX - minX, maxY - minY);
        invSize = invSize !== 0 ? 1 / invSize : 0;
    }
    earcutLinked(outerNode, triangles, dim, minX, minY, invSize);
    return triangles;
}
// create a circular doubly linked list from polygon points in the specified winding order
function linkedList(data, start, end, dim, clockwise) {
    var i, last;
    if (clockwise === signedArea(data, start, end, dim) > 0) for(i = start; i < end; i += dim)last = insertNode(i, data[i], data[i + 1], last);
    else for(i = end - dim; i >= start; i -= dim)last = insertNode(i, data[i], data[i + 1], last);
    if (last && equals(last, last.next)) {
        removeNode(last);
        last = last.next;
    }
    return last;
}
// eliminate colinear or duplicate points
function filterPoints(start, end) {
    if (!start) return start;
    if (!end) end = start;
    var p = start, again;
    do {
        again = false;
        if (!p.steiner && (equals(p, p.next) || area(p.prev, p, p.next) === 0)) {
            removeNode(p);
            p = end = p.prev;
            if (p === p.next) break;
            again = true;
        } else p = p.next;
    }while (again || p !== end)
    return end;
}
// main ear slicing loop which triangulates a polygon (given as a linked list)
function earcutLinked(ear, triangles, dim, minX, minY, invSize, pass) {
    if (!ear) return;
    // interlink polygon nodes in z-order
    if (!pass && invSize) indexCurve(ear, minX, minY, invSize);
    var stop = ear, prev, next;
    // iterate through ears, slicing them one by one
    while(ear.prev !== ear.next){
        prev = ear.prev;
        next = ear.next;
        if (invSize ? isEarHashed(ear, minX, minY, invSize) : isEar(ear)) {
            // cut off the triangle
            triangles.push(prev.i / dim);
            triangles.push(ear.i / dim);
            triangles.push(next.i / dim);
            removeNode(ear);
            // skipping the next vertex leads to less sliver triangles
            ear = next.next;
            stop = next.next;
            continue;
        }
        ear = next;
        // if we looped through the whole remaining polygon and can't find any more ears
        if (ear === stop) {
            // try filtering points and slicing again
            if (!pass) earcutLinked(filterPoints(ear), triangles, dim, minX, minY, invSize, 1);
            else if (pass === 1) {
                ear = cureLocalIntersections(filterPoints(ear), triangles, dim);
                earcutLinked(ear, triangles, dim, minX, minY, invSize, 2);
            // as a last resort, try splitting the remaining polygon into two
            } else if (pass === 2) splitEarcut(ear, triangles, dim, minX, minY, invSize);
            break;
        }
    }
}
// check whether a polygon node forms a valid ear with adjacent nodes
function isEar(ear) {
    var a = ear.prev, b = ear, c = ear.next;
    if (area(a, b, c) >= 0) return false; // reflex, can't be an ear
    // now make sure we don't have other points inside the potential ear
    var p = ear.next.next;
    while(p !== ear.prev){
        if (pointInTriangle(a.x, a.y, b.x, b.y, c.x, c.y, p.x, p.y) && area(p.prev, p, p.next) >= 0) return false;
        p = p.next;
    }
    return true;
}
function isEarHashed(ear, minX, minY, invSize) {
    var a = ear.prev, b = ear, c = ear.next;
    if (area(a, b, c) >= 0) return false; // reflex, can't be an ear
    // triangle bbox; min & max are calculated like this for speed
    var minTX = a.x < b.x ? a.x < c.x ? a.x : c.x : b.x < c.x ? b.x : c.x, minTY = a.y < b.y ? a.y < c.y ? a.y : c.y : b.y < c.y ? b.y : c.y, maxTX = a.x > b.x ? a.x > c.x ? a.x : c.x : b.x > c.x ? b.x : c.x, maxTY = a.y > b.y ? a.y > c.y ? a.y : c.y : b.y > c.y ? b.y : c.y;
    // z-order range for the current triangle bbox;
    var minZ = zOrder(minTX, minTY, minX, minY, invSize), maxZ = zOrder(maxTX, maxTY, minX, minY, invSize);
    var p = ear.prevZ, n = ear.nextZ;
    // look for points inside the triangle in both directions
    while(p && p.z >= minZ && n && n.z <= maxZ){
        if (p !== ear.prev && p !== ear.next && pointInTriangle(a.x, a.y, b.x, b.y, c.x, c.y, p.x, p.y) && area(p.prev, p, p.next) >= 0) return false;
        p = p.prevZ;
        if (n !== ear.prev && n !== ear.next && pointInTriangle(a.x, a.y, b.x, b.y, c.x, c.y, n.x, n.y) && area(n.prev, n, n.next) >= 0) return false;
        n = n.nextZ;
    }
    // look for remaining points in decreasing z-order
    while(p && p.z >= minZ){
        if (p !== ear.prev && p !== ear.next && pointInTriangle(a.x, a.y, b.x, b.y, c.x, c.y, p.x, p.y) && area(p.prev, p, p.next) >= 0) return false;
        p = p.prevZ;
    }
    // look for remaining points in increasing z-order
    while(n && n.z <= maxZ){
        if (n !== ear.prev && n !== ear.next && pointInTriangle(a.x, a.y, b.x, b.y, c.x, c.y, n.x, n.y) && area(n.prev, n, n.next) >= 0) return false;
        n = n.nextZ;
    }
    return true;
}
// go through all polygon nodes and cure small local self-intersections
function cureLocalIntersections(start, triangles, dim) {
    var p = start;
    do {
        var a = p.prev, b = p.next.next;
        if (!equals(a, b) && intersects(a, p, p.next, b) && locallyInside(a, b) && locallyInside(b, a)) {
            triangles.push(a.i / dim);
            triangles.push(p.i / dim);
            triangles.push(b.i / dim);
            // remove two nodes involved
            removeNode(p);
            removeNode(p.next);
            p = start = b;
        }
        p = p.next;
    }while (p !== start)
    return filterPoints(p);
}
// try splitting polygon into two and triangulate them independently
function splitEarcut(start, triangles, dim, minX, minY, invSize) {
    // look for a valid diagonal that divides the polygon into two
    var a = start;
    do {
        var b = a.next.next;
        while(b !== a.prev){
            if (a.i !== b.i && isValidDiagonal(a, b)) {
                // split the polygon in two by the diagonal
                var c = splitPolygon(a, b);
                // filter colinear points around the cuts
                a = filterPoints(a, a.next);
                c = filterPoints(c, c.next);
                // run earcut on each half
                earcutLinked(a, triangles, dim, minX, minY, invSize);
                earcutLinked(c, triangles, dim, minX, minY, invSize);
                return;
            }
            b = b.next;
        }
        a = a.next;
    }while (a !== start)
}
// link every hole into the outer loop, producing a single-ring polygon without holes
function eliminateHoles(data, holeIndices, outerNode, dim) {
    var queue = [], i, len, start, end, list;
    for(i = 0, len = holeIndices.length; i < len; i++){
        start = holeIndices[i] * dim;
        end = i < len - 1 ? holeIndices[i + 1] * dim : data.length;
        list = linkedList(data, start, end, dim, false);
        if (list === list.next) list.steiner = true;
        queue.push(getLeftmost(list));
    }
    queue.sort(compareX);
    // process holes from left to right
    for(i = 0; i < queue.length; i++){
        outerNode = eliminateHole(queue[i], outerNode);
        outerNode = filterPoints(outerNode, outerNode.next);
    }
    return outerNode;
}
function compareX(a, b) {
    return a.x - b.x;
}
// find a bridge between vertices that connects hole with an outer ring and and link it
function eliminateHole(hole, outerNode) {
    var bridge = findHoleBridge(hole, outerNode);
    if (!bridge) return outerNode;
    var bridgeReverse = splitPolygon(bridge, hole);
    // filter collinear points around the cuts
    var filteredBridge = filterPoints(bridge, bridge.next);
    filterPoints(bridgeReverse, bridgeReverse.next);
    // Check if input node was removed by the filtering
    return outerNode === bridge ? filteredBridge : outerNode;
}
// David Eberly's algorithm for finding a bridge between hole and outer polygon
function findHoleBridge(hole, outerNode) {
    var p = outerNode, hx = hole.x, hy = hole.y, qx = -Infinity, m;
    // find a segment intersected by a ray from the hole's leftmost point to the left;
    // segment's endpoint with lesser x will be potential connection point
    do {
        if (hy <= p.y && hy >= p.next.y && p.next.y !== p.y) {
            var x = p.x + (hy - p.y) * (p.next.x - p.x) / (p.next.y - p.y);
            if (x <= hx && x > qx) {
                qx = x;
                if (x === hx) {
                    if (hy === p.y) return p;
                    if (hy === p.next.y) return p.next;
                }
                m = p.x < p.next.x ? p : p.next;
            }
        }
        p = p.next;
    }while (p !== outerNode)
    if (!m) return null;
    if (hx === qx) return m; // hole touches outer segment; pick leftmost endpoint
    // look for points inside the triangle of hole point, segment intersection and endpoint;
    // if there are no points found, we have a valid connection;
    // otherwise choose the point of the minimum angle with the ray as connection point
    var stop = m, mx = m.x, my = m.y, tanMin = Infinity, tan;
    p = m;
    do {
        if (hx >= p.x && p.x >= mx && hx !== p.x && pointInTriangle(hy < my ? hx : qx, hy, mx, my, hy < my ? qx : hx, hy, p.x, p.y)) {
            tan = Math.abs(hy - p.y) / (hx - p.x); // tangential
            if (locallyInside(p, hole) && (tan < tanMin || tan === tanMin && (p.x > m.x || p.x === m.x && sectorContainsSector(m, p)))) {
                m = p;
                tanMin = tan;
            }
        }
        p = p.next;
    }while (p !== stop)
    return m;
}
// whether sector in vertex m contains sector in vertex p in the same coordinates
function sectorContainsSector(m, p) {
    return area(m.prev, m, p.prev) < 0 && area(p.next, m, m.next) < 0;
}
// interlink polygon nodes in z-order
function indexCurve(start, minX, minY, invSize) {
    var p = start;
    do {
        if (p.z === null) p.z = zOrder(p.x, p.y, minX, minY, invSize);
        p.prevZ = p.prev;
        p.nextZ = p.next;
        p = p.next;
    }while (p !== start)
    p.prevZ.nextZ = null;
    p.prevZ = null;
    sortLinked(p);
}
// Simon Tatham's linked list merge sort algorithm
// http://www.chiark.greenend.org.uk/~sgtatham/algorithms/listsort.html
function sortLinked(list) {
    var i, p, q, e, tail, numMerges, pSize, qSize, inSize = 1;
    do {
        p = list;
        list = null;
        tail = null;
        numMerges = 0;
        while(p){
            numMerges++;
            q = p;
            pSize = 0;
            for(i = 0; i < inSize; i++){
                pSize++;
                q = q.nextZ;
                if (!q) break;
            }
            qSize = inSize;
            while(pSize > 0 || qSize > 0 && q){
                if (pSize !== 0 && (qSize === 0 || !q || p.z <= q.z)) {
                    e = p;
                    p = p.nextZ;
                    pSize--;
                } else {
                    e = q;
                    q = q.nextZ;
                    qSize--;
                }
                if (tail) tail.nextZ = e;
                else list = e;
                e.prevZ = tail;
                tail = e;
            }
            p = q;
        }
        tail.nextZ = null;
        inSize *= 2;
    }while (numMerges > 1)
    return list;
}
// z-order of a point given coords and inverse of the longer side of data bbox
function zOrder(x, y, minX, minY, invSize) {
    // coords are transformed into non-negative 15-bit integer range
    x = 32767 * (x - minX) * invSize;
    y = 32767 * (y - minY) * invSize;
    x = (x | x << 8) & 16711935;
    x = (x | x << 4) & 252645135;
    x = (x | x << 2) & 858993459;
    x = (x | x << 1) & 1431655765;
    y = (y | y << 8) & 16711935;
    y = (y | y << 4) & 252645135;
    y = (y | y << 2) & 858993459;
    y = (y | y << 1) & 1431655765;
    return x | y << 1;
}
// find the leftmost node of a polygon ring
function getLeftmost(start) {
    var p = start, leftmost = start;
    do {
        if (p.x < leftmost.x || p.x === leftmost.x && p.y < leftmost.y) leftmost = p;
        p = p.next;
    }while (p !== start)
    return leftmost;
}
// check if a point lies within a convex triangle
function pointInTriangle(ax, ay, bx, by, cx, cy, px, py) {
    return (cx - px) * (ay - py) - (ax - px) * (cy - py) >= 0 && (ax - px) * (by - py) - (bx - px) * (ay - py) >= 0 && (bx - px) * (cy - py) - (cx - px) * (by - py) >= 0;
}
// check if a diagonal between two polygon nodes is valid (lies in polygon interior)
function isValidDiagonal(a, b) {
    return a.next.i !== b.i && a.prev.i !== b.i && !intersectsPolygon(a, b) && (locallyInside(a, b) && locallyInside(b, a) && middleInside(a, b) && (area(a.prev, a, b.prev) || area(a, b.prev, b)) || equals(a, b) && area(a.prev, a, a.next) > 0 && area(b.prev, b, b.next) > 0); // special zero-length case
}
// signed area of a triangle
function area(p, q, r) {
    return (q.y - p.y) * (r.x - q.x) - (q.x - p.x) * (r.y - q.y);
}
// check if two points are equal
function equals(p1, p2) {
    return p1.x === p2.x && p1.y === p2.y;
}
// check if two segments intersect
function intersects(p1, q1, p2, q2) {
    var o1 = sign(area(p1, q1, p2));
    var o2 = sign(area(p1, q1, q2));
    var o3 = sign(area(p2, q2, p1));
    var o4 = sign(area(p2, q2, q1));
    if (o1 !== o2 && o3 !== o4) return true; // general case
    if (o1 === 0 && onSegment(p1, p2, q1)) return true; // p1, q1 and p2 are collinear and p2 lies on p1q1
    if (o2 === 0 && onSegment(p1, q2, q1)) return true; // p1, q1 and q2 are collinear and q2 lies on p1q1
    if (o3 === 0 && onSegment(p2, p1, q2)) return true; // p2, q2 and p1 are collinear and p1 lies on p2q2
    if (o4 === 0 && onSegment(p2, q1, q2)) return true; // p2, q2 and q1 are collinear and q1 lies on p2q2
    return false;
}
// for collinear points p, q, r, check if point q lies on segment pr
function onSegment(p, q, r) {
    return q.x <= Math.max(p.x, r.x) && q.x >= Math.min(p.x, r.x) && q.y <= Math.max(p.y, r.y) && q.y >= Math.min(p.y, r.y);
}
function sign(num) {
    return num > 0 ? 1 : num < 0 ? -1 : 0;
}
// check if a polygon diagonal intersects any polygon segments
function intersectsPolygon(a, b) {
    var p = a;
    do {
        if (p.i !== a.i && p.next.i !== a.i && p.i !== b.i && p.next.i !== b.i && intersects(p, p.next, a, b)) return true;
        p = p.next;
    }while (p !== a)
    return false;
}
// check if a polygon diagonal is locally inside the polygon
function locallyInside(a, b) {
    return area(a.prev, a, a.next) < 0 ? area(a, b, a.next) >= 0 && area(a, a.prev, b) >= 0 : area(a, b, a.prev) < 0 || area(a, a.next, b) < 0;
}
// check if the middle point of a polygon diagonal is inside the polygon
function middleInside(a, b) {
    var p = a, inside = false, px = (a.x + b.x) / 2, py = (a.y + b.y) / 2;
    do {
        if (p.y > py !== p.next.y > py && p.next.y !== p.y && px < (p.next.x - p.x) * (py - p.y) / (p.next.y - p.y) + p.x) inside = !inside;
        p = p.next;
    }while (p !== a)
    return inside;
}
// link two polygon vertices with a bridge; if the vertices belong to the same ring, it splits polygon into two;
// if one belongs to the outer ring and another to a hole, it merges it into a single ring
function splitPolygon(a, b) {
    var a2 = new Node1(a.i, a.x, a.y), b2 = new Node1(b.i, b.x, b.y), an = a.next, bp = b.prev;
    a.next = b;
    b.prev = a;
    a2.next = an;
    an.prev = a2;
    b2.next = a2;
    a2.prev = b2;
    bp.next = b2;
    b2.prev = bp;
    return b2;
}
// create a node and optionally link it with previous one (in a circular doubly linked list)
function insertNode(i, x, y, last) {
    var p = new Node1(i, x, y);
    if (!last) {
        p.prev = p;
        p.next = p;
    } else {
        p.next = last.next;
        p.prev = last;
        last.next.prev = p;
        last.next = p;
    }
    return p;
}
function removeNode(p) {
    p.next.prev = p.prev;
    p.prev.next = p.next;
    if (p.prevZ) p.prevZ.nextZ = p.nextZ;
    if (p.nextZ) p.nextZ.prevZ = p.prevZ;
}
function Node1(i, x, y) {
    // vertex index in coordinates array
    this.i = i;
    // vertex coordinates
    this.x = x;
    this.y = y;
    // previous and next vertex nodes in a polygon ring
    this.prev = null;
    this.next = null;
    // z-order curve value
    this.z = null;
    // previous and next nodes in z-order
    this.prevZ = null;
    this.nextZ = null;
    // indicates whether this is a steiner point
    this.steiner = false;
}
// return a percentage difference between the polygon area and its triangulation area;
// used to verify correctness of triangulation
earcut.deviation = function(data, holeIndices, dim, triangles) {
    var hasHoles = holeIndices && holeIndices.length;
    var outerLen = hasHoles ? holeIndices[0] * dim : data.length;
    var polygonArea = Math.abs(signedArea(data, 0, outerLen, dim));
    if (hasHoles) for(var i = 0, len = holeIndices.length; i < len; i++){
        var start = holeIndices[i] * dim;
        var end = i < len - 1 ? holeIndices[i + 1] * dim : data.length;
        polygonArea -= Math.abs(signedArea(data, start, end, dim));
    }
    var trianglesArea = 0;
    for(i = 0; i < triangles.length; i += 3){
        var a = triangles[i] * dim;
        var b = triangles[i + 1] * dim;
        var c = triangles[i + 2] * dim;
        trianglesArea += Math.abs((data[a] - data[c]) * (data[b + 1] - data[a + 1]) - (data[a] - data[b]) * (data[c + 1] - data[a + 1]));
    }
    return polygonArea === 0 && trianglesArea === 0 ? 0 : Math.abs((trianglesArea - polygonArea) / polygonArea);
};
function signedArea(data, start, end, dim) {
    var sum = 0;
    for(var i = start, j = end - dim; i < end; i += dim){
        sum += (data[j] - data[i]) * (data[i + 1] + data[j + 1]);
        j = i;
    }
    return sum;
}
// turn a polygon in a multi-dimensional array form (e.g. as in GeoJSON) into a form Earcut accepts
earcut.flatten = function(data) {
    var dim = data[0][0].length, result = {
        vertices: [],
        holes: [],
        dimensions: dim
    }, holeIndex = 0;
    for(var i = 0; i < data.length; i++){
        for(var j = 0; j < data[i].length; j++)for(var d = 0; d < dim; d++)result.vertices.push(data[i][j][d]);
        if (i > 0) {
            holeIndex += data[i - 1].length;
            result.holes.push(holeIndex);
        }
    }
    return result;
};

},{}],"4B2Rd":[function(require,module,exports) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
'use strict';
var punycode = require('punycode');
var util = require('./util');
exports.parse = urlParse;
exports.resolve = urlResolve;
exports.resolveObject = urlResolveObject;
exports.format = urlFormat;
exports.Url = Url;
function Url() {
    this.protocol = null;
    this.slashes = null;
    this.auth = null;
    this.host = null;
    this.port = null;
    this.hostname = null;
    this.hash = null;
    this.search = null;
    this.query = null;
    this.pathname = null;
    this.path = null;
    this.href = null;
}
// Reference: RFC 3986, RFC 1808, RFC 2396
// define these here so at least they only have to be
// compiled once on the first module load.
var protocolPattern = /^([a-z0-9.+-]+:)/i, portPattern = /:[0-9]*$/, // Special case for a simple path URL
simplePathPattern = /^(\/\/?(?!\/)[^\?\s]*)(\?[^\s]*)?$/, // RFC 2396: characters reserved for delimiting URLs.
// We actually just auto-escape these.
delims = [
    '<',
    '>',
    '"',
    '`',
    ' ',
    '\r',
    '\n',
    '\t'
], // RFC 2396: characters not allowed for various reasons.
unwise = [
    '{',
    '}',
    '|',
    '\\',
    '^',
    '`'
].concat(delims), // Allowed by RFCs, but cause of XSS attacks.  Always escape these.
autoEscape = [
    '\''
].concat(unwise), // Characters that are never ever allowed in a hostname.
// Note that any invalid chars are also handled, but these
// are the ones that are *expected* to be seen, so we fast-path
// them.
nonHostChars = [
    '%',
    '/',
    '?',
    ';',
    '#'
].concat(autoEscape), hostEndingChars = [
    '/',
    '?',
    '#'
], hostnameMaxLen = 255, hostnamePartPattern = /^[+a-z0-9A-Z_-]{0,63}$/, hostnamePartStart = /^([+a-z0-9A-Z_-]{0,63})(.*)$/, // protocols that can allow "unsafe" and "unwise" chars.
unsafeProtocol = {
    'javascript': true,
    'javascript:': true
}, // protocols that never have a hostname.
hostlessProtocol = {
    'javascript': true,
    'javascript:': true
}, // protocols that always contain a // bit.
slashedProtocol = {
    'http': true,
    'https': true,
    'ftp': true,
    'gopher': true,
    'file': true,
    'http:': true,
    'https:': true,
    'ftp:': true,
    'gopher:': true,
    'file:': true
}, querystring = require('querystring');
function urlParse(url, parseQueryString, slashesDenoteHost) {
    if (url && util.isObject(url) && url instanceof Url) return url;
    var u = new Url;
    u.parse(url, parseQueryString, slashesDenoteHost);
    return u;
}
Url.prototype.parse = function(url, parseQueryString, slashesDenoteHost) {
    if (!util.isString(url)) throw new TypeError("Parameter 'url' must be a string, not " + typeof url);
    // Copy chrome, IE, opera backslash-handling behavior.
    // Back slashes before the query string get converted to forward slashes
    // See: https://code.google.com/p/chromium/issues/detail?id=25916
    var queryIndex = url.indexOf('?'), splitter = queryIndex !== -1 && queryIndex < url.indexOf('#') ? '?' : '#', uSplit = url.split(splitter), slashRegex = /\\/g;
    uSplit[0] = uSplit[0].replace(slashRegex, '/');
    url = uSplit.join(splitter);
    var rest = url;
    // trim before proceeding.
    // This is to support parse stuff like "  http://foo.com  \n"
    rest = rest.trim();
    if (!slashesDenoteHost && url.split('#').length === 1) {
        // Try fast path regexp
        var simplePath = simplePathPattern.exec(rest);
        if (simplePath) {
            this.path = rest;
            this.href = rest;
            this.pathname = simplePath[1];
            if (simplePath[2]) {
                this.search = simplePath[2];
                if (parseQueryString) this.query = querystring.parse(this.search.substr(1));
                else this.query = this.search.substr(1);
            } else if (parseQueryString) {
                this.search = '';
                this.query = {
                };
            }
            return this;
        }
    }
    var proto = protocolPattern.exec(rest);
    if (proto) {
        proto = proto[0];
        var lowerProto = proto.toLowerCase();
        this.protocol = lowerProto;
        rest = rest.substr(proto.length);
    }
    // figure out if it's got a host
    // user@server is *always* interpreted as a hostname, and url
    // resolution will treat //foo/bar as host=foo,path=bar because that's
    // how the browser resolves relative URLs.
    if (slashesDenoteHost || proto || rest.match(/^\/\/[^@\/]+@[^@\/]+/)) {
        var slashes = rest.substr(0, 2) === '//';
        if (slashes && !(proto && hostlessProtocol[proto])) {
            rest = rest.substr(2);
            this.slashes = true;
        }
    }
    if (!hostlessProtocol[proto] && (slashes || proto && !slashedProtocol[proto])) {
        // there's a hostname.
        // the first instance of /, ?, ;, or # ends the host.
        //
        // If there is an @ in the hostname, then non-host chars *are* allowed
        // to the left of the last @ sign, unless some host-ending character
        // comes *before* the @-sign.
        // URLs are obnoxious.
        //
        // ex:
        // http://a@b@c/ => user:a@b host:c
        // http://a@b?@c => user:a host:c path:/?@c
        // v0.12 TODO(isaacs): This is not quite how Chrome does things.
        // Review our test case against browsers more comprehensively.
        // find the first instance of any hostEndingChars
        var hostEnd = -1;
        for(var i = 0; i < hostEndingChars.length; i++){
            var hec = rest.indexOf(hostEndingChars[i]);
            if (hec !== -1 && (hostEnd === -1 || hec < hostEnd)) hostEnd = hec;
        }
        // at this point, either we have an explicit point where the
        // auth portion cannot go past, or the last @ char is the decider.
        var auth, atSign;
        if (hostEnd === -1) // atSign can be anywhere.
        atSign = rest.lastIndexOf('@');
        else // atSign must be in auth portion.
        // http://a@b/c@d => host:b auth:a path:/c@d
        atSign = rest.lastIndexOf('@', hostEnd);
        // Now we have a portion which is definitely the auth.
        // Pull that off.
        if (atSign !== -1) {
            auth = rest.slice(0, atSign);
            rest = rest.slice(atSign + 1);
            this.auth = decodeURIComponent(auth);
        }
        // the host is the remaining to the left of the first non-host char
        hostEnd = -1;
        for(var i = 0; i < nonHostChars.length; i++){
            var hec = rest.indexOf(nonHostChars[i]);
            if (hec !== -1 && (hostEnd === -1 || hec < hostEnd)) hostEnd = hec;
        }
        // if we still have not hit it, then the entire thing is a host.
        if (hostEnd === -1) hostEnd = rest.length;
        this.host = rest.slice(0, hostEnd);
        rest = rest.slice(hostEnd);
        // pull out port.
        this.parseHost();
        // we've indicated that there is a hostname,
        // so even if it's empty, it has to be present.
        this.hostname = this.hostname || '';
        // if hostname begins with [ and ends with ]
        // assume that it's an IPv6 address.
        var ipv6Hostname = this.hostname[0] === '[' && this.hostname[this.hostname.length - 1] === ']';
        // validate a little.
        if (!ipv6Hostname) {
            var hostparts = this.hostname.split(/\./);
            for(var i = 0, l = hostparts.length; i < l; i++){
                var part = hostparts[i];
                if (!part) continue;
                if (!part.match(hostnamePartPattern)) {
                    var newpart = '';
                    for(var j = 0, k = part.length; j < k; j++)if (part.charCodeAt(j) > 127) // we replace non-ASCII char with a temporary placeholder
                    // we need this to make sure size of hostname is not
                    // broken by replacing non-ASCII by nothing
                    newpart += 'x';
                    else newpart += part[j];
                    // we test again with ASCII char only
                    if (!newpart.match(hostnamePartPattern)) {
                        var validParts = hostparts.slice(0, i);
                        var notHost = hostparts.slice(i + 1);
                        var bit = part.match(hostnamePartStart);
                        if (bit) {
                            validParts.push(bit[1]);
                            notHost.unshift(bit[2]);
                        }
                        if (notHost.length) rest = '/' + notHost.join('.') + rest;
                        this.hostname = validParts.join('.');
                        break;
                    }
                }
            }
        }
        if (this.hostname.length > hostnameMaxLen) this.hostname = '';
        else // hostnames are always lower case.
        this.hostname = this.hostname.toLowerCase();
        if (!ipv6Hostname) // IDNA Support: Returns a punycoded representation of "domain".
        // It only converts parts of the domain name that
        // have non-ASCII characters, i.e. it doesn't matter if
        // you call it with a domain that already is ASCII-only.
        this.hostname = punycode.toASCII(this.hostname);
        var p = this.port ? ':' + this.port : '';
        var h = this.hostname || '';
        this.host = h + p;
        this.href += this.host;
        // strip [ and ] from the hostname
        // the host field still retains them, though
        if (ipv6Hostname) {
            this.hostname = this.hostname.substr(1, this.hostname.length - 2);
            if (rest[0] !== '/') rest = '/' + rest;
        }
    }
    // now rest is set to the post-host stuff.
    // chop off any delim chars.
    if (!unsafeProtocol[lowerProto]) // First, make 100% sure that any "autoEscape" chars get
    // escaped, even if encodeURIComponent doesn't think they
    // need to be.
    for(var i = 0, l = autoEscape.length; i < l; i++){
        var ae = autoEscape[i];
        if (rest.indexOf(ae) === -1) continue;
        var esc = encodeURIComponent(ae);
        if (esc === ae) esc = escape(ae);
        rest = rest.split(ae).join(esc);
    }
    // chop off from the tail first.
    var hash = rest.indexOf('#');
    if (hash !== -1) {
        // got a fragment string.
        this.hash = rest.substr(hash);
        rest = rest.slice(0, hash);
    }
    var qm = rest.indexOf('?');
    if (qm !== -1) {
        this.search = rest.substr(qm);
        this.query = rest.substr(qm + 1);
        if (parseQueryString) this.query = querystring.parse(this.query);
        rest = rest.slice(0, qm);
    } else if (parseQueryString) {
        // no query string, but parseQueryString still requested
        this.search = '';
        this.query = {
        };
    }
    if (rest) this.pathname = rest;
    if (slashedProtocol[lowerProto] && this.hostname && !this.pathname) this.pathname = '/';
    //to support http.request
    if (this.pathname || this.search) {
        var p = this.pathname || '';
        var s = this.search || '';
        this.path = p + s;
    }
    // finally, reconstruct the href based on what has been validated.
    this.href = this.format();
    return this;
};
// format a parsed object into a url string
function urlFormat(obj) {
    // ensure it's an object, and not a string url.
    // If it's an obj, this is a no-op.
    // this way, you can call url_format() on strings
    // to clean up potentially wonky urls.
    if (util.isString(obj)) obj = urlParse(obj);
    if (!(obj instanceof Url)) return Url.prototype.format.call(obj);
    return obj.format();
}
Url.prototype.format = function() {
    var auth = this.auth || '';
    if (auth) {
        auth = encodeURIComponent(auth);
        auth = auth.replace(/%3A/i, ':');
        auth += '@';
    }
    var protocol = this.protocol || '', pathname = this.pathname || '', hash = this.hash || '', host = false, query = '';
    if (this.host) host = auth + this.host;
    else if (this.hostname) {
        host = auth + (this.hostname.indexOf(':') === -1 ? this.hostname : '[' + this.hostname + ']');
        if (this.port) host += ':' + this.port;
    }
    if (this.query && util.isObject(this.query) && Object.keys(this.query).length) query = querystring.stringify(this.query);
    var search = this.search || query && '?' + query || '';
    if (protocol && protocol.substr(-1) !== ':') protocol += ':';
    // only the slashedProtocols get the //.  Not mailto:, xmpp:, etc.
    // unless they had them to begin with.
    if (this.slashes || (!protocol || slashedProtocol[protocol]) && host !== false) {
        host = '//' + (host || '');
        if (pathname && pathname.charAt(0) !== '/') pathname = '/' + pathname;
    } else if (!host) host = '';
    if (hash && hash.charAt(0) !== '#') hash = '#' + hash;
    if (search && search.charAt(0) !== '?') search = '?' + search;
    pathname = pathname.replace(/[?#]/g, function(match) {
        return encodeURIComponent(match);
    });
    search = search.replace('#', '%23');
    return protocol + host + pathname + search + hash;
};
function urlResolve(source, relative) {
    return urlParse(source, false, true).resolve(relative);
}
Url.prototype.resolve = function(relative) {
    return this.resolveObject(urlParse(relative, false, true)).format();
};
function urlResolveObject(source, relative) {
    if (!source) return relative;
    return urlParse(source, false, true).resolveObject(relative);
}
Url.prototype.resolveObject = function(relative) {
    if (util.isString(relative)) {
        var rel = new Url();
        rel.parse(relative, false, true);
        relative = rel;
    }
    var result = new Url();
    var tkeys = Object.keys(this);
    for(var tk = 0; tk < tkeys.length; tk++){
        var tkey = tkeys[tk];
        result[tkey] = this[tkey];
    }
    // hash is always overridden, no matter what.
    // even href="" will remove it.
    result.hash = relative.hash;
    // if the relative url is empty, then there's nothing left to do here.
    if (relative.href === '') {
        result.href = result.format();
        return result;
    }
    // hrefs like //foo/bar always cut to the protocol.
    if (relative.slashes && !relative.protocol) {
        // take everything except the protocol from relative
        var rkeys = Object.keys(relative);
        for(var rk = 0; rk < rkeys.length; rk++){
            var rkey = rkeys[rk];
            if (rkey !== 'protocol') result[rkey] = relative[rkey];
        }
        //urlParse appends trailing / to urls like http://www.example.com
        if (slashedProtocol[result.protocol] && result.hostname && !result.pathname) result.path = result.pathname = '/';
        result.href = result.format();
        return result;
    }
    if (relative.protocol && relative.protocol !== result.protocol) {
        // if it's a known url protocol, then changing
        // the protocol does weird things
        // first, if it's not file:, then we MUST have a host,
        // and if there was a path
        // to begin with, then we MUST have a path.
        // if it is file:, then the host is dropped,
        // because that's known to be hostless.
        // anything else is assumed to be absolute.
        if (!slashedProtocol[relative.protocol]) {
            var keys = Object.keys(relative);
            for(var v = 0; v < keys.length; v++){
                var k = keys[v];
                result[k] = relative[k];
            }
            result.href = result.format();
            return result;
        }
        result.protocol = relative.protocol;
        if (!relative.host && !hostlessProtocol[relative.protocol]) {
            var relPath = (relative.pathname || '').split('/');
            while(relPath.length && !(relative.host = relPath.shift()));
            if (!relative.host) relative.host = '';
            if (!relative.hostname) relative.hostname = '';
            if (relPath[0] !== '') relPath.unshift('');
            if (relPath.length < 2) relPath.unshift('');
            result.pathname = relPath.join('/');
        } else result.pathname = relative.pathname;
        result.search = relative.search;
        result.query = relative.query;
        result.host = relative.host || '';
        result.auth = relative.auth;
        result.hostname = relative.hostname || relative.host;
        result.port = relative.port;
        // to support http.request
        if (result.pathname || result.search) {
            var p = result.pathname || '';
            var s = result.search || '';
            result.path = p + s;
        }
        result.slashes = result.slashes || relative.slashes;
        result.href = result.format();
        return result;
    }
    var isSourceAbs = result.pathname && result.pathname.charAt(0) === '/', isRelAbs = relative.host || relative.pathname && relative.pathname.charAt(0) === '/', mustEndAbs = isRelAbs || isSourceAbs || result.host && relative.pathname, removeAllDots = mustEndAbs, srcPath = result.pathname && result.pathname.split('/') || [], relPath = relative.pathname && relative.pathname.split('/') || [], psychotic = result.protocol && !slashedProtocol[result.protocol];
    // if the url is a non-slashed url, then relative
    // links like ../.. should be able
    // to crawl up to the hostname, as well.  This is strange.
    // result.protocol has already been set by now.
    // Later on, put the first path part into the host field.
    if (psychotic) {
        result.hostname = '';
        result.port = null;
        if (result.host) {
            if (srcPath[0] === '') srcPath[0] = result.host;
            else srcPath.unshift(result.host);
        }
        result.host = '';
        if (relative.protocol) {
            relative.hostname = null;
            relative.port = null;
            if (relative.host) {
                if (relPath[0] === '') relPath[0] = relative.host;
                else relPath.unshift(relative.host);
            }
            relative.host = null;
        }
        mustEndAbs = mustEndAbs && (relPath[0] === '' || srcPath[0] === '');
    }
    if (isRelAbs) {
        // it's absolute.
        result.host = relative.host || relative.host === '' ? relative.host : result.host;
        result.hostname = relative.hostname || relative.hostname === '' ? relative.hostname : result.hostname;
        result.search = relative.search;
        result.query = relative.query;
        srcPath = relPath;
    // fall through to the dot-handling below.
    } else if (relPath.length) {
        // it's relative
        // throw away the existing file, and take the new path instead.
        if (!srcPath) srcPath = [];
        srcPath.pop();
        srcPath = srcPath.concat(relPath);
        result.search = relative.search;
        result.query = relative.query;
    } else if (!util.isNullOrUndefined(relative.search)) {
        // just pull out the search.
        // like href='?foo'.
        // Put this after the other two cases because it simplifies the booleans
        if (psychotic) {
            result.hostname = result.host = srcPath.shift();
            //occationaly the auth can get stuck only in host
            //this especially happens in cases like
            //url.resolveObject('mailto:local1@domain1', 'local2@domain2')
            var authInHost = result.host && result.host.indexOf('@') > 0 ? result.host.split('@') : false;
            if (authInHost) {
                result.auth = authInHost.shift();
                result.host = result.hostname = authInHost.shift();
            }
        }
        result.search = relative.search;
        result.query = relative.query;
        //to support http.request
        if (!util.isNull(result.pathname) || !util.isNull(result.search)) result.path = (result.pathname ? result.pathname : '') + (result.search ? result.search : '');
        result.href = result.format();
        return result;
    }
    if (!srcPath.length) {
        // no path at all.  easy.
        // we've already handled the other stuff above.
        result.pathname = null;
        //to support http.request
        if (result.search) result.path = '/' + result.search;
        else result.path = null;
        result.href = result.format();
        return result;
    }
    // if a url ENDs in . or .., then it must get a trailing slash.
    // however, if it ends in anything else non-slashy,
    // then it must NOT get a trailing slash.
    var last = srcPath.slice(-1)[0];
    var hasTrailingSlash = (result.host || relative.host || srcPath.length > 1) && (last === '.' || last === '..') || last === '';
    // strip single dots, resolve double dots to parent dir
    // if the path tries to go above the root, `up` ends up > 0
    var up = 0;
    for(var i = srcPath.length; i >= 0; i--){
        last = srcPath[i];
        if (last === '.') srcPath.splice(i, 1);
        else if (last === '..') {
            srcPath.splice(i, 1);
            up++;
        } else if (up) {
            srcPath.splice(i, 1);
            up--;
        }
    }
    // if the path is allowed to go above the root, restore leading ..s
    if (!mustEndAbs && !removeAllDots) for(; up--;)srcPath.unshift('..');
    if (mustEndAbs && srcPath[0] !== '' && (!srcPath[0] || srcPath[0].charAt(0) !== '/')) srcPath.unshift('');
    if (hasTrailingSlash && srcPath.join('/').substr(-1) !== '/') srcPath.push('');
    var isAbsolute = srcPath[0] === '' || srcPath[0] && srcPath[0].charAt(0) === '/';
    // put the host back
    if (psychotic) {
        result.hostname = result.host = isAbsolute ? '' : srcPath.length ? srcPath.shift() : '';
        //occationaly the auth can get stuck only in host
        //this especially happens in cases like
        //url.resolveObject('mailto:local1@domain1', 'local2@domain2')
        var authInHost = result.host && result.host.indexOf('@') > 0 ? result.host.split('@') : false;
        if (authInHost) {
            result.auth = authInHost.shift();
            result.host = result.hostname = authInHost.shift();
        }
    }
    mustEndAbs = mustEndAbs || result.host && srcPath.length;
    if (mustEndAbs && !isAbsolute) srcPath.unshift('');
    if (!srcPath.length) {
        result.pathname = null;
        result.path = null;
    } else result.pathname = srcPath.join('/');
    //to support request.http
    if (!util.isNull(result.pathname) || !util.isNull(result.search)) result.path = (result.pathname ? result.pathname : '') + (result.search ? result.search : '');
    result.auth = relative.auth || result.auth;
    result.slashes = result.slashes || relative.slashes;
    result.href = result.format();
    return result;
};
Url.prototype.parseHost = function() {
    var host = this.host;
    var port = portPattern.exec(host);
    if (port) {
        port = port[0];
        if (port !== ':') this.port = port.substr(1);
        host = host.substr(0, host.length - port.length);
    }
    if (host) this.hostname = host;
};

},{"punycode":"5ZGx2","./util":"guGBf","querystring":"1n5rq"}],"5ZGx2":[function(require,module,exports) {
var global = arguments[3];
(function(root) {
    /** Detect free variables */ var freeExports = typeof exports == 'object' && exports && !exports.nodeType && exports;
    var freeModule = typeof module == 'object' && module && !module.nodeType && module;
    var freeGlobal = typeof global == 'object' && global;
    if (freeGlobal.global === freeGlobal || freeGlobal.window === freeGlobal || freeGlobal.self === freeGlobal) root = freeGlobal;
    /**
	 * The `punycode` object.
	 * @name punycode
	 * @type Object
	 */ var punycode, /** Highest positive signed 32-bit float value */ maxInt = 2147483647, /** Bootstring parameters */ base = 36, tMin = 1, tMax = 26, skew = 38, damp = 700, initialBias = 72, initialN = 128, delimiter = '-', /** Regular expressions */ regexPunycode = /^xn--/, regexNonASCII = /[^\x20-\x7E]/, regexSeparators = /[\x2E\u3002\uFF0E\uFF61]/g, /** Error messages */ errors = {
        'overflow': 'Overflow: input needs wider integers to process',
        'not-basic': 'Illegal input >= 0x80 (not a basic code point)',
        'invalid-input': 'Invalid input'
    }, /** Convenience shortcuts */ baseMinusTMin = base - tMin, floor = Math.floor, stringFromCharCode = String.fromCharCode, /** Temporary variable */ key;
    /*--------------------------------------------------------------------------*/ /**
	 * A generic error utility function.
	 * @private
	 * @param {String} type The error type.
	 * @returns {Error} Throws a `RangeError` with the applicable error message.
	 */ function error(type) {
        throw new RangeError(errors[type]);
    }
    /**
	 * A generic `Array#map` utility function.
	 * @private
	 * @param {Array} array The array to iterate over.
	 * @param {Function} callback The function that gets called for every array
	 * item.
	 * @returns {Array} A new array of values returned by the callback function.
	 */ function map(array, fn) {
        var length = array.length;
        var result = [];
        while(length--)result[length] = fn(array[length]);
        return result;
    }
    /**
	 * A simple `Array#map`-like wrapper to work with domain name strings or email
	 * addresses.
	 * @private
	 * @param {String} domain The domain name or email address.
	 * @param {Function} callback The function that gets called for every
	 * character.
	 * @returns {Array} A new string of characters returned by the callback
	 * function.
	 */ function mapDomain(string, fn) {
        var parts = string.split('@');
        var result = '';
        if (parts.length > 1) {
            // In email addresses, only the domain name should be punycoded. Leave
            // the local part (i.e. everything up to `@`) intact.
            result = parts[0] + '@';
            string = parts[1];
        }
        // Avoid `split(regex)` for IE8 compatibility. See #17.
        string = string.replace(regexSeparators, '\x2E');
        var labels = string.split('.');
        var encoded = map(labels, fn).join('.');
        return result + encoded;
    }
    /**
	 * Creates an array containing the numeric code points of each Unicode
	 * character in the string. While JavaScript uses UCS-2 internally,
	 * this function will convert a pair of surrogate halves (each of which
	 * UCS-2 exposes as separate characters) into a single code point,
	 * matching UTF-16.
	 * @see `punycode.ucs2.encode`
	 * @see <https://mathiasbynens.be/notes/javascript-encoding>
	 * @memberOf punycode.ucs2
	 * @name decode
	 * @param {String} string The Unicode input string (UCS-2).
	 * @returns {Array} The new array of code points.
	 */ function ucs2decode(string) {
        var output = [], counter = 0, length = string.length, value, extra;
        while(counter < length){
            value = string.charCodeAt(counter++);
            if (value >= 55296 && value <= 56319 && counter < length) {
                // high surrogate, and there is a next character
                extra = string.charCodeAt(counter++);
                if ((extra & 64512) == 56320) output.push(((value & 1023) << 10) + (extra & 1023) + 65536);
                else {
                    // unmatched surrogate; only append this code unit, in case the next
                    // code unit is the high surrogate of a surrogate pair
                    output.push(value);
                    counter--;
                }
            } else output.push(value);
        }
        return output;
    }
    /**
	 * Creates a string based on an array of numeric code points.
	 * @see `punycode.ucs2.decode`
	 * @memberOf punycode.ucs2
	 * @name encode
	 * @param {Array} codePoints The array of numeric code points.
	 * @returns {String} The new Unicode string (UCS-2).
	 */ function ucs2encode(array) {
        return map(array, function(value) {
            var output = '';
            if (value > 65535) {
                value -= 65536;
                output += stringFromCharCode(value >>> 10 & 1023 | 55296);
                value = 56320 | value & 1023;
            }
            output += stringFromCharCode(value);
            return output;
        }).join('');
    }
    /**
	 * Converts a basic code point into a digit/integer.
	 * @see `digitToBasic()`
	 * @private
	 * @param {Number} codePoint The basic numeric code point value.
	 * @returns {Number} The numeric value of a basic code point (for use in
	 * representing integers) in the range `0` to `base - 1`, or `base` if
	 * the code point does not represent a value.
	 */ function basicToDigit(codePoint) {
        if (codePoint - 48 < 10) return codePoint - 22;
        if (codePoint - 65 < 26) return codePoint - 65;
        if (codePoint - 97 < 26) return codePoint - 97;
        return base;
    }
    /**
	 * Converts a digit/integer into a basic code point.
	 * @see `basicToDigit()`
	 * @private
	 * @param {Number} digit The numeric value of a basic code point.
	 * @returns {Number} The basic code point whose value (when used for
	 * representing integers) is `digit`, which needs to be in the range
	 * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is
	 * used; else, the lowercase form is used. The behavior is undefined
	 * if `flag` is non-zero and `digit` has no uppercase form.
	 */ function digitToBasic(digit, flag) {
        //  0..25 map to ASCII a..z or A..Z
        // 26..35 map to ASCII 0..9
        return digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);
    }
    /**
	 * Bias adaptation function as per section 3.4 of RFC 3492.
	 * https://tools.ietf.org/html/rfc3492#section-3.4
	 * @private
	 */ function adapt(delta, numPoints, firstTime) {
        var k = 0;
        delta = firstTime ? floor(delta / damp) : delta >> 1;
        delta += floor(delta / numPoints);
        for(; delta > baseMinusTMin * tMax >> 1; k += base)delta = floor(delta / baseMinusTMin);
        return floor(k + (baseMinusTMin + 1) * delta / (delta + skew));
    }
    /**
	 * Converts a Punycode string of ASCII-only symbols to a string of Unicode
	 * symbols.
	 * @memberOf punycode
	 * @param {String} input The Punycode string of ASCII-only symbols.
	 * @returns {String} The resulting string of Unicode symbols.
	 */ function decode(input) {
        // Don't use UCS-2
        var output = [], inputLength = input.length, out, i = 0, n = initialN, bias = initialBias, basic, j, index, oldi, w, k, digit, t, /** Cached calculation results */ baseMinusT;
        // Handle the basic code points: let `basic` be the number of input code
        // points before the last delimiter, or `0` if there is none, then copy
        // the first basic code points to the output.
        basic = input.lastIndexOf(delimiter);
        if (basic < 0) basic = 0;
        for(j = 0; j < basic; ++j){
            // if it's not a basic code point
            if (input.charCodeAt(j) >= 128) error('not-basic');
            output.push(input.charCodeAt(j));
        }
        // Main decoding loop: start just after the last delimiter if any basic code
        // points were copied; start at the beginning otherwise.
        for(index = basic > 0 ? basic + 1 : 0; index < inputLength;){
            // `index` is the index of the next character to be consumed.
            // Decode a generalized variable-length integer into `delta`,
            // which gets added to `i`. The overflow checking is easier
            // if we increase `i` as we go, then subtract off its starting
            // value at the end to obtain `delta`.
            for(oldi = i, w = 1, k = base;; k += base){
                if (index >= inputLength) error('invalid-input');
                digit = basicToDigit(input.charCodeAt(index++));
                if (digit >= base || digit > floor((maxInt - i) / w)) error('overflow');
                i += digit * w;
                t = k <= bias ? tMin : k >= bias + tMax ? tMax : k - bias;
                if (digit < t) break;
                baseMinusT = base - t;
                if (w > floor(maxInt / baseMinusT)) error('overflow');
                w *= baseMinusT;
            }
            out = output.length + 1;
            bias = adapt(i - oldi, out, oldi == 0);
            // `i` was supposed to wrap around from `out` to `0`,
            // incrementing `n` each time, so we'll fix that now:
            if (floor(i / out) > maxInt - n) error('overflow');
            n += floor(i / out);
            i %= out;
            // Insert `n` at position `i` of the output
            output.splice(i++, 0, n);
        }
        return ucs2encode(output);
    }
    /**
	 * Converts a string of Unicode symbols (e.g. a domain name label) to a
	 * Punycode string of ASCII-only symbols.
	 * @memberOf punycode
	 * @param {String} input The string of Unicode symbols.
	 * @returns {String} The resulting Punycode string of ASCII-only symbols.
	 */ function encode(input) {
        var n, delta, handledCPCount, basicLength, bias, j, m, q, k, t, currentValue, output = [], /** `inputLength` will hold the number of code points in `input`. */ inputLength, /** Cached calculation results */ handledCPCountPlusOne, baseMinusT, qMinusT;
        // Convert the input in UCS-2 to Unicode
        input = ucs2decode(input);
        // Cache the length
        inputLength = input.length;
        // Initialize the state
        n = initialN;
        delta = 0;
        bias = initialBias;
        // Handle the basic code points
        for(j = 0; j < inputLength; ++j){
            currentValue = input[j];
            if (currentValue < 128) output.push(stringFromCharCode(currentValue));
        }
        handledCPCount = basicLength = output.length;
        // `handledCPCount` is the number of code points that have been handled;
        // `basicLength` is the number of basic code points.
        // Finish the basic string - if it is not empty - with a delimiter
        if (basicLength) output.push(delimiter);
        // Main encoding loop:
        while(handledCPCount < inputLength){
            // All non-basic code points < n have been handled already. Find the next
            // larger one:
            for(m = maxInt, j = 0; j < inputLength; ++j){
                currentValue = input[j];
                if (currentValue >= n && currentValue < m) m = currentValue;
            }
            // Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,
            // but guard against overflow
            handledCPCountPlusOne = handledCPCount + 1;
            if (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) error('overflow');
            delta += (m - n) * handledCPCountPlusOne;
            n = m;
            for(j = 0; j < inputLength; ++j){
                currentValue = input[j];
                if (currentValue < n && (++delta) > maxInt) error('overflow');
                if (currentValue == n) {
                    // Represent delta as a generalized variable-length integer
                    for(q = delta, k = base;; k += base){
                        t = k <= bias ? tMin : k >= bias + tMax ? tMax : k - bias;
                        if (q < t) break;
                        qMinusT = q - t;
                        baseMinusT = base - t;
                        output.push(stringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0)));
                        q = floor(qMinusT / baseMinusT);
                    }
                    output.push(stringFromCharCode(digitToBasic(q, 0)));
                    bias = adapt(delta, handledCPCountPlusOne, handledCPCount == basicLength);
                    delta = 0;
                    ++handledCPCount;
                }
            }
            ++delta;
            ++n;
        }
        return output.join('');
    }
    /**
	 * Converts a Punycode string representing a domain name or an email address
	 * to Unicode. Only the Punycoded parts of the input will be converted, i.e.
	 * it doesn't matter if you call it on a string that has already been
	 * converted to Unicode.
	 * @memberOf punycode
	 * @param {String} input The Punycoded domain name or email address to
	 * convert to Unicode.
	 * @returns {String} The Unicode representation of the given Punycode
	 * string.
	 */ function toUnicode(input) {
        return mapDomain(input, function(string) {
            return regexPunycode.test(string) ? decode(string.slice(4).toLowerCase()) : string;
        });
    }
    /**
	 * Converts a Unicode string representing a domain name or an email address to
	 * Punycode. Only the non-ASCII parts of the domain name will be converted,
	 * i.e. it doesn't matter if you call it with a domain that's already in
	 * ASCII.
	 * @memberOf punycode
	 * @param {String} input The domain name or email address to convert, as a
	 * Unicode string.
	 * @returns {String} The Punycode representation of the given domain name or
	 * email address.
	 */ function toASCII(input) {
        return mapDomain(input, function(string) {
            return regexNonASCII.test(string) ? 'xn--' + encode(string) : string;
        });
    }
    /*--------------------------------------------------------------------------*/ /** Define the public API */ punycode = {
        /**
		 * A string representing the current Punycode.js version number.
		 * @memberOf punycode
		 * @type String
		 */ 'version': '1.4.1',
        /**
		 * An object of methods to convert from JavaScript's internal character
		 * representation (UCS-2) to Unicode code points, and back.
		 * @see <https://mathiasbynens.be/notes/javascript-encoding>
		 * @memberOf punycode
		 * @type Object
		 */ 'ucs2': {
            'decode': ucs2decode,
            'encode': ucs2encode
        },
        'decode': decode,
        'encode': encode,
        'toASCII': toASCII,
        'toUnicode': toUnicode
    };
    /** Expose `punycode` */ // Some AMD build optimizers, like r.js, check for specific condition patterns
    // like the following:
    if (typeof define == 'function' && typeof define.amd == 'object' && define.amd) define('punycode', function() {
        return punycode;
    });
    else if (freeExports && freeModule) {
        if (module.exports == freeExports) // in Node.js, io.js, or RingoJS v0.8.0+
        freeModule.exports = punycode;
        else // in Narwhal or RingoJS v0.7.0-
        for(key in punycode)punycode.hasOwnProperty(key) && (freeExports[key] = punycode[key]);
    } else // in Rhino or a web browser
    root.punycode = punycode;
})(this);

},{}],"guGBf":[function(require,module,exports) {
'use strict';
module.exports = {
    isString: function(arg) {
        return typeof arg === 'string';
    },
    isObject: function(arg) {
        return typeof arg === 'object' && arg !== null;
    },
    isNull: function(arg) {
        return arg === null;
    },
    isNullOrUndefined: function(arg) {
        return arg == null;
    }
};

},{}],"1n5rq":[function(require,module,exports) {
'use strict';
exports.decode = exports.parse = require('./decode');
exports.encode = exports.stringify = require('./encode');

},{"./decode":"cjZl4","./encode":"3KOdD"}],"cjZl4":[function(require,module,exports) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
'use strict';
// If obj.hasOwnProperty has been overridden, then calling
// obj.hasOwnProperty(prop) will break.
// See: https://github.com/joyent/node/issues/1707
function hasOwnProperty(obj, prop) {
    return Object.prototype.hasOwnProperty.call(obj, prop);
}
module.exports = function(qs, sep, eq, options) {
    sep = sep || '&';
    eq = eq || '=';
    var obj = {
    };
    if (typeof qs !== 'string' || qs.length === 0) return obj;
    var regexp = /\+/g;
    qs = qs.split(sep);
    var maxKeys = 1000;
    if (options && typeof options.maxKeys === 'number') maxKeys = options.maxKeys;
    var len = qs.length;
    // maxKeys <= 0 means that we should not limit keys count
    if (maxKeys > 0 && len > maxKeys) len = maxKeys;
    for(var i = 0; i < len; ++i){
        var x = qs[i].replace(regexp, '%20'), idx = x.indexOf(eq), kstr, vstr, k, v;
        if (idx >= 0) {
            kstr = x.substr(0, idx);
            vstr = x.substr(idx + 1);
        } else {
            kstr = x;
            vstr = '';
        }
        k = decodeURIComponent(kstr);
        v = decodeURIComponent(vstr);
        if (!hasOwnProperty(obj, k)) obj[k] = v;
        else if (isArray(obj[k])) obj[k].push(v);
        else obj[k] = [
            obj[k],
            v
        ];
    }
    return obj;
};
var isArray = Array.isArray || function(xs) {
    return Object.prototype.toString.call(xs) === '[object Array]';
};

},{}],"3KOdD":[function(require,module,exports) {
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
'use strict';
var stringifyPrimitive = function(v) {
    switch(typeof v){
        case 'string':
            return v;
        case 'boolean':
            return v ? 'true' : 'false';
        case 'number':
            return isFinite(v) ? v : '';
        default:
            return '';
    }
};
module.exports = function(obj, sep, eq, name) {
    sep = sep || '&';
    eq = eq || '=';
    if (obj === null) obj = undefined;
    if (typeof obj === 'object') return map(objectKeys(obj), function(k) {
        var ks = encodeURIComponent(stringifyPrimitive(k)) + eq;
        if (isArray(obj[k])) return map(obj[k], function(v) {
            return ks + encodeURIComponent(stringifyPrimitive(v));
        }).join(sep);
        else return ks + encodeURIComponent(stringifyPrimitive(obj[k]));
    }).join(sep);
    if (!name) return '';
    return encodeURIComponent(stringifyPrimitive(name)) + eq + encodeURIComponent(stringifyPrimitive(obj));
};
var isArray = Array.isArray || function(xs) {
    return Object.prototype.toString.call(xs) === '[object Array]';
};
function map(xs, f) {
    if (xs.map) return xs.map(f);
    var res = [];
    for(var i = 0; i < xs.length; i++)res.push(f(xs[i], i));
    return res;
}
var objectKeys = Object.keys || function(obj) {
    var res = [];
    for(var key in obj)if (Object.prototype.hasOwnProperty.call(obj, key)) res.push(key);
    return res;
};

},{}],"lqjFh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ALPHA_MODES", ()=>ALPHA_MODES
);
parcelHelpers.export(exports, "BLEND_MODES", ()=>BLEND_MODES
);
parcelHelpers.export(exports, "BUFFER_BITS", ()=>BUFFER_BITS
);
parcelHelpers.export(exports, "BUFFER_TYPE", ()=>BUFFER_TYPE
);
parcelHelpers.export(exports, "CLEAR_MODES", ()=>CLEAR_MODES
);
parcelHelpers.export(exports, "DRAW_MODES", ()=>DRAW_MODES
);
parcelHelpers.export(exports, "ENV", ()=>ENV
);
parcelHelpers.export(exports, "FORMATS", ()=>FORMATS
);
parcelHelpers.export(exports, "GC_MODES", ()=>GC_MODES
);
parcelHelpers.export(exports, "MASK_TYPES", ()=>MASK_TYPES
);
parcelHelpers.export(exports, "MIPMAP_MODES", ()=>MIPMAP_MODES
);
parcelHelpers.export(exports, "MSAA_QUALITY", ()=>MSAA_QUALITY
);
parcelHelpers.export(exports, "PRECISION", ()=>PRECISION
);
parcelHelpers.export(exports, "RENDERER_TYPE", ()=>RENDERER_TYPE
);
parcelHelpers.export(exports, "SAMPLER_TYPES", ()=>SAMPLER_TYPES
);
parcelHelpers.export(exports, "SCALE_MODES", ()=>SCALE_MODES
);
parcelHelpers.export(exports, "TARGETS", ()=>TARGETS
);
parcelHelpers.export(exports, "TYPES", ()=>TYPES
);
parcelHelpers.export(exports, "WRAP_MODES", ()=>WRAP_MODES
);
/*!
 * @pixi/constants - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/constants is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ /**
 * Different types of environments for WebGL.
 *
 * @static
 * @memberof PIXI
 * @name ENV
 * @enum {number}
 * @property {number} WEBGL_LEGACY - Used for older v1 WebGL devices. PixiJS will aim to ensure compatibility
 *  with older / less advanced devices. If you experience unexplained flickering prefer this environment.
 * @property {number} WEBGL - Version 1 of WebGL
 * @property {number} WEBGL2 - Version 2 of WebGL
 */ var ENV;
(function(ENV1) {
    ENV1[ENV1["WEBGL_LEGACY"] = 0] = "WEBGL_LEGACY";
    ENV1[ENV1["WEBGL"] = 1] = "WEBGL";
    ENV1[ENV1["WEBGL2"] = 2] = "WEBGL2";
})(ENV || (ENV = {
}));
/**
 * Constant to identify the Renderer Type.
 *
 * @static
 * @memberof PIXI
 * @name RENDERER_TYPE
 * @enum {number}
 * @property {number} UNKNOWN - Unknown render type.
 * @property {number} WEBGL - WebGL render type.
 * @property {number} CANVAS - Canvas render type.
 */ var RENDERER_TYPE;
(function(RENDERER_TYPE1) {
    RENDERER_TYPE1[RENDERER_TYPE1["UNKNOWN"] = 0] = "UNKNOWN";
    RENDERER_TYPE1[RENDERER_TYPE1["WEBGL"] = 1] = "WEBGL";
    RENDERER_TYPE1[RENDERER_TYPE1["CANVAS"] = 2] = "CANVAS";
})(RENDERER_TYPE || (RENDERER_TYPE = {
}));
/**
 * Bitwise OR of masks that indicate the buffers to be cleared.
 *
 * @static
 * @memberof PIXI
 * @name BUFFER_BITS
 * @enum {number}
 * @property {number} COLOR - Indicates the buffers currently enabled for color writing.
 * @property {number} DEPTH - Indicates the depth buffer.
 * @property {number} STENCIL - Indicates the stencil buffer.
 */ var BUFFER_BITS;
(function(BUFFER_BITS1) {
    BUFFER_BITS1[BUFFER_BITS1["COLOR"] = 16384] = "COLOR";
    BUFFER_BITS1[BUFFER_BITS1["DEPTH"] = 256] = "DEPTH";
    BUFFER_BITS1[BUFFER_BITS1["STENCIL"] = 1024] = "STENCIL";
})(BUFFER_BITS || (BUFFER_BITS = {
}));
/**
 * Various blend modes supported by PIXI.
 *
 * IMPORTANT - The WebGL renderer only supports the NORMAL, ADD, MULTIPLY and SCREEN blend modes.
 * Anything else will silently act like NORMAL.
 *
 * @memberof PIXI
 * @name BLEND_MODES
 * @enum {number}
 * @property {number} NORMAL
 * @property {number} ADD
 * @property {number} MULTIPLY
 * @property {number} SCREEN
 * @property {number} OVERLAY
 * @property {number} DARKEN
 * @property {number} LIGHTEN
 * @property {number} COLOR_DODGE
 * @property {number} COLOR_BURN
 * @property {number} HARD_LIGHT
 * @property {number} SOFT_LIGHT
 * @property {number} DIFFERENCE
 * @property {number} EXCLUSION
 * @property {number} HUE
 * @property {number} SATURATION
 * @property {number} COLOR
 * @property {number} LUMINOSITY
 * @property {number} NORMAL_NPM
 * @property {number} ADD_NPM
 * @property {number} SCREEN_NPM
 * @property {number} NONE
 * @property {number} SRC_IN
 * @property {number} SRC_OUT
 * @property {number} SRC_ATOP
 * @property {number} DST_OVER
 * @property {number} DST_IN
 * @property {number} DST_OUT
 * @property {number} DST_ATOP
 * @property {number} SUBTRACT
 * @property {number} SRC_OVER
 * @property {number} ERASE
 * @property {number} XOR
 */ var BLEND_MODES;
(function(BLEND_MODES1) {
    BLEND_MODES1[BLEND_MODES1["NORMAL"] = 0] = "NORMAL";
    BLEND_MODES1[BLEND_MODES1["ADD"] = 1] = "ADD";
    BLEND_MODES1[BLEND_MODES1["MULTIPLY"] = 2] = "MULTIPLY";
    BLEND_MODES1[BLEND_MODES1["SCREEN"] = 3] = "SCREEN";
    BLEND_MODES1[BLEND_MODES1["OVERLAY"] = 4] = "OVERLAY";
    BLEND_MODES1[BLEND_MODES1["DARKEN"] = 5] = "DARKEN";
    BLEND_MODES1[BLEND_MODES1["LIGHTEN"] = 6] = "LIGHTEN";
    BLEND_MODES1[BLEND_MODES1["COLOR_DODGE"] = 7] = "COLOR_DODGE";
    BLEND_MODES1[BLEND_MODES1["COLOR_BURN"] = 8] = "COLOR_BURN";
    BLEND_MODES1[BLEND_MODES1["HARD_LIGHT"] = 9] = "HARD_LIGHT";
    BLEND_MODES1[BLEND_MODES1["SOFT_LIGHT"] = 10] = "SOFT_LIGHT";
    BLEND_MODES1[BLEND_MODES1["DIFFERENCE"] = 11] = "DIFFERENCE";
    BLEND_MODES1[BLEND_MODES1["EXCLUSION"] = 12] = "EXCLUSION";
    BLEND_MODES1[BLEND_MODES1["HUE"] = 13] = "HUE";
    BLEND_MODES1[BLEND_MODES1["SATURATION"] = 14] = "SATURATION";
    BLEND_MODES1[BLEND_MODES1["COLOR"] = 15] = "COLOR";
    BLEND_MODES1[BLEND_MODES1["LUMINOSITY"] = 16] = "LUMINOSITY";
    BLEND_MODES1[BLEND_MODES1["NORMAL_NPM"] = 17] = "NORMAL_NPM";
    BLEND_MODES1[BLEND_MODES1["ADD_NPM"] = 18] = "ADD_NPM";
    BLEND_MODES1[BLEND_MODES1["SCREEN_NPM"] = 19] = "SCREEN_NPM";
    BLEND_MODES1[BLEND_MODES1["NONE"] = 20] = "NONE";
    BLEND_MODES1[BLEND_MODES1["SRC_OVER"] = 0] = "SRC_OVER";
    BLEND_MODES1[BLEND_MODES1["SRC_IN"] = 21] = "SRC_IN";
    BLEND_MODES1[BLEND_MODES1["SRC_OUT"] = 22] = "SRC_OUT";
    BLEND_MODES1[BLEND_MODES1["SRC_ATOP"] = 23] = "SRC_ATOP";
    BLEND_MODES1[BLEND_MODES1["DST_OVER"] = 24] = "DST_OVER";
    BLEND_MODES1[BLEND_MODES1["DST_IN"] = 25] = "DST_IN";
    BLEND_MODES1[BLEND_MODES1["DST_OUT"] = 26] = "DST_OUT";
    BLEND_MODES1[BLEND_MODES1["DST_ATOP"] = 27] = "DST_ATOP";
    BLEND_MODES1[BLEND_MODES1["ERASE"] = 26] = "ERASE";
    BLEND_MODES1[BLEND_MODES1["SUBTRACT"] = 28] = "SUBTRACT";
    BLEND_MODES1[BLEND_MODES1["XOR"] = 29] = "XOR";
})(BLEND_MODES || (BLEND_MODES = {
}));
/**
 * Various webgl draw modes. These can be used to specify which GL drawMode to use
 * under certain situations and renderers.
 *
 * @memberof PIXI
 * @static
 * @name DRAW_MODES
 * @enum {number}
 * @property {number} POINTS
 * @property {number} LINES
 * @property {number} LINE_LOOP
 * @property {number} LINE_STRIP
 * @property {number} TRIANGLES
 * @property {number} TRIANGLE_STRIP
 * @property {number} TRIANGLE_FAN
 */ var DRAW_MODES;
(function(DRAW_MODES1) {
    DRAW_MODES1[DRAW_MODES1["POINTS"] = 0] = "POINTS";
    DRAW_MODES1[DRAW_MODES1["LINES"] = 1] = "LINES";
    DRAW_MODES1[DRAW_MODES1["LINE_LOOP"] = 2] = "LINE_LOOP";
    DRAW_MODES1[DRAW_MODES1["LINE_STRIP"] = 3] = "LINE_STRIP";
    DRAW_MODES1[DRAW_MODES1["TRIANGLES"] = 4] = "TRIANGLES";
    DRAW_MODES1[DRAW_MODES1["TRIANGLE_STRIP"] = 5] = "TRIANGLE_STRIP";
    DRAW_MODES1[DRAW_MODES1["TRIANGLE_FAN"] = 6] = "TRIANGLE_FAN";
})(DRAW_MODES || (DRAW_MODES = {
}));
/**
 * Various GL texture/resources formats.
 *
 * @memberof PIXI
 * @static
 * @name FORMATS
 * @enum {number}
 * @property {number} RGBA=6408
 * @property {number} RGB=6407
 * @property {number} RG=33319
 * @property {number} RED=6403
 * @property {number} RGBA_INTEGER=36249
 * @property {number} RGB_INTEGER=36248
 * @property {number} RG_INTEGER=33320
 * @property {number} RED_INTEGER=36244
 * @property {number} ALPHA=6406
 * @property {number} LUMINANCE=6409
 * @property {number} LUMINANCE_ALPHA=6410
 * @property {number} DEPTH_COMPONENT=6402
 * @property {number} DEPTH_STENCIL=34041
 */ var FORMATS;
(function(FORMATS1) {
    FORMATS1[FORMATS1["RGBA"] = 6408] = "RGBA";
    FORMATS1[FORMATS1["RGB"] = 6407] = "RGB";
    FORMATS1[FORMATS1["RG"] = 33319] = "RG";
    FORMATS1[FORMATS1["RED"] = 6403] = "RED";
    FORMATS1[FORMATS1["RGBA_INTEGER"] = 36249] = "RGBA_INTEGER";
    FORMATS1[FORMATS1["RGB_INTEGER"] = 36248] = "RGB_INTEGER";
    FORMATS1[FORMATS1["RG_INTEGER"] = 33320] = "RG_INTEGER";
    FORMATS1[FORMATS1["RED_INTEGER"] = 36244] = "RED_INTEGER";
    FORMATS1[FORMATS1["ALPHA"] = 6406] = "ALPHA";
    FORMATS1[FORMATS1["LUMINANCE"] = 6409] = "LUMINANCE";
    FORMATS1[FORMATS1["LUMINANCE_ALPHA"] = 6410] = "LUMINANCE_ALPHA";
    FORMATS1[FORMATS1["DEPTH_COMPONENT"] = 6402] = "DEPTH_COMPONENT";
    FORMATS1[FORMATS1["DEPTH_STENCIL"] = 34041] = "DEPTH_STENCIL";
})(FORMATS || (FORMATS = {
}));
/**
 * Various GL target types.
 *
 * @memberof PIXI
 * @static
 * @name TARGETS
 * @enum {number}
 * @property {number} TEXTURE_2D=3553
 * @property {number} TEXTURE_CUBE_MAP=34067
 * @property {number} TEXTURE_2D_ARRAY=35866
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_X=34069
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_X=34070
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_Y=34071
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_Y=34072
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_Z=34073
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_Z=34074
 */ var TARGETS;
(function(TARGETS1) {
    TARGETS1[TARGETS1["TEXTURE_2D"] = 3553] = "TEXTURE_2D";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP"] = 34067] = "TEXTURE_CUBE_MAP";
    TARGETS1[TARGETS1["TEXTURE_2D_ARRAY"] = 35866] = "TEXTURE_2D_ARRAY";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_X"] = 34069] = "TEXTURE_CUBE_MAP_POSITIVE_X";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_X"] = 34070] = "TEXTURE_CUBE_MAP_NEGATIVE_X";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_Y"] = 34071] = "TEXTURE_CUBE_MAP_POSITIVE_Y";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_Y"] = 34072] = "TEXTURE_CUBE_MAP_NEGATIVE_Y";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_Z"] = 34073] = "TEXTURE_CUBE_MAP_POSITIVE_Z";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_Z"] = 34074] = "TEXTURE_CUBE_MAP_NEGATIVE_Z";
})(TARGETS || (TARGETS = {
}));
/**
 * Various GL data format types.
 *
 * @memberof PIXI
 * @static
 * @name TYPES
 * @enum {number}
 * @property {number} UNSIGNED_BYTE=5121
 * @property {number} UNSIGNED_SHORT=5123
 * @property {number} UNSIGNED_SHORT_5_6_5=33635
 * @property {number} UNSIGNED_SHORT_4_4_4_4=32819
 * @property {number} UNSIGNED_SHORT_5_5_5_1=32820
 * @property {number} UNSIGNED_INT=5125
 * @property {number} UNSIGNED_INT_10F_11F_11F_REV=35899
 * @property {number} UNSIGNED_INT_2_10_10_10_REV=33640
 * @property {number} UNSIGNED_INT_24_8=34042
 * @property {number} UNSIGNED_INT_5_9_9_9_REV=35902
 * @property {number} BYTE=5120
 * @property {number} SHORT=5122
 * @property {number} INT=5124
 * @property {number} FLOAT=5126
 * @property {number} FLOAT_32_UNSIGNED_INT_24_8_REV=36269
 * @property {number} HALF_FLOAT=36193
 */ var TYPES;
(function(TYPES1) {
    TYPES1[TYPES1["UNSIGNED_BYTE"] = 5121] = "UNSIGNED_BYTE";
    TYPES1[TYPES1["UNSIGNED_SHORT"] = 5123] = "UNSIGNED_SHORT";
    TYPES1[TYPES1["UNSIGNED_SHORT_5_6_5"] = 33635] = "UNSIGNED_SHORT_5_6_5";
    TYPES1[TYPES1["UNSIGNED_SHORT_4_4_4_4"] = 32819] = "UNSIGNED_SHORT_4_4_4_4";
    TYPES1[TYPES1["UNSIGNED_SHORT_5_5_5_1"] = 32820] = "UNSIGNED_SHORT_5_5_5_1";
    TYPES1[TYPES1["UNSIGNED_INT"] = 5125] = "UNSIGNED_INT";
    TYPES1[TYPES1["UNSIGNED_INT_10F_11F_11F_REV"] = 35899] = "UNSIGNED_INT_10F_11F_11F_REV";
    TYPES1[TYPES1["UNSIGNED_INT_2_10_10_10_REV"] = 33640] = "UNSIGNED_INT_2_10_10_10_REV";
    TYPES1[TYPES1["UNSIGNED_INT_24_8"] = 34042] = "UNSIGNED_INT_24_8";
    TYPES1[TYPES1["UNSIGNED_INT_5_9_9_9_REV"] = 35902] = "UNSIGNED_INT_5_9_9_9_REV";
    TYPES1[TYPES1["BYTE"] = 5120] = "BYTE";
    TYPES1[TYPES1["SHORT"] = 5122] = "SHORT";
    TYPES1[TYPES1["INT"] = 5124] = "INT";
    TYPES1[TYPES1["FLOAT"] = 5126] = "FLOAT";
    TYPES1[TYPES1["FLOAT_32_UNSIGNED_INT_24_8_REV"] = 36269] = "FLOAT_32_UNSIGNED_INT_24_8_REV";
    TYPES1[TYPES1["HALF_FLOAT"] = 36193] = "HALF_FLOAT";
})(TYPES || (TYPES = {
}));
/**
 * Various sampler types. Correspond to `sampler`, `isampler`, `usampler` GLSL types respectively.
 * WebGL1 works only with FLOAT.
 *
 * @memberof PIXI
 * @static
 * @name SAMPLER_TYPES
 * @enum {number}
 * @property {number} FLOAT=0
 * @property {number} INT=1
 * @property {number} UINT=2
 */ var SAMPLER_TYPES;
(function(SAMPLER_TYPES1) {
    SAMPLER_TYPES1[SAMPLER_TYPES1["FLOAT"] = 0] = "FLOAT";
    SAMPLER_TYPES1[SAMPLER_TYPES1["INT"] = 1] = "INT";
    SAMPLER_TYPES1[SAMPLER_TYPES1["UINT"] = 2] = "UINT";
})(SAMPLER_TYPES || (SAMPLER_TYPES = {
}));
/**
 * The scale modes that are supported by pixi.
 *
 * The {@link PIXI.settings.SCALE_MODE} scale mode affects the default scaling mode of future operations.
 * It can be re-assigned to either LINEAR or NEAREST, depending upon suitability.
 *
 * @memberof PIXI
 * @static
 * @name SCALE_MODES
 * @enum {number}
 * @property {number} LINEAR Smooth scaling
 * @property {number} NEAREST Pixelating scaling
 */ var SCALE_MODES;
(function(SCALE_MODES1) {
    SCALE_MODES1[SCALE_MODES1["NEAREST"] = 0] = "NEAREST";
    SCALE_MODES1[SCALE_MODES1["LINEAR"] = 1] = "LINEAR";
})(SCALE_MODES || (SCALE_MODES = {
}));
/**
 * The wrap modes that are supported by pixi.
 *
 * The {@link PIXI.settings.WRAP_MODE} wrap mode affects the default wrapping mode of future operations.
 * It can be re-assigned to either CLAMP or REPEAT, depending upon suitability.
 * If the texture is non power of two then clamp will be used regardless as WebGL can
 * only use REPEAT if the texture is po2.
 *
 * This property only affects WebGL.
 *
 * @name WRAP_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} CLAMP - The textures uvs are clamped
 * @property {number} REPEAT - The texture uvs tile and repeat
 * @property {number} MIRRORED_REPEAT - The texture uvs tile and repeat with mirroring
 */ var WRAP_MODES;
(function(WRAP_MODES1) {
    WRAP_MODES1[WRAP_MODES1["CLAMP"] = 33071] = "CLAMP";
    WRAP_MODES1[WRAP_MODES1["REPEAT"] = 10497] = "REPEAT";
    WRAP_MODES1[WRAP_MODES1["MIRRORED_REPEAT"] = 33648] = "MIRRORED_REPEAT";
})(WRAP_MODES || (WRAP_MODES = {
}));
/**
 * Mipmap filtering modes that are supported by pixi.
 *
 * The {@link PIXI.settings.MIPMAP_TEXTURES} affects default texture filtering.
 * Mipmaps are generated for a baseTexture if its `mipmap` field is `ON`,
 * or its `POW2` and texture dimensions are powers of 2.
 * Due to platform restriction, `ON` option will work like `POW2` for webgl-1.
 *
 * This property only affects WebGL.
 *
 * @name MIPMAP_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} OFF - No mipmaps
 * @property {number} POW2 - Generate mipmaps if texture dimensions are pow2
 * @property {number} ON - Always generate mipmaps
 * @property {number} ON_MANUAL - Use mipmaps, but do not auto-generate them; this is used with a resource
 *   that supports buffering each level-of-detail.
 */ var MIPMAP_MODES;
(function(MIPMAP_MODES1) {
    MIPMAP_MODES1[MIPMAP_MODES1["OFF"] = 0] = "OFF";
    MIPMAP_MODES1[MIPMAP_MODES1["POW2"] = 1] = "POW2";
    MIPMAP_MODES1[MIPMAP_MODES1["ON"] = 2] = "ON";
    MIPMAP_MODES1[MIPMAP_MODES1["ON_MANUAL"] = 3] = "ON_MANUAL";
})(MIPMAP_MODES || (MIPMAP_MODES = {
}));
/**
 * How to treat textures with premultiplied alpha
 *
 * @name ALPHA_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NO_PREMULTIPLIED_ALPHA - Source is not premultiplied, leave it like that.
 *  Option for compressed and data textures that are created from typed arrays.
 * @property {number} PREMULTIPLY_ON_UPLOAD - Source is not premultiplied, premultiply on upload.
 *  Default option, used for all loaded images.
 * @property {number} PREMULTIPLIED_ALPHA - Source is already premultiplied
 *  Example: spine atlases with `_pma` suffix.
 * @property {number} NPM - Alias for NO_PREMULTIPLIED_ALPHA.
 * @property {number} UNPACK - Default option, alias for PREMULTIPLY_ON_UPLOAD.
 * @property {number} PMA - Alias for PREMULTIPLIED_ALPHA.
 */ var ALPHA_MODES;
(function(ALPHA_MODES1) {
    ALPHA_MODES1[ALPHA_MODES1["NPM"] = 0] = "NPM";
    ALPHA_MODES1[ALPHA_MODES1["UNPACK"] = 1] = "UNPACK";
    ALPHA_MODES1[ALPHA_MODES1["PMA"] = 2] = "PMA";
    ALPHA_MODES1[ALPHA_MODES1["NO_PREMULTIPLIED_ALPHA"] = 0] = "NO_PREMULTIPLIED_ALPHA";
    ALPHA_MODES1[ALPHA_MODES1["PREMULTIPLY_ON_UPLOAD"] = 1] = "PREMULTIPLY_ON_UPLOAD";
    ALPHA_MODES1[ALPHA_MODES1["PREMULTIPLY_ALPHA"] = 2] = "PREMULTIPLY_ALPHA";
})(ALPHA_MODES || (ALPHA_MODES = {
}));
/**
 * Configure whether filter textures are cleared after binding.
 *
 * Filter textures need not be cleared if the filter does not use pixel blending. {@link CLEAR_MODES.BLIT} will detect
 * this and skip clearing as an optimization.
 *
 * @name CLEAR_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} BLEND - Do not clear the filter texture. The filter's output will blend on top of the output texture.
 * @property {number} CLEAR - Always clear the filter texture.
 * @property {number} BLIT - Clear only if {@link FilterSystem.forceClear} is set or if the filter uses pixel blending.
 * @property {number} NO - Alias for BLEND, same as `false` in earlier versions
 * @property {number} YES - Alias for CLEAR, same as `true` in earlier versions
 * @property {number} AUTO - Alias for BLIT
 */ var CLEAR_MODES;
(function(CLEAR_MODES1) {
    CLEAR_MODES1[CLEAR_MODES1["NO"] = 0] = "NO";
    CLEAR_MODES1[CLEAR_MODES1["YES"] = 1] = "YES";
    CLEAR_MODES1[CLEAR_MODES1["AUTO"] = 2] = "AUTO";
    CLEAR_MODES1[CLEAR_MODES1["BLEND"] = 0] = "BLEND";
    CLEAR_MODES1[CLEAR_MODES1["CLEAR"] = 1] = "CLEAR";
    CLEAR_MODES1[CLEAR_MODES1["BLIT"] = 2] = "BLIT";
})(CLEAR_MODES || (CLEAR_MODES = {
}));
/**
 * The gc modes that are supported by pixi.
 *
 * The {@link PIXI.settings.GC_MODE} Garbage Collection mode for PixiJS textures is AUTO
 * If set to GC_MODE, the renderer will occasionally check textures usage. If they are not
 * used for a specified period of time they will be removed from the GPU. They will of course
 * be uploaded again when they are required. This is a silent behind the scenes process that
 * should ensure that the GPU does not  get filled up.
 *
 * Handy for mobile devices!
 * This property only affects WebGL.
 *
 * @name GC_MODES
 * @enum {number}
 * @static
 * @memberof PIXI
 * @property {number} AUTO - Garbage collection will happen periodically automatically
 * @property {number} MANUAL - Garbage collection will need to be called manually
 */ var GC_MODES;
(function(GC_MODES1) {
    GC_MODES1[GC_MODES1["AUTO"] = 0] = "AUTO";
    GC_MODES1[GC_MODES1["MANUAL"] = 1] = "MANUAL";
})(GC_MODES || (GC_MODES = {
}));
/**
 * Constants that specify float precision in shaders.
 *
 * @name PRECISION
 * @memberof PIXI
 * @constant
 * @static
 * @enum {string}
 * @property {string} LOW='lowp'
 * @property {string} MEDIUM='mediump'
 * @property {string} HIGH='highp'
 */ var PRECISION;
(function(PRECISION1) {
    PRECISION1["LOW"] = "lowp";
    PRECISION1["MEDIUM"] = "mediump";
    PRECISION1["HIGH"] = "highp";
})(PRECISION || (PRECISION = {
}));
/**
 * Constants for mask implementations.
 * We use `type` suffix because it leads to very different behaviours
 *
 * @name MASK_TYPES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NONE - Mask is ignored
 * @property {number} SCISSOR - Scissor mask, rectangle on screen, cheap
 * @property {number} STENCIL - Stencil mask, 1-bit, medium, works only if renderer supports stencil
 * @property {number} SPRITE - Mask that uses SpriteMaskFilter, uses temporary RenderTexture
 */ var MASK_TYPES;
(function(MASK_TYPES1) {
    MASK_TYPES1[MASK_TYPES1["NONE"] = 0] = "NONE";
    MASK_TYPES1[MASK_TYPES1["SCISSOR"] = 1] = "SCISSOR";
    MASK_TYPES1[MASK_TYPES1["STENCIL"] = 2] = "STENCIL";
    MASK_TYPES1[MASK_TYPES1["SPRITE"] = 3] = "SPRITE";
})(MASK_TYPES || (MASK_TYPES = {
}));
/**
 * Constants for multi-sampling antialiasing.
 *
 * @see PIXI.Framebuffer#multisample
 *
 * @name MSAA_QUALITY
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NONE - No multisampling for this renderTexture
 * @property {number} LOW - Try 2 samples
 * @property {number} MEDIUM - Try 4 samples
 * @property {number} HIGH - Try 8 samples
 */ var MSAA_QUALITY;
(function(MSAA_QUALITY1) {
    MSAA_QUALITY1[MSAA_QUALITY1["NONE"] = 0] = "NONE";
    MSAA_QUALITY1[MSAA_QUALITY1["LOW"] = 2] = "LOW";
    MSAA_QUALITY1[MSAA_QUALITY1["MEDIUM"] = 4] = "MEDIUM";
    MSAA_QUALITY1[MSAA_QUALITY1["HIGH"] = 8] = "HIGH";
})(MSAA_QUALITY || (MSAA_QUALITY = {
}));
/**
 * Constants for various buffer types in Pixi
 *
 * @see PIXI.BUFFER_TYPE
 *
 * @name BUFFER_TYPE
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} ELEMENT_ARRAY_BUFFER - buffer type for using as an index buffer
 * @property {number} ARRAY_BUFFER - buffer type for using attribute data
 * @property {number} UNIFORM_BUFFER - the buffer type is for uniform buffer objects
 */ var BUFFER_TYPE;
(function(BUFFER_TYPE1) {
    BUFFER_TYPE1[BUFFER_TYPE1["ELEMENT_ARRAY_BUFFER"] = 34963] = "ELEMENT_ARRAY_BUFFER";
    BUFFER_TYPE1[BUFFER_TYPE1["ARRAY_BUFFER"] = 34962] = "ARRAY_BUFFER";
    // NOT YET SUPPORTED
    BUFFER_TYPE1[BUFFER_TYPE1["UNIFORM_BUFFER"] = 35345] = "UNIFORM_BUFFER";
})(BUFFER_TYPE || (BUFFER_TYPE = {
}));

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5A0wu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AccessibilityManager", ()=>AccessibilityManager
);
parcelHelpers.export(exports, "accessibleTarget", ()=>accessibleTarget
);
/*!
 * @pixi/accessibility - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/accessibility is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _display = require("@pixi/display");
var _utils = require("@pixi/utils");
/**
 * Default property values of accessible objects
 * used by {@link PIXI.AccessibilityManager}.
 *
 * @private
 * @function accessibleTarget
 * @memberof PIXI
 * @type {Object}
 * @example
 *      function MyObject() {}
 *
 *      Object.assign(
 *          MyObject.prototype,
 *          PIXI.accessibleTarget
 *      );
 */ var accessibleTarget = {
    /**
     *  Flag for if the object is accessible. If true AccessibilityManager will overlay a
     *   shadow div with attributes set
     *
     * @member {boolean}
     * @memberof PIXI.DisplayObject#
     */ accessible: false,
    /**
     * Sets the title attribute of the shadow div
     * If accessibleTitle AND accessibleHint has not been this will default to 'displayObject [tabIndex]'
     *
     * @member {?string}
     * @memberof PIXI.DisplayObject#
     */ accessibleTitle: null,
    /**
     * Sets the aria-label attribute of the shadow div
     *
     * @member {string}
     * @memberof PIXI.DisplayObject#
     */ accessibleHint: null,
    /**
     * @member {number}
     * @memberof PIXI.DisplayObject#
     * @private
     * @todo Needs docs.
     */ tabIndex: 0,
    /**
     * @member {boolean}
     * @memberof PIXI.DisplayObject#
     * @todo Needs docs.
     */ _accessibleActive: false,
    /**
     * @member {boolean}
     * @memberof PIXI.DisplayObject#
     * @todo Needs docs.
     */ _accessibleDiv: null,
    /**
     * Specify the type of div the accessible layer is. Screen readers treat the element differently
     * depending on this type. Defaults to button.
     *
     * @member {string}
     * @memberof PIXI.DisplayObject#
     * @default 'button'
     */ accessibleType: 'button',
    /**
     * Specify the pointer-events the accessible div will use
     * Defaults to auto.
     *
     * @member {string}
     * @memberof PIXI.DisplayObject#
     * @default 'auto'
     */ accessiblePointerEvents: 'auto',
    /**
     * Setting to false will prevent any children inside this container to
     * be accessible. Defaults to true.
     *
     * @member {boolean}
     * @memberof PIXI.DisplayObject#
     * @default true
     */ accessibleChildren: true,
    renderId: -1
};
// add some extra variables to the container..
_display.DisplayObject.mixin(accessibleTarget);
var KEY_CODE_TAB = 9;
var DIV_TOUCH_SIZE = 100;
var DIV_TOUCH_POS_X = 0;
var DIV_TOUCH_POS_Y = 0;
var DIV_TOUCH_ZINDEX = 2;
var DIV_HOOK_SIZE = 1;
var DIV_HOOK_POS_X = -1000;
var DIV_HOOK_POS_Y = -1000;
var DIV_HOOK_ZINDEX = 2;
/**
 * The Accessibility manager recreates the ability to tab and have content read by screen readers.
 * This is very important as it can possibly help people with disabilities access PixiJS content.
 *
 * A DisplayObject can be made accessible just like it can be made interactive. This manager will map the
 * events as if the mouse was being used, minimizing the effort required to implement.
 *
 * An instance of this class is automatically created by default, and can be found at `renderer.plugins.accessibility`
 *
 * @class
 * @memberof PIXI
 */ var AccessibilityManager = function() {
    /**
     * @param {PIXI.CanvasRenderer|PIXI.Renderer} renderer - A reference to the current renderer
     */ function AccessibilityManager1(renderer) {
        /** Setting this to true will visually show the divs. */ this.debug = false;
        /** Internal variable, see isActive getter. */ this._isActive = false;
        /** Internal variable, see isMobileAccessibility getter. */ this._isMobileAccessibility = false;
        /** A simple pool for storing divs. */ this.pool = [];
        /** This is a tick used to check if an object is no longer being rendered. */ this.renderId = 0;
        /** The array of currently active accessible items. */ this.children = [];
        /** Count to throttle div updates on android devices. */ this.androidUpdateCount = 0;
        /**  The frequency to update the div elements. */ this.androidUpdateFrequency = 500; // 2fps
        this._hookDiv = null;
        if (_utils.isMobile.tablet || _utils.isMobile.phone) this.createTouchHook();
        // first we create a div that will sit over the PixiJS element. This is where the div overlays will go.
        var div = document.createElement('div');
        div.style.width = DIV_TOUCH_SIZE + "px";
        div.style.height = DIV_TOUCH_SIZE + "px";
        div.style.position = 'absolute';
        div.style.top = DIV_TOUCH_POS_X + "px";
        div.style.left = DIV_TOUCH_POS_Y + "px";
        div.style.zIndex = DIV_TOUCH_ZINDEX.toString();
        this.div = div;
        this.renderer = renderer;
        /**
         * pre-bind the functions
         *
         * @type {Function}
         * @private
         */ this._onKeyDown = this._onKeyDown.bind(this);
        /**
         * pre-bind the functions
         *
         * @type {Function}
         * @private
         */ this._onMouseMove = this._onMouseMove.bind(this);
        // let listen for tab.. once pressed we can fire up and show the accessibility layer
        self.addEventListener('keydown', this._onKeyDown, false);
    }
    Object.defineProperty(AccessibilityManager1.prototype, "isActive", {
        /**
         * Value of `true` if accessibility is currently active and accessibility layers are showing.
         * @member {boolean}
         * @readonly
         */ get: function() {
            return this._isActive;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(AccessibilityManager1.prototype, "isMobileAccessibility", {
        /**
         * Value of `true` if accessibility is enabled for touch devices.
         * @member {boolean}
         * @readonly
         */ get: function() {
            return this._isMobileAccessibility;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Creates the touch hooks.
     *
     * @private
     */ AccessibilityManager1.prototype.createTouchHook = function() {
        var _this = this;
        var hookDiv = document.createElement('button');
        hookDiv.style.width = DIV_HOOK_SIZE + "px";
        hookDiv.style.height = DIV_HOOK_SIZE + "px";
        hookDiv.style.position = 'absolute';
        hookDiv.style.top = DIV_HOOK_POS_X + "px";
        hookDiv.style.left = DIV_HOOK_POS_Y + "px";
        hookDiv.style.zIndex = DIV_HOOK_ZINDEX.toString();
        hookDiv.style.backgroundColor = '#FF0000';
        hookDiv.title = 'select to enable accessibility for this content';
        hookDiv.addEventListener('focus', function() {
            _this._isMobileAccessibility = true;
            _this.activate();
            _this.destroyTouchHook();
        });
        document.body.appendChild(hookDiv);
        this._hookDiv = hookDiv;
    };
    /**
     * Destroys the touch hooks.
     *
     * @private
     */ AccessibilityManager1.prototype.destroyTouchHook = function() {
        if (!this._hookDiv) return;
        document.body.removeChild(this._hookDiv);
        this._hookDiv = null;
    };
    /**
     * Activating will cause the Accessibility layer to be shown.
     * This is called when a user presses the tab key.
     *
     * @private
     */ AccessibilityManager1.prototype.activate = function() {
        var _a;
        if (this._isActive) return;
        this._isActive = true;
        self.document.addEventListener('mousemove', this._onMouseMove, true);
        self.removeEventListener('keydown', this._onKeyDown, false);
        this.renderer.on('postrender', this.update, this);
        (_a = this.renderer.view.parentNode) === null || _a === void 0 || _a.appendChild(this.div);
    };
    /**
     * Deactivating will cause the Accessibility layer to be hidden.
     * This is called when a user moves the mouse.
     *
     * @private
     */ AccessibilityManager1.prototype.deactivate = function() {
        var _a;
        if (!this._isActive || this._isMobileAccessibility) return;
        this._isActive = false;
        self.document.removeEventListener('mousemove', this._onMouseMove, true);
        self.addEventListener('keydown', this._onKeyDown, false);
        this.renderer.off('postrender', this.update);
        (_a = this.div.parentNode) === null || _a === void 0 || _a.removeChild(this.div);
    };
    /**
     * This recursive function will run through the scene graph and add any new accessible objects to the DOM layer.
     *
     * @private
     * @param {PIXI.Container} displayObject - The DisplayObject to check.
     */ AccessibilityManager1.prototype.updateAccessibleObjects = function(displayObject) {
        if (!displayObject.visible || !displayObject.accessibleChildren) return;
        if (displayObject.accessible && displayObject.interactive) {
            if (!displayObject._accessibleActive) this.addChild(displayObject);
            displayObject.renderId = this.renderId;
        }
        var children = displayObject.children;
        for(var i = 0; i < children.length; i++)this.updateAccessibleObjects(children[i]);
    };
    /**
     * Before each render this function will ensure that all divs are mapped correctly to their DisplayObjects.
     *
     * @private
     */ AccessibilityManager1.prototype.update = function() {
        /* On Android default web browser, tab order seems to be calculated by position rather than tabIndex,
        *  moving buttons can cause focus to flicker between two buttons making it hard/impossible to navigate,
        *  so I am just running update every half a second, seems to fix it.
        */ var now = performance.now();
        if (_utils.isMobile.android.device && now < this.androidUpdateCount) return;
        this.androidUpdateCount = now + this.androidUpdateFrequency;
        if (!this.renderer.renderingToScreen) return;
        // update children...
        if (this.renderer._lastObjectRendered) this.updateAccessibleObjects(this.renderer._lastObjectRendered);
        var _a = this.renderer.view.getBoundingClientRect(), left = _a.left, top = _a.top, width = _a.width, height = _a.height;
        var _b = this.renderer, viewWidth = _b.width, viewHeight = _b.height, resolution = _b.resolution;
        var sx = width / viewWidth * resolution;
        var sy = height / viewHeight * resolution;
        var div = this.div;
        div.style.left = left + "px";
        div.style.top = top + "px";
        div.style.width = viewWidth + "px";
        div.style.height = viewHeight + "px";
        for(var i = 0; i < this.children.length; i++){
            var child = this.children[i];
            if (child.renderId !== this.renderId) {
                child._accessibleActive = false;
                _utils.removeItems(this.children, i, 1);
                this.div.removeChild(child._accessibleDiv);
                this.pool.push(child._accessibleDiv);
                child._accessibleDiv = null;
                i--;
            } else {
                // map div to display..
                div = child._accessibleDiv;
                var hitArea = child.hitArea;
                var wt = child.worldTransform;
                if (child.hitArea) {
                    div.style.left = (wt.tx + hitArea.x * wt.a) * sx + "px";
                    div.style.top = (wt.ty + hitArea.y * wt.d) * sy + "px";
                    div.style.width = hitArea.width * wt.a * sx + "px";
                    div.style.height = hitArea.height * wt.d * sy + "px";
                } else {
                    hitArea = child.getBounds();
                    this.capHitArea(hitArea);
                    div.style.left = hitArea.x * sx + "px";
                    div.style.top = hitArea.y * sy + "px";
                    div.style.width = hitArea.width * sx + "px";
                    div.style.height = hitArea.height * sy + "px";
                    // update button titles and hints if they exist and they've changed
                    if (div.title !== child.accessibleTitle && child.accessibleTitle !== null) div.title = child.accessibleTitle;
                    if (div.getAttribute('aria-label') !== child.accessibleHint && child.accessibleHint !== null) div.setAttribute('aria-label', child.accessibleHint);
                }
                // the title or index may have changed, if so lets update it!
                if (child.accessibleTitle !== div.title || child.tabIndex !== div.tabIndex) {
                    div.title = child.accessibleTitle;
                    div.tabIndex = child.tabIndex;
                    if (this.debug) this.updateDebugHTML(div);
                }
            }
        }
        // increment the render id..
        this.renderId++;
    };
    /**
     * private function that will visually add the information to the
     * accessability div
     *
     * @param {HTMLElement} div
     */ AccessibilityManager1.prototype.updateDebugHTML = function(div) {
        div.innerHTML = "type: " + div.type + "</br> title : " + div.title + "</br> tabIndex: " + div.tabIndex;
    };
    /**
     * Adjust the hit area based on the bounds of a display object
     *
     * @param {PIXI.Rectangle} hitArea - Bounds of the child
     */ AccessibilityManager1.prototype.capHitArea = function(hitArea) {
        if (hitArea.x < 0) {
            hitArea.width += hitArea.x;
            hitArea.x = 0;
        }
        if (hitArea.y < 0) {
            hitArea.height += hitArea.y;
            hitArea.y = 0;
        }
        var _a = this.renderer, viewWidth = _a.width, viewHeight = _a.height;
        if (hitArea.x + hitArea.width > viewWidth) hitArea.width = viewWidth - hitArea.x;
        if (hitArea.y + hitArea.height > viewHeight) hitArea.height = viewHeight - hitArea.y;
    };
    /**
     * Adds a DisplayObject to the accessibility manager
     *
     * @private
     * @param {PIXI.DisplayObject} displayObject - The child to make accessible.
     */ AccessibilityManager1.prototype.addChild = function(displayObject) {
        //    this.activate();
        var div = this.pool.pop();
        if (!div) {
            div = document.createElement('button');
            div.style.width = DIV_TOUCH_SIZE + "px";
            div.style.height = DIV_TOUCH_SIZE + "px";
            div.style.backgroundColor = this.debug ? 'rgba(255,255,255,0.5)' : 'transparent';
            div.style.position = 'absolute';
            div.style.zIndex = DIV_TOUCH_ZINDEX.toString();
            div.style.borderStyle = 'none';
            // ARIA attributes ensure that button title and hint updates are announced properly
            if (navigator.userAgent.toLowerCase().indexOf('chrome') > -1) // Chrome doesn't need aria-live to work as intended; in fact it just gets more confused.
            div.setAttribute('aria-live', 'off');
            else div.setAttribute('aria-live', 'polite');
            if (navigator.userAgent.match(/rv:.*Gecko\//)) // FireFox needs this to announce only the new button name
            div.setAttribute('aria-relevant', 'additions');
            else // required by IE, other browsers don't much care
            div.setAttribute('aria-relevant', 'text');
            div.addEventListener('click', this._onClick.bind(this));
            div.addEventListener('focus', this._onFocus.bind(this));
            div.addEventListener('focusout', this._onFocusOut.bind(this));
        }
        // set pointer events
        div.style.pointerEvents = displayObject.accessiblePointerEvents;
        // set the type, this defaults to button!
        div.type = displayObject.accessibleType;
        if (displayObject.accessibleTitle && displayObject.accessibleTitle !== null) div.title = displayObject.accessibleTitle;
        else if (!displayObject.accessibleHint || displayObject.accessibleHint === null) div.title = "displayObject " + displayObject.tabIndex;
        if (displayObject.accessibleHint && displayObject.accessibleHint !== null) div.setAttribute('aria-label', displayObject.accessibleHint);
        if (this.debug) this.updateDebugHTML(div);
        displayObject._accessibleActive = true;
        displayObject._accessibleDiv = div;
        div.displayObject = displayObject;
        this.children.push(displayObject);
        this.div.appendChild(displayObject._accessibleDiv);
        displayObject._accessibleDiv.tabIndex = displayObject.tabIndex;
    };
    /**
     * Maps the div button press to pixi's InteractionManager (click)
     *
     * @private
     * @param {MouseEvent} e - The click event.
     */ AccessibilityManager1.prototype._onClick = function(e) {
        var interactionManager = this.renderer.plugins.interaction;
        var displayObject = e.target.displayObject;
        var eventData = interactionManager.eventData;
        interactionManager.dispatchEvent(displayObject, 'click', eventData);
        interactionManager.dispatchEvent(displayObject, 'pointertap', eventData);
        interactionManager.dispatchEvent(displayObject, 'tap', eventData);
    };
    /**
     * Maps the div focus events to pixi's InteractionManager (mouseover)
     *
     * @private
     * @param {FocusEvent} e - The focus event.
     */ AccessibilityManager1.prototype._onFocus = function(e) {
        if (!e.target.getAttribute('aria-live')) e.target.setAttribute('aria-live', 'assertive');
        var interactionManager = this.renderer.plugins.interaction;
        var displayObject = e.target.displayObject;
        var eventData = interactionManager.eventData;
        interactionManager.dispatchEvent(displayObject, 'mouseover', eventData);
    };
    /**
     * Maps the div focus events to pixi's InteractionManager (mouseout)
     *
     * @private
     * @param {FocusEvent} e - The focusout event.
     */ AccessibilityManager1.prototype._onFocusOut = function(e) {
        if (!e.target.getAttribute('aria-live')) e.target.setAttribute('aria-live', 'polite');
        var interactionManager = this.renderer.plugins.interaction;
        var displayObject = e.target.displayObject;
        var eventData = interactionManager.eventData;
        interactionManager.dispatchEvent(displayObject, 'mouseout', eventData);
    };
    /**
     * Is called when a key is pressed
     *
     * @private
     * @param {KeyboardEvent} e - The keydown event.
     */ AccessibilityManager1.prototype._onKeyDown = function(e) {
        if (e.keyCode !== KEY_CODE_TAB) return;
        this.activate();
    };
    /**
     * Is called when the mouse moves across the renderer element
     *
     * @private
     * @param {MouseEvent} e - The mouse event.
     */ AccessibilityManager1.prototype._onMouseMove = function(e) {
        if (e.movementX === 0 && e.movementY === 0) return;
        this.deactivate();
    };
    /**
     * Destroys the accessibility manager
     *
     */ AccessibilityManager1.prototype.destroy = function() {
        this.destroyTouchHook();
        this.div = null;
        self.document.removeEventListener('mousemove', this._onMouseMove, true);
        self.removeEventListener('keydown', this._onKeyDown);
        this.pool = null;
        this.children = null;
        this.renderer = null;
    };
    return AccessibilityManager1;
}();

},{"@pixi/display":"hQqz5","@pixi/utils":"joR65","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hQqz5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Bounds", ()=>Bounds
);
parcelHelpers.export(exports, "Container", ()=>Container1
);
parcelHelpers.export(exports, "DisplayObject", ()=>DisplayObject1
);
parcelHelpers.export(exports, "TemporaryDisplayObject", ()=>TemporaryDisplayObject1
);
/*!
 * @pixi/display - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/display is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _settings = require("@pixi/settings");
var _math = require("@pixi/math");
var _utils = require("@pixi/utils");
/**
 * Sets the default value for the container property 'sortableChildren'.
 * If set to true, the container will sort its children by zIndex value
 * when updateTransform() is called, or manually if sortChildren() is called.
 *
 * This actually changes the order of elements in the array, so should be treated
 * as a basic solution that is not performant compared to other solutions,
 * such as @link https://github.com/pixijs/pixi-display
 *
 * Also be aware of that this may not work nicely with the addChildAt() function,
 * as the zIndex sorting may cause the child to automatically sorted to another position.
 *
 * @static
 * @constant
 * @name SORTABLE_CHILDREN
 * @memberof PIXI.settings
 * @type {boolean}
 * @default false
 */ _settings.settings.SORTABLE_CHILDREN = false;
/**
 * 'Builder' pattern for bounds rectangles.
 *
 * This could be called an Axis-Aligned Bounding Box.
 * It is not an actual shape. It is a mutable thing; no 'EMPTY' or those kind of problems.
 *
 * @class
 * @memberof PIXI
 */ var Bounds = function() {
    function Bounds1() {
        /**
         * @member {number}
         * @default 0
         */ this.minX = Infinity;
        /**
         * @member {number}
         * @default 0
         */ this.minY = Infinity;
        /**
         * @member {number}
         * @default 0
         */ this.maxX = -Infinity;
        /**
         * @member {number}
         * @default 0
         */ this.maxY = -Infinity;
        this.rect = null;
        /**
         * It is updated to _boundsID of corresponding object to keep bounds in sync with content.
         * Updated from outside, thus public modifier.
         *
         * @member {number}
         * @public
         */ this.updateID = -1;
    }
    /**
     * Checks if bounds are empty.
     *
     * @return {boolean} True if empty.
     */ Bounds1.prototype.isEmpty = function() {
        return this.minX > this.maxX || this.minY > this.maxY;
    };
    /**
     * Clears the bounds and resets.
     *
     */ Bounds1.prototype.clear = function() {
        this.minX = Infinity;
        this.minY = Infinity;
        this.maxX = -Infinity;
        this.maxY = -Infinity;
    };
    /**
     * Can return Rectangle.EMPTY constant, either construct new rectangle, either use your rectangle
     * It is not guaranteed that it will return tempRect
     *
     * @param {PIXI.Rectangle} rect - temporary object will be used if AABB is not empty
     * @returns {PIXI.Rectangle} A rectangle of the bounds
     */ Bounds1.prototype.getRectangle = function(rect) {
        if (this.minX > this.maxX || this.minY > this.maxY) return _math.Rectangle.EMPTY;
        rect = rect || new _math.Rectangle(0, 0, 1, 1);
        rect.x = this.minX;
        rect.y = this.minY;
        rect.width = this.maxX - this.minX;
        rect.height = this.maxY - this.minY;
        return rect;
    };
    /**
     * This function should be inlined when its possible.
     *
     * @param {PIXI.IPointData} point - The point to add.
     */ Bounds1.prototype.addPoint = function(point) {
        this.minX = Math.min(this.minX, point.x);
        this.maxX = Math.max(this.maxX, point.x);
        this.minY = Math.min(this.minY, point.y);
        this.maxY = Math.max(this.maxY, point.y);
    };
    /**
     * Adds a point, after transformed. This should be inlined when its possible.
     *
     * @param matrix
     * @param point
     */ Bounds1.prototype.addPointMatrix = function(matrix, point) {
        var a = matrix.a, b = matrix.b, c = matrix.c, d = matrix.d, tx = matrix.tx, ty = matrix.ty;
        var x = a * point.x + c * point.y + tx;
        var y = b * point.x + d * point.y + ty;
        this.minX = Math.min(this.minX, x);
        this.maxX = Math.max(this.maxX, x);
        this.minY = Math.min(this.minY, y);
        this.maxY = Math.max(this.maxY, y);
    };
    /**
     * Adds a quad, not transformed
     *
     * @param {Float32Array} vertices - The verts to add.
     */ Bounds1.prototype.addQuad = function(vertices) {
        var minX = this.minX;
        var minY = this.minY;
        var maxX = this.maxX;
        var maxY = this.maxY;
        var x = vertices[0];
        var y = vertices[1];
        minX = x < minX ? x : minX;
        minY = y < minY ? y : minY;
        maxX = x > maxX ? x : maxX;
        maxY = y > maxY ? y : maxY;
        x = vertices[2];
        y = vertices[3];
        minX = x < minX ? x : minX;
        minY = y < minY ? y : minY;
        maxX = x > maxX ? x : maxX;
        maxY = y > maxY ? y : maxY;
        x = vertices[4];
        y = vertices[5];
        minX = x < minX ? x : minX;
        minY = y < minY ? y : minY;
        maxX = x > maxX ? x : maxX;
        maxY = y > maxY ? y : maxY;
        x = vertices[6];
        y = vertices[7];
        minX = x < minX ? x : minX;
        minY = y < minY ? y : minY;
        maxX = x > maxX ? x : maxX;
        maxY = y > maxY ? y : maxY;
        this.minX = minX;
        this.minY = minY;
        this.maxX = maxX;
        this.maxY = maxY;
    };
    /**
     * Adds sprite frame, transformed.
     *
     * @param {PIXI.Transform} transform - transform to apply
     * @param {number} x0 - left X of frame
     * @param {number} y0 - top Y of frame
     * @param {number} x1 - right X of frame
     * @param {number} y1 - bottom Y of frame
     */ Bounds1.prototype.addFrame = function(transform, x0, y0, x1, y1) {
        this.addFrameMatrix(transform.worldTransform, x0, y0, x1, y1);
    };
    /**
     * Adds sprite frame, multiplied by matrix
     *
     * @param {PIXI.Matrix} matrix - matrix to apply
     * @param {number} x0 - left X of frame
     * @param {number} y0 - top Y of frame
     * @param {number} x1 - right X of frame
     * @param {number} y1 - bottom Y of frame
     */ Bounds1.prototype.addFrameMatrix = function(matrix, x0, y0, x1, y1) {
        var a = matrix.a;
        var b = matrix.b;
        var c = matrix.c;
        var d = matrix.d;
        var tx = matrix.tx;
        var ty = matrix.ty;
        var minX = this.minX;
        var minY = this.minY;
        var maxX = this.maxX;
        var maxY = this.maxY;
        var x = a * x0 + c * y0 + tx;
        var y = b * x0 + d * y0 + ty;
        minX = x < minX ? x : minX;
        minY = y < minY ? y : minY;
        maxX = x > maxX ? x : maxX;
        maxY = y > maxY ? y : maxY;
        x = a * x1 + c * y0 + tx;
        y = b * x1 + d * y0 + ty;
        minX = x < minX ? x : minX;
        minY = y < minY ? y : minY;
        maxX = x > maxX ? x : maxX;
        maxY = y > maxY ? y : maxY;
        x = a * x0 + c * y1 + tx;
        y = b * x0 + d * y1 + ty;
        minX = x < minX ? x : minX;
        minY = y < minY ? y : minY;
        maxX = x > maxX ? x : maxX;
        maxY = y > maxY ? y : maxY;
        x = a * x1 + c * y1 + tx;
        y = b * x1 + d * y1 + ty;
        minX = x < minX ? x : minX;
        minY = y < minY ? y : minY;
        maxX = x > maxX ? x : maxX;
        maxY = y > maxY ? y : maxY;
        this.minX = minX;
        this.minY = minY;
        this.maxX = maxX;
        this.maxY = maxY;
    };
    /**
     * Adds screen vertices from array
     *
     * @param {Float32Array} vertexData - calculated vertices
     * @param {number} beginOffset - begin offset
     * @param {number} endOffset - end offset, excluded
     */ Bounds1.prototype.addVertexData = function(vertexData, beginOffset, endOffset) {
        var minX = this.minX;
        var minY = this.minY;
        var maxX = this.maxX;
        var maxY = this.maxY;
        for(var i = beginOffset; i < endOffset; i += 2){
            var x = vertexData[i];
            var y = vertexData[i + 1];
            minX = x < minX ? x : minX;
            minY = y < minY ? y : minY;
            maxX = x > maxX ? x : maxX;
            maxY = y > maxY ? y : maxY;
        }
        this.minX = minX;
        this.minY = minY;
        this.maxX = maxX;
        this.maxY = maxY;
    };
    /**
     * Add an array of mesh vertices
     *
     * @param {PIXI.Transform} transform - mesh transform
     * @param {Float32Array} vertices - mesh coordinates in array
     * @param {number} beginOffset - begin offset
     * @param {number} endOffset - end offset, excluded
     */ Bounds1.prototype.addVertices = function(transform, vertices, beginOffset, endOffset) {
        this.addVerticesMatrix(transform.worldTransform, vertices, beginOffset, endOffset);
    };
    /**
     * Add an array of mesh vertices.
     *
     * @param {PIXI.Matrix} matrix - mesh matrix
     * @param {Float32Array} vertices - mesh coordinates in array
     * @param {number} beginOffset - begin offset
     * @param {number} endOffset - end offset, excluded
     * @param {number} [padX=0] - x padding
     * @param {number} [padY=0] - y padding
     */ Bounds1.prototype.addVerticesMatrix = function(matrix, vertices, beginOffset, endOffset, padX, padY) {
        if (padX === void 0) padX = 0;
        if (padY === void 0) padY = padX;
        var a = matrix.a;
        var b = matrix.b;
        var c = matrix.c;
        var d = matrix.d;
        var tx = matrix.tx;
        var ty = matrix.ty;
        var minX = this.minX;
        var minY = this.minY;
        var maxX = this.maxX;
        var maxY = this.maxY;
        for(var i = beginOffset; i < endOffset; i += 2){
            var rawX = vertices[i];
            var rawY = vertices[i + 1];
            var x = a * rawX + c * rawY + tx;
            var y = d * rawY + b * rawX + ty;
            minX = Math.min(minX, x - padX);
            maxX = Math.max(maxX, x + padX);
            minY = Math.min(minY, y - padY);
            maxY = Math.max(maxY, y + padY);
        }
        this.minX = minX;
        this.minY = minY;
        this.maxX = maxX;
        this.maxY = maxY;
    };
    /**
     * Adds other Bounds.
     *
     * @param {PIXI.Bounds} bounds - The Bounds to be added
     */ Bounds1.prototype.addBounds = function(bounds) {
        var minX = this.minX;
        var minY = this.minY;
        var maxX = this.maxX;
        var maxY = this.maxY;
        this.minX = bounds.minX < minX ? bounds.minX : minX;
        this.minY = bounds.minY < minY ? bounds.minY : minY;
        this.maxX = bounds.maxX > maxX ? bounds.maxX : maxX;
        this.maxY = bounds.maxY > maxY ? bounds.maxY : maxY;
    };
    /**
     * Adds other Bounds, masked with Bounds.
     *
     * @param {PIXI.Bounds} bounds - The Bounds to be added.
     * @param {PIXI.Bounds} mask - TODO
     */ Bounds1.prototype.addBoundsMask = function(bounds, mask) {
        var _minX = bounds.minX > mask.minX ? bounds.minX : mask.minX;
        var _minY = bounds.minY > mask.minY ? bounds.minY : mask.minY;
        var _maxX = bounds.maxX < mask.maxX ? bounds.maxX : mask.maxX;
        var _maxY = bounds.maxY < mask.maxY ? bounds.maxY : mask.maxY;
        if (_minX <= _maxX && _minY <= _maxY) {
            var minX = this.minX;
            var minY = this.minY;
            var maxX = this.maxX;
            var maxY = this.maxY;
            this.minX = _minX < minX ? _minX : minX;
            this.minY = _minY < minY ? _minY : minY;
            this.maxX = _maxX > maxX ? _maxX : maxX;
            this.maxY = _maxY > maxY ? _maxY : maxY;
        }
    };
    /**
     * Adds other Bounds, multiplied by matrix. Bounds shouldn't be empty.
     *
     * @param {PIXI.Bounds} bounds - other bounds
     * @param {PIXI.Matrix} matrix - multiplicator
     */ Bounds1.prototype.addBoundsMatrix = function(bounds, matrix) {
        this.addFrameMatrix(matrix, bounds.minX, bounds.minY, bounds.maxX, bounds.maxY);
    };
    /**
     * Adds other Bounds, masked with Rectangle.
     *
     * @param {PIXI.Bounds} bounds - TODO
     * @param {PIXI.Rectangle} area - TODO
     */ Bounds1.prototype.addBoundsArea = function(bounds, area) {
        var _minX = bounds.minX > area.x ? bounds.minX : area.x;
        var _minY = bounds.minY > area.y ? bounds.minY : area.y;
        var _maxX = bounds.maxX < area.x + area.width ? bounds.maxX : area.x + area.width;
        var _maxY = bounds.maxY < area.y + area.height ? bounds.maxY : area.y + area.height;
        if (_minX <= _maxX && _minY <= _maxY) {
            var minX = this.minX;
            var minY = this.minY;
            var maxX = this.maxX;
            var maxY = this.maxY;
            this.minX = _minX < minX ? _minX : minX;
            this.minY = _minY < minY ? _minY : minY;
            this.maxX = _maxX > maxX ? _maxX : maxX;
            this.maxY = _maxY > maxY ? _maxY : maxY;
        }
    };
    /**
     * Pads bounds object, making it grow in all directions.
     * If paddingY is omitted, both paddingX and paddingY will be set to paddingX.
     *
     * @param {number} [paddingX=0] - The horizontal padding amount.
     * @param {number} [paddingY=0] - The vertical padding amount.
     */ Bounds1.prototype.pad = function(paddingX, paddingY) {
        if (paddingX === void 0) paddingX = 0;
        if (paddingY === void 0) paddingY = paddingX;
        if (!this.isEmpty()) {
            this.minX -= paddingX;
            this.maxX += paddingX;
            this.minY -= paddingY;
            this.maxY += paddingY;
        }
    };
    /**
     * Adds padded frame. (x0, y0) should be strictly less than (x1, y1)
     *
     * @param {number} x0 - left X of frame
     * @param {number} y0 - top Y of frame
     * @param {number} x1 - right X of frame
     * @param {number} y1 - bottom Y of frame
     * @param {number} padX - padding X
     * @param {number} padY - padding Y
     */ Bounds1.prototype.addFramePad = function(x0, y0, x1, y1, padX, padY) {
        x0 -= padX;
        y0 -= padY;
        x1 += padX;
        y1 += padY;
        this.minX = this.minX < x0 ? this.minX : x0;
        this.maxX = this.maxX > x1 ? this.maxX : x1;
        this.minY = this.minY < y0 ? this.minY : y0;
        this.maxY = this.maxY > y1 ? this.maxY : y1;
    };
    return Bounds1;
}();
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * The base class for all objects that are rendered on the screen.
 *
 * This is an abstract class and can not be used on its own; rather it should be extended.
 *
 * ## Display objects implemented in PixiJS
 *
 * | Display Object                  | Description                                                           |
 * | ------------------------------- | --------------------------------------------------------------------- |
 * | {@link PIXI.Container}          | Adds support for `children` to DisplayObject                          |
 * | {@link PIXI.Graphics}           | Shape-drawing display object similar to the Canvas API                |
 * | {@link PIXI.Sprite}             | Draws textures (i.e. images)                                          |
 * | {@link PIXI.Text}               | Draws text using the Canvas API internally                            |
 * | {@link PIXI.BitmapText}         | More scaleable solution for text rendering, reusing glyph textures    |
 * | {@link PIXI.TilingSprite}       | Draws textures/images in a tiled fashion                              |
 * | {@link PIXI.AnimatedSprite}     | Draws an animation of multiple images                                 |
 * | {@link PIXI.Mesh}               | Provides a lower-level API for drawing meshes with custom data        |
 * | {@link PIXI.NineSlicePlane}     | Mesh-related                                                          |
 * | {@link PIXI.SimpleMesh}         | v4-compatibile mesh                                                   |
 * | {@link PIXI.SimplePlane}        | Mesh-related                                                          |
 * | {@link PIXI.SimpleRope}         | Mesh-related                                                          |
 *
 * ## Transforms
 *
 * The [transform]{@link DisplayObject#transform} of a display object describes the projection from its
 * local coordinate space to its parent's local coordinate space. The following properties are derived
 * from the transform:
 *
 * <table>
 *   <thead>
 *     <tr>
 *       <th>Property</th>
 *       <th>Description</th>
 *     </tr>
 *   </thead>
 *   <tbody>
 *     <tr>
 *       <td>[pivot]{@link PIXI.DisplayObject#pivot}</td>
 *       <td>
 *         Invariant under rotation, scaling, and skewing. The projection of into the parent's space of the pivot
 *         is equal to position, regardless of the other three transformations. In other words, It is the center of
 *         rotation, scaling, and skewing.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[position]{@link PIXI.DisplayObject#position}</td>
 *       <td>
 *         Translation. This is the position of the [pivot]{@link PIXI.DisplayObject#pivot} in the parent's local
 *         space. The default value of the pivot is the origin (0,0). If the top-left corner of your display object
 *         is (0,0) in its local space, then the position will be its top-left corner in the parent's local space.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[scale]{@link PIXI.DisplayObject#scale}</td>
 *       <td>
 *         Scaling. This will stretch (or compress) the display object's projection. The scale factors are along the
 *         local coordinate axes. In other words, the display object is scaled before rotated or skewed. The center
 *         of scaling is the [pivot]{@link PIXI.DisplayObject#pivot}.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[rotation]{@link PIXI.DisplayObject#rotation}</td>
 *       <td>
 *          Rotation. This will rotate the display object's projection by this angle (in radians).
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>[skew]{@link PIXI.DisplayObject#skew}</td>
 *       <td>
 *         <p>Skewing. This can be used to deform a rectangular display object into a parallelogram.</p>
 *         <p>
 *         In PixiJS, skew has a slightly different behaviour than the conventional meaning. It can be
 *         thought of the net rotation applied to the coordinate axes (separately). For example, if "skew.x" is
 *         ⍺ and "skew.y" is β, then the line x = 0 will be rotated by ⍺ (y = -x*cot⍺) and the line y = 0 will be
 *         rotated by β (y = x*tanβ). A line y = x*tanϴ (i.e. a line at angle ϴ to the x-axis in local-space) will
 *         be rotated by an angle between ⍺ and β.
 *         </p>
 *         <p>
 *         It can be observed that if skew is applied equally to both axes, then it will be equivalent to applying
 *         a rotation. Indeed, if "skew.x" = -ϴ and "skew.y" = ϴ, it will produce an equivalent of "rotation" = ϴ.
 *         </p>
 *         <p>
 *         Another quite interesting observation is that "skew.x", "skew.y", rotation are communtative operations. Indeed,
 *         because rotation is essentially a careful combination of the two.
 *         </p>
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>angle</td>
 *       <td>Rotation. This is an alias for [rotation]{@link PIXI.DisplayObject#rotation}, but in degrees.</td>
 *     </tr>
 *     <tr>
 *       <td>x</td>
 *       <td>Translation. This is an alias for position.x!</td>
 *     </tr>
 *     <tr>
 *       <td>y</td>
 *       <td>Translation. This is an alias for position.y!</td>
 *     </tr>
 *     <tr>
 *       <td>width</td>
 *       <td>
 *         Implemented in [Container]{@link PIXI.Container}. Scaling. The width property calculates scale.x by dividing
 *         the "requested" width by the local bounding box width. It is indirectly an abstraction over scale.x, and there
 *         is no concept of user-defined width.
 *       </td>
 *     </tr>
 *     <tr>
 *       <td>height</td>
 *       <td>
 *         Implemented in [Container]{@link PIXI.Container}. Scaling. The height property calculates scale.y by dividing
 *         the "requested" height by the local bounding box height. It is indirectly an abstraction over scale.y, and there
 *         is no concept of user-defined height.
 *       </td>
 *     </tr>
 *   </tbody>
 * </table>
 *
 * ## Bounds
 *
 * The bounds of a display object is defined by the minimum axis-aligned rectangle in world space that can fit
 * around it. The abstract `calculateBounds` method is responsible for providing it (and it should use the
 * `worldTransform` to calculate in world space).
 *
 * There are a few additional types of bounding boxes:
 *
 * | Bounds                | Description                                                                              |
 * | --------------------- | ---------------------------------------------------------------------------------------- |
 * | World Bounds          | This is synonymous is the regular bounds described above. See `getBounds()`.             |
 * | Local Bounds          | This the axis-aligned bounding box in the parent's local space. See `getLocalBounds()`.  |
 * | Render Bounds         | The bounds, but including extra rendering effects like filter padding.                   |
 * | Projected Bounds      | The bounds of the projected display object onto the screen. Usually equals world bounds. |
 * | Relative Bounds       | The bounds of a display object when projected onto a ancestor's (or parent's) space.     |
 * | Natural Bounds        | The bounds of an object in its own local space (not parent's space, like in local bounds)|
 * | Content Bounds        | The natural bounds when excluding all children of a `Container`.                         |
 *
 * ### calculateBounds
 *
 * [Container]{@link Container} already implements `calculateBounds` in a manner that includes children.
 *
 * But for a non-Container display object, the `calculateBounds` method must be overridden in order for `getBounds` and
 * `getLocalBounds` to work. This method must write the bounds into `this._bounds`.
 *
 * Generally, the following technique works for most simple cases: take the list of points
 * forming the "hull" of the object (i.e. outline of the object's shape), and then add them
 * using {@link PIXI.Bounds#addPointMatrix}.
 *
 * ```js
 * calculateBounds(): void
 * {
 *     const points = [...];
 *
 *     for (let i = 0, j = points.length; i < j; i++)
 *     {
 *         this._bounds.addPointMatrix(this.worldTransform, points[i]);
 *     }
 * }
 * ```
 *
 * You can optimize this for a large number of points by using {@link PIXI.Bounds#addVerticesMatrix} to pass them
 * in one array together.
 *
 * ## Alpha
 *
 * This alpha sets a display object's **relative opacity** w.r.t its parent. For example, if the alpha of a display
 * object is 0.5 and its parent's alpha is 0.5, then it will be rendered with 25% opacity (assuming alpha is not
 * applied on any ancestor further up the chain).
 *
 * The alpha with which the display object will be rendered is called the [worldAlpha]{@link PIXI.DisplayObject#worldAlpha}.
 *
 * ## Renderable vs Visible
 *
 * The `renderable` and `visible` properties can be used to prevent a display object from being rendered to the
 * screen. However, there is a subtle difference between the two. When using `renderable`, the transforms  of the display
 * object (and its children subtree) will continue to be calculated. When using `visible`, the transforms will not
 * be calculated.
 *
 * It is recommended that applications use the `renderable` property for culling. See
 * [@pixi-essentials/cull]{@link https://www.npmjs.com/package/@pixi-essentials/cull} or
 * [pixi-cull]{@link https://www.npmjs.com/package/pixi-cull} for more details.
 *
 * Otherwise, to prevent an object from rendering in the general-purpose sense - `visible` is the property to use. This
 * one is also better in terms of performance.
 *
 * @class
 * @extends PIXI.utils.EventEmitter
 * @memberof PIXI
 */ var DisplayObject1 = function(_super) {
    __extends(DisplayObject2, _super);
    function DisplayObject2() {
        var _this = _super.call(this) || this;
        _this.tempDisplayObjectParent = null;
        // TODO: need to create Transform from factory
        /**
         * World transform and local transform of this object.
         * This will become read-only later, please do not assign anything there unless you know what are you doing.
         *
         * @member {PIXI.Transform}
         */ _this.transform = new _math.Transform();
        /**
         * The opacity of the object.
         *
         * @member {number}
         */ _this.alpha = 1;
        /**
         * The visibility of the object. If false the object will not be drawn, and
         * the updateTransform function will not be called.
         *
         * Only affects recursive calls from parent. You can ask for bounds or call updateTransform manually.
         *
         * @member {boolean}
         */ _this.visible = true;
        /**
         * Can this object be rendered, if false the object will not be drawn but the updateTransform
         * methods will still be called.
         *
         * Only affects recursive calls from parent. You can ask for bounds manually.
         *
         * @member {boolean}
         */ _this.renderable = true;
        /**
         * The display object container that contains this display object.
         *
         * @member {PIXI.Container}
         */ _this.parent = null;
        /**
         * The multiplied alpha of the displayObject.
         *
         * @member {number}
         * @readonly
         */ _this.worldAlpha = 1;
        /**
         * Which index in the children array the display component was before the previous zIndex sort.
         * Used by containers to help sort objects with the same zIndex, by using previous array index as the decider.
         *
         * @member {number}
         * @protected
         */ _this._lastSortedIndex = 0;
        /**
         * The zIndex of the displayObject.
         * A higher value will mean it will be rendered on top of other displayObjects within the same container.
         *
         * @member {number}
         * @protected
         */ _this._zIndex = 0;
        /**
         * The area the filter is applied to. This is used as more of an optimization
         * rather than figuring out the dimensions of the displayObject each frame you can set this rectangle.
         *
         * Also works as an interaction mask.
         *
         * @member {?PIXI.Rectangle}
         */ _this.filterArea = null;
        /**
         * Sets the filters for the displayObject.
         * * IMPORTANT: This is a WebGL only feature and will be ignored by the canvas renderer.
         * To remove filters simply set this property to `'null'`.
         *
         * @member {?PIXI.Filter[]}
         */ _this.filters = null;
        /**
         * Currently enabled filters
         * @member {PIXI.Filter[]}
         * @protected
         */ _this._enabledFilters = null;
        /**
         * The bounds object, this is used to calculate and store the bounds of the displayObject.
         *
         * @member {PIXI.Bounds}
         */ _this._bounds = new Bounds();
        /**
         * Local bounds object, swapped with `_bounds` when using `getLocalBounds()`.
         *
         * @member {PIXI.Bounds}
         */ _this._localBounds = null;
        /**
         * Flags the cached bounds as dirty.
         *
         * @member {number}
         * @protected
         */ _this._boundsID = 0;
        /**
         * Cache of this display-object's bounds-rectangle.
         *
         * @member {PIXI.Bounds}
         * @protected
         */ _this._boundsRect = null;
        /**
         * Cache of this display-object's local-bounds rectangle.
         *
         * @member {PIXI.Bounds}
         * @protected
         */ _this._localBoundsRect = null;
        /**
         * The original, cached mask of the object.
         *
         * @member {PIXI.Container|PIXI.MaskData|null}
         * @protected
         */ _this._mask = null;
        /**
         * If the object has been destroyed via destroy(). If true, it should not be used.
         *
         * @member {boolean}
         * @protected
         */ _this._destroyed = false;
        /**
         * used to fast check if a sprite is.. a sprite!
         * @member {boolean}
         */ _this.isSprite = false;
        /**
         * Does any other displayObject use this object as a mask?
         * @member {boolean}
         */ _this.isMask = false;
        return _this;
    }
    /**
     * Mixes all enumerable properties and methods from a source object to DisplayObject.
     *
     * @param {object} source - The source of properties and methods to mix in.
     */ DisplayObject2.mixin = function(source) {
        // in ES8/ES2017, this would be really easy:
        // Object.defineProperties(DisplayObject.prototype, Object.getOwnPropertyDescriptors(source));
        // get all the enumerable property keys
        var keys = Object.keys(source);
        // loop through properties
        for(var i = 0; i < keys.length; ++i){
            var propertyName = keys[i];
            // Set the property using the property descriptor - this works for accessors and normal value properties
            Object.defineProperty(DisplayObject2.prototype, propertyName, Object.getOwnPropertyDescriptor(source, propertyName));
        }
    };
    Object.defineProperty(DisplayObject2.prototype, "destroyed", {
        /**
         * Fired when this DisplayObject is added to a Container.
         *
         * @instance
         * @event added
         * @param {PIXI.Container} container - The container added to.
         */ /**
         * Fired when this DisplayObject is removed from a Container.
         *
         * @instance
         * @event removed
         * @param {PIXI.Container} container - The container removed from.
         */ /**
         * Fired when this DisplayObject is destroyed.
         *
         * @instance
         * @event destroyed
         */ /**
         * Readonly flag for destroyed display objects.
         */ get: function() {
            return this._destroyed;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Recursively updates transform of all objects from the root to this one
     * internal function for toLocal()
     */ DisplayObject2.prototype._recursivePostUpdateTransform = function() {
        if (this.parent) {
            this.parent._recursivePostUpdateTransform();
            this.transform.updateTransform(this.parent.transform);
        } else this.transform.updateTransform(this._tempDisplayObjectParent.transform);
    };
    /**
     * Updates the object transform for rendering.
     *
     * TODO - Optimization pass!
     */ DisplayObject2.prototype.updateTransform = function() {
        this._boundsID++;
        this.transform.updateTransform(this.parent.transform);
        // multiply the alphas..
        this.worldAlpha = this.alpha * this.parent.worldAlpha;
    };
    /**
     * Calculates and returns the (world) bounds of the display object as a [Rectangle]{@link PIXI.Rectangle}.
     *
     * This method is expensive on containers with a large subtree (like the stage). This is because the bounds
     * of a container depend on its children's bounds, which recursively causes all bounds in the subtree to
     * be recalculated. The upside, however, is that calling `getBounds` once on a container will indeed update
     * the bounds of all children (the whole subtree, in fact). This side effect should be exploited by using
     * `displayObject._bounds.getRectangle()` when traversing through all the bounds in a scene graph. Otherwise,
     * calling `getBounds` on each object in a subtree will cause the total cost to increase quadratically as
     * its height increases.
     *
     * * The transforms of all objects in a container's **subtree** and of all **ancestors** are updated.
     * * The world bounds of all display objects in a container's **subtree** will also be recalculated.
     *
     * The `_bounds` object stores the last calculation of the bounds. You can use to entirely skip bounds
     * calculation if needed.
     *
     * ```js
     * const lastCalculatedBounds = displayObject._bounds.getRectangle(optionalRect);
     * ```
     *
     * Do know that usage of `getLocalBounds` can corrupt the `_bounds` of children (the whole subtree, actually). This
     * is a known issue that has not been solved. See [getLocalBounds]{@link PIXI.DisplayObject#getLocalBounds} for more
     * details.
     *
     * `getBounds` should be called with `skipUpdate` equal to `true` in a render() call. This is because the transforms
     * are guaranteed to be update-to-date. In fact, recalculating inside a render() call may cause corruption in certain
     * cases.
     *
     * @param {boolean} [skipUpdate] - Setting to `true` will stop the transforms of the scene graph from
     *  being updated. This means the calculation returned MAY be out of date BUT will give you a
     *  nice performance boost.
     * @param {PIXI.Rectangle} [rect] - Optional rectangle to store the result of the bounds calculation.
     * @return {PIXI.Rectangle} The minimum axis-aligned rectangle in world space that fits around this object.
     */ DisplayObject2.prototype.getBounds = function(skipUpdate, rect) {
        if (!skipUpdate) {
            if (!this.parent) {
                this.parent = this._tempDisplayObjectParent;
                this.updateTransform();
                this.parent = null;
            } else {
                this._recursivePostUpdateTransform();
                this.updateTransform();
            }
        }
        if (this._bounds.updateID !== this._boundsID) {
            this.calculateBounds();
            this._bounds.updateID = this._boundsID;
        }
        if (!rect) {
            if (!this._boundsRect) this._boundsRect = new _math.Rectangle();
            rect = this._boundsRect;
        }
        return this._bounds.getRectangle(rect);
    };
    /**
     * Retrieves the local bounds of the displayObject as a rectangle object.
     *
     * @param {PIXI.Rectangle} [rect] - Optional rectangle to store the result of the bounds calculation.
     * @return {PIXI.Rectangle} The rectangular bounding area.
     */ DisplayObject2.prototype.getLocalBounds = function(rect) {
        if (!rect) {
            if (!this._localBoundsRect) this._localBoundsRect = new _math.Rectangle();
            rect = this._localBoundsRect;
        }
        if (!this._localBounds) this._localBounds = new Bounds();
        var transformRef = this.transform;
        var parentRef = this.parent;
        this.parent = null;
        this.transform = this._tempDisplayObjectParent.transform;
        var worldBounds = this._bounds;
        var worldBoundsID = this._boundsID;
        this._bounds = this._localBounds;
        var bounds = this.getBounds(false, rect);
        this.parent = parentRef;
        this.transform = transformRef;
        this._bounds = worldBounds;
        this._bounds.updateID += this._boundsID - worldBoundsID; // reflect side-effects
        return bounds;
    };
    /**
     * Calculates the global position of the display object.
     *
     * @param {PIXI.IPointData} position - The world origin to calculate from.
     * @param {PIXI.Point} [point] - A Point object in which to store the value, optional
     *  (otherwise will create a new Point).
     * @param {boolean} [skipUpdate=false] - Should we skip the update transform.
     * @return {PIXI.Point} A point object representing the position of this object.
     */ DisplayObject2.prototype.toGlobal = function(position, point, skipUpdate) {
        if (skipUpdate === void 0) skipUpdate = false;
        if (!skipUpdate) {
            this._recursivePostUpdateTransform();
            // this parent check is for just in case the item is a root object.
            // If it is we need to give it a temporary parent so that displayObjectUpdateTransform works correctly
            // this is mainly to avoid a parent check in the main loop. Every little helps for performance :)
            if (!this.parent) {
                this.parent = this._tempDisplayObjectParent;
                this.displayObjectUpdateTransform();
                this.parent = null;
            } else this.displayObjectUpdateTransform();
        }
        // don't need to update the lot
        return this.worldTransform.apply(position, point);
    };
    /**
     * Calculates the local position of the display object relative to another point.
     *
     * @param {PIXI.IPointData} position - The world origin to calculate from.
     * @param {PIXI.DisplayObject} [from] - The DisplayObject to calculate the global position from.
     * @param {PIXI.Point} [point] - A Point object in which to store the value, optional
     *  (otherwise will create a new Point).
     * @param {boolean} [skipUpdate=false] - Should we skip the update transform
     * @return {PIXI.Point} A point object representing the position of this object
     */ DisplayObject2.prototype.toLocal = function(position, from, point, skipUpdate) {
        if (from) position = from.toGlobal(position, point, skipUpdate);
        if (!skipUpdate) {
            this._recursivePostUpdateTransform();
            // this parent check is for just in case the item is a root object.
            // If it is we need to give it a temporary parent so that displayObjectUpdateTransform works correctly
            // this is mainly to avoid a parent check in the main loop. Every little helps for performance :)
            if (!this.parent) {
                this.parent = this._tempDisplayObjectParent;
                this.displayObjectUpdateTransform();
                this.parent = null;
            } else this.displayObjectUpdateTransform();
        }
        // simply apply the matrix..
        return this.worldTransform.applyInverse(position, point);
    };
    /**
     * Set the parent Container of this DisplayObject.
     *
     * @param {PIXI.Container} container - The Container to add this DisplayObject to.
     * @return {PIXI.Container} The Container that this DisplayObject was added to.
     */ DisplayObject2.prototype.setParent = function(container) {
        if (!container || !container.addChild) throw new Error('setParent: Argument must be a Container');
        container.addChild(this);
        return container;
    };
    /**
     * Convenience function to set the position, scale, skew and pivot at once.
     *
     * @param {number} [x=0] - The X position
     * @param {number} [y=0] - The Y position
     * @param {number} [scaleX=1] - The X scale value
     * @param {number} [scaleY=1] - The Y scale value
     * @param {number} [rotation=0] - The rotation
     * @param {number} [skewX=0] - The X skew value
     * @param {number} [skewY=0] - The Y skew value
     * @param {number} [pivotX=0] - The X pivot value
     * @param {number} [pivotY=0] - The Y pivot value
     * @return {PIXI.DisplayObject} The DisplayObject instance
     */ DisplayObject2.prototype.setTransform = function(x, y, scaleX, scaleY, rotation, skewX, skewY, pivotX, pivotY) {
        if (x === void 0) x = 0;
        if (y === void 0) y = 0;
        if (scaleX === void 0) scaleX = 1;
        if (scaleY === void 0) scaleY = 1;
        if (rotation === void 0) rotation = 0;
        if (skewX === void 0) skewX = 0;
        if (skewY === void 0) skewY = 0;
        if (pivotX === void 0) pivotX = 0;
        if (pivotY === void 0) pivotY = 0;
        this.position.x = x;
        this.position.y = y;
        this.scale.x = !scaleX ? 1 : scaleX;
        this.scale.y = !scaleY ? 1 : scaleY;
        this.rotation = rotation;
        this.skew.x = skewX;
        this.skew.y = skewY;
        this.pivot.x = pivotX;
        this.pivot.y = pivotY;
        return this;
    };
    /**
     * Base destroy method for generic display objects. This will automatically
     * remove the display object from its parent Container as well as remove
     * all current event listeners and internal references. Do not use a DisplayObject
     * after calling `destroy()`.
     *
     */ DisplayObject2.prototype.destroy = function(_options) {
        if (this.parent) this.parent.removeChild(this);
        this.emit('destroyed');
        this.removeAllListeners();
        this.transform = null;
        this.parent = null;
        this._bounds = null;
        this._mask = null;
        this.filters = null;
        this.filterArea = null;
        this.hitArea = null;
        this.interactive = false;
        this.interactiveChildren = false;
        this._destroyed = true;
    };
    Object.defineProperty(DisplayObject2.prototype, "_tempDisplayObjectParent", {
        /**
         * @protected
         * @member {PIXI.Container}
         */ get: function() {
            if (this.tempDisplayObjectParent === null) // eslint-disable-next-line @typescript-eslint/no-use-before-define
            this.tempDisplayObjectParent = new TemporaryDisplayObject1();
            return this.tempDisplayObjectParent;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Used in Renderer, cacheAsBitmap and other places where you call an `updateTransform` on root
     *
     * ```
     * const cacheParent = elem.enableTempParent();
     * elem.updateTransform();
     * elem.disableTempParent(cacheParent);
     * ```
     *
     * @returns {PIXI.Container} current parent
     */ DisplayObject2.prototype.enableTempParent = function() {
        var myParent = this.parent;
        this.parent = this._tempDisplayObjectParent;
        return myParent;
    };
    /**
     * Pair method for `enableTempParent`
     *
     * @param {PIXI.Container} cacheParent - Actual parent of element
     */ DisplayObject2.prototype.disableTempParent = function(cacheParent) {
        this.parent = cacheParent;
    };
    Object.defineProperty(DisplayObject2.prototype, "x", {
        /**
         * The position of the displayObject on the x axis relative to the local coordinates of the parent.
         * An alias to position.x
         *
         * @member {number}
         */ get: function() {
            return this.position.x;
        },
        set: function(value) {
            this.transform.position.x = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "y", {
        /**
         * The position of the displayObject on the y axis relative to the local coordinates of the parent.
         * An alias to position.y
         *
         * @member {number}
         */ get: function() {
            return this.position.y;
        },
        set: function(value) {
            this.transform.position.y = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "worldTransform", {
        /**
         * Current transform of the object based on world (parent) factors.
         *
         * @member {PIXI.Matrix}
         * @readonly
         */ get: function() {
            return this.transform.worldTransform;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "localTransform", {
        /**
         * Current transform of the object based on local factors: position, scale, other stuff.
         *
         * @member {PIXI.Matrix}
         * @readonly
         */ get: function() {
            return this.transform.localTransform;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "position", {
        /**
         * The coordinate of the object relative to the local coordinates of the parent.
         *
         * @since PixiJS 4
         * @member {PIXI.ObservablePoint}
         */ get: function() {
            return this.transform.position;
        },
        set: function(value) {
            this.transform.position.copyFrom(value);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "scale", {
        /**
         * The scale factors of this object along the local coordinate axes.
         *
         * The default scale is (1, 1).
         *
         * @since PixiJS 4
         * @member {PIXI.ObservablePoint}
         */ get: function() {
            return this.transform.scale;
        },
        set: function(value) {
            this.transform.scale.copyFrom(value);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "pivot", {
        /**
         * The center of rotation, scaling, and skewing for this display object in its local space. The `position`
         * is the projection of `pivot` in the parent's local space.
         *
         * By default, the pivot is the origin (0, 0).
         *
         * @since PixiJS 4
         * @member {PIXI.ObservablePoint}
         */ get: function() {
            return this.transform.pivot;
        },
        set: function(value) {
            this.transform.pivot.copyFrom(value);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "skew", {
        /**
         * The skew factor for the object in radians.
         *
         * @since PixiJS 4
         * @member {PIXI.ObservablePoint}
         */ get: function() {
            return this.transform.skew;
        },
        set: function(value) {
            this.transform.skew.copyFrom(value);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "rotation", {
        /**
         * The rotation of the object in radians.
         * 'rotation' and 'angle' have the same effect on a display object; rotation is in radians, angle is in degrees.
         *
         * @member {number}
         */ get: function() {
            return this.transform.rotation;
        },
        set: function(value) {
            this.transform.rotation = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "angle", {
        /**
         * The angle of the object in degrees.
         * 'rotation' and 'angle' have the same effect on a display object; rotation is in radians, angle is in degrees.
         *
         * @member {number}
         */ get: function() {
            return this.transform.rotation * _math.RAD_TO_DEG;
        },
        set: function(value) {
            this.transform.rotation = value * _math.DEG_TO_RAD;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "zIndex", {
        /**
         * The zIndex of the displayObject.
         *
         * If a container has the sortableChildren property set to true, children will be automatically
         * sorted by zIndex value; a higher value will mean it will be moved towards the end of the array,
         * and thus rendered on top of other display objects within the same container.
         *
         * @member {number}
         * @see PIXI.Container#sortableChildren
         */ get: function() {
            return this._zIndex;
        },
        set: function(value) {
            this._zIndex = value;
            if (this.parent) this.parent.sortDirty = true;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "worldVisible", {
        /**
         * Indicates if the object is globally visible.
         *
         * @member {boolean}
         * @readonly
         */ get: function() {
            var item = this;
            do {
                if (!item.visible) return false;
                item = item.parent;
            }while (item)
            return true;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(DisplayObject2.prototype, "mask", {
        /**
         * Sets a mask for the displayObject. A mask is an object that limits the visibility of an
         * object to the shape of the mask applied to it. In PixiJS a regular mask must be a
         * {@link PIXI.Graphics} or a {@link PIXI.Sprite} object. This allows for much faster masking in canvas as it
         * utilities shape clipping. To remove a mask, set this property to `null`.
         *
         * For sprite mask both alpha and red channel are used. Black mask is the same as transparent mask.
         *
         * @example
         * const graphics = new PIXI.Graphics();
         * graphics.beginFill(0xFF3300);
         * graphics.drawRect(50, 250, 100, 100);
         * graphics.endFill();
         *
         * const sprite = new PIXI.Sprite(texture);
         * sprite.mask = graphics;
         *
         * @todo At the moment, PIXI.CanvasRenderer doesn't support PIXI.Sprite as mask.
         * @member {PIXI.Container|PIXI.MaskData|null}
         */ get: function() {
            return this._mask;
        },
        set: function(value) {
            if (this._mask) {
                var maskObject = this._mask.maskObject || this._mask;
                maskObject.renderable = true;
                maskObject.isMask = false;
            }
            this._mask = value;
            if (this._mask) {
                var maskObject = this._mask.maskObject || this._mask;
                maskObject.renderable = false;
                maskObject.isMask = true;
            }
        },
        enumerable: false,
        configurable: true
    });
    return DisplayObject2;
}(_utils.EventEmitter);
/**
 * @private
 */ var TemporaryDisplayObject1 = function(_super) {
    __extends(TemporaryDisplayObject2, _super);
    function TemporaryDisplayObject2() {
        var _this = _super !== null && _super.apply(this, arguments) || this;
        _this.sortDirty = null;
        return _this;
    }
    return TemporaryDisplayObject2;
}(DisplayObject1);
/**
 * DisplayObject default updateTransform, does not update children of container.
 * Will crash if there's no parent element.
 *
 * @memberof PIXI.DisplayObject#
 * @method displayObjectUpdateTransform
 */ DisplayObject1.prototype.displayObjectUpdateTransform = DisplayObject1.prototype.updateTransform;
function sortChildren(a, b) {
    if (a.zIndex === b.zIndex) return a._lastSortedIndex - b._lastSortedIndex;
    return a.zIndex - b.zIndex;
}
/**
 * Container is a general-purpose display object that holds children. It also adds built-in support for advanced
 * rendering features like masking and filtering.
 *
 * It is the base class of all display objects that act as a container for other objects, including Graphics
 * and Sprite.
 *
 * ```js
 * import { BlurFilter } from '@pixi/filter-blur';
 * import { Container } from '@pixi/display';
 * import { Graphics } from '@pixi/graphics';
 * import { Sprite } from '@pixi/sprite';
 *
 * let container = new Container();
 * let sprite = Sprite.from("https://s3-us-west-2.amazonaws.com/s.cdpn.io/693612/IaUrttj.png");
 *
 * sprite.width = 512;
 * sprite.height = 512;
 *
 * // Adds a sprite as a child to this container. As a result, the sprite will be rendered whenever the container
 * // is rendered.
 * container.addChild(sprite);
 *
 * // Blurs whatever is rendered by the container
 * container.filters = [new BlurFilter()];
 *
 * // Only the contents within a circle at the center should be rendered onto the screen.
 * container.mask = new Graphics()
 *  .beginFill(0xffffff)
 *  .drawCircle(sprite.width / 2, sprite.height / 2, Math.min(sprite.width, sprite.height) / 2)
 *  .endFill();
 * ```
 *
 * @class
 * @extends PIXI.DisplayObject
 * @memberof PIXI
 */ var Container1 = function(_super) {
    __extends(Container2, _super);
    function Container2() {
        var _this = _super.call(this) || this;
        /**
         * The array of children of this container.
         *
         * @member {PIXI.DisplayObject[]}
         * @readonly
         */ _this.children = [];
        /**
         * If set to true, the container will sort its children by zIndex value
         * when updateTransform() is called, or manually if sortChildren() is called.
         *
         * This actually changes the order of elements in the array, so should be treated
         * as a basic solution that is not performant compared to other solutions,
         * such as @link https://github.com/pixijs/pixi-display
         *
         * Also be aware of that this may not work nicely with the addChildAt() function,
         * as the zIndex sorting may cause the child to automatically sorted to another position.
         *
         * @see PIXI.settings.SORTABLE_CHILDREN
         *
         * @member {boolean}
         */ _this.sortableChildren = _settings.settings.SORTABLE_CHILDREN;
        /**
         * Should children be sorted by zIndex at the next updateTransform call.
         *
         * Will get automatically set to true if a new child is added, or if a child's zIndex changes.
         *
         * @member {boolean}
         */ _this.sortDirty = false;
        return _this;
    /**
         * Fired when a DisplayObject is added to this Container.
         *
         * @event PIXI.Container#childAdded
         * @param {PIXI.DisplayObject} child - The child added to the Container.
         * @param {PIXI.Container} container - The container that added the child.
         * @param {number} index - The children's index of the added child.
         */ /**
         * Fired when a DisplayObject is removed from this Container.
         *
         * @event PIXI.DisplayObject#removedFrom
         * @param {PIXI.DisplayObject} child - The child removed from the Container.
         * @param {PIXI.Container} container - The container that removed removed the child.
         * @param {number} index - The former children's index of the removed child
         */ }
    /**
     * Overridable method that can be used by Container subclasses whenever the children array is modified
     *
     * @protected
     */ Container2.prototype.onChildrenChange = function(_length) {
    /* empty */ };
    /**
     * Adds one or more children to the container.
     *
     * Multiple items can be added like so: `myContainer.addChild(thingOne, thingTwo, thingThree)`
     *
     * @param {...PIXI.DisplayObject} children - The DisplayObject(s) to add to the container
     * @return {PIXI.DisplayObject} The first child that was added.
     */ Container2.prototype.addChild = function() {
        var arguments$1 = arguments;
        var children = [];
        for(var _i = 0; _i < arguments.length; _i++)children[_i] = arguments$1[_i];
        // if there is only one argument we can bypass looping through the them
        if (children.length > 1) // loop through the array and add all children
        for(var i = 0; i < children.length; i++)// eslint-disable-next-line prefer-rest-params
        this.addChild(children[i]);
        else {
            var child = children[0];
            // if the child has a parent then lets remove it as PixiJS objects can only exist in one place
            if (child.parent) child.parent.removeChild(child);
            child.parent = this;
            this.sortDirty = true;
            // ensure child transform will be recalculated
            child.transform._parentID = -1;
            this.children.push(child);
            // ensure bounds will be recalculated
            this._boundsID++;
            // TODO - lets either do all callbacks or all events.. not both!
            this.onChildrenChange(this.children.length - 1);
            this.emit('childAdded', child, this, this.children.length - 1);
            child.emit('added', this);
        }
        return children[0];
    };
    /**
     * Adds a child to the container at a specified index. If the index is out of bounds an error will be thrown
     *
     * @param {PIXI.DisplayObject} child - The child to add
     * @param {number} index - The index to place the child in
     * @return {PIXI.DisplayObject} The child that was added.
     */ Container2.prototype.addChildAt = function(child, index) {
        if (index < 0 || index > this.children.length) throw new Error(child + "addChildAt: The index " + index + " supplied is out of bounds " + this.children.length);
        if (child.parent) child.parent.removeChild(child);
        child.parent = this;
        this.sortDirty = true;
        // ensure child transform will be recalculated
        child.transform._parentID = -1;
        this.children.splice(index, 0, child);
        // ensure bounds will be recalculated
        this._boundsID++;
        // TODO - lets either do all callbacks or all events.. not both!
        this.onChildrenChange(index);
        child.emit('added', this);
        this.emit('childAdded', child, this, index);
        return child;
    };
    /**
     * Swaps the position of 2 Display Objects within this container.
     *
     * @param {PIXI.DisplayObject} child - First display object to swap
     * @param {PIXI.DisplayObject} child2 - Second display object to swap
     */ Container2.prototype.swapChildren = function(child, child2) {
        if (child === child2) return;
        var index1 = this.getChildIndex(child);
        var index2 = this.getChildIndex(child2);
        this.children[index1] = child2;
        this.children[index2] = child;
        this.onChildrenChange(index1 < index2 ? index1 : index2);
    };
    /**
     * Returns the index position of a child DisplayObject instance
     *
     * @param {PIXI.DisplayObject} child - The DisplayObject instance to identify
     * @return {number} The index position of the child display object to identify
     */ Container2.prototype.getChildIndex = function(child) {
        var index = this.children.indexOf(child);
        if (index === -1) throw new Error('The supplied DisplayObject must be a child of the caller');
        return index;
    };
    /**
     * Changes the position of an existing child in the display object container
     *
     * @param {PIXI.DisplayObject} child - The child DisplayObject instance for which you want to change the index number
     * @param {number} index - The resulting index number for the child display object
     */ Container2.prototype.setChildIndex = function(child, index) {
        if (index < 0 || index >= this.children.length) throw new Error("The index " + index + " supplied is out of bounds " + this.children.length);
        var currentIndex = this.getChildIndex(child);
        _utils.removeItems(this.children, currentIndex, 1); // remove from old position
        this.children.splice(index, 0, child); // add at new position
        this.onChildrenChange(index);
    };
    /**
     * Returns the child at the specified index
     *
     * @param {number} index - The index to get the child at
     * @return {PIXI.DisplayObject} The child at the given index, if any.
     */ Container2.prototype.getChildAt = function(index) {
        if (index < 0 || index >= this.children.length) throw new Error("getChildAt: Index (" + index + ") does not exist.");
        return this.children[index];
    };
    /**
     * Removes one or more children from the container.
     *
     * @param {...PIXI.DisplayObject} children - The DisplayObject(s) to remove
     * @return {PIXI.DisplayObject} The first child that was removed.
     */ Container2.prototype.removeChild = function() {
        var arguments$1 = arguments;
        var children = [];
        for(var _i = 0; _i < arguments.length; _i++)children[_i] = arguments$1[_i];
        // if there is only one argument we can bypass looping through the them
        if (children.length > 1) // loop through the arguments property and remove all children
        for(var i = 0; i < children.length; i++)this.removeChild(children[i]);
        else {
            var child = children[0];
            var index = this.children.indexOf(child);
            if (index === -1) return null;
            child.parent = null;
            // ensure child transform will be recalculated
            child.transform._parentID = -1;
            _utils.removeItems(this.children, index, 1);
            // ensure bounds will be recalculated
            this._boundsID++;
            // TODO - lets either do all callbacks or all events.. not both!
            this.onChildrenChange(index);
            child.emit('removed', this);
            this.emit('childRemoved', child, this, index);
        }
        return children[0];
    };
    /**
     * Removes a child from the specified index position.
     *
     * @param {number} index - The index to get the child from
     * @return {PIXI.DisplayObject} The child that was removed.
     */ Container2.prototype.removeChildAt = function(index) {
        var child = this.getChildAt(index);
        // ensure child transform will be recalculated..
        child.parent = null;
        child.transform._parentID = -1;
        _utils.removeItems(this.children, index, 1);
        // ensure bounds will be recalculated
        this._boundsID++;
        // TODO - lets either do all callbacks or all events.. not both!
        this.onChildrenChange(index);
        child.emit('removed', this);
        this.emit('childRemoved', child, this, index);
        return child;
    };
    /**
     * Removes all children from this container that are within the begin and end indexes.
     *
     * @param {number} [beginIndex=0] - The beginning position.
     * @param {number} [endIndex=this.children.length] - The ending position. Default value is size of the container.
     * @returns {PIXI.DisplayObject[]} List of removed children
     */ Container2.prototype.removeChildren = function(beginIndex, endIndex) {
        if (beginIndex === void 0) beginIndex = 0;
        if (endIndex === void 0) endIndex = this.children.length;
        var begin = beginIndex;
        var end = endIndex;
        var range = end - begin;
        var removed;
        if (range > 0 && range <= end) {
            removed = this.children.splice(begin, range);
            for(var i = 0; i < removed.length; ++i){
                removed[i].parent = null;
                if (removed[i].transform) removed[i].transform._parentID = -1;
            }
            this._boundsID++;
            this.onChildrenChange(beginIndex);
            for(var i = 0; i < removed.length; ++i){
                removed[i].emit('removed', this);
                this.emit('childRemoved', removed[i], this, i);
            }
            return removed;
        } else if (range === 0 && this.children.length === 0) return [];
        throw new RangeError('removeChildren: numeric values are outside the acceptable range.');
    };
    /**
     * Sorts children by zIndex. Previous order is maintained for 2 children with the same zIndex.
     */ Container2.prototype.sortChildren = function() {
        var sortRequired = false;
        for(var i = 0, j = this.children.length; i < j; ++i){
            var child = this.children[i];
            child._lastSortedIndex = i;
            if (!sortRequired && child.zIndex !== 0) sortRequired = true;
        }
        if (sortRequired && this.children.length > 1) this.children.sort(sortChildren);
        this.sortDirty = false;
    };
    /**
     * Updates the transform on all children of this container for rendering
     */ Container2.prototype.updateTransform = function() {
        if (this.sortableChildren && this.sortDirty) this.sortChildren();
        this._boundsID++;
        this.transform.updateTransform(this.parent.transform);
        // TODO: check render flags, how to process stuff here
        this.worldAlpha = this.alpha * this.parent.worldAlpha;
        for(var i = 0, j = this.children.length; i < j; ++i){
            var child = this.children[i];
            if (child.visible) child.updateTransform();
        }
    };
    /**
     * Recalculates the bounds of the container.
     *
     * This implementation will automatically fit the children's bounds into the calculation. Each child's bounds
     * is limited to its mask's bounds or filterArea, if any is applied.
     */ Container2.prototype.calculateBounds = function() {
        this._bounds.clear();
        this._calculateBounds();
        for(var i = 0; i < this.children.length; i++){
            var child = this.children[i];
            if (!child.visible || !child.renderable) continue;
            child.calculateBounds();
            // TODO: filter+mask, need to mask both somehow
            if (child._mask) {
                var maskObject = child._mask.maskObject || child._mask;
                maskObject.calculateBounds();
                this._bounds.addBoundsMask(child._bounds, maskObject._bounds);
            } else if (child.filterArea) this._bounds.addBoundsArea(child._bounds, child.filterArea);
            else this._bounds.addBounds(child._bounds);
        }
        this._bounds.updateID = this._boundsID;
    };
    /**
     * Retrieves the local bounds of the displayObject as a rectangle object.
     *
     * Calling `getLocalBounds` may invalidate the `_bounds` of the whole subtree below. If using it inside a render()
     * call, it is advised to call `getBounds()` immediately after to recalculate the world bounds of the subtree.
     *
     * @param {PIXI.Rectangle} [rect] - Optional rectangle to store the result of the bounds calculation.
     * @param {boolean} [skipChildrenUpdate=false] - Setting to `true` will stop re-calculation of children transforms,
     *  it was default behaviour of pixi 4.0-5.2 and caused many problems to users.
     * @return {PIXI.Rectangle} The rectangular bounding area.
     */ Container2.prototype.getLocalBounds = function(rect, skipChildrenUpdate) {
        if (skipChildrenUpdate === void 0) skipChildrenUpdate = false;
        var result = _super.prototype.getLocalBounds.call(this, rect);
        if (!skipChildrenUpdate) for(var i = 0, j = this.children.length; i < j; ++i){
            var child = this.children[i];
            if (child.visible) child.updateTransform();
        }
        return result;
    };
    /**
     * Recalculates the content bounds of this object. This should be overriden to
     * calculate the bounds of this specific object (not including children).
     *
     * @protected
     */ Container2.prototype._calculateBounds = function() {
    // FILL IN//
    };
    /**
     * Renders the object using the WebGL renderer.
     *
     * The [_render]{@link PIXI.Container#_render} method is be overriden for rendering the contents of the
     * container itself. This `render` method will invoke it, and also invoke the `render` methods of all
     * children afterward.
     *
     * If `renderable` or `visible` is false or if `worldAlpha` is not positive, this implementation will entirely
     * skip rendering. See {@link PIXI.DisplayObject} for choosing between `renderable` or `visible`. Generally,
     * setting alpha to zero is not recommended for purely skipping rendering.
     *
     * When your scene becomes large (especially when it is larger than can be viewed in a single screen), it is
     * advised to employ **culling** to automatically skip rendering objects outside of the current screen. The
     * [@pixi-essentials/cull]{@link https://www.npmjs.com/package/@pixi-essentials/cull} and
     * [pixi-cull]{@link https://www.npmjs.com/package/pixi-cull} packages do this out of the box.
     *
     * The [renderAdvanced]{@link PIXI.Container#renderAdvanced} method is internally used when when masking or
     * filtering is applied on a container. This does, however, break batching and can affect performance when
     * masking and filtering is applied extensively throughout the scene graph.
     *
     * @param {PIXI.Renderer} renderer - The renderer
     */ Container2.prototype.render = function(renderer) {
        // if the object is not visible or the alpha is 0 then no need to render this element
        if (!this.visible || this.worldAlpha <= 0 || !this.renderable) return;
        // do a quick check to see if this element has a mask or a filter.
        if (this._mask || this.filters && this.filters.length) this.renderAdvanced(renderer);
        else {
            this._render(renderer);
            // simple render children!
            for(var i = 0, j = this.children.length; i < j; ++i)this.children[i].render(renderer);
        }
    };
    /**
     * Render the object using the WebGL renderer and advanced features.
     *
     * @protected
     * @param {PIXI.Renderer} renderer - The renderer
     */ Container2.prototype.renderAdvanced = function(renderer) {
        renderer.batch.flush();
        var filters = this.filters;
        var mask = this._mask;
        // push filter first as we need to ensure the stencil buffer is correct for any masking
        if (filters) {
            if (!this._enabledFilters) this._enabledFilters = [];
            this._enabledFilters.length = 0;
            for(var i = 0; i < filters.length; i++)if (filters[i].enabled) this._enabledFilters.push(filters[i]);
            if (this._enabledFilters.length) renderer.filter.push(this, this._enabledFilters);
        }
        if (mask) renderer.mask.push(this, this._mask);
        // add this object to the batch, only rendered if it has a texture.
        this._render(renderer);
        // now loop through the children and make sure they get rendered
        for(var i = 0, j = this.children.length; i < j; i++)this.children[i].render(renderer);
        renderer.batch.flush();
        if (mask) renderer.mask.pop(this);
        if (filters && this._enabledFilters && this._enabledFilters.length) renderer.filter.pop();
    };
    /**
     * To be overridden by the subclasses.
     *
     * @protected
     * @param {PIXI.Renderer} renderer - The renderer
     */ Container2.prototype._render = function(_renderer) {
    // this is where content itself gets rendered...
    };
    /**
     * Removes all internal references and listeners as well as removes children from the display list.
     * Do not use a Container after calling `destroy`.
     *
     * @param {object|boolean} [options] - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.children=false] - if set to true, all the children will have their destroy
     *  method called as well. 'options' will be passed on to those calls.
     * @param {boolean} [options.texture=false] - Only used for child Sprites if options.children is set to true
     *  Should it destroy the texture of the child sprite
     * @param {boolean} [options.baseTexture=false] - Only used for child Sprites if options.children is set to true
     *  Should it destroy the base texture of the child sprite
     */ Container2.prototype.destroy = function(options) {
        _super.prototype.destroy.call(this);
        this.sortDirty = false;
        var destroyChildren = typeof options === 'boolean' ? options : options && options.children;
        var oldChildren = this.removeChildren(0, this.children.length);
        if (destroyChildren) for(var i = 0; i < oldChildren.length; ++i)oldChildren[i].destroy(options);
    };
    Object.defineProperty(Container2.prototype, "width", {
        /**
         * The width of the Container, setting this will actually modify the scale to achieve the value set
         *
         * @member {number}
         */ get: function() {
            return this.scale.x * this.getLocalBounds().width;
        },
        set: function(value) {
            var width = this.getLocalBounds().width;
            if (width !== 0) this.scale.x = value / width;
            else this.scale.x = 1;
            this._width = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Container2.prototype, "height", {
        /**
         * The height of the Container, setting this will actually modify the scale to achieve the value set
         *
         * @member {number}
         */ get: function() {
            return this.scale.y * this.getLocalBounds().height;
        },
        set: function(value) {
            var height = this.getLocalBounds().height;
            if (height !== 0) this.scale.y = value / height;
            else this.scale.y = 1;
            this._height = value;
        },
        enumerable: false,
        configurable: true
    });
    return Container2;
}(DisplayObject1);
/**
 * Container default updateTransform, does update children of container.
 * Will crash if there's no parent element.
 *
 * @memberof PIXI.Container#
 * @method containerUpdateTransform
 */ Container1.prototype.containerUpdateTransform = Container1.prototype.updateTransform;

},{"@pixi/settings":"habh9","@pixi/math":"1qR3C","@pixi/utils":"joR65","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1qR3C":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Circle", ()=>Circle
);
parcelHelpers.export(exports, "DEG_TO_RAD", ()=>DEG_TO_RAD
);
parcelHelpers.export(exports, "Ellipse", ()=>Ellipse
);
parcelHelpers.export(exports, "Matrix", ()=>Matrix
);
parcelHelpers.export(exports, "ObservablePoint", ()=>ObservablePoint
);
parcelHelpers.export(exports, "PI_2", ()=>PI_2
);
parcelHelpers.export(exports, "Point", ()=>Point
);
parcelHelpers.export(exports, "Polygon", ()=>Polygon
);
parcelHelpers.export(exports, "RAD_TO_DEG", ()=>RAD_TO_DEG
);
parcelHelpers.export(exports, "Rectangle", ()=>Rectangle
);
parcelHelpers.export(exports, "RoundedRectangle", ()=>RoundedRectangle
);
parcelHelpers.export(exports, "SHAPES", ()=>SHAPES
);
parcelHelpers.export(exports, "Transform", ()=>Transform
);
parcelHelpers.export(exports, "groupD8", ()=>groupD8
);
/*!
 * @pixi/math - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/math is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ /**
 * Two Pi.
 *
 * @static
 * @member {number}
 * @memberof PIXI
 */ var PI_2 = Math.PI * 2;
/**
 * Conversion factor for converting radians to degrees.
 *
 * @static
 * @member {number} RAD_TO_DEG
 * @memberof PIXI
 */ var RAD_TO_DEG = 180 / Math.PI;
/**
 * Conversion factor for converting degrees to radians.
 *
 * @static
 * @member {number}
 * @memberof PIXI
 */ var DEG_TO_RAD = Math.PI / 180;
/**
 * Constants that identify shapes, mainly to prevent `instanceof` calls.
 *
 * @static
 * @memberof PIXI
 * @enum {number}
 * @property {number} POLY Polygon
 * @property {number} RECT Rectangle
 * @property {number} CIRC Circle
 * @property {number} ELIP Ellipse
 * @property {number} RREC Rounded Rectangle
 */ var SHAPES;
(function(SHAPES1) {
    SHAPES1[SHAPES1["POLY"] = 0] = "POLY";
    SHAPES1[SHAPES1["RECT"] = 1] = "RECT";
    SHAPES1[SHAPES1["CIRC"] = 2] = "CIRC";
    SHAPES1[SHAPES1["ELIP"] = 3] = "ELIP";
    SHAPES1[SHAPES1["RREC"] = 4] = "RREC";
})(SHAPES || (SHAPES = {
}));
/**
 * Size object, contains width and height
 *
 * @memberof PIXI
 * @typedef {object} ISize
 * @property {number} width - Width component
 * @property {number} height - Height component
 */ /**
 * Rectangle object is an area defined by its position, as indicated by its top-left corner
 * point (x, y) and by its width and its height.
 *
 * @class
 * @memberof PIXI
 */ var Rectangle = function() {
    /**
     * @param {number} [x=0] - The X coordinate of the upper-left corner of the rectangle
     * @param {number} [y=0] - The Y coordinate of the upper-left corner of the rectangle
     * @param {number} [width=0] - The overall width of this rectangle
     * @param {number} [height=0] - The overall height of this rectangle
     */ function Rectangle1(x, y, width, height) {
        if (x === void 0) x = 0;
        if (y === void 0) y = 0;
        if (width === void 0) width = 0;
        if (height === void 0) height = 0;
        /**
         * @member {number}
         * @default 0
         */ this.x = Number(x);
        /**
         * @member {number}
         * @default 0
         */ this.y = Number(y);
        /**
         * @member {number}
         * @default 0
         */ this.width = Number(width);
        /**
         * @member {number}
         * @default 0
         */ this.height = Number(height);
        /**
         * The type of the object, mainly used to avoid `instanceof` checks
         *
         * @member {number}
         * @readOnly
         * @default PIXI.SHAPES.RECT
         * @see PIXI.SHAPES
         */ this.type = SHAPES.RECT;
    }
    Object.defineProperty(Rectangle1.prototype, "left", {
        /**
         * returns the left edge of the rectangle
         *
         * @member {number}
         */ get: function() {
            return this.x;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Rectangle1.prototype, "right", {
        /**
         * returns the right edge of the rectangle
         *
         * @member {number}
         */ get: function() {
            return this.x + this.width;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Rectangle1.prototype, "top", {
        /**
         * returns the top edge of the rectangle
         *
         * @member {number}
         */ get: function() {
            return this.y;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Rectangle1.prototype, "bottom", {
        /**
         * returns the bottom edge of the rectangle
         *
         * @member {number}
         */ get: function() {
            return this.y + this.height;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Rectangle1, "EMPTY", {
        /**
         * A constant empty rectangle.
         *
         * @static
         * @constant
         * @member {PIXI.Rectangle}
         * @return {PIXI.Rectangle} An empty rectangle
         */ get: function() {
            return new Rectangle1(0, 0, 0, 0);
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Creates a clone of this Rectangle
     *
     * @return {PIXI.Rectangle} a copy of the rectangle
     */ Rectangle1.prototype.clone = function() {
        return new Rectangle1(this.x, this.y, this.width, this.height);
    };
    /**
     * Copies another rectangle to this one.
     *
     * @param {PIXI.Rectangle} rectangle - The rectangle to copy from.
     * @return {PIXI.Rectangle} Returns itself.
     */ Rectangle1.prototype.copyFrom = function(rectangle) {
        this.x = rectangle.x;
        this.y = rectangle.y;
        this.width = rectangle.width;
        this.height = rectangle.height;
        return this;
    };
    /**
     * Copies this rectangle to another one.
     *
     * @param {PIXI.Rectangle} rectangle - The rectangle to copy to.
     * @return {PIXI.Rectangle} Returns given parameter.
     */ Rectangle1.prototype.copyTo = function(rectangle) {
        rectangle.x = this.x;
        rectangle.y = this.y;
        rectangle.width = this.width;
        rectangle.height = this.height;
        return rectangle;
    };
    /**
     * Checks whether the x and y coordinates given are contained within this Rectangle
     *
     * @param {number} x - The X coordinate of the point to test
     * @param {number} y - The Y coordinate of the point to test
     * @return {boolean} Whether the x/y coordinates are within this Rectangle
     */ Rectangle1.prototype.contains = function(x, y) {
        if (this.width <= 0 || this.height <= 0) return false;
        if (x >= this.x && x < this.x + this.width) {
            if (y >= this.y && y < this.y + this.height) return true;
        }
        return false;
    };
    /**
     * Pads the rectangle making it grow in all directions.
     * If paddingY is omitted, both paddingX and paddingY will be set to paddingX.
     *
     * @param {number} [paddingX=0] - The horizontal padding amount.
     * @param {number} [paddingY=0] - The vertical padding amount.
     * @return {PIXI.Rectangle} Returns itself.
     */ Rectangle1.prototype.pad = function(paddingX, paddingY) {
        if (paddingX === void 0) paddingX = 0;
        if (paddingY === void 0) paddingY = paddingX;
        this.x -= paddingX;
        this.y -= paddingY;
        this.width += paddingX * 2;
        this.height += paddingY * 2;
        return this;
    };
    /**
     * Fits this rectangle around the passed one.
     *
     * @param {PIXI.Rectangle} rectangle - The rectangle to fit.
     * @return {PIXI.Rectangle} Returns itself.
     */ Rectangle1.prototype.fit = function(rectangle) {
        var x1 = Math.max(this.x, rectangle.x);
        var x2 = Math.min(this.x + this.width, rectangle.x + rectangle.width);
        var y1 = Math.max(this.y, rectangle.y);
        var y2 = Math.min(this.y + this.height, rectangle.y + rectangle.height);
        this.x = x1;
        this.width = Math.max(x2 - x1, 0);
        this.y = y1;
        this.height = Math.max(y2 - y1, 0);
        return this;
    };
    /**
     * Enlarges rectangle that way its corners lie on grid
     *
     * @param {number} [resolution=1] - resolution
     * @param {number} [eps=0.001] - precision
     * @return {PIXI.Rectangle} Returns itself.
     */ Rectangle1.prototype.ceil = function(resolution, eps) {
        if (resolution === void 0) resolution = 1;
        if (eps === void 0) eps = 0.001;
        var x2 = Math.ceil((this.x + this.width - eps) * resolution) / resolution;
        var y2 = Math.ceil((this.y + this.height - eps) * resolution) / resolution;
        this.x = Math.floor((this.x + eps) * resolution) / resolution;
        this.y = Math.floor((this.y + eps) * resolution) / resolution;
        this.width = x2 - this.x;
        this.height = y2 - this.y;
        return this;
    };
    /**
     * Enlarges this rectangle to include the passed rectangle.
     *
     * @param {PIXI.Rectangle} rectangle - The rectangle to include.
     * @return {PIXI.Rectangle} Returns itself.
     */ Rectangle1.prototype.enlarge = function(rectangle) {
        var x1 = Math.min(this.x, rectangle.x);
        var x2 = Math.max(this.x + this.width, rectangle.x + rectangle.width);
        var y1 = Math.min(this.y, rectangle.y);
        var y2 = Math.max(this.y + this.height, rectangle.y + rectangle.height);
        this.x = x1;
        this.width = x2 - x1;
        this.y = y1;
        this.height = y2 - y1;
        return this;
    };
    Rectangle1.prototype.toString = function() {
        return "[@pixi/math:Rectangle x=" + this.x + " y=" + this.y + " width=" + this.width + " height=" + this.height + "]";
    };
    return Rectangle1;
}();
/**
 * The Circle object is used to help draw graphics and can also be used to specify a hit area for displayObjects.
 *
 * @class
 * @memberof PIXI
 */ var Circle = function() {
    /**
     * @param {number} [x=0] - The X coordinate of the center of this circle
     * @param {number} [y=0] - The Y coordinate of the center of this circle
     * @param {number} [radius=0] - The radius of the circle
     */ function Circle1(x, y, radius) {
        if (x === void 0) x = 0;
        if (y === void 0) y = 0;
        if (radius === void 0) radius = 0;
        /**
         * @member {number}
         * @default 0
         */ this.x = x;
        /**
         * @member {number}
         * @default 0
         */ this.y = y;
        /**
         * @member {number}
         * @default 0
         */ this.radius = radius;
        /**
         * The type of the object, mainly used to avoid `instanceof` checks
         *
         * @member {number}
         * @readOnly
         * @default PIXI.SHAPES.CIRC
         * @see PIXI.SHAPES
         */ this.type = SHAPES.CIRC;
    }
    /**
     * Creates a clone of this Circle instance
     *
     * @return {PIXI.Circle} a copy of the Circle
     */ Circle1.prototype.clone = function() {
        return new Circle1(this.x, this.y, this.radius);
    };
    /**
     * Checks whether the x and y coordinates given are contained within this circle
     *
     * @param {number} x - The X coordinate of the point to test
     * @param {number} y - The Y coordinate of the point to test
     * @return {boolean} Whether the x/y coordinates are within this Circle
     */ Circle1.prototype.contains = function(x, y) {
        if (this.radius <= 0) return false;
        var r2 = this.radius * this.radius;
        var dx = this.x - x;
        var dy = this.y - y;
        dx *= dx;
        dy *= dy;
        return dx + dy <= r2;
    };
    /**
    * Returns the framing rectangle of the circle as a Rectangle object
    *
    * @return {PIXI.Rectangle} the framing rectangle
    */ Circle1.prototype.getBounds = function() {
        return new Rectangle(this.x - this.radius, this.y - this.radius, this.radius * 2, this.radius * 2);
    };
    Circle1.prototype.toString = function() {
        return "[@pixi/math:Circle x=" + this.x + " y=" + this.y + " radius=" + this.radius + "]";
    };
    return Circle1;
}();
/**
 * The Ellipse object is used to help draw graphics and can also be used to specify a hit area for displayObjects.
 *
 * @class
 * @memberof PIXI
 */ var Ellipse = function() {
    /**
     * @param {number} [x=0] - The X coordinate of the center of this ellipse
     * @param {number} [y=0] - The Y coordinate of the center of this ellipse
     * @param {number} [halfWidth=0] - The half width of this ellipse
     * @param {number} [halfHeight=0] - The half height of this ellipse
     */ function Ellipse1(x, y, halfWidth, halfHeight) {
        if (x === void 0) x = 0;
        if (y === void 0) y = 0;
        if (halfWidth === void 0) halfWidth = 0;
        if (halfHeight === void 0) halfHeight = 0;
        /**
         * @member {number}
         * @default 0
         */ this.x = x;
        /**
         * @member {number}
         * @default 0
         */ this.y = y;
        /**
         * @member {number}
         * @default 0
         */ this.width = halfWidth;
        /**
         * @member {number}
         * @default 0
         */ this.height = halfHeight;
        /**
         * The type of the object, mainly used to avoid `instanceof` checks
         *
         * @member {number}
         * @readOnly
         * @default PIXI.SHAPES.ELIP
         * @see PIXI.SHAPES
         */ this.type = SHAPES.ELIP;
    }
    /**
     * Creates a clone of this Ellipse instance
     *
     * @return {PIXI.Ellipse} a copy of the ellipse
     */ Ellipse1.prototype.clone = function() {
        return new Ellipse1(this.x, this.y, this.width, this.height);
    };
    /**
     * Checks whether the x and y coordinates given are contained within this ellipse
     *
     * @param {number} x - The X coordinate of the point to test
     * @param {number} y - The Y coordinate of the point to test
     * @return {boolean} Whether the x/y coords are within this ellipse
     */ Ellipse1.prototype.contains = function(x, y) {
        if (this.width <= 0 || this.height <= 0) return false;
        // normalize the coords to an ellipse with center 0,0
        var normx = (x - this.x) / this.width;
        var normy = (y - this.y) / this.height;
        normx *= normx;
        normy *= normy;
        return normx + normy <= 1;
    };
    /**
     * Returns the framing rectangle of the ellipse as a Rectangle object
     *
     * @return {PIXI.Rectangle} the framing rectangle
     */ Ellipse1.prototype.getBounds = function() {
        return new Rectangle(this.x - this.width, this.y - this.height, this.width, this.height);
    };
    Ellipse1.prototype.toString = function() {
        return "[@pixi/math:Ellipse x=" + this.x + " y=" + this.y + " width=" + this.width + " height=" + this.height + "]";
    };
    return Ellipse1;
}();
/**
 * A class to define a shape via user defined coordinates.
 *
 * @class
 * @memberof PIXI
 */ var Polygon = function() {
    /**
     * @param {PIXI.IPointData[]|number[]} points - This can be an array of Points
     *  that form the polygon, a flat array of numbers that will be interpreted as [x,y, x,y, ...], or
     *  the arguments passed can be all the points of the polygon e.g.
     *  `new PIXI.Polygon(new PIXI.Point(), new PIXI.Point(), ...)`, or the arguments passed can be flat
     *  x,y values e.g. `new Polygon(x,y, x,y, x,y, ...)` where `x` and `y` are Numbers.
     */ function Polygon1() {
        var arguments$1 = arguments;
        var points = [];
        for(var _i = 0; _i < arguments.length; _i++)points[_i] = arguments$1[_i];
        var flat = Array.isArray(points[0]) ? points[0] : points;
        // if this is an array of points, convert it to a flat array of numbers
        if (typeof flat[0] !== 'number') {
            var p = [];
            for(var i = 0, il = flat.length; i < il; i++)p.push(flat[i].x, flat[i].y);
            flat = p;
        }
        /**
         * An array of the points of this polygon
         *
         * @member {number[]}
         */ this.points = flat;
        /**
         * The type of the object, mainly used to avoid `instanceof` checks
         *
         * @member {number}
         * @readOnly
         * @default PIXI.SHAPES.POLY
         * @see PIXI.SHAPES
         */ this.type = SHAPES.POLY;
        /**
         * `false` after moveTo, `true` after `closePath`. In all other cases it is `true`.
         * @member {boolean}
         * @default true
         */ this.closeStroke = true;
    }
    /**
     * Creates a clone of this polygon
     *
     * @return {PIXI.Polygon} a copy of the polygon
     */ Polygon1.prototype.clone = function() {
        var points = this.points.slice();
        var polygon = new Polygon1(points);
        polygon.closeStroke = this.closeStroke;
        return polygon;
    };
    /**
     * Checks whether the x and y coordinates passed to this function are contained within this polygon
     *
     * @param {number} x - The X coordinate of the point to test
     * @param {number} y - The Y coordinate of the point to test
     * @return {boolean} Whether the x/y coordinates are within this polygon
     */ Polygon1.prototype.contains = function(x, y) {
        var inside = false;
        // use some raycasting to test hits
        // https://github.com/substack/point-in-polygon/blob/master/index.js
        var length = this.points.length / 2;
        for(var i = 0, j = length - 1; i < length; j = i++){
            var xi = this.points[i * 2];
            var yi = this.points[i * 2 + 1];
            var xj = this.points[j * 2];
            var yj = this.points[j * 2 + 1];
            var intersect = yi > y !== yj > y && x < (xj - xi) * ((y - yi) / (yj - yi)) + xi;
            if (intersect) inside = !inside;
        }
        return inside;
    };
    Polygon1.prototype.toString = function() {
        return "[@pixi/math:Polygon" + ("closeStroke=" + this.closeStroke) + ("points=" + this.points.reduce(function(pointsDesc, currentPoint) {
            return pointsDesc + ", " + currentPoint;
        }, '') + "]");
    };
    return Polygon1;
}();
/**
 * The Rounded Rectangle object is an area that has nice rounded corners, as indicated by its
 * top-left corner point (x, y) and by its width and its height and its radius.
 *
 * @class
 * @memberof PIXI
 */ var RoundedRectangle = function() {
    /**
     * @param {number} [x=0] - The X coordinate of the upper-left corner of the rounded rectangle
     * @param {number} [y=0] - The Y coordinate of the upper-left corner of the rounded rectangle
     * @param {number} [width=0] - The overall width of this rounded rectangle
     * @param {number} [height=0] - The overall height of this rounded rectangle
     * @param {number} [radius=20] - Controls the radius of the rounded corners
     */ function RoundedRectangle1(x, y, width, height, radius) {
        if (x === void 0) x = 0;
        if (y === void 0) y = 0;
        if (width === void 0) width = 0;
        if (height === void 0) height = 0;
        if (radius === void 0) radius = 20;
        /**
         * @member {number}
         * @default 0
         */ this.x = x;
        /**
         * @member {number}
         * @default 0
         */ this.y = y;
        /**
         * @member {number}
         * @default 0
         */ this.width = width;
        /**
         * @member {number}
         * @default 0
         */ this.height = height;
        /**
         * @member {number}
         * @default 20
         */ this.radius = radius;
        /**
         * The type of the object, mainly used to avoid `instanceof` checks
         *
         * @member {number}
         * @readonly
         * @default PIXI.SHAPES.RREC
         * @see PIXI.SHAPES
         */ this.type = SHAPES.RREC;
    }
    /**
     * Creates a clone of this Rounded Rectangle
     *
     * @return {PIXI.RoundedRectangle} a copy of the rounded rectangle
     */ RoundedRectangle1.prototype.clone = function() {
        return new RoundedRectangle1(this.x, this.y, this.width, this.height, this.radius);
    };
    /**
     * Checks whether the x and y coordinates given are contained within this Rounded Rectangle
     *
     * @param {number} x - The X coordinate of the point to test
     * @param {number} y - The Y coordinate of the point to test
     * @return {boolean} Whether the x/y coordinates are within this Rounded Rectangle
     */ RoundedRectangle1.prototype.contains = function(x, y) {
        if (this.width <= 0 || this.height <= 0) return false;
        if (x >= this.x && x <= this.x + this.width) {
            if (y >= this.y && y <= this.y + this.height) {
                if (y >= this.y + this.radius && y <= this.y + this.height - this.radius || x >= this.x + this.radius && x <= this.x + this.width - this.radius) return true;
                var dx = x - (this.x + this.radius);
                var dy = y - (this.y + this.radius);
                var radius2 = this.radius * this.radius;
                if (dx * dx + dy * dy <= radius2) return true;
                dx = x - (this.x + this.width - this.radius);
                if (dx * dx + dy * dy <= radius2) return true;
                dy = y - (this.y + this.height - this.radius);
                if (dx * dx + dy * dy <= radius2) return true;
                dx = x - (this.x + this.radius);
                if (dx * dx + dy * dy <= radius2) return true;
            }
        }
        return false;
    };
    RoundedRectangle1.prototype.toString = function() {
        return "[@pixi/math:RoundedRectangle x=" + this.x + " y=" + this.y + ("width=" + this.width + " height=" + this.height + " radius=" + this.radius + "]");
    };
    return RoundedRectangle1;
}();
/**
 * The Point object represents a location in a two-dimensional coordinate system, where `x` represents
 * the position on the horizontal axis and `y` represents the position on the vertical axis
 *
 * @class
 * @memberof PIXI
 * @implements IPoint
 */ var Point = function() {
    /** Creates a new `Point`
     * @param {number} [x=0] - position of the point on the x axis
     * @param {number} [y=0] - position of the point on the y axis
     */ function Point1(x, y) {
        if (x === void 0) x = 0;
        if (y === void 0) y = 0;
        /** Position of the point on the x axis */ this.x = 0;
        /** Position of the point on the y axis */ this.y = 0;
        this.x = x;
        this.y = y;
    }
    /** Creates a clone of this point
     * @returns A clone of this point
     */ Point1.prototype.clone = function() {
        return new Point1(this.x, this.y);
    };
    /**
     * Copies `x` and `y` from the given point into this point
     *
     * @param p - The point to copy from
     * @returns The point instance itself
     */ Point1.prototype.copyFrom = function(p) {
        this.set(p.x, p.y);
        return this;
    };
    /**
     * Copies this point's x and y into the given point (`p`).
     *
     * @param p - The point to copy to. Can be any of type that is or extends `IPointData`
     * @returns The point (`p`) with values updated
     */ Point1.prototype.copyTo = function(p) {
        p.set(this.x, this.y);
        return p;
    };
    /**
     * Accepts another point (`p`) and returns `true` if the given point is equal to this point
     *
     * @param p - The point to check
     * @returns Returns `true` if both `x` and `y` are equal
     */ Point1.prototype.equals = function(p) {
        return p.x === this.x && p.y === this.y;
    };
    /**
     * Sets the point to a new `x` and `y` position.
     * If `y` is omitted, both `x` and `y` will be set to `x`.
     *
     * @param {number} [x=0] - position of the point on the `x` axis
     * @param {number} [y=x] - position of the point on the `y` axis
     * @returns The point instance itself
     */ Point1.prototype.set = function(x, y) {
        if (x === void 0) x = 0;
        if (y === void 0) y = x;
        this.x = x;
        this.y = y;
        return this;
    };
    Point1.prototype.toString = function() {
        return "[@pixi/math:Point x=" + this.x + " y=" + this.y + "]";
    };
    return Point1;
}();
/**
 * The ObservablePoint object represents a location in a two-dimensional coordinate system, where `x` represents
 * the position on the horizontal axis and `y` represents the position on the vertical axis.
 *
 * An `ObservablePoint` is a point that triggers a callback when the point's position is changed.
 *
 * @class
 * @memberof PIXI
 * @implements IPoint
 */ var ObservablePoint = function() {
    /**
     * Creates a new `ObservablePoint`
     *
     * @param cb - callback function triggered when `x` and/or `y` are changed
     * @param scope - owner of callback
     * @param {number} [x=0] - position of the point on the x axis
     * @param {number} [y=0] - position of the point on the y axis
    */ function ObservablePoint1(cb, scope, x, y) {
        if (x === void 0) x = 0;
        if (y === void 0) y = 0;
        this._x = x;
        this._y = y;
        this.cb = cb;
        this.scope = scope;
    }
    /**
     * Creates a clone of this point.
     * The callback and scope params can be overridden otherwise they will default
     * to the clone object's values.
     *
     * @override
     * @param cb - The callback function triggered when `x` and/or `y` are changed
     * @param scope - The owner of the callback
     * @return a copy of this observable point
     */ ObservablePoint1.prototype.clone = function(cb, scope) {
        if (cb === void 0) cb = this.cb;
        if (scope === void 0) scope = this.scope;
        return new ObservablePoint1(cb, scope, this._x, this._y);
    };
    /**
     * Sets the point to a new `x` and `y` position.
     * If `y` is omitted, both `x` and `y` will be set to `x`.
     *
     * @param {number} [x=0] - position of the point on the x axis
     * @param {number} [y=x] - position of the point on the y axis
     * @returns The observable point instance itself
     */ ObservablePoint1.prototype.set = function(x, y) {
        if (x === void 0) x = 0;
        if (y === void 0) y = x;
        if (this._x !== x || this._y !== y) {
            this._x = x;
            this._y = y;
            this.cb.call(this.scope);
        }
        return this;
    };
    /**
     * Copies x and y from the given point (`p`)
     *
     * @param p - The point to copy from. Can be any of type that is or extends `IPointData`
     * @returns The observable point instance itself
     */ ObservablePoint1.prototype.copyFrom = function(p) {
        if (this._x !== p.x || this._y !== p.y) {
            this._x = p.x;
            this._y = p.y;
            this.cb.call(this.scope);
        }
        return this;
    };
    /**
     * Copies this point's x and y into that of the given point (`p`)
     *
     * @param p - The point to copy to. Can be any of type that is or extends `IPointData`
     * @returns The point (`p`) with values updated
     */ ObservablePoint1.prototype.copyTo = function(p) {
        p.set(this._x, this._y);
        return p;
    };
    /**
     * Accepts another point (`p`) and returns `true` if the given point is equal to this point
     *
     * @param p - The point to check
     * @returns Returns `true` if both `x` and `y` are equal
     */ ObservablePoint1.prototype.equals = function(p) {
        return p.x === this._x && p.y === this._y;
    };
    ObservablePoint1.prototype.toString = function() {
        return "[@pixi/math:ObservablePoint x=0 y=0 scope=" + this.scope + "]";
    };
    Object.defineProperty(ObservablePoint1.prototype, "x", {
        /** Position of the observable point on the x axis
         * @type {number}
         */ get: function() {
            return this._x;
        },
        set: function(value) {
            if (this._x !== value) {
                this._x = value;
                this.cb.call(this.scope);
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ObservablePoint1.prototype, "y", {
        /** Position of the observable point on the y axis
         * @type {number}
         */ get: function() {
            return this._y;
        },
        set: function(value) {
            if (this._y !== value) {
                this._y = value;
                this.cb.call(this.scope);
            }
        },
        enumerable: false,
        configurable: true
    });
    return ObservablePoint1;
}();
/**
 * The PixiJS Matrix as a class makes it a lot faster.
 *
 * Here is a representation of it:
 * ```js
 * | a | c | tx|
 * | b | d | ty|
 * | 0 | 0 | 1 |
 * ```
 * @class
 * @memberof PIXI
 */ var Matrix = function() {
    /**
     * @param {number} [a=1] - x scale
     * @param {number} [b=0] - y skew
     * @param {number} [c=0] - x skew
     * @param {number} [d=1] - y scale
     * @param {number} [tx=0] - x translation
     * @param {number} [ty=0] - y translation
     */ function Matrix1(a, b, c, d, tx, ty) {
        if (a === void 0) a = 1;
        if (b === void 0) b = 0;
        if (c === void 0) c = 0;
        if (d === void 0) d = 1;
        if (tx === void 0) tx = 0;
        if (ty === void 0) ty = 0;
        this.array = null;
        /**
         * @member {number}
         * @default 1
         */ this.a = a;
        /**
         * @member {number}
         * @default 0
         */ this.b = b;
        /**
         * @member {number}
         * @default 0
         */ this.c = c;
        /**
         * @member {number}
         * @default 1
         */ this.d = d;
        /**
         * @member {number}
         * @default 0
         */ this.tx = tx;
        /**
         * @member {number}
         * @default 0
         */ this.ty = ty;
    }
    /**
     * Creates a Matrix object based on the given array. The Element to Matrix mapping order is as follows:
     *
     * a = array[0]
     * b = array[1]
     * c = array[3]
     * d = array[4]
     * tx = array[2]
     * ty = array[5]
     *
     * @param {number[]} array - The array that the matrix will be populated from.
     */ Matrix1.prototype.fromArray = function(array) {
        this.a = array[0];
        this.b = array[1];
        this.c = array[3];
        this.d = array[4];
        this.tx = array[2];
        this.ty = array[5];
    };
    /**
     * sets the matrix properties
     *
     * @param {number} a - Matrix component
     * @param {number} b - Matrix component
     * @param {number} c - Matrix component
     * @param {number} d - Matrix component
     * @param {number} tx - Matrix component
     * @param {number} ty - Matrix component
     *
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.set = function(a, b, c, d, tx, ty) {
        this.a = a;
        this.b = b;
        this.c = c;
        this.d = d;
        this.tx = tx;
        this.ty = ty;
        return this;
    };
    /**
     * Creates an array from the current Matrix object.
     *
     * @param {boolean} transpose - Whether we need to transpose the matrix or not
     * @param {Float32Array} [out=new Float32Array(9)] - If provided the array will be assigned to out
     * @return {number[]} the newly created array which contains the matrix
     */ Matrix1.prototype.toArray = function(transpose, out) {
        if (!this.array) this.array = new Float32Array(9);
        var array = out || this.array;
        if (transpose) {
            array[0] = this.a;
            array[1] = this.b;
            array[2] = 0;
            array[3] = this.c;
            array[4] = this.d;
            array[5] = 0;
            array[6] = this.tx;
            array[7] = this.ty;
            array[8] = 1;
        } else {
            array[0] = this.a;
            array[1] = this.c;
            array[2] = this.tx;
            array[3] = this.b;
            array[4] = this.d;
            array[5] = this.ty;
            array[6] = 0;
            array[7] = 0;
            array[8] = 1;
        }
        return array;
    };
    /**
     * Get a new position with the current transformation applied.
     * Can be used to go from a child's coordinate space to the world coordinate space. (e.g. rendering)
     *
     * @param {PIXI.IPointData} pos - The origin
     * @param {PIXI.Point} [newPos] - The point that the new position is assigned to (allowed to be same as input)
     * @return {PIXI.Point} The new point, transformed through this matrix
     */ Matrix1.prototype.apply = function(pos, newPos) {
        newPos = newPos || new Point();
        var x = pos.x;
        var y = pos.y;
        newPos.x = this.a * x + this.c * y + this.tx;
        newPos.y = this.b * x + this.d * y + this.ty;
        return newPos;
    };
    /**
     * Get a new position with the inverse of the current transformation applied.
     * Can be used to go from the world coordinate space to a child's coordinate space. (e.g. input)
     *
     * @param {PIXI.IPointData} pos - The origin
     * @param {PIXI.Point} [newPos] - The point that the new position is assigned to (allowed to be same as input)
     * @return {PIXI.Point} The new point, inverse-transformed through this matrix
     */ Matrix1.prototype.applyInverse = function(pos, newPos) {
        newPos = newPos || new Point();
        var id = 1 / (this.a * this.d + this.c * -this.b);
        var x = pos.x;
        var y = pos.y;
        newPos.x = this.d * id * x + -this.c * id * y + (this.ty * this.c - this.tx * this.d) * id;
        newPos.y = this.a * id * y + -this.b * id * x + (-this.ty * this.a + this.tx * this.b) * id;
        return newPos;
    };
    /**
     * Translates the matrix on the x and y.
     *
     * @param {number} x - How much to translate x by
     * @param {number} y - How much to translate y by
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.translate = function(x, y) {
        this.tx += x;
        this.ty += y;
        return this;
    };
    /**
     * Applies a scale transformation to the matrix.
     *
     * @param {number} x - The amount to scale horizontally
     * @param {number} y - The amount to scale vertically
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.scale = function(x, y) {
        this.a *= x;
        this.d *= y;
        this.c *= x;
        this.b *= y;
        this.tx *= x;
        this.ty *= y;
        return this;
    };
    /**
     * Applies a rotation transformation to the matrix.
     *
     * @param {number} angle - The angle in radians.
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.rotate = function(angle) {
        var cos = Math.cos(angle);
        var sin = Math.sin(angle);
        var a1 = this.a;
        var c1 = this.c;
        var tx1 = this.tx;
        this.a = a1 * cos - this.b * sin;
        this.b = a1 * sin + this.b * cos;
        this.c = c1 * cos - this.d * sin;
        this.d = c1 * sin + this.d * cos;
        this.tx = tx1 * cos - this.ty * sin;
        this.ty = tx1 * sin + this.ty * cos;
        return this;
    };
    /**
     * Appends the given Matrix to this Matrix.
     *
     * @param {PIXI.Matrix} matrix - The matrix to append.
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.append = function(matrix) {
        var a1 = this.a;
        var b1 = this.b;
        var c1 = this.c;
        var d1 = this.d;
        this.a = matrix.a * a1 + matrix.b * c1;
        this.b = matrix.a * b1 + matrix.b * d1;
        this.c = matrix.c * a1 + matrix.d * c1;
        this.d = matrix.c * b1 + matrix.d * d1;
        this.tx = matrix.tx * a1 + matrix.ty * c1 + this.tx;
        this.ty = matrix.tx * b1 + matrix.ty * d1 + this.ty;
        return this;
    };
    /**
     * Sets the matrix based on all the available properties
     *
     * @param {number} x - Position on the x axis
     * @param {number} y - Position on the y axis
     * @param {number} pivotX - Pivot on the x axis
     * @param {number} pivotY - Pivot on the y axis
     * @param {number} scaleX - Scale on the x axis
     * @param {number} scaleY - Scale on the y axis
     * @param {number} rotation - Rotation in radians
     * @param {number} skewX - Skew on the x axis
     * @param {number} skewY - Skew on the y axis
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.setTransform = function(x, y, pivotX, pivotY, scaleX, scaleY, rotation, skewX, skewY) {
        this.a = Math.cos(rotation + skewY) * scaleX;
        this.b = Math.sin(rotation + skewY) * scaleX;
        this.c = -Math.sin(rotation - skewX) * scaleY;
        this.d = Math.cos(rotation - skewX) * scaleY;
        this.tx = x - (pivotX * this.a + pivotY * this.c);
        this.ty = y - (pivotX * this.b + pivotY * this.d);
        return this;
    };
    /**
     * Prepends the given Matrix to this Matrix.
     *
     * @param {PIXI.Matrix} matrix - The matrix to prepend
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.prepend = function(matrix) {
        var tx1 = this.tx;
        if (matrix.a !== 1 || matrix.b !== 0 || matrix.c !== 0 || matrix.d !== 1) {
            var a1 = this.a;
            var c1 = this.c;
            this.a = a1 * matrix.a + this.b * matrix.c;
            this.b = a1 * matrix.b + this.b * matrix.d;
            this.c = c1 * matrix.a + this.d * matrix.c;
            this.d = c1 * matrix.b + this.d * matrix.d;
        }
        this.tx = tx1 * matrix.a + this.ty * matrix.c + matrix.tx;
        this.ty = tx1 * matrix.b + this.ty * matrix.d + matrix.ty;
        return this;
    };
    /**
     * Decomposes the matrix (x, y, scaleX, scaleY, and rotation) and sets the properties on to a transform.
     *
     * @param {PIXI.Transform} transform - The transform to apply the properties to.
     * @return {PIXI.Transform} The transform with the newly applied properties
     */ Matrix1.prototype.decompose = function(transform) {
        // sort out rotation / skew..
        var a = this.a;
        var b = this.b;
        var c = this.c;
        var d = this.d;
        var pivot = transform.pivot;
        var skewX = -Math.atan2(-c, d);
        var skewY = Math.atan2(b, a);
        var delta = Math.abs(skewX + skewY);
        if (delta < 0.00001 || Math.abs(PI_2 - delta) < 0.00001) {
            transform.rotation = skewY;
            transform.skew.x = transform.skew.y = 0;
        } else {
            transform.rotation = 0;
            transform.skew.x = skewX;
            transform.skew.y = skewY;
        }
        // next set scale
        transform.scale.x = Math.sqrt(a * a + b * b);
        transform.scale.y = Math.sqrt(c * c + d * d);
        // next set position
        transform.position.x = this.tx + (pivot.x * a + pivot.y * c);
        transform.position.y = this.ty + (pivot.x * b + pivot.y * d);
        return transform;
    };
    /**
     * Inverts this matrix
     *
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.invert = function() {
        var a1 = this.a;
        var b1 = this.b;
        var c1 = this.c;
        var d1 = this.d;
        var tx1 = this.tx;
        var n = a1 * d1 - b1 * c1;
        this.a = d1 / n;
        this.b = -b1 / n;
        this.c = -c1 / n;
        this.d = a1 / n;
        this.tx = (c1 * this.ty - d1 * tx1) / n;
        this.ty = -(a1 * this.ty - b1 * tx1) / n;
        return this;
    };
    /**
     * Resets this Matrix to an identity (default) matrix.
     *
     * @return {PIXI.Matrix} This matrix. Good for chaining method calls.
     */ Matrix1.prototype.identity = function() {
        this.a = 1;
        this.b = 0;
        this.c = 0;
        this.d = 1;
        this.tx = 0;
        this.ty = 0;
        return this;
    };
    /**
     * Creates a new Matrix object with the same values as this one.
     *
     * @return {PIXI.Matrix} A copy of this matrix. Good for chaining method calls.
     */ Matrix1.prototype.clone = function() {
        var matrix = new Matrix1();
        matrix.a = this.a;
        matrix.b = this.b;
        matrix.c = this.c;
        matrix.d = this.d;
        matrix.tx = this.tx;
        matrix.ty = this.ty;
        return matrix;
    };
    /**
     * Changes the values of the given matrix to be the same as the ones in this matrix
     *
     * @param {PIXI.Matrix} matrix - The matrix to copy to.
     * @return {PIXI.Matrix} The matrix given in parameter with its values updated.
     */ Matrix1.prototype.copyTo = function(matrix) {
        matrix.a = this.a;
        matrix.b = this.b;
        matrix.c = this.c;
        matrix.d = this.d;
        matrix.tx = this.tx;
        matrix.ty = this.ty;
        return matrix;
    };
    /**
     * Changes the values of the matrix to be the same as the ones in given matrix
     *
     * @param {PIXI.Matrix} matrix - The matrix to copy from.
     * @return {PIXI.Matrix} this
     */ Matrix1.prototype.copyFrom = function(matrix) {
        this.a = matrix.a;
        this.b = matrix.b;
        this.c = matrix.c;
        this.d = matrix.d;
        this.tx = matrix.tx;
        this.ty = matrix.ty;
        return this;
    };
    Matrix1.prototype.toString = function() {
        return "[@pixi/math:Matrix a=" + this.a + " b=" + this.b + " c=" + this.c + " d=" + this.d + " tx=" + this.tx + " ty=" + this.ty + "]";
    };
    Object.defineProperty(Matrix1, "IDENTITY", {
        /**
         * A default (identity) matrix
         *
         * @static
         * @const
         * @member {PIXI.Matrix}
         */ get: function() {
            return new Matrix1();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Matrix1, "TEMP_MATRIX", {
        /**
         * A temp matrix
         *
         * @static
         * @const
         * @member {PIXI.Matrix}
         */ get: function() {
            return new Matrix1();
        },
        enumerable: false,
        configurable: true
    });
    return Matrix1;
}();
// Your friendly neighbour https://en.wikipedia.org/wiki/Dihedral_group
/*
 * Transform matrix for operation n is:
 * | ux | vx |
 * | uy | vy |
 */ var ux = [
    1,
    1,
    0,
    -1,
    -1,
    -1,
    0,
    1,
    1,
    1,
    0,
    -1,
    -1,
    -1,
    0,
    1
];
var uy = [
    0,
    1,
    1,
    1,
    0,
    -1,
    -1,
    -1,
    0,
    1,
    1,
    1,
    0,
    -1,
    -1,
    -1
];
var vx = [
    0,
    -1,
    -1,
    -1,
    0,
    1,
    1,
    1,
    0,
    1,
    1,
    1,
    0,
    -1,
    -1,
    -1
];
var vy = [
    1,
    1,
    0,
    -1,
    -1,
    -1,
    0,
    1,
    -1,
    -1,
    0,
    1,
    1,
    1,
    0,
    -1
];
/**
 * [Cayley Table]{@link https://en.wikipedia.org/wiki/Cayley_table}
 * for the composition of each rotation in the dihederal group D8.
 *
 * @type number[][]
 * @private
 */ var rotationCayley = [];
/**
 * Matrices for each `GD8Symmetry` rotation.
 *
 * @type Matrix[]
 * @private
 */ var rotationMatrices = [];
/*
 * Alias for {@code Math.sign}.
 */ var signum = Math.sign;
/*
 * Initializes `rotationCayley` and `rotationMatrices`. It is called
 * only once below.
 */ function init() {
    for(var i = 0; i < 16; i++){
        var row = [];
        rotationCayley.push(row);
        for(var j = 0; j < 16; j++){
            /* Multiplies rotation matrices i and j. */ var _ux = signum(ux[i] * ux[j] + vx[i] * uy[j]);
            var _uy = signum(uy[i] * ux[j] + vy[i] * uy[j]);
            var _vx = signum(ux[i] * vx[j] + vx[i] * vy[j]);
            var _vy = signum(uy[i] * vx[j] + vy[i] * vy[j]);
            /* Finds rotation matrix matching the product and pushes it. */ for(var k = 0; k < 16; k++)if (ux[k] === _ux && uy[k] === _uy && vx[k] === _vx && vy[k] === _vy) {
                row.push(k);
                break;
            }
        }
    }
    for(var i = 0; i < 16; i++){
        var mat = new Matrix();
        mat.set(ux[i], uy[i], vx[i], vy[i], 0, 0);
        rotationMatrices.push(mat);
    }
}
init();
/**
 * @memberof PIXI
 * @typedef {number} GD8Symmetry
 * @see PIXI.groupD8
 */ /**
 * Implements the dihedral group D8, which is similar to
 * [group D4]{@link http://mathworld.wolfram.com/DihedralGroupD4.html};
 * D8 is the same but with diagonals, and it is used for texture
 * rotations.
 *
 * The directions the U- and V- axes after rotation
 * of an angle of `a: GD8Constant` are the vectors `(uX(a), uY(a))`
 * and `(vX(a), vY(a))`. These aren't necessarily unit vectors.
 *
 * **Origin:**<br>
 *  This is the small part of gameofbombs.com portal system. It works.
 *
 * @see PIXI.groupD8.E
 * @see PIXI.groupD8.SE
 * @see PIXI.groupD8.S
 * @see PIXI.groupD8.SW
 * @see PIXI.groupD8.W
 * @see PIXI.groupD8.NW
 * @see PIXI.groupD8.N
 * @see PIXI.groupD8.NE
 * @author Ivan @ivanpopelyshev
 * @namespace PIXI.groupD8
 * @memberof PIXI
 */ var groupD8 = {
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 0°       | East      |
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ E: 0,
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 45°↻     | Southeast |
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ SE: 1,
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 90°↻     | South     |
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ S: 2,
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 135°↻    | Southwest |
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ SW: 3,
    /**
     * | Rotation | Direction |
     * |----------|-----------|
     * | 180°     | West      |
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ W: 4,
    /**
     * | Rotation    | Direction    |
     * |-------------|--------------|
     * | -135°/225°↻ | Northwest    |
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ NW: 5,
    /**
     * | Rotation    | Direction    |
     * |-------------|--------------|
     * | -90°/270°↻  | North        |
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ N: 6,
    /**
     * | Rotation    | Direction    |
     * |-------------|--------------|
     * | -45°/315°↻  | Northeast    |
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ NE: 7,
    /**
     * Reflection about Y-axis.
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ MIRROR_VERTICAL: 8,
    /**
     * Reflection about the main diagonal.
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ MAIN_DIAGONAL: 10,
    /**
     * Reflection about X-axis.
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ MIRROR_HORIZONTAL: 12,
    /**
     * Reflection about reverse diagonal.
     *
     * @memberof PIXI.groupD8
     * @constant {PIXI.GD8Symmetry}
     */ REVERSE_DIAGONAL: 14,
    /**
     * @memberof PIXI.groupD8
     * @param {PIXI.GD8Symmetry} ind - sprite rotation angle.
     * @return {PIXI.GD8Symmetry} The X-component of the U-axis
     *    after rotating the axes.
     */ uX: function(ind) {
        return ux[ind];
    },
    /**
     * @memberof PIXI.groupD8
     * @param {PIXI.GD8Symmetry} ind - sprite rotation angle.
     * @return {PIXI.GD8Symmetry} The Y-component of the U-axis
     *    after rotating the axes.
     */ uY: function(ind) {
        return uy[ind];
    },
    /**
     * @memberof PIXI.groupD8
     * @param {PIXI.GD8Symmetry} ind - sprite rotation angle.
     * @return {PIXI.GD8Symmetry} The X-component of the V-axis
     *    after rotating the axes.
     */ vX: function(ind) {
        return vx[ind];
    },
    /**
     * @memberof PIXI.groupD8
     * @param {PIXI.GD8Symmetry} ind - sprite rotation angle.
     * @return {PIXI.GD8Symmetry} The Y-component of the V-axis
     *    after rotating the axes.
     */ vY: function(ind) {
        return vy[ind];
    },
    /**
     * @memberof PIXI.groupD8
     * @param {PIXI.GD8Symmetry} rotation - symmetry whose opposite
     *   is needed. Only rotations have opposite symmetries while
     *   reflections don't.
     * @return {PIXI.GD8Symmetry} The opposite symmetry of `rotation`
     */ inv: function(rotation) {
        if (rotation & 8) return rotation & 15; // or rotation % 16
        return -rotation & 7; // or (8 - rotation) % 8
    },
    /**
     * Composes the two D8 operations.
     *
     * Taking `^` as reflection:
     *
     * |       | E=0 | S=2 | W=4 | N=6 | E^=8 | S^=10 | W^=12 | N^=14 |
     * |-------|-----|-----|-----|-----|------|-------|-------|-------|
     * | E=0   | E   | S   | W   | N   | E^   | S^    | W^    | N^    |
     * | S=2   | S   | W   | N   | E   | S^   | W^    | N^    | E^    |
     * | W=4   | W   | N   | E   | S   | W^   | N^    | E^    | S^    |
     * | N=6   | N   | E   | S   | W   | N^   | E^    | S^    | W^    |
     * | E^=8  | E^  | N^  | W^  | S^  | E    | N     | W     | S     |
     * | S^=10 | S^  | E^  | N^  | W^  | S    | E     | N     | W     |
     * | W^=12 | W^  | S^  | E^  | N^  | W    | S     | E     | N     |
     * | N^=14 | N^  | W^  | S^  | E^  | N    | W     | S     | E     |
     *
     * [This is a Cayley table]{@link https://en.wikipedia.org/wiki/Cayley_table}
     * @memberof PIXI.groupD8
     * @param {PIXI.GD8Symmetry} rotationSecond - Second operation, which
     *   is the row in the above cayley table.
     * @param {PIXI.GD8Symmetry} rotationFirst - First operation, which
     *   is the column in the above cayley table.
     * @return {PIXI.GD8Symmetry} Composed operation
     */ add: function(rotationSecond, rotationFirst) {
        return rotationCayley[rotationSecond][rotationFirst];
    },
    /**
     * Reverse of `add`.
     *
     * @memberof PIXI.groupD8
     * @param {PIXI.GD8Symmetry} rotationSecond - Second operation
     * @param {PIXI.GD8Symmetry} rotationFirst - First operation
     * @return {PIXI.GD8Symmetry} Result
     */ sub: function(rotationSecond, rotationFirst) {
        return rotationCayley[rotationSecond][groupD8.inv(rotationFirst)];
    },
    /**
     * Adds 180 degrees to rotation, which is a commutative
     * operation.
     *
     * @memberof PIXI.groupD8
     * @param {number} rotation - The number to rotate.
     * @returns {number} Rotated number
     */ rotate180: function(rotation) {
        return rotation ^ 4;
    },
    /**
     * Checks if the rotation angle is vertical, i.e. south
     * or north. It doesn't work for reflections.
     *
     * @memberof PIXI.groupD8
     * @param {PIXI.GD8Symmetry} rotation - The number to check.
     * @returns {boolean} Whether or not the direction is vertical
     */ isVertical: function(rotation) {
        return (rotation & 3) === 2;
    },
    /**
     * Approximates the vector `V(dx,dy)` into one of the
     * eight directions provided by `groupD8`.
     *
     * @memberof PIXI.groupD8
     * @param {number} dx - X-component of the vector
     * @param {number} dy - Y-component of the vector
     * @return {PIXI.GD8Symmetry} Approximation of the vector into
     *  one of the eight symmetries.
     */ byDirection: function(dx, dy) {
        if (Math.abs(dx) * 2 <= Math.abs(dy)) {
            if (dy >= 0) return groupD8.S;
            return groupD8.N;
        } else if (Math.abs(dy) * 2 <= Math.abs(dx)) {
            if (dx > 0) return groupD8.E;
            return groupD8.W;
        } else if (dy > 0) {
            if (dx > 0) return groupD8.SE;
            return groupD8.SW;
        } else if (dx > 0) return groupD8.NE;
        return groupD8.NW;
    },
    /**
     * Helps sprite to compensate texture packer rotation.
     *
     * @memberof PIXI.groupD8
     * @param {PIXI.Matrix} matrix - sprite world matrix
     * @param {PIXI.GD8Symmetry} rotation - The rotation factor to use.
     * @param {number} tx - sprite anchoring
     * @param {number} ty - sprite anchoring
     */ matrixAppendRotationInv: function(matrix, rotation, tx, ty) {
        if (tx === void 0) tx = 0;
        if (ty === void 0) ty = 0;
        // Packer used "rotation", we use "inv(rotation)"
        var mat = rotationMatrices[groupD8.inv(rotation)];
        mat.tx = tx;
        mat.ty = ty;
        matrix.append(mat);
    }
};
/**
 * Transform that takes care about its versions
 *
 * @class
 * @memberof PIXI
 */ var Transform = function() {
    function Transform1() {
        /**
         * The world transformation matrix.
         *
         * @member {PIXI.Matrix}
         */ this.worldTransform = new Matrix();
        /**
         * The local transformation matrix.
         *
         * @member {PIXI.Matrix}
         */ this.localTransform = new Matrix();
        /**
         * The coordinate of the object relative to the local coordinates of the parent.
         *
         * @member {PIXI.ObservablePoint}
         */ this.position = new ObservablePoint(this.onChange, this, 0, 0);
        /**
         * The scale factor of the object.
         *
         * @member {PIXI.ObservablePoint}
         */ this.scale = new ObservablePoint(this.onChange, this, 1, 1);
        /**
         * The pivot point of the displayObject that it rotates around.
         *
         * @member {PIXI.ObservablePoint}
         */ this.pivot = new ObservablePoint(this.onChange, this, 0, 0);
        /**
         * The skew amount, on the x and y axis.
         *
         * @member {PIXI.ObservablePoint}
         */ this.skew = new ObservablePoint(this.updateSkew, this, 0, 0);
        /**
         * The rotation amount.
         *
         * @protected
         * @member {number}
         */ this._rotation = 0;
        /**
         * The X-coordinate value of the normalized local X axis,
         * the first column of the local transformation matrix without a scale.
         *
         * @protected
         * @member {number}
         */ this._cx = 1;
        /**
         * The Y-coordinate value of the normalized local X axis,
         * the first column of the local transformation matrix without a scale.
         *
         * @protected
         * @member {number}
         */ this._sx = 0;
        /**
         * The X-coordinate value of the normalized local Y axis,
         * the second column of the local transformation matrix without a scale.
         *
         * @protected
         * @member {number}
         */ this._cy = 0;
        /**
         * The Y-coordinate value of the normalized local Y axis,
         * the second column of the local transformation matrix without a scale.
         *
         * @protected
         * @member {number}
         */ this._sy = 1;
        /**
         * The locally unique ID of the local transform.
         *
         * @protected
         * @member {number}
         */ this._localID = 0;
        /**
         * The locally unique ID of the local transform
         * used to calculate the current local transformation matrix.
         *
         * @protected
         * @member {number}
         */ this._currentLocalID = 0;
        /**
         * The locally unique ID of the world transform.
         *
         * @protected
         * @member {number}
         */ this._worldID = 0;
        /**
         * The locally unique ID of the parent's world transform
         * used to calculate the current world transformation matrix.
         *
         * @protected
         * @member {number}
         */ this._parentID = 0;
    }
    /**
     * Called when a value changes.
     *
     * @protected
     */ Transform1.prototype.onChange = function() {
        this._localID++;
    };
    /**
     * Called when the skew or the rotation changes.
     *
     * @protected
     */ Transform1.prototype.updateSkew = function() {
        this._cx = Math.cos(this._rotation + this.skew.y);
        this._sx = Math.sin(this._rotation + this.skew.y);
        this._cy = -Math.sin(this._rotation - this.skew.x); // cos, added PI/2
        this._sy = Math.cos(this._rotation - this.skew.x); // sin, added PI/2
        this._localID++;
    };
    Transform1.prototype.toString = function() {
        return "[@pixi/math:Transform " + ("position=(" + this.position.x + ", " + this.position.y + ") ") + ("rotation=" + this.rotation + " ") + ("scale=(" + this.scale.x + ", " + this.scale.y + ") ") + ("skew=(" + this.skew.x + ", " + this.skew.y + ") ") + "]";
    };
    /**
     * Updates the local transformation matrix.
     */ Transform1.prototype.updateLocalTransform = function() {
        var lt = this.localTransform;
        if (this._localID !== this._currentLocalID) {
            // get the matrix values of the displayobject based on its transform properties..
            lt.a = this._cx * this.scale.x;
            lt.b = this._sx * this.scale.x;
            lt.c = this._cy * this.scale.y;
            lt.d = this._sy * this.scale.y;
            lt.tx = this.position.x - (this.pivot.x * lt.a + this.pivot.y * lt.c);
            lt.ty = this.position.y - (this.pivot.x * lt.b + this.pivot.y * lt.d);
            this._currentLocalID = this._localID;
            // force an update..
            this._parentID = -1;
        }
    };
    /**
     * Updates the local and the world transformation matrices.
     *
     * @param {PIXI.Transform} parentTransform - The parent transform
     */ Transform1.prototype.updateTransform = function(parentTransform) {
        var lt = this.localTransform;
        if (this._localID !== this._currentLocalID) {
            // get the matrix values of the displayobject based on its transform properties..
            lt.a = this._cx * this.scale.x;
            lt.b = this._sx * this.scale.x;
            lt.c = this._cy * this.scale.y;
            lt.d = this._sy * this.scale.y;
            lt.tx = this.position.x - (this.pivot.x * lt.a + this.pivot.y * lt.c);
            lt.ty = this.position.y - (this.pivot.x * lt.b + this.pivot.y * lt.d);
            this._currentLocalID = this._localID;
            // force an update..
            this._parentID = -1;
        }
        if (this._parentID !== parentTransform._worldID) {
            // concat the parent matrix with the objects transform.
            var pt = parentTransform.worldTransform;
            var wt = this.worldTransform;
            wt.a = lt.a * pt.a + lt.b * pt.c;
            wt.b = lt.a * pt.b + lt.b * pt.d;
            wt.c = lt.c * pt.a + lt.d * pt.c;
            wt.d = lt.c * pt.b + lt.d * pt.d;
            wt.tx = lt.tx * pt.a + lt.ty * pt.c + pt.tx;
            wt.ty = lt.tx * pt.b + lt.ty * pt.d + pt.ty;
            this._parentID = parentTransform._worldID;
            // update the id of the transform..
            this._worldID++;
        }
    };
    /**
     * Decomposes a matrix and sets the transforms properties based on it.
     *
     * @param {PIXI.Matrix} matrix - The matrix to decompose
     */ Transform1.prototype.setFromMatrix = function(matrix) {
        matrix.decompose(this);
        this._localID++;
    };
    Object.defineProperty(Transform1.prototype, "rotation", {
        /**
         * The rotation of the object in radians.
         *
         * @member {number}
         */ get: function() {
            return this._rotation;
        },
        set: function(value) {
            if (this._rotation !== value) {
                this._rotation = value;
                this.updateSkew();
            }
        },
        enumerable: false,
        configurable: true
    });
    /**
     * A default (identity) transform
     *
     * @static
     * @constant
     * @member {PIXI.Transform}
     */ Transform1.IDENTITY = new Transform1();
    return Transform1;
}();

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"351da":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "InteractionData", ()=>InteractionData
);
parcelHelpers.export(exports, "InteractionEvent", ()=>InteractionEvent
);
parcelHelpers.export(exports, "InteractionManager", ()=>InteractionManager1
);
parcelHelpers.export(exports, "InteractionTrackingData", ()=>InteractionTrackingData
);
parcelHelpers.export(exports, "interactiveTarget", ()=>interactiveTarget
);
/*!
 * @pixi/interaction - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/interaction is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _math = require("@pixi/math");
var _ticker = require("@pixi/ticker");
var _display = require("@pixi/display");
var _utils = require("@pixi/utils");
/**
 * Holds all information related to an Interaction event
 *
 * @class
 * @memberof PIXI
 */ var InteractionData = function() {
    function InteractionData1() {
        this.pressure = 0;
        this.rotationAngle = 0;
        this.twist = 0;
        this.tangentialPressure = 0;
        /**
         * This point stores the global coords of where the touch/mouse event happened
         *
         * @member {PIXI.Point}
         */ this.global = new _math.Point();
        /**
         * The target Sprite that was interacted with
         *
         * @member {PIXI.Sprite}
         */ this.target = null;
        /**
         * When passed to an event handler, this will be the original DOM Event that was captured
         *
         * @see https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent
         * @see https://developer.mozilla.org/en-US/docs/Web/API/TouchEvent
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent
         * @member {MouseEvent|TouchEvent|PointerEvent}
         */ this.originalEvent = null;
        /**
         * Unique identifier for this interaction
         *
         * @member {number}
         */ this.identifier = null;
        /**
         * Indicates whether or not the pointer device that created the event is the primary pointer.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/isPrimary
         * @type {Boolean}
         */ this.isPrimary = false;
        /**
         * Indicates which button was pressed on the mouse or pointer device to trigger the event.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/button
         * @type {number}
         */ this.button = 0;
        /**
         * Indicates which buttons are pressed on the mouse or pointer device when the event is triggered.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/buttons
         * @type {number}
         */ this.buttons = 0;
        /**
         * The width of the pointer's contact along the x-axis, measured in CSS pixels.
         * radiusX of TouchEvents will be represented by this value.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/width
         * @type {number}
         */ this.width = 0;
        /**
         * The height of the pointer's contact along the y-axis, measured in CSS pixels.
         * radiusY of TouchEvents will be represented by this value.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/height
         * @type {number}
         */ this.height = 0;
        /**
         * The angle, in degrees, between the pointer device and the screen.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tiltX
         * @type {number}
         */ this.tiltX = 0;
        /**
         * The angle, in degrees, between the pointer device and the screen.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/tiltY
         * @type {number}
         */ this.tiltY = 0;
        /**
         * The type of pointer that triggered the event.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pointerType
         * @type {string}
         */ this.pointerType = null;
        /**
         * Pressure applied by the pointing device during the event. A Touch's force property
         * will be represented by this value.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pressure
         * @type {number}
         */ this.pressure = 0;
        /**
         * From TouchEvents (not PointerEvents triggered by touches), the rotationAngle of the Touch.
         * @see https://developer.mozilla.org/en-US/docs/Web/API/Touch/rotationAngle
         * @type {number}
         */ this.rotationAngle = 0;
        /**
         * Twist of a stylus pointer.
         * @see https://w3c.github.io/pointerevents/#pointerevent-interface
         * @type {number}
         */ this.twist = 0;
        /**
         * Barrel pressure on a stylus pointer.
         * @see https://w3c.github.io/pointerevents/#pointerevent-interface
         * @type {number}
         */ this.tangentialPressure = 0;
    }
    Object.defineProperty(InteractionData1.prototype, "pointerId", {
        /**
         * The unique identifier of the pointer. It will be the same as `identifier`.
         * @readonly
         * @member {number}
         * @see https://developer.mozilla.org/en-US/docs/Web/API/PointerEvent/pointerId
         */ get: function() {
            return this.identifier;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * This will return the local coordinates of the specified displayObject for this InteractionData
     *
     * @param {PIXI.DisplayObject} displayObject - The DisplayObject that you would like the local
     *  coords off
     * @param {PIXI.Point} [point] - A Point object in which to store the value, optional (otherwise
     *  will create a new point)
     * @param {PIXI.Point} [globalPos] - A Point object containing your custom global coords, optional
     *  (otherwise will use the current global coords)
     * @return {PIXI.Point} A point containing the coordinates of the InteractionData position relative
     *  to the DisplayObject
     */ InteractionData1.prototype.getLocalPosition = function(displayObject, point, globalPos) {
        return displayObject.worldTransform.applyInverse(globalPos || this.global, point);
    };
    /**
     * Copies properties from normalized event data.
     *
     * @param {Touch|MouseEvent|PointerEvent} event - The normalized event data
     */ InteractionData1.prototype.copyEvent = function(event) {
        // isPrimary should only change on touchstart/pointerdown, so we don't want to overwrite
        // it with "false" on later events when our shim for it on touch events might not be
        // accurate
        if ('isPrimary' in event && event.isPrimary) this.isPrimary = true;
        this.button = 'button' in event && event.button;
        // event.buttons is not available in all browsers (ie. Safari), but it does have a non-standard
        // event.which property instead, which conveys the same information.
        var buttons = 'buttons' in event && event.buttons;
        this.buttons = Number.isInteger(buttons) ? buttons : 'which' in event && event.which;
        this.width = 'width' in event && event.width;
        this.height = 'height' in event && event.height;
        this.tiltX = 'tiltX' in event && event.tiltX;
        this.tiltY = 'tiltY' in event && event.tiltY;
        this.pointerType = 'pointerType' in event && event.pointerType;
        this.pressure = 'pressure' in event && event.pressure;
        this.rotationAngle = 'rotationAngle' in event && event.rotationAngle;
        this.twist = 'twist' in event && event.twist || 0;
        this.tangentialPressure = 'tangentialPressure' in event && event.tangentialPressure || 0;
    };
    /**
     * Resets the data for pooling.
     */ InteractionData1.prototype.reset = function() {
        // isPrimary is the only property that we really need to reset - everything else is
        // guaranteed to be overwritten
        this.isPrimary = false;
    };
    return InteractionData1;
}();
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * Event class that mimics native DOM events.
 *
 * @class
 * @memberof PIXI
 */ var InteractionEvent = function() {
    function InteractionEvent1() {
        /**
         * Whether this event will continue propagating in the tree.
         *
         * Remaining events for the {@link stopsPropagatingAt} object
         * will still be dispatched.
         *
         * @member {boolean}
         */ this.stopped = false;
        /**
         * At which object this event stops propagating.
         *
         * @private
         * @member {PIXI.DisplayObject}
         */ this.stopsPropagatingAt = null;
        /**
         * Whether we already reached the element we want to
         * stop propagating at. This is important for delayed events,
         * where we start over deeper in the tree again.
         *
         * @private
         * @member {boolean}
         */ this.stopPropagationHint = false;
        /**
         * The object which caused this event to be dispatched.
         * For listener callback see {@link PIXI.InteractionEvent.currentTarget}.
         *
         * @member {PIXI.DisplayObject}
         */ this.target = null;
        /**
         * The object whose event listener’s callback is currently being invoked.
         *
         * @member {PIXI.DisplayObject}
         */ this.currentTarget = null;
        /**
         * Type of the event
         *
         * @member {string}
         */ this.type = null;
        /**
         * InteractionData related to this event
         *
         * @member {PIXI.InteractionData}
         */ this.data = null;
    }
    /**
     * Prevents event from reaching any objects other than the current object.
     *
     */ InteractionEvent1.prototype.stopPropagation = function() {
        this.stopped = true;
        this.stopPropagationHint = true;
        this.stopsPropagatingAt = this.currentTarget;
    };
    /**
     * Resets the event.
     */ InteractionEvent1.prototype.reset = function() {
        this.stopped = false;
        this.stopsPropagatingAt = null;
        this.stopPropagationHint = false;
        this.currentTarget = null;
        this.target = null;
    };
    return InteractionEvent1;
}();
/**
 * DisplayObjects with the {@link PIXI.interactiveTarget} mixin use this class to track interactions
 *
 * @class
 * @private
 * @memberof PIXI
 */ var InteractionTrackingData = function() {
    /**
     * @param {number} pointerId - Unique pointer id of the event
     * @private
     */ function InteractionTrackingData1(pointerId) {
        this._pointerId = pointerId;
        this._flags = InteractionTrackingData1.FLAGS.NONE;
    }
    /**
     *
     * @private
     * @param {number} flag - The interaction flag to set
     * @param {boolean} yn - Should the flag be set or unset
     */ InteractionTrackingData1.prototype._doSet = function(flag, yn) {
        if (yn) this._flags = this._flags | flag;
        else this._flags = this._flags & ~flag;
    };
    Object.defineProperty(InteractionTrackingData1.prototype, "pointerId", {
        /**
         * Unique pointer id of the event
         *
         * @readonly
         * @private
         * @member {number}
         */ get: function() {
            return this._pointerId;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(InteractionTrackingData1.prototype, "flags", {
        /**
         * State of the tracking data, expressed as bit flags
         *
         * @private
         * @member {number}
         */ get: function() {
            return this._flags;
        },
        set: function(flags) {
            this._flags = flags;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(InteractionTrackingData1.prototype, "none", {
        /**
         * Is the tracked event inactive (not over or down)?
         *
         * @private
         * @member {number}
         */ get: function() {
            return this._flags === InteractionTrackingData1.FLAGS.NONE;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(InteractionTrackingData1.prototype, "over", {
        /**
         * Is the tracked event over the DisplayObject?
         *
         * @private
         * @member {boolean}
         */ get: function() {
            return (this._flags & InteractionTrackingData1.FLAGS.OVER) !== 0;
        },
        set: function(yn) {
            this._doSet(InteractionTrackingData1.FLAGS.OVER, yn);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(InteractionTrackingData1.prototype, "rightDown", {
        /**
         * Did the right mouse button come down in the DisplayObject?
         *
         * @private
         * @member {boolean}
         */ get: function() {
            return (this._flags & InteractionTrackingData1.FLAGS.RIGHT_DOWN) !== 0;
        },
        set: function(yn) {
            this._doSet(InteractionTrackingData1.FLAGS.RIGHT_DOWN, yn);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(InteractionTrackingData1.prototype, "leftDown", {
        /**
         * Did the left mouse button come down in the DisplayObject?
         *
         * @private
         * @member {boolean}
         */ get: function() {
            return (this._flags & InteractionTrackingData1.FLAGS.LEFT_DOWN) !== 0;
        },
        set: function(yn) {
            this._doSet(InteractionTrackingData1.FLAGS.LEFT_DOWN, yn);
        },
        enumerable: false,
        configurable: true
    });
    InteractionTrackingData1.FLAGS = Object.freeze({
        NONE: 0,
        OVER: 1,
        LEFT_DOWN: 2,
        RIGHT_DOWN: 4
    });
    return InteractionTrackingData1;
}();
/**
 * Strategy how to search through stage tree for interactive objects
 *
 * @private
 * @class
 * @memberof PIXI
 */ var TreeSearch = function() {
    function TreeSearch1() {
        this._tempPoint = new _math.Point();
    }
    /**
     * Recursive implementation for findHit
     *
     * @private
     * @param {PIXI.InteractionEvent} interactionEvent - event containing the point that
     *  is tested for collision
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - the displayObject
     *  that will be hit test (recursively crawls its children)
     * @param {Function} [func] - the function that will be called on each interactive object. The
     *  interactionEvent, displayObject and hit will be passed to the function
     * @param {boolean} [hitTest] - this indicates if the objects inside should be hit test against the point
     * @param {boolean} [interactive] - Whether the displayObject is interactive
     * @return {boolean} returns true if the displayObject hit the point
     */ TreeSearch1.prototype.recursiveFindHit = function(interactionEvent, displayObject, func, hitTest, interactive) {
        if (!displayObject || !displayObject.visible) return false;
        var point = interactionEvent.data.global;
        // Took a little while to rework this function correctly! But now it is done and nice and optimized! ^_^
        //
        // This function will now loop through all objects and then only hit test the objects it HAS
        // to, not all of them. MUCH faster..
        // An object will be hit test if the following is true:
        //
        // 1: It is interactive.
        // 2: It belongs to a parent that is interactive AND one of the parents children have not already been hit.
        //
        // As another little optimization once an interactive object has been hit we can carry on
        // through the scenegraph, but we know that there will be no more hits! So we can avoid extra hit tests
        // A final optimization is that an object is not hit test directly if a child has already been hit.
        interactive = displayObject.interactive || interactive;
        var hit = false;
        var interactiveParent = interactive;
        // Flag here can set to false if the event is outside the parents hitArea or mask
        var hitTestChildren = true;
        // If there is a hitArea, no need to test against anything else if the pointer is not within the hitArea
        // There is also no longer a need to hitTest children.
        if (displayObject.hitArea) {
            if (hitTest) {
                displayObject.worldTransform.applyInverse(point, this._tempPoint);
                if (!displayObject.hitArea.contains(this._tempPoint.x, this._tempPoint.y)) {
                    hitTest = false;
                    hitTestChildren = false;
                } else hit = true;
            }
            interactiveParent = false;
        } else if (displayObject._mask) {
            if (hitTest) {
                if (!(displayObject._mask.containsPoint && displayObject._mask.containsPoint(point))) hitTest = false;
            }
        }
        // ** FREE TIP **! If an object is not interactive or has no buttons in it
        // (such as a game scene!) set interactiveChildren to false for that displayObject.
        // This will allow PixiJS to completely ignore and bypass checking the displayObjects children.
        if (hitTestChildren && displayObject.interactiveChildren && displayObject.children) {
            var children = displayObject.children;
            for(var i = children.length - 1; i >= 0; i--){
                var child = children[i];
                // time to get recursive.. if this function will return if something is hit..
                var childHit = this.recursiveFindHit(interactionEvent, child, func, hitTest, interactiveParent);
                if (childHit) {
                    // its a good idea to check if a child has lost its parent.
                    // this means it has been removed whilst looping so its best
                    if (!child.parent) continue;
                    // we no longer need to hit test any more objects in this container as we we
                    // now know the parent has been hit
                    interactiveParent = false;
                    // If the child is interactive , that means that the object hit was actually
                    // interactive and not just the child of an interactive object.
                    // This means we no longer need to hit test anything else. We still need to run
                    // through all objects, but we don't need to perform any hit tests.
                    if (childHit) {
                        if (interactionEvent.target) hitTest = false;
                        hit = true;
                    }
                }
            }
        }
        // no point running this if the item is not interactive or does not have an interactive parent.
        if (interactive) {
            // if we are hit testing (as in we have no hit any objects yet)
            // We also don't need to worry about hit testing if once of the displayObjects children
            // has already been hit - but only if it was interactive, otherwise we need to keep
            // looking for an interactive child, just in case we hit one
            if (hitTest && !interactionEvent.target) {
                // already tested against hitArea if it is defined
                if (!displayObject.hitArea && displayObject.containsPoint) {
                    if (displayObject.containsPoint(point)) hit = true;
                }
            }
            if (displayObject.interactive) {
                if (hit && !interactionEvent.target) interactionEvent.target = displayObject;
                if (func) func(interactionEvent, displayObject, !!hit);
            }
        }
        return hit;
    };
    /**
     * This function is provides a neat way of crawling through the scene graph and running a
     * specified function on all interactive objects it finds. It will also take care of hit
     * testing the interactive objects and passes the hit across in the function.
     *
     * @private
     * @param {PIXI.InteractionEvent} interactionEvent - event containing the point that
     *  is tested for collision
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - the displayObject
     *  that will be hit test (recursively crawls its children)
     * @param {Function} [func] - the function that will be called on each interactive object. The
     *  interactionEvent, displayObject and hit will be passed to the function
     * @param {boolean} [hitTest] - this indicates if the objects inside should be hit test against the point
     * @return {boolean} returns true if the displayObject hit the point
     */ TreeSearch1.prototype.findHit = function(interactionEvent, displayObject, func, hitTest) {
        this.recursiveFindHit(interactionEvent, displayObject, func, hitTest, false);
    };
    return TreeSearch1;
}();
/**
 * Interface for classes that represent a hit area.
 *
 * It is implemented by the following classes:
 * - {@link PIXI.Circle}
 * - {@link PIXI.Ellipse}
 * - {@link PIXI.Polygon}
 * - {@link PIXI.RoundedRectangle}
 *
 * @interface IHitArea
 * @memberof PIXI
 */ /**
 * Checks whether the x and y coordinates given are contained within this area
 *
 * @method
 * @name contains
 * @memberof PIXI.IHitArea#
 * @param {number} x - The X coordinate of the point to test
 * @param {number} y - The Y coordinate of the point to test
 * @return {boolean} Whether the x/y coordinates are within this area
 */ /**
 * Default property values of interactive objects
 * Used by {@link PIXI.InteractionManager} to automatically give all DisplayObjects these properties
 *
 * @private
 * @name interactiveTarget
 * @type {Object}
 * @memberof PIXI
 * @example
 *      function MyObject() {}
 *
 *      Object.assign(
 *          DisplayObject.prototype,
 *          PIXI.interactiveTarget
 *      );
 */ var interactiveTarget = {
    interactive: false,
    interactiveChildren: true,
    hitArea: null,
    /**
     * If enabled, the mouse cursor use the pointer behavior when hovered over the displayObject if it is interactive
     * Setting this changes the 'cursor' property to `'pointer'`.
     *
     * @example
     * const sprite = new PIXI.Sprite(texture);
     * sprite.interactive = true;
     * sprite.buttonMode = true;
     * @member {boolean}
     * @memberof PIXI.DisplayObject#
     */ get buttonMode () {
        return this.cursor === 'pointer';
    },
    set buttonMode (value){
        if (value) this.cursor = 'pointer';
        else if (this.cursor === 'pointer') this.cursor = null;
    },
    /**
     * This defines what cursor mode is used when the mouse cursor
     * is hovered over the displayObject.
     *
     * @example
     * const sprite = new PIXI.Sprite(texture);
     * sprite.interactive = true;
     * sprite.cursor = 'wait';
     * @see https://developer.mozilla.org/en/docs/Web/CSS/cursor
     *
     * @member {string}
     * @memberof PIXI.DisplayObject#
     */ cursor: null,
    /**
     * Internal set of all active pointers, by identifier
     *
     * @member {Map<number, InteractionTrackingData>}
     * @memberof PIXI.DisplayObject#
     * @private
     */ get trackedPointers () {
        if (this._trackedPointers === undefined) this._trackedPointers = {
        };
        return this._trackedPointers;
    },
    /**
     * Map of all tracked pointers, by identifier. Use trackedPointers to access.
     *
     * @private
     * @type {Map<number, InteractionTrackingData>}
     */ _trackedPointers: undefined
};
// Mix interactiveTarget into DisplayObject.prototype
_display.DisplayObject.mixin(interactiveTarget);
var MOUSE_POINTER_ID = 1;
// helpers for hitTest() - only used inside hitTest()
var hitTestEvent = {
    target: null,
    data: {
        global: null
    }
};
/**
 * The interaction manager deals with mouse, touch and pointer events.
 *
 * Any DisplayObject can be interactive if its `interactive` property is set to true.
 *
 * This manager also supports multitouch.
 *
 * An instance of this class is automatically created by default, and can be found at `renderer.plugins.interaction`
 *
 * @class
 * @extends PIXI.utils.EventEmitter
 * @memberof PIXI
 */ var InteractionManager1 = function(_super) {
    __extends(InteractionManager2, _super);
    /**
     * @param {PIXI.CanvasRenderer|PIXI.Renderer} renderer - A reference to the current renderer
     * @param {object} [options] - The options for the manager.
     * @param {boolean} [options.autoPreventDefault=true] - Should the manager automatically prevent default browser actions.
     * @param {number} [options.interactionFrequency=10] - Maximum frequency (ms) at pointer over/out states will be checked.
     * @param {number} [options.useSystemTicker=true] - Whether to add {@link tickerUpdate} to {@link PIXI.Ticker.system}.
     */ function InteractionManager2(renderer, options) {
        var _this = _super.call(this) || this;
        options = options || {
        };
        /**
         * The renderer this interaction manager works for.
         *
         * @member {PIXI.AbstractRenderer}
         */ _this.renderer = renderer;
        /**
         * Should default browser actions automatically be prevented.
         * Does not apply to pointer events for backwards compatibility
         * preventDefault on pointer events stops mouse events from firing
         * Thus, for every pointer event, there will always be either a mouse of touch event alongside it.
         *
         * @member {boolean}
         * @default true
         */ _this.autoPreventDefault = options.autoPreventDefault !== undefined ? options.autoPreventDefault : true;
        /**
         * Maximum frequency in milliseconds at which pointer over/out states will be checked by {@link tickerUpdate}.
         *
         * @member {number}
         * @default 10
         */ _this.interactionFrequency = options.interactionFrequency || 10;
        /**
         * The mouse data
         *
         * @member {PIXI.InteractionData}
         */ _this.mouse = new InteractionData();
        _this.mouse.identifier = MOUSE_POINTER_ID;
        // setting the mouse to start off far off screen will mean that mouse over does
        //  not get called before we even move the mouse.
        _this.mouse.global.set(-999999);
        /**
         * Actively tracked InteractionData
         *
         * @private
         * @member {Object.<number,PIXI.InteractionData>}
         */ _this.activeInteractionData = {
        };
        _this.activeInteractionData[MOUSE_POINTER_ID] = _this.mouse;
        /**
         * Pool of unused InteractionData
         *
         * @private
         * @member {PIXI.InteractionData[]}
         */ _this.interactionDataPool = [];
        /**
         * An event data object to handle all the event tracking/dispatching
         *
         * @member {object}
         */ _this.eventData = new InteractionEvent();
        /**
         * The DOM element to bind to.
         *
         * @protected
         * @member {HTMLElement}
         */ _this.interactionDOMElement = null;
        /**
         * This property determines if mousemove and touchmove events are fired only when the cursor
         * is over the object.
         * Setting to true will make things work more in line with how the DOM version works.
         * Setting to false can make things easier for things like dragging
         * It is currently set to false as this is how PixiJS used to work. This will be set to true in
         * future versions of pixi.
         *
         * @member {boolean}
         * @default false
         */ _this.moveWhenInside = false;
        /**
         * Have events been attached to the dom element?
         *
         * @protected
         * @member {boolean}
         */ _this.eventsAdded = false;
        /**
         * Has the system ticker been added?
         *
         * @protected
         * @member {boolean}
         */ _this.tickerAdded = false;
        /**
         * Is the mouse hovering over the renderer? If working in worker mouse considered to be over renderer by default.
         *
         * @protected
         * @member {boolean}
         */ _this.mouseOverRenderer = !('PointerEvent' in self);
        /**
         * Does the device support touch events
         * https://www.w3.org/TR/touch-events/
         *
         * @readonly
         * @member {boolean}
         */ _this.supportsTouchEvents = 'ontouchstart' in self;
        /**
         * Does the device support pointer events
         * https://www.w3.org/Submission/pointer-events/
         *
         * @readonly
         * @member {boolean}
         */ _this.supportsPointerEvents = !!self.PointerEvent;
        // this will make it so that you don't have to call bind all the time
        /**
         * @private
         * @member {Function}
         */ _this.onPointerUp = _this.onPointerUp.bind(_this);
        _this.processPointerUp = _this.processPointerUp.bind(_this);
        /**
         * @private
         * @member {Function}
         */ _this.onPointerCancel = _this.onPointerCancel.bind(_this);
        _this.processPointerCancel = _this.processPointerCancel.bind(_this);
        /**
         * @private
         * @member {Function}
         */ _this.onPointerDown = _this.onPointerDown.bind(_this);
        _this.processPointerDown = _this.processPointerDown.bind(_this);
        /**
         * @private
         * @member {Function}
         */ _this.onPointerMove = _this.onPointerMove.bind(_this);
        _this.processPointerMove = _this.processPointerMove.bind(_this);
        /**
         * @private
         * @member {Function}
         */ _this.onPointerOut = _this.onPointerOut.bind(_this);
        _this.processPointerOverOut = _this.processPointerOverOut.bind(_this);
        /**
         * @private
         * @member {Function}
         */ _this.onPointerOver = _this.onPointerOver.bind(_this);
        /**
         * Dictionary of how different cursor modes are handled. Strings are handled as CSS cursor
         * values, objects are handled as dictionaries of CSS values for interactionDOMElement,
         * and functions are called instead of changing the CSS.
         * Default CSS cursor values are provided for 'default' and 'pointer' modes.
         * @member {Object.<string, Object>}
         */ _this.cursorStyles = {
            default: 'inherit',
            pointer: 'pointer'
        };
        /**
         * The mode of the cursor that is being used.
         * The value of this is a key from the cursorStyles dictionary.
         *
         * @member {string}
         */ _this.currentCursorMode = null;
        /**
         * Internal cached let.
         *
         * @private
         * @member {string}
         */ _this.cursor = null;
        /**
         * The current resolution / device pixel ratio.
         *
         * @member {number}
         * @default 1
         */ _this.resolution = 1;
        /**
         * Delayed pointer events. Used to guarantee correct ordering of over/out events.
         *
         * @private
         * @member {Array}
         */ _this.delayedEvents = [];
        /**
         * TreeSearch component that is used to hitTest stage tree
         *
         * @private
         * @member {PIXI.TreeSearch}
         */ _this.search = new TreeSearch();
        /**
         * Used as a last rendered object in case renderer doesnt have _lastObjectRendered
         * @member {DisplayObject}
         * @private
         */ _this._tempDisplayObject = new _display.TemporaryDisplayObject();
        /**
         * An options object specifies characteristics about the event listener.
         * @private
         * @readonly
         * @member {Object.<string, boolean>}
         */ _this._eventListenerOptions = {
            capture: true,
            passive: false
        };
        /**
         * Fired when a pointer device button (usually a mouse left-button) is pressed on the display
         * object.
         *
         * @event PIXI.InteractionManager#mousedown
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device secondary button (usually a mouse right-button) is pressed
         * on the display object.
         *
         * @event PIXI.InteractionManager#rightdown
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button (usually a mouse left-button) is released over the display
         * object.
         *
         * @event PIXI.InteractionManager#mouseup
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device secondary button (usually a mouse right-button) is released
         * over the display object.
         *
         * @event PIXI.InteractionManager#rightup
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button (usually a mouse left-button) is pressed and released on
         * the display object.
         *
         * @event PIXI.InteractionManager#click
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device secondary button (usually a mouse right-button) is pressed
         * and released on the display object.
         *
         * @event PIXI.InteractionManager#rightclick
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button (usually a mouse left-button) is released outside the
         * display object that initially registered a
         * [mousedown]{@link PIXI.InteractionManager#event:mousedown}.
         *
         * @event PIXI.InteractionManager#mouseupoutside
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device secondary button (usually a mouse right-button) is released
         * outside the display object that initially registered a
         * [rightdown]{@link PIXI.InteractionManager#event:rightdown}.
         *
         * @event PIXI.InteractionManager#rightupoutside
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device (usually a mouse) is moved while over the display object
         *
         * @event PIXI.InteractionManager#mousemove
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device (usually a mouse) is moved onto the display object
         *
         * @event PIXI.InteractionManager#mouseover
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device (usually a mouse) is moved off the display object
         *
         * @event PIXI.InteractionManager#mouseout
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button is pressed on the display object.
         *
         * @event PIXI.InteractionManager#pointerdown
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button is released over the display object.
         * Not always fired when some buttons are held down while others are released. In those cases,
         * use [mousedown]{@link PIXI.InteractionManager#event:mousedown} and
         * [mouseup]{@link PIXI.InteractionManager#event:mouseup} instead.
         *
         * @event PIXI.InteractionManager#pointerup
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when the operating system cancels a pointer event
         *
         * @event PIXI.InteractionManager#pointercancel
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button is pressed and released on the display object.
         *
         * @event PIXI.InteractionManager#pointertap
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button is released outside the display object that initially
         * registered a [pointerdown]{@link PIXI.InteractionManager#event:pointerdown}.
         *
         * @event PIXI.InteractionManager#pointerupoutside
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device is moved while over the display object
         *
         * @event PIXI.InteractionManager#pointermove
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device is moved onto the display object
         *
         * @event PIXI.InteractionManager#pointerover
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device is moved off the display object
         *
         * @event PIXI.InteractionManager#pointerout
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is placed on the display object.
         *
         * @event PIXI.InteractionManager#touchstart
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is removed from the display object.
         *
         * @event PIXI.InteractionManager#touchend
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when the operating system cancels a touch
         *
         * @event PIXI.InteractionManager#touchcancel
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is placed and removed from the display object.
         *
         * @event PIXI.InteractionManager#tap
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is removed outside of the display object that initially
         * registered a [touchstart]{@link PIXI.InteractionManager#event:touchstart}.
         *
         * @event PIXI.InteractionManager#touchendoutside
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is moved along the display object.
         *
         * @event PIXI.InteractionManager#touchmove
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button (usually a mouse left-button) is pressed on the display.
         * object. DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#mousedown
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device secondary button (usually a mouse right-button) is pressed
         * on the display object. DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#rightdown
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button (usually a mouse left-button) is released over the display
         * object. DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#mouseup
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device secondary button (usually a mouse right-button) is released
         * over the display object. DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#rightup
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button (usually a mouse left-button) is pressed and released on
         * the display object. DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#click
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device secondary button (usually a mouse right-button) is pressed
         * and released on the display object. DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#rightclick
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button (usually a mouse left-button) is released outside the
         * display object that initially registered a
         * [mousedown]{@link PIXI.DisplayObject#event:mousedown}.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#mouseupoutside
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device secondary button (usually a mouse right-button) is released
         * outside the display object that initially registered a
         * [rightdown]{@link PIXI.DisplayObject#event:rightdown}.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#rightupoutside
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device (usually a mouse) is moved while over the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#mousemove
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device (usually a mouse) is moved onto the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#mouseover
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device (usually a mouse) is moved off the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#mouseout
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button is pressed on the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#pointerdown
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button is released over the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#pointerup
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when the operating system cancels a pointer event.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#pointercancel
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button is pressed and released on the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#pointertap
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device button is released outside the display object that initially
         * registered a [pointerdown]{@link PIXI.DisplayObject#event:pointerdown}.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#pointerupoutside
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device is moved while over the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#pointermove
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device is moved onto the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#pointerover
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a pointer device is moved off the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#pointerout
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is placed on the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#touchstart
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is removed from the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#touchend
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when the operating system cancels a touch.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#touchcancel
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is placed and removed from the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#tap
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is removed outside of the display object that initially
         * registered a [touchstart]{@link PIXI.DisplayObject#event:touchstart}.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#touchendoutside
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ /**
         * Fired when a touch point is moved along the display object.
         * DisplayObject's `interactive` property must be set to `true` to fire event.
         *
         * This comes from the @pixi/interaction package.
         *
         * @event PIXI.DisplayObject#touchmove
         * @param {PIXI.InteractionEvent} event - Interaction event
         */ _this._useSystemTicker = options.useSystemTicker !== undefined ? options.useSystemTicker : true;
        _this.setTargetElement(_this.renderer.view, _this.renderer.resolution);
        return _this;
    }
    Object.defineProperty(InteractionManager2.prototype, "useSystemTicker", {
        /**
         * Should the InteractionManager automatically add {@link tickerUpdate} to {@link PIXI.Ticker.system}.
         *
         * @member {boolean}
         * @default true
         */ get: function() {
            return this._useSystemTicker;
        },
        set: function(useSystemTicker) {
            this._useSystemTicker = useSystemTicker;
            if (useSystemTicker) this.addTickerListener();
            else this.removeTickerListener();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(InteractionManager2.prototype, "lastObjectRendered", {
        /**
         * Last rendered object or temp object
         * @readonly
         * @protected
         * @member {PIXI.DisplayObject}
         */ get: function() {
            return this.renderer._lastObjectRendered || this._tempDisplayObject;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Hit tests a point against the display tree, returning the first interactive object that is hit.
     *
     * @param {PIXI.Point} globalPoint - A point to hit test with, in global space.
     * @param {PIXI.Container} [root] - The root display object to start from. If omitted, defaults
     * to the last rendered root of the associated renderer.
     * @return {PIXI.DisplayObject} The hit display object, if any.
     */ InteractionManager2.prototype.hitTest = function(globalPoint, root) {
        // clear the target for our hit test
        hitTestEvent.target = null;
        // assign the global point
        hitTestEvent.data.global = globalPoint;
        // ensure safety of the root
        if (!root) root = this.lastObjectRendered;
        // run the hit test
        this.processInteractive(hitTestEvent, root, null, true);
        // return our found object - it'll be null if we didn't hit anything
        return hitTestEvent.target;
    };
    /**
     * Sets the DOM element which will receive mouse/touch events. This is useful for when you have
     * other DOM elements on top of the renderers Canvas element. With this you'll be bale to delegate
     * another DOM element to receive those events.
     *
     * @param {HTMLElement} element - the DOM element which will receive mouse and touch events.
     * @param {number} [resolution=1] - The resolution / device pixel ratio of the new element (relative to the canvas).
     */ InteractionManager2.prototype.setTargetElement = function(element, resolution) {
        if (resolution === void 0) resolution = 1;
        this.removeTickerListener();
        this.removeEvents();
        this.interactionDOMElement = element;
        this.resolution = resolution;
        this.addEvents();
        this.addTickerListener();
    };
    /**
     * Add the ticker listener
     *
     * @private
     */ InteractionManager2.prototype.addTickerListener = function() {
        if (this.tickerAdded || !this.interactionDOMElement || !this._useSystemTicker) return;
        _ticker.Ticker.system.add(this.tickerUpdate, this, _ticker.UPDATE_PRIORITY.INTERACTION);
        this.tickerAdded = true;
    };
    /**
     * Remove the ticker listener
     *
     * @private
     */ InteractionManager2.prototype.removeTickerListener = function() {
        if (!this.tickerAdded) return;
        _ticker.Ticker.system.remove(this.tickerUpdate, this);
        this.tickerAdded = false;
    };
    /**
     * Registers all the DOM events
     *
     * @private
     */ InteractionManager2.prototype.addEvents = function() {
        if (this.eventsAdded || !this.interactionDOMElement) return;
        var style = this.interactionDOMElement.style;
        if (self.navigator.msPointerEnabled) {
            style.msContentZooming = 'none';
            style.msTouchAction = 'none';
        } else if (this.supportsPointerEvents) style.touchAction = 'none';
        /*
         * These events are added first, so that if pointer events are normalized, they are fired
         * in the same order as non-normalized events. ie. pointer event 1st, mouse / touch 2nd
         */ if (this.supportsPointerEvents) {
            self.document.addEventListener('pointermove', this.onPointerMove, this._eventListenerOptions);
            this.interactionDOMElement.addEventListener('pointerdown', this.onPointerDown, this._eventListenerOptions);
            // pointerout is fired in addition to pointerup (for touch events) and pointercancel
            // we already handle those, so for the purposes of what we do in onPointerOut, we only
            // care about the pointerleave event
            this.interactionDOMElement.addEventListener('pointerleave', this.onPointerOut, this._eventListenerOptions);
            this.interactionDOMElement.addEventListener('pointerover', this.onPointerOver, this._eventListenerOptions);
            self.addEventListener('pointercancel', this.onPointerCancel, this._eventListenerOptions);
            self.addEventListener('pointerup', this.onPointerUp, this._eventListenerOptions);
        } else {
            self.document.addEventListener('mousemove', this.onPointerMove, this._eventListenerOptions);
            this.interactionDOMElement.addEventListener('mousedown', this.onPointerDown, this._eventListenerOptions);
            this.interactionDOMElement.addEventListener('mouseout', this.onPointerOut, this._eventListenerOptions);
            this.interactionDOMElement.addEventListener('mouseover', this.onPointerOver, this._eventListenerOptions);
            self.addEventListener('mouseup', this.onPointerUp, this._eventListenerOptions);
        }
        // always look directly for touch events so that we can provide original data
        // In a future version we should change this to being just a fallback and rely solely on
        // PointerEvents whenever available
        if (this.supportsTouchEvents) {
            this.interactionDOMElement.addEventListener('touchstart', this.onPointerDown, this._eventListenerOptions);
            this.interactionDOMElement.addEventListener('touchcancel', this.onPointerCancel, this._eventListenerOptions);
            this.interactionDOMElement.addEventListener('touchend', this.onPointerUp, this._eventListenerOptions);
            this.interactionDOMElement.addEventListener('touchmove', this.onPointerMove, this._eventListenerOptions);
        }
        this.eventsAdded = true;
    };
    /**
     * Removes all the DOM events that were previously registered
     *
     * @private
     */ InteractionManager2.prototype.removeEvents = function() {
        if (!this.eventsAdded || !this.interactionDOMElement) return;
        var style = this.interactionDOMElement.style;
        if (self.navigator.msPointerEnabled) {
            style.msContentZooming = '';
            style.msTouchAction = '';
        } else if (this.supportsPointerEvents) style.touchAction = '';
        if (this.supportsPointerEvents) {
            self.document.removeEventListener('pointermove', this.onPointerMove, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('pointerdown', this.onPointerDown, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('pointerleave', this.onPointerOut, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('pointerover', this.onPointerOver, this._eventListenerOptions);
            self.removeEventListener('pointercancel', this.onPointerCancel, this._eventListenerOptions);
            self.removeEventListener('pointerup', this.onPointerUp, this._eventListenerOptions);
        } else {
            self.document.removeEventListener('mousemove', this.onPointerMove, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('mousedown', this.onPointerDown, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('mouseout', this.onPointerOut, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('mouseover', this.onPointerOver, this._eventListenerOptions);
            self.removeEventListener('mouseup', this.onPointerUp, this._eventListenerOptions);
        }
        if (this.supportsTouchEvents) {
            this.interactionDOMElement.removeEventListener('touchstart', this.onPointerDown, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('touchcancel', this.onPointerCancel, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('touchend', this.onPointerUp, this._eventListenerOptions);
            this.interactionDOMElement.removeEventListener('touchmove', this.onPointerMove, this._eventListenerOptions);
        }
        this.interactionDOMElement = null;
        this.eventsAdded = false;
    };
    /**
     * Updates the state of interactive objects if at least {@link interactionFrequency}
     * milliseconds have passed since the last invocation.
     *
     * Invoked by a throttled ticker update from {@link PIXI.Ticker.system}.
     *
     * @param {number} deltaTime - time delta since the last call
     */ InteractionManager2.prototype.tickerUpdate = function(deltaTime) {
        this._deltaTime += deltaTime;
        if (this._deltaTime < this.interactionFrequency) return;
        this._deltaTime = 0;
        this.update();
    };
    /**
     * Updates the state of interactive objects.
     */ InteractionManager2.prototype.update = function() {
        if (!this.interactionDOMElement) return;
        // if the user move the mouse this check has already been done using the mouse move!
        if (this._didMove) {
            this._didMove = false;
            return;
        }
        this.cursor = null;
        // Resets the flag as set by a stopPropagation call. This flag is usually reset by a user interaction of any kind,
        // but there was a scenario of a display object moving under a static mouse cursor.
        // In this case, mouseover and mouseevents would not pass the flag test in dispatchEvent function
        for(var k in this.activeInteractionData)// eslint-disable-next-line no-prototype-builtins
        if (this.activeInteractionData.hasOwnProperty(k)) {
            var interactionData = this.activeInteractionData[k];
            if (interactionData.originalEvent && interactionData.pointerType !== 'touch') {
                var interactionEvent = this.configureInteractionEventForDOMEvent(this.eventData, interactionData.originalEvent, interactionData);
                this.processInteractive(interactionEvent, this.lastObjectRendered, this.processPointerOverOut, true);
            }
        }
        this.setCursorMode(this.cursor);
    };
    /**
     * Sets the current cursor mode, handling any callbacks or CSS style changes.
     *
     * @param {string} mode - cursor mode, a key from the cursorStyles dictionary
     */ InteractionManager2.prototype.setCursorMode = function(mode) {
        mode = mode || 'default';
        var applyStyles = true;
        // offscreen canvas does not support setting styles, but cursor modes can be functions,
        // in order to handle pixi rendered cursors, so we can't bail
        if (self.OffscreenCanvas && this.interactionDOMElement instanceof OffscreenCanvas) applyStyles = false;
        // if the mode didn't actually change, bail early
        if (this.currentCursorMode === mode) return;
        this.currentCursorMode = mode;
        var style = this.cursorStyles[mode];
        // only do things if there is a cursor style for it
        if (style) switch(typeof style){
            case 'string':
                // string styles are handled as cursor CSS
                if (applyStyles) this.interactionDOMElement.style.cursor = style;
                break;
            case 'function':
                // functions are just called, and passed the cursor mode
                style(mode);
                break;
            case 'object':
                // if it is an object, assume that it is a dictionary of CSS styles,
                // apply it to the interactionDOMElement
                if (applyStyles) Object.assign(this.interactionDOMElement.style, style);
                break;
        }
        else if (applyStyles && typeof mode === 'string' && !Object.prototype.hasOwnProperty.call(this.cursorStyles, mode)) // if it mode is a string (not a Symbol) and cursorStyles doesn't have any entry
        // for the mode, then assume that the dev wants it to be CSS for the cursor.
        this.interactionDOMElement.style.cursor = mode;
    };
    /**
     * Dispatches an event on the display object that was interacted with
     *
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - the display object in question
     * @param {string} eventString - the name of the event (e.g, mousedown)
     * @param {PIXI.InteractionEvent} eventData - the event data object
     * @private
     */ InteractionManager2.prototype.dispatchEvent = function(displayObject, eventString, eventData) {
        // Even if the event was stopped, at least dispatch any remaining events
        // for the same display object.
        if (!eventData.stopPropagationHint || displayObject === eventData.stopsPropagatingAt) {
            eventData.currentTarget = displayObject;
            eventData.type = eventString;
            displayObject.emit(eventString, eventData);
            if (displayObject[eventString]) displayObject[eventString](eventData);
        }
    };
    /**
     * Puts a event on a queue to be dispatched later. This is used to guarantee correct
     * ordering of over/out events.
     *
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - the display object in question
     * @param {string} eventString - the name of the event (e.g, mousedown)
     * @param {object} eventData - the event data object
     * @private
     */ InteractionManager2.prototype.delayDispatchEvent = function(displayObject, eventString, eventData) {
        this.delayedEvents.push({
            displayObject: displayObject,
            eventString: eventString,
            eventData: eventData
        });
    };
    /**
     * Maps x and y coords from a DOM object and maps them correctly to the PixiJS view. The
     * resulting value is stored in the point. This takes into account the fact that the DOM
     * element could be scaled and positioned anywhere on the screen.
     *
     * @param  {PIXI.IPointData} point - the point that the result will be stored in
     * @param  {number} x - the x coord of the position to map
     * @param  {number} y - the y coord of the position to map
     */ InteractionManager2.prototype.mapPositionToPoint = function(point, x, y) {
        var rect;
        // IE 11 fix
        if (!this.interactionDOMElement.parentElement) rect = {
            x: 0,
            y: 0,
            width: this.interactionDOMElement.width,
            height: this.interactionDOMElement.height,
            left: 0,
            top: 0
        };
        else rect = this.interactionDOMElement.getBoundingClientRect();
        var resolutionMultiplier = 1 / this.resolution;
        point.x = (x - rect.left) * (this.interactionDOMElement.width / rect.width) * resolutionMultiplier;
        point.y = (y - rect.top) * (this.interactionDOMElement.height / rect.height) * resolutionMultiplier;
    };
    /**
     * This function is provides a neat way of crawling through the scene graph and running a
     * specified function on all interactive objects it finds. It will also take care of hit
     * testing the interactive objects and passes the hit across in the function.
     *
     * @protected
     * @param {PIXI.InteractionEvent} interactionEvent - event containing the point that
     *  is tested for collision
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - the displayObject
     *  that will be hit test (recursively crawls its children)
     * @param {Function} [func] - the function that will be called on each interactive object. The
     *  interactionEvent, displayObject and hit will be passed to the function
     * @param {boolean} [hitTest] - indicates whether we want to calculate hits
     *  or just iterate through all interactive objects
     */ InteractionManager2.prototype.processInteractive = function(interactionEvent, displayObject, func, hitTest) {
        var hit = this.search.findHit(interactionEvent, displayObject, func, hitTest);
        var delayedEvents = this.delayedEvents;
        if (!delayedEvents.length) return hit;
        // Reset the propagation hint, because we start deeper in the tree again.
        interactionEvent.stopPropagationHint = false;
        var delayedLen = delayedEvents.length;
        this.delayedEvents = [];
        for(var i = 0; i < delayedLen; i++){
            var _a = delayedEvents[i], displayObject_1 = _a.displayObject, eventString = _a.eventString, eventData = _a.eventData;
            // When we reach the object we wanted to stop propagating at,
            // set the propagation hint.
            if (eventData.stopsPropagatingAt === displayObject_1) eventData.stopPropagationHint = true;
            this.dispatchEvent(displayObject_1, eventString, eventData);
        }
        return hit;
    };
    /**
     * Is called when the pointer button is pressed down on the renderer element
     *
     * @private
     * @param {PointerEvent} originalEvent - The DOM event of a pointer button being pressed down
     */ InteractionManager2.prototype.onPointerDown = function(originalEvent) {
        // if we support touch events, then only use those for touch events, not pointer events
        if (this.supportsTouchEvents && originalEvent.pointerType === 'touch') return;
        var events = this.normalizeToPointerData(originalEvent);
        /*
         * No need to prevent default on natural pointer events, as there are no side effects
         * Normalized events, however, may have the double mousedown/touchstart issue on the native android browser,
         * so still need to be prevented.
         */ // Guaranteed that there will be at least one event in events, and all events must have the same pointer type
        if (this.autoPreventDefault && events[0].isNormalized) {
            var cancelable = originalEvent.cancelable || !('cancelable' in originalEvent);
            if (cancelable) originalEvent.preventDefault();
        }
        var eventLen = events.length;
        for(var i = 0; i < eventLen; i++){
            var event = events[i];
            var interactionData = this.getInteractionDataForPointerId(event);
            var interactionEvent = this.configureInteractionEventForDOMEvent(this.eventData, event, interactionData);
            interactionEvent.data.originalEvent = originalEvent;
            this.processInteractive(interactionEvent, this.lastObjectRendered, this.processPointerDown, true);
            this.emit('pointerdown', interactionEvent);
            if (event.pointerType === 'touch') this.emit('touchstart', interactionEvent);
            else if (event.pointerType === 'mouse' || event.pointerType === 'pen') {
                var isRightButton = event.button === 2;
                this.emit(isRightButton ? 'rightdown' : 'mousedown', this.eventData);
            }
        }
    };
    /**
     * Processes the result of the pointer down check and dispatches the event if need be
     *
     * @private
     * @param {PIXI.InteractionEvent} interactionEvent - The interaction event wrapping the DOM event
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - The display object that was tested
     * @param {boolean} hit - the result of the hit test on the display object
     */ InteractionManager2.prototype.processPointerDown = function(interactionEvent, displayObject, hit) {
        var data = interactionEvent.data;
        var id = interactionEvent.data.identifier;
        if (hit) {
            if (!displayObject.trackedPointers[id]) displayObject.trackedPointers[id] = new InteractionTrackingData(id);
            this.dispatchEvent(displayObject, 'pointerdown', interactionEvent);
            if (data.pointerType === 'touch') this.dispatchEvent(displayObject, 'touchstart', interactionEvent);
            else if (data.pointerType === 'mouse' || data.pointerType === 'pen') {
                var isRightButton = data.button === 2;
                if (isRightButton) displayObject.trackedPointers[id].rightDown = true;
                else displayObject.trackedPointers[id].leftDown = true;
                this.dispatchEvent(displayObject, isRightButton ? 'rightdown' : 'mousedown', interactionEvent);
            }
        }
    };
    /**
     * Is called when the pointer button is released on the renderer element
     *
     * @private
     * @param {PointerEvent} originalEvent - The DOM event of a pointer button being released
     * @param {boolean} cancelled - true if the pointer is cancelled
     * @param {Function} func - Function passed to {@link processInteractive}
     */ InteractionManager2.prototype.onPointerComplete = function(originalEvent, cancelled, func) {
        var events = this.normalizeToPointerData(originalEvent);
        var eventLen = events.length;
        // if the event wasn't targeting our canvas, then consider it to be pointerupoutside
        // in all cases (unless it was a pointercancel)
        var eventAppend = originalEvent.target !== this.interactionDOMElement ? 'outside' : '';
        for(var i = 0; i < eventLen; i++){
            var event = events[i];
            var interactionData = this.getInteractionDataForPointerId(event);
            var interactionEvent = this.configureInteractionEventForDOMEvent(this.eventData, event, interactionData);
            interactionEvent.data.originalEvent = originalEvent;
            // perform hit testing for events targeting our canvas or cancel events
            this.processInteractive(interactionEvent, this.lastObjectRendered, func, cancelled || !eventAppend);
            this.emit(cancelled ? 'pointercancel' : "pointerup" + eventAppend, interactionEvent);
            if (event.pointerType === 'mouse' || event.pointerType === 'pen') {
                var isRightButton = event.button === 2;
                this.emit(isRightButton ? "rightup" + eventAppend : "mouseup" + eventAppend, interactionEvent);
            } else if (event.pointerType === 'touch') {
                this.emit(cancelled ? 'touchcancel' : "touchend" + eventAppend, interactionEvent);
                this.releaseInteractionDataForPointerId(event.pointerId);
            }
        }
    };
    /**
     * Is called when the pointer button is cancelled
     *
     * @private
     * @param {PointerEvent} event - The DOM event of a pointer button being released
     */ InteractionManager2.prototype.onPointerCancel = function(event) {
        // if we support touch events, then only use those for touch events, not pointer events
        if (this.supportsTouchEvents && event.pointerType === 'touch') return;
        this.onPointerComplete(event, true, this.processPointerCancel);
    };
    /**
     * Processes the result of the pointer cancel check and dispatches the event if need be
     *
     * @private
     * @param {PIXI.InteractionEvent} interactionEvent - The interaction event wrapping the DOM event
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - The display object that was tested
     */ InteractionManager2.prototype.processPointerCancel = function(interactionEvent, displayObject) {
        var data = interactionEvent.data;
        var id = interactionEvent.data.identifier;
        if (displayObject.trackedPointers[id] !== undefined) {
            delete displayObject.trackedPointers[id];
            this.dispatchEvent(displayObject, 'pointercancel', interactionEvent);
            if (data.pointerType === 'touch') this.dispatchEvent(displayObject, 'touchcancel', interactionEvent);
        }
    };
    /**
     * Is called when the pointer button is released on the renderer element
     *
     * @private
     * @param {PointerEvent} event - The DOM event of a pointer button being released
     */ InteractionManager2.prototype.onPointerUp = function(event) {
        // if we support touch events, then only use those for touch events, not pointer events
        if (this.supportsTouchEvents && event.pointerType === 'touch') return;
        this.onPointerComplete(event, false, this.processPointerUp);
    };
    /**
     * Processes the result of the pointer up check and dispatches the event if need be
     *
     * @private
     * @param {PIXI.InteractionEvent} interactionEvent - The interaction event wrapping the DOM event
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - The display object that was tested
     * @param {boolean} hit - the result of the hit test on the display object
     */ InteractionManager2.prototype.processPointerUp = function(interactionEvent, displayObject, hit) {
        var data = interactionEvent.data;
        var id = interactionEvent.data.identifier;
        var trackingData = displayObject.trackedPointers[id];
        var isTouch = data.pointerType === 'touch';
        var isMouse = data.pointerType === 'mouse' || data.pointerType === 'pen';
        // need to track mouse down status in the mouse block so that we can emit
        // event in a later block
        var isMouseTap = false;
        // Mouse only
        if (isMouse) {
            var isRightButton = data.button === 2;
            var flags = InteractionTrackingData.FLAGS;
            var test = isRightButton ? flags.RIGHT_DOWN : flags.LEFT_DOWN;
            var isDown = trackingData !== undefined && trackingData.flags & test;
            if (hit) {
                this.dispatchEvent(displayObject, isRightButton ? 'rightup' : 'mouseup', interactionEvent);
                if (isDown) {
                    this.dispatchEvent(displayObject, isRightButton ? 'rightclick' : 'click', interactionEvent);
                    // because we can confirm that the mousedown happened on this object, flag for later emit of pointertap
                    isMouseTap = true;
                }
            } else if (isDown) this.dispatchEvent(displayObject, isRightButton ? 'rightupoutside' : 'mouseupoutside', interactionEvent);
            // update the down state of the tracking data
            if (trackingData) {
                if (isRightButton) trackingData.rightDown = false;
                else trackingData.leftDown = false;
            }
        }
        // Pointers and Touches, and Mouse
        if (hit) {
            this.dispatchEvent(displayObject, 'pointerup', interactionEvent);
            if (isTouch) this.dispatchEvent(displayObject, 'touchend', interactionEvent);
            if (trackingData) {
                // emit pointertap if not a mouse, or if the mouse block decided it was a tap
                if (!isMouse || isMouseTap) this.dispatchEvent(displayObject, 'pointertap', interactionEvent);
                if (isTouch) {
                    this.dispatchEvent(displayObject, 'tap', interactionEvent);
                    // touches are no longer over (if they ever were) when we get the touchend
                    // so we should ensure that we don't keep pretending that they are
                    trackingData.over = false;
                }
            }
        } else if (trackingData) {
            this.dispatchEvent(displayObject, 'pointerupoutside', interactionEvent);
            if (isTouch) this.dispatchEvent(displayObject, 'touchendoutside', interactionEvent);
        }
        // Only remove the tracking data if there is no over/down state still associated with it
        if (trackingData && trackingData.none) delete displayObject.trackedPointers[id];
    };
    /**
     * Is called when the pointer moves across the renderer element
     *
     * @private
     * @param {PointerEvent} originalEvent - The DOM event of a pointer moving
     */ InteractionManager2.prototype.onPointerMove = function(originalEvent) {
        // if we support touch events, then only use those for touch events, not pointer events
        if (this.supportsTouchEvents && originalEvent.pointerType === 'touch') return;
        var events = this.normalizeToPointerData(originalEvent);
        if (events[0].pointerType === 'mouse' || events[0].pointerType === 'pen') {
            this._didMove = true;
            this.cursor = null;
        }
        var eventLen = events.length;
        for(var i = 0; i < eventLen; i++){
            var event = events[i];
            var interactionData = this.getInteractionDataForPointerId(event);
            var interactionEvent = this.configureInteractionEventForDOMEvent(this.eventData, event, interactionData);
            interactionEvent.data.originalEvent = originalEvent;
            this.processInteractive(interactionEvent, this.lastObjectRendered, this.processPointerMove, true);
            this.emit('pointermove', interactionEvent);
            if (event.pointerType === 'touch') this.emit('touchmove', interactionEvent);
            if (event.pointerType === 'mouse' || event.pointerType === 'pen') this.emit('mousemove', interactionEvent);
        }
        if (events[0].pointerType === 'mouse') this.setCursorMode(this.cursor);
    };
    /**
     * Processes the result of the pointer move check and dispatches the event if need be
     *
     * @private
     * @param {PIXI.InteractionEvent} interactionEvent - The interaction event wrapping the DOM event
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - The display object that was tested
     * @param {boolean} hit - the result of the hit test on the display object
     */ InteractionManager2.prototype.processPointerMove = function(interactionEvent, displayObject, hit) {
        var data = interactionEvent.data;
        var isTouch = data.pointerType === 'touch';
        var isMouse = data.pointerType === 'mouse' || data.pointerType === 'pen';
        if (isMouse) this.processPointerOverOut(interactionEvent, displayObject, hit);
        if (!this.moveWhenInside || hit) {
            this.dispatchEvent(displayObject, 'pointermove', interactionEvent);
            if (isTouch) this.dispatchEvent(displayObject, 'touchmove', interactionEvent);
            if (isMouse) this.dispatchEvent(displayObject, 'mousemove', interactionEvent);
        }
    };
    /**
     * Is called when the pointer is moved out of the renderer element
     *
     * @private
     * @param {PointerEvent} originalEvent - The DOM event of a pointer being moved out
     */ InteractionManager2.prototype.onPointerOut = function(originalEvent) {
        // if we support touch events, then only use those for touch events, not pointer events
        if (this.supportsTouchEvents && originalEvent.pointerType === 'touch') return;
        var events = this.normalizeToPointerData(originalEvent);
        // Only mouse and pointer can call onPointerOut, so events will always be length 1
        var event = events[0];
        if (event.pointerType === 'mouse') {
            this.mouseOverRenderer = false;
            this.setCursorMode(null);
        }
        var interactionData = this.getInteractionDataForPointerId(event);
        var interactionEvent = this.configureInteractionEventForDOMEvent(this.eventData, event, interactionData);
        interactionEvent.data.originalEvent = event;
        this.processInteractive(interactionEvent, this.lastObjectRendered, this.processPointerOverOut, false);
        this.emit('pointerout', interactionEvent);
        if (event.pointerType === 'mouse' || event.pointerType === 'pen') this.emit('mouseout', interactionEvent);
        else // we can get touchleave events after touchend, so we want to make sure we don't
        // introduce memory leaks
        this.releaseInteractionDataForPointerId(interactionData.identifier);
    };
    /**
     * Processes the result of the pointer over/out check and dispatches the event if need be
     *
     * @private
     * @param {PIXI.InteractionEvent} interactionEvent - The interaction event wrapping the DOM event
     * @param {PIXI.Container|PIXI.Sprite|PIXI.TilingSprite} displayObject - The display object that was tested
     * @param {boolean} hit - the result of the hit test on the display object
     */ InteractionManager2.prototype.processPointerOverOut = function(interactionEvent, displayObject, hit) {
        var data = interactionEvent.data;
        var id = interactionEvent.data.identifier;
        var isMouse = data.pointerType === 'mouse' || data.pointerType === 'pen';
        var trackingData = displayObject.trackedPointers[id];
        // if we just moused over the display object, then we need to track that state
        if (hit && !trackingData) trackingData = displayObject.trackedPointers[id] = new InteractionTrackingData(id);
        if (trackingData === undefined) return;
        if (hit && this.mouseOverRenderer) {
            if (!trackingData.over) {
                trackingData.over = true;
                this.delayDispatchEvent(displayObject, 'pointerover', interactionEvent);
                if (isMouse) this.delayDispatchEvent(displayObject, 'mouseover', interactionEvent);
            }
            // only change the cursor if it has not already been changed (by something deeper in the
            // display tree)
            if (isMouse && this.cursor === null) this.cursor = displayObject.cursor;
        } else if (trackingData.over) {
            trackingData.over = false;
            this.dispatchEvent(displayObject, 'pointerout', this.eventData);
            if (isMouse) this.dispatchEvent(displayObject, 'mouseout', interactionEvent);
            // if there is no mouse down information for the pointer, then it is safe to delete
            if (trackingData.none) delete displayObject.trackedPointers[id];
        }
    };
    /**
     * Is called when the pointer is moved into the renderer element
     *
     * @private
     * @param {PointerEvent} originalEvent - The DOM event of a pointer button being moved into the renderer view
     */ InteractionManager2.prototype.onPointerOver = function(originalEvent) {
        var events = this.normalizeToPointerData(originalEvent);
        // Only mouse and pointer can call onPointerOver, so events will always be length 1
        var event = events[0];
        var interactionData = this.getInteractionDataForPointerId(event);
        var interactionEvent = this.configureInteractionEventForDOMEvent(this.eventData, event, interactionData);
        interactionEvent.data.originalEvent = event;
        if (event.pointerType === 'mouse') this.mouseOverRenderer = true;
        this.emit('pointerover', interactionEvent);
        if (event.pointerType === 'mouse' || event.pointerType === 'pen') this.emit('mouseover', interactionEvent);
    };
    /**
     * Get InteractionData for a given pointerId. Store that data as well
     *
     * @private
     * @param {PointerEvent} event - Normalized pointer event, output from normalizeToPointerData
     * @return {PIXI.InteractionData} - Interaction data for the given pointer identifier
     */ InteractionManager2.prototype.getInteractionDataForPointerId = function(event) {
        var pointerId = event.pointerId;
        var interactionData;
        if (pointerId === MOUSE_POINTER_ID || event.pointerType === 'mouse') interactionData = this.mouse;
        else if (this.activeInteractionData[pointerId]) interactionData = this.activeInteractionData[pointerId];
        else {
            interactionData = this.interactionDataPool.pop() || new InteractionData();
            interactionData.identifier = pointerId;
            this.activeInteractionData[pointerId] = interactionData;
        }
        // copy properties from the event, so that we can make sure that touch/pointer specific
        // data is available
        interactionData.copyEvent(event);
        return interactionData;
    };
    /**
     * Return unused InteractionData to the pool, for a given pointerId
     *
     * @private
     * @param {number} pointerId - Identifier from a pointer event
     */ InteractionManager2.prototype.releaseInteractionDataForPointerId = function(pointerId) {
        var interactionData = this.activeInteractionData[pointerId];
        if (interactionData) {
            delete this.activeInteractionData[pointerId];
            interactionData.reset();
            this.interactionDataPool.push(interactionData);
        }
    };
    /**
     * Configure an InteractionEvent to wrap a DOM PointerEvent and InteractionData
     *
     * @private
     * @param {PIXI.InteractionEvent} interactionEvent - The event to be configured
     * @param {PointerEvent} pointerEvent - The DOM event that will be paired with the InteractionEvent
     * @param {PIXI.InteractionData} interactionData - The InteractionData that will be paired
     *        with the InteractionEvent
     * @return {PIXI.InteractionEvent} the interaction event that was passed in
     */ InteractionManager2.prototype.configureInteractionEventForDOMEvent = function(interactionEvent, pointerEvent, interactionData) {
        interactionEvent.data = interactionData;
        this.mapPositionToPoint(interactionData.global, pointerEvent.clientX, pointerEvent.clientY);
        // Not really sure why this is happening, but it's how a previous version handled things
        if (pointerEvent.pointerType === 'touch') {
            pointerEvent.globalX = interactionData.global.x;
            pointerEvent.globalY = interactionData.global.y;
        }
        interactionData.originalEvent = pointerEvent;
        interactionEvent.reset();
        return interactionEvent;
    };
    /**
     * Ensures that the original event object contains all data that a regular pointer event would have
     *
     * @private
     * @param {TouchEvent|MouseEvent|PointerEvent} event - The original event data from a touch or mouse event
     * @return {PointerEvent[]} An array containing a single normalized pointer event, in the case of a pointer
     *  or mouse event, or a multiple normalized pointer events if there are multiple changed touches
     */ InteractionManager2.prototype.normalizeToPointerData = function(event) {
        var normalizedEvents = [];
        if (this.supportsTouchEvents && event instanceof TouchEvent) for(var i = 0, li = event.changedTouches.length; i < li; i++){
            var touch = event.changedTouches[i];
            if (typeof touch.button === 'undefined') touch.button = event.touches.length ? 1 : 0;
            if (typeof touch.buttons === 'undefined') touch.buttons = event.touches.length ? 1 : 0;
            if (typeof touch.isPrimary === 'undefined') touch.isPrimary = event.touches.length === 1 && event.type === 'touchstart';
            if (typeof touch.width === 'undefined') touch.width = touch.radiusX || 1;
            if (typeof touch.height === 'undefined') touch.height = touch.radiusY || 1;
            if (typeof touch.tiltX === 'undefined') touch.tiltX = 0;
            if (typeof touch.tiltY === 'undefined') touch.tiltY = 0;
            if (typeof touch.pointerType === 'undefined') touch.pointerType = 'touch';
            if (typeof touch.pointerId === 'undefined') touch.pointerId = touch.identifier || 0;
            if (typeof touch.pressure === 'undefined') touch.pressure = touch.force || 0.5;
            if (typeof touch.twist === 'undefined') touch.twist = 0;
            if (typeof touch.tangentialPressure === 'undefined') touch.tangentialPressure = 0;
            // TODO: Remove these, as layerX/Y is not a standard, is deprecated, has uneven
            // support, and the fill ins are not quite the same
            // offsetX/Y might be okay, but is not the same as clientX/Y when the canvas's top
            // left is not 0,0 on the page
            if (typeof touch.layerX === 'undefined') touch.layerX = touch.offsetX = touch.clientX;
            if (typeof touch.layerY === 'undefined') touch.layerY = touch.offsetY = touch.clientY;
            // mark the touch as normalized, just so that we know we did it
            touch.isNormalized = true;
            normalizedEvents.push(touch);
        }
        else if (!self.MouseEvent || event instanceof MouseEvent && (!this.supportsPointerEvents || !(event instanceof self.PointerEvent))) {
            var tempEvent = event;
            if (typeof tempEvent.isPrimary === 'undefined') tempEvent.isPrimary = true;
            if (typeof tempEvent.width === 'undefined') tempEvent.width = 1;
            if (typeof tempEvent.height === 'undefined') tempEvent.height = 1;
            if (typeof tempEvent.tiltX === 'undefined') tempEvent.tiltX = 0;
            if (typeof tempEvent.tiltY === 'undefined') tempEvent.tiltY = 0;
            if (typeof tempEvent.pointerType === 'undefined') tempEvent.pointerType = 'mouse';
            if (typeof tempEvent.pointerId === 'undefined') tempEvent.pointerId = MOUSE_POINTER_ID;
            if (typeof tempEvent.pressure === 'undefined') tempEvent.pressure = 0.5;
            if (typeof tempEvent.twist === 'undefined') tempEvent.twist = 0;
            if (typeof tempEvent.tangentialPressure === 'undefined') tempEvent.tangentialPressure = 0;
            // mark the mouse event as normalized, just so that we know we did it
            tempEvent.isNormalized = true;
            normalizedEvents.push(tempEvent);
        } else normalizedEvents.push(event);
        return normalizedEvents;
    };
    /**
     * Destroys the interaction manager
     *
     */ InteractionManager2.prototype.destroy = function() {
        this.removeEvents();
        this.removeTickerListener();
        this.removeAllListeners();
        this.renderer = null;
        this.mouse = null;
        this.eventData = null;
        this.interactionDOMElement = null;
        this.onPointerDown = null;
        this.processPointerDown = null;
        this.onPointerUp = null;
        this.processPointerUp = null;
        this.onPointerCancel = null;
        this.processPointerCancel = null;
        this.onPointerMove = null;
        this.processPointerMove = null;
        this.onPointerOut = null;
        this.processPointerOverOut = null;
        this.onPointerOver = null;
        this.search = null;
    };
    return InteractionManager2;
}(_utils.EventEmitter);

},{"@pixi/math":"1qR3C","@pixi/ticker":"5j6Uq","@pixi/display":"hQqz5","@pixi/utils":"joR65","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5j6Uq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Ticker", ()=>Ticker
);
parcelHelpers.export(exports, "TickerPlugin", ()=>TickerPlugin
);
parcelHelpers.export(exports, "UPDATE_PRIORITY", ()=>UPDATE_PRIORITY
);
/*!
 * @pixi/ticker - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/ticker is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _settings = require("@pixi/settings");
/**
 * Target frames per millisecond.
 *
 * @static
 * @name TARGET_FPMS
 * @memberof PIXI.settings
 * @type {number}
 * @default 0.06
 */ _settings.settings.TARGET_FPMS = 0.06;
/**
 * Represents the update priorities used by internal PIXI classes when registered with
 * the {@link PIXI.Ticker} object. Higher priority items are updated first and lower
 * priority items, such as render, should go later.
 *
 * @static
 * @constant
 * @name UPDATE_PRIORITY
 * @memberof PIXI
 * @enum {number}
 * @property {number} INTERACTION=50 Highest priority, used for {@link PIXI.InteractionManager}
 * @property {number} HIGH=25 High priority updating, {@link PIXI.VideoBaseTexture} and {@link PIXI.AnimatedSprite}
 * @property {number} NORMAL=0 Default priority for ticker events, see {@link PIXI.Ticker#add}.
 * @property {number} LOW=-25 Low priority used for {@link PIXI.Application} rendering.
 * @property {number} UTILITY=-50 Lowest priority used for {@link PIXI.BasePrepare} utility.
 */ var UPDATE_PRIORITY;
(function(UPDATE_PRIORITY1) {
    UPDATE_PRIORITY1[UPDATE_PRIORITY1["INTERACTION"] = 50] = "INTERACTION";
    UPDATE_PRIORITY1[UPDATE_PRIORITY1["HIGH"] = 25] = "HIGH";
    UPDATE_PRIORITY1[UPDATE_PRIORITY1["NORMAL"] = 0] = "NORMAL";
    UPDATE_PRIORITY1[UPDATE_PRIORITY1["LOW"] = -25] = "LOW";
    UPDATE_PRIORITY1[UPDATE_PRIORITY1["UTILITY"] = -50] = "UTILITY";
})(UPDATE_PRIORITY || (UPDATE_PRIORITY = {
}));
/**
 * Internal class for handling the priority sorting of ticker handlers.
 *
 * @private
 * @class
 * @memberof PIXI
 */ var TickerListener = function() {
    /**
     * Constructor
     * @private
     * @param fn - The listener function to be added for one update
     * @param context - The listener context
     * @param priority - The priority for emitting
     * @param once - If the handler should fire once
     */ function TickerListener1(fn, context, priority, once) {
        if (context === void 0) context = null;
        if (priority === void 0) priority = 0;
        if (once === void 0) once = false;
        /** The next item in chain. */ this.next = null;
        /** The previous item in chain. */ this.previous = null;
        /** `true` if this listener has been destroyed already. */ this._destroyed = false;
        this.fn = fn;
        this.context = context;
        this.priority = priority;
        this.once = once;
    }
    /**
     * Simple compare function to figure out if a function and context match.
     * @private
     * @param fn - The listener function to be added for one update
     * @param context - The listener context
     * @return `true` if the listener match the arguments
     */ TickerListener1.prototype.match = function(fn, context) {
        if (context === void 0) context = null;
        return this.fn === fn && this.context === context;
    };
    /**
     * Emit by calling the current function.
     * @private
     * @param deltaTime - time since the last emit.
     * @return Next ticker
     */ TickerListener1.prototype.emit = function(deltaTime) {
        if (this.fn) {
            if (this.context) this.fn.call(this.context, deltaTime);
            else this.fn(deltaTime);
        }
        var redirect = this.next;
        if (this.once) this.destroy(true);
        // Soft-destroying should remove
        // the next reference
        if (this._destroyed) this.next = null;
        return redirect;
    };
    /**
     * Connect to the list.
     * @private
     * @param previous - Input node, previous listener
     */ TickerListener1.prototype.connect = function(previous) {
        this.previous = previous;
        if (previous.next) previous.next.previous = this;
        this.next = previous.next;
        previous.next = this;
    };
    /**
     * Destroy and don't use after this.
     * @private
     * @param hard - `true` to remove the `next` reference, this
     *        is considered a hard destroy. Soft destroy maintains the next reference.
     * @return The listener to redirect while emitting or removing.
     */ TickerListener1.prototype.destroy = function(hard) {
        if (hard === void 0) hard = false;
        this._destroyed = true;
        this.fn = null;
        this.context = null;
        // Disconnect, hook up next and previous
        if (this.previous) this.previous.next = this.next;
        if (this.next) this.next.previous = this.previous;
        // Redirect to the next item
        var redirect = this.next;
        // Remove references
        this.next = hard ? null : redirect;
        this.previous = null;
        return redirect;
    };
    return TickerListener1;
}();
/**
 * A Ticker class that runs an update loop that other objects listen to.
 *
 * This class is composed around listeners meant for execution on the next requested animation frame.
 * Animation frames are requested only when necessary, e.g. When the ticker is started and the emitter has listeners.
 *
 * @class
 * @memberof PIXI
 */ var Ticker = function() {
    function Ticker1() {
        var _this = this;
        /**
         * Whether or not this ticker should invoke the method
         * {@link PIXI.Ticker#start} automatically
         * when a listener is added.
         */ this.autoStart = false;
        /**
         * Scalar time value from last frame to this frame.
         * This value is capped by setting {@link PIXI.Ticker#minFPS}
         * and is scaled with {@link PIXI.Ticker#speed}.
         * **Note:** The cap may be exceeded by scaling.
         */ this.deltaTime = 1;
        /**
         * The last time {@link PIXI.Ticker#update} was invoked.
         * This value is also reset internally outside of invoking
         * update, but only when a new animation frame is requested.
         * If the platform supports DOMHighResTimeStamp,
         * this value will have a precision of 1 µs.
         */ this.lastTime = -1;
        /**
         * Factor of current {@link PIXI.Ticker#deltaTime}.
         * @example
         * // Scales ticker.deltaTime to what would be
         * // the equivalent of approximately 120 FPS
         * ticker.speed = 2;
         */ this.speed = 1;
        /**
         * Whether or not this ticker has been started.
         * `true` if {@link PIXI.Ticker#start} has been called.
         * `false` if {@link PIXI.Ticker#stop} has been called.
         * While `false`, this value may change to `true` in the
         * event of {@link PIXI.Ticker#autoStart} being `true`
         * and a listener is added.
         */ this.started = false;
        /** Internal current frame request ID */ this._requestId = null;
        /**
         * Internal value managed by minFPS property setter and getter.
         * This is the maximum allowed milliseconds between updates.
         */ this._maxElapsedMS = 100;
        /**
         * Internal value managed by minFPS property setter and getter.
         * This is the maximum allowed milliseconds between updates.
         */ this._minElapsedMS = 0;
        /** If enabled, deleting is disabled.*/ this._protected = false;
        /**
         * The last time keyframe was executed.
         * Maintains a relatively fixed interval with the previous value.
         */ this._lastFrame = -1;
        this._head = new TickerListener(null, null, Infinity);
        this.deltaMS = 1 / _settings.settings.TARGET_FPMS;
        this.elapsedMS = 1 / _settings.settings.TARGET_FPMS;
        this._tick = function(time) {
            _this._requestId = null;
            if (_this.started) {
                // Invoke listeners now
                _this.update(time);
                // Listener side effects may have modified ticker state.
                if (_this.started && _this._requestId === null && _this._head.next) _this._requestId = requestAnimationFrame(_this._tick);
            }
        };
    }
    /**
     * Conditionally requests a new animation frame.
     * If a frame has not already been requested, and if the internal
     * emitter has listeners, a new frame is requested.
     *
     * @private
     */ Ticker1.prototype._requestIfNeeded = function() {
        if (this._requestId === null && this._head.next) {
            // ensure callbacks get correct delta
            this.lastTime = performance.now();
            this._lastFrame = this.lastTime;
            this._requestId = requestAnimationFrame(this._tick);
        }
    };
    /**
     * Conditionally cancels a pending animation frame.
     * @private
     */ Ticker1.prototype._cancelIfNeeded = function() {
        if (this._requestId !== null) {
            cancelAnimationFrame(this._requestId);
            this._requestId = null;
        }
    };
    /**
     * Conditionally requests a new animation frame.
     * If the ticker has been started it checks if a frame has not already
     * been requested, and if the internal emitter has listeners. If these
     * conditions are met, a new frame is requested. If the ticker has not
     * been started, but autoStart is `true`, then the ticker starts now,
     * and continues with the previous conditions to request a new frame.
     *
     * @private
     */ Ticker1.prototype._startIfPossible = function() {
        if (this.started) this._requestIfNeeded();
        else if (this.autoStart) this.start();
    };
    /**
     * Register a handler for tick events. Calls continuously unless
     * it is removed or the ticker is stopped.
     *
     * @param fn - The listener function to be added for updates
     * @param context - The listener context
     * @param {number} [priority=PIXI.UPDATE_PRIORITY.NORMAL] - The priority for emitting
     * @returns This instance of a ticker
     */ Ticker1.prototype.add = function(fn, context, priority) {
        if (priority === void 0) priority = UPDATE_PRIORITY.NORMAL;
        return this._addListener(new TickerListener(fn, context, priority));
    };
    /**
     * Add a handler for the tick event which is only execute once.
     *
     * @param fn - The listener function to be added for one update
     * @param context - The listener context
     * @param {number} [priority=PIXI.UPDATE_PRIORITY.NORMAL] - The priority for emitting
     * @returns This instance of a ticker
     */ Ticker1.prototype.addOnce = function(fn, context, priority) {
        if (priority === void 0) priority = UPDATE_PRIORITY.NORMAL;
        return this._addListener(new TickerListener(fn, context, priority, true));
    };
    /**
     * Internally adds the event handler so that it can be sorted by priority.
     * Priority allows certain handler (user, AnimatedSprite, Interaction) to be run
     * before the rendering.
     *
     * @private
     * @param listener - Current listener being added.
     * @returns This instance of a ticker
     */ Ticker1.prototype._addListener = function(listener) {
        // For attaching to head
        var current = this._head.next;
        var previous = this._head;
        // Add the first item
        if (!current) listener.connect(previous);
        else {
            // Go from highest to lowest priority
            while(current){
                if (listener.priority > current.priority) {
                    listener.connect(previous);
                    break;
                }
                previous = current;
                current = current.next;
            }
            // Not yet connected
            if (!listener.previous) listener.connect(previous);
        }
        this._startIfPossible();
        return this;
    };
    /**
     * Removes any handlers matching the function and context parameters.
     * If no handlers are left after removing, then it cancels the animation frame.
     *
     * @param fn - The listener function to be removed
     * @param context - The listener context to be removed
     * @returns This instance of a ticker
     */ Ticker1.prototype.remove = function(fn, context) {
        var listener = this._head.next;
        while(listener)// We found a match, lets remove it
        // no break to delete all possible matches
        // incase a listener was added 2+ times
        if (listener.match(fn, context)) listener = listener.destroy();
        else listener = listener.next;
        if (!this._head.next) this._cancelIfNeeded();
        return this;
    };
    Object.defineProperty(Ticker1.prototype, "count", {
        /**
         * The number of listeners on this ticker, calculated by walking through linked list
         *
         * @readonly
         * @member {number}
         */ get: function() {
            if (!this._head) return 0;
            var count = 0;
            var current = this._head;
            while(current = current.next)count++;
            return count;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Starts the ticker. If the ticker has listeners
     * a new animation frame is requested at this point.
     */ Ticker1.prototype.start = function() {
        if (!this.started) {
            this.started = true;
            this._requestIfNeeded();
        }
    };
    /**
     * Stops the ticker. If the ticker has requested
     * an animation frame it is canceled at this point.
     */ Ticker1.prototype.stop = function() {
        if (this.started) {
            this.started = false;
            this._cancelIfNeeded();
        }
    };
    /**
     * Destroy the ticker and don't use after this. Calling
     * this method removes all references to internal events.
     */ Ticker1.prototype.destroy = function() {
        if (!this._protected) {
            this.stop();
            var listener = this._head.next;
            while(listener)listener = listener.destroy(true);
            this._head.destroy();
            this._head = null;
        }
    };
    /**
     * Triggers an update. An update entails setting the
     * current {@link PIXI.Ticker#elapsedMS},
     * the current {@link PIXI.Ticker#deltaTime},
     * invoking all listeners with current deltaTime,
     * and then finally setting {@link PIXI.Ticker#lastTime}
     * with the value of currentTime that was provided.
     * This method will be called automatically by animation
     * frame callbacks if the ticker instance has been started
     * and listeners are added.
     *
     * @param {number} [currentTime=performance.now()] - the current time of execution
     */ Ticker1.prototype.update = function(currentTime) {
        if (currentTime === void 0) currentTime = performance.now();
        var elapsedMS;
        // If the difference in time is zero or negative, we ignore most of the work done here.
        // If there is no valid difference, then should be no reason to let anyone know about it.
        // A zero delta, is exactly that, nothing should update.
        //
        // The difference in time can be negative, and no this does not mean time traveling.
        // This can be the result of a race condition between when an animation frame is requested
        // on the current JavaScript engine event loop, and when the ticker's start method is invoked
        // (which invokes the internal _requestIfNeeded method). If a frame is requested before
        // _requestIfNeeded is invoked, then the callback for the animation frame the ticker requests,
        // can receive a time argument that can be less than the lastTime value that was set within
        // _requestIfNeeded. This difference is in microseconds, but this is enough to cause problems.
        //
        // This check covers this browser engine timing issue, as well as if consumers pass an invalid
        // currentTime value. This may happen if consumers opt-out of the autoStart, and update themselves.
        if (currentTime > this.lastTime) {
            // Save uncapped elapsedMS for measurement
            elapsedMS = this.elapsedMS = currentTime - this.lastTime;
            // cap the milliseconds elapsed used for deltaTime
            if (elapsedMS > this._maxElapsedMS) elapsedMS = this._maxElapsedMS;
            elapsedMS *= this.speed;
            // If not enough time has passed, exit the function.
            // Get ready for next frame by setting _lastFrame, but based on _minElapsedMS
            // adjustment to ensure a relatively stable interval.
            if (this._minElapsedMS) {
                var delta = currentTime - this._lastFrame | 0;
                if (delta < this._minElapsedMS) return;
                this._lastFrame = currentTime - delta % this._minElapsedMS;
            }
            this.deltaMS = elapsedMS;
            this.deltaTime = this.deltaMS * _settings.settings.TARGET_FPMS;
            // Cache a local reference, in-case ticker is destroyed
            // during the emit, we can still check for head.next
            var head = this._head;
            // Invoke listeners added to internal emitter
            var listener = head.next;
            while(listener)listener = listener.emit(this.deltaTime);
            if (!head.next) this._cancelIfNeeded();
        } else this.deltaTime = this.deltaMS = this.elapsedMS = 0;
        this.lastTime = currentTime;
    };
    Object.defineProperty(Ticker1.prototype, "FPS", {
        /**
         * The frames per second at which this ticker is running.
         * The default is approximately 60 in most modern browsers.
         * **Note:** This does not factor in the value of
         * {@link PIXI.Ticker#speed}, which is specific
         * to scaling {@link PIXI.Ticker#deltaTime}.
         *
         * @member {number}
         * @readonly
         */ get: function() {
            return 1000 / this.elapsedMS;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Ticker1.prototype, "minFPS", {
        /**
         * Manages the maximum amount of milliseconds allowed to
         * elapse between invoking {@link PIXI.Ticker#update}.
         * This value is used to cap {@link PIXI.Ticker#deltaTime},
         * but does not effect the measured value of {@link PIXI.Ticker#FPS}.
         * When setting this property it is clamped to a value between
         * `0` and `PIXI.settings.TARGET_FPMS * 1000`.
         *
         * @member {number}
         * @default 10
         */ get: function() {
            return 1000 / this._maxElapsedMS;
        },
        set: function(fps) {
            // Minimum must be below the maxFPS
            var minFPS = Math.min(this.maxFPS, fps);
            // Must be at least 0, but below 1 / settings.TARGET_FPMS
            var minFPMS = Math.min(Math.max(0, minFPS) / 1000, _settings.settings.TARGET_FPMS);
            this._maxElapsedMS = 1 / minFPMS;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Ticker1.prototype, "maxFPS", {
        /**
         * Manages the minimum amount of milliseconds required to
         * elapse between invoking {@link PIXI.Ticker#update}.
         * This will effect the measured value of {@link PIXI.Ticker#FPS}.
         * If it is set to `0`, then there is no limit; PixiJS will render as many frames as it can.
         * Otherwise it will be at least `minFPS`
         *
         * @member {number}
         * @default 0
         */ get: function() {
            if (this._minElapsedMS) return Math.round(1000 / this._minElapsedMS);
            return 0;
        },
        set: function(fps) {
            if (fps === 0) this._minElapsedMS = 0;
            else {
                // Max must be at least the minFPS
                var maxFPS = Math.max(this.minFPS, fps);
                this._minElapsedMS = 1 / (maxFPS / 1000);
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Ticker1, "shared", {
        /**
         * The shared ticker instance used by {@link PIXI.AnimatedSprite} and by
         * {@link PIXI.VideoResource} to update animation frames / video textures.
         *
         * It may also be used by {@link PIXI.Application} if created with the `sharedTicker` option property set to true.
         *
         * The property {@link PIXI.Ticker#autoStart} is set to `true` for this instance.
         * Please follow the examples for usage, including how to opt-out of auto-starting the shared ticker.
         *
         * @example
         * let ticker = PIXI.Ticker.shared;
         * // Set this to prevent starting this ticker when listeners are added.
         * // By default this is true only for the PIXI.Ticker.shared instance.
         * ticker.autoStart = false;
         * // FYI, call this to ensure the ticker is stopped. It should be stopped
         * // if you have not attempted to render anything yet.
         * ticker.stop();
         * // Call this when you are ready for a running shared ticker.
         * ticker.start();
         *
         * @example
         * // You may use the shared ticker to render...
         * let renderer = PIXI.autoDetectRenderer();
         * let stage = new PIXI.Container();
         * document.body.appendChild(renderer.view);
         * ticker.add(function (time) {
         *     renderer.render(stage);
         * });
         *
         * @example
         * // Or you can just update it manually.
         * ticker.autoStart = false;
         * ticker.stop();
         * function animate(time) {
         *     ticker.update(time);
         *     renderer.render(stage);
         *     requestAnimationFrame(animate);
         * }
         * animate(performance.now());
         *
         * @member {PIXI.Ticker}
         * @static
         */ get: function() {
            if (!Ticker1._shared) {
                var shared = Ticker1._shared = new Ticker1();
                shared.autoStart = true;
                shared._protected = true;
            }
            return Ticker1._shared;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Ticker1, "system", {
        /**
         * The system ticker instance used by {@link PIXI.InteractionManager} and by
         * {@link PIXI.BasePrepare} for core timing functionality that shouldn't usually need to be paused,
         * unlike the `shared` ticker which drives visual animations and rendering which may want to be paused.
         *
         * The property {@link PIXI.Ticker#autoStart} is set to `true` for this instance.
         *
         * @member {PIXI.Ticker}
         * @static
         */ get: function() {
            if (!Ticker1._system) {
                var system = Ticker1._system = new Ticker1();
                system.autoStart = true;
                system._protected = true;
            }
            return Ticker1._system;
        },
        enumerable: false,
        configurable: true
    });
    return Ticker1;
}();
/**
 * Middleware for for Application Ticker.
 *
 * @example
 * import {TickerPlugin} from '@pixi/ticker';
 * import {Application} from '@pixi/app';
 * Application.registerPlugin(TickerPlugin);
 *
 * @class
 * @memberof PIXI
 */ var TickerPlugin = function() {
    function TickerPlugin1() {
    }
    /**
     * Initialize the plugin with scope of application instance
     *
     * @static
     * @private
     * @param {object} [options] - See application options
     */ TickerPlugin1.init = function(options) {
        var _this = this;
        // Set default
        options = Object.assign({
            autoStart: true,
            sharedTicker: false
        }, options);
        // Create ticker setter
        Object.defineProperty(this, 'ticker', {
            set: function(ticker) {
                if (this._ticker) this._ticker.remove(this.render, this);
                this._ticker = ticker;
                if (ticker) ticker.add(this.render, this, UPDATE_PRIORITY.LOW);
            },
            get: function() {
                return this._ticker;
            }
        });
        /**
         * Convenience method for stopping the render.
         *
         * @method
         * @memberof PIXI.Application
         * @instance
         */ this.stop = function() {
            _this._ticker.stop();
        };
        /**
         * Convenience method for starting the render.
         *
         * @method
         * @memberof PIXI.Application
         * @instance
         */ this.start = function() {
            _this._ticker.start();
        };
        /**
         * Internal reference to the ticker.
         *
         * @type {PIXI.Ticker}
         * @name _ticker
         * @memberof PIXI.Application#
         * @private
         */ this._ticker = null;
        /**
         * Ticker for doing render updates.
         *
         * @type {PIXI.Ticker}
         * @name ticker
         * @memberof PIXI.Application#
         * @default PIXI.Ticker.shared
         */ this.ticker = options.sharedTicker ? Ticker.shared : new Ticker();
        // Start the rendering
        if (options.autoStart) this.start();
    };
    /**
     * Clean up the ticker, scoped to application.
     *
     * @static
     * @private
     */ TickerPlugin1.destroy = function() {
        if (this._ticker) {
            var oldTicker = this._ticker;
            this.ticker = null;
            oldTicker.destroy();
        }
    };
    return TickerPlugin1;
}();

},{"@pixi/settings":"habh9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bGbnz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Application", ()=>Application
);
/*!
 * @pixi/app - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/app is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _display = require("@pixi/display");
var _core = require("@pixi/core");
/**
 * Convenience class to create a new PIXI application.
 *
 * This class automatically creates the renderer, ticker and root container.
 *
 * @example
 * // Create the application
 * const app = new PIXI.Application();
 *
 * // Add the view to the DOM
 * document.body.appendChild(app.view);
 *
 * // ex, add display objects
 * app.stage.addChild(PIXI.Sprite.from('something.png'));
 *
 * @class
 * @memberof PIXI
 */ var Application = function() {
    /**
     * @param {object} [options] - The optional renderer parameters.
     * @param {boolean} [options.autoStart=true] - Automatically starts the rendering after the construction.
     *     **Note**: Setting this parameter to false does NOT stop the shared ticker even if you set
     *     options.sharedTicker to true in case that it is already started. Stop it by your own.
     * @param {number} [options.width=800] - The width of the renderers view.
     * @param {number} [options.height=600] - The height of the renderers view.
     * @param {HTMLCanvasElement} [options.view] - The canvas to use as a view, optional.
     * @param {boolean} [options.useContextAlpha=true] - Pass-through value for canvas' context `alpha` property.
     *   If you want to set transparency, please use `backgroundAlpha`. This option is for cases where the
     *   canvas needs to be opaque, possibly for performance reasons on some older devices.
     * @param {boolean} [options.autoDensity=false] - Resizes renderer view in CSS pixels to allow for
     *   resolutions other than 1.
     * @param {boolean} [options.antialias=false] - Sets antialias
     * @param {boolean} [options.preserveDrawingBuffer=false] - Enables drawing buffer preservation, enable this if you
     *  need to call toDataUrl on the WebGL context.
     * @param {number} [options.resolution=PIXI.settings.RESOLUTION] - The resolution / device pixel ratio of the renderer.
     * @param {boolean} [options.forceCanvas=false] - prevents selection of WebGL renderer, even if such is present, this
     *   option only is available when using **pixi.js-legacy** or **@pixi/canvas-renderer** modules, otherwise
     *   it is ignored.
     * @param {number} [options.backgroundColor=0x000000] - The background color of the rendered area
     *  (shown if not transparent).
     * @param {number} [options.backgroundAlpha=1] - Value from 0 (fully transparent) to 1 (fully opaque).
     * @param {boolean} [options.clearBeforeRender=true] - This sets if the renderer will clear the canvas or
     *   not before the new render pass.
     * @param {string} [options.powerPreference] - Parameter passed to webgl context, set to "high-performance"
     *  for devices with dual graphics card. **(WebGL only)**.
     * @param {boolean} [options.sharedTicker=false] - `true` to use PIXI.Ticker.shared, `false` to create new ticker.
     *  If set to false, you cannot register a handler to occur before anything that runs on the shared ticker.
     *  The system ticker will always run before both the shared ticker and the app ticker.
     * @param {boolean} [options.sharedLoader=false] - `true` to use PIXI.Loader.shared, `false` to create new Loader.
     * @param {Window|HTMLElement} [options.resizeTo] - Element to automatically resize stage to.
     */ function Application1(options) {
        var _this = this;
        /**
         * The root display container that's rendered.
         * @member {PIXI.Container}
         */ this.stage = new _display.Container();
        // The default options
        options = Object.assign({
            forceCanvas: false
        }, options);
        this.renderer = _core.autoDetectRenderer(options);
        // install plugins here
        Application1._plugins.forEach(function(plugin) {
            plugin.init.call(_this, options);
        });
    }
    /**
     * Register a middleware plugin for the application
     * @static
     * @param {PIXI.IApplicationPlugin} plugin - Plugin being installed
     */ Application1.registerPlugin = function(plugin) {
        Application1._plugins.push(plugin);
    };
    /**
     * Render the current stage.
     */ Application1.prototype.render = function() {
        this.renderer.render(this.stage);
    };
    Object.defineProperty(Application1.prototype, "view", {
        /**
         * Reference to the renderer's canvas element.
         * @member {HTMLCanvasElement}
         * @readonly
         */ get: function() {
            return this.renderer.view;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Application1.prototype, "screen", {
        /**
         * Reference to the renderer's screen rectangle. Its safe to use as `filterArea` or `hitArea` for the whole screen.
         * @member {PIXI.Rectangle}
         * @readonly
         */ get: function() {
            return this.renderer.screen;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Destroy and don't use after this.
     * @param {Boolean} [removeView=false] - Automatically remove canvas from DOM.
     * @param {object|boolean} [stageOptions] - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [stageOptions.children=false] - if set to true, all the children will have their destroy
     *  method called as well. 'stageOptions' will be passed on to those calls.
     * @param {boolean} [stageOptions.texture=false] - Only used for child Sprites if stageOptions.children is set
     *  to true. Should it destroy the texture of the child sprite
     * @param {boolean} [stageOptions.baseTexture=false] - Only used for child Sprites if stageOptions.children is set
     *  to true. Should it destroy the base texture of the child sprite
     */ Application1.prototype.destroy = function(removeView, stageOptions) {
        var _this = this;
        // Destroy plugins in the opposite order
        // which they were constructed
        var plugins = Application1._plugins.slice(0);
        plugins.reverse();
        plugins.forEach(function(plugin) {
            plugin.destroy.call(_this);
        });
        this.stage.destroy(stageOptions);
        this.stage = null;
        this.renderer.destroy(removeView);
        this.renderer = null;
    };
    /** Collection of installed plugins. */ Application1._plugins = [];
    return Application1;
}();
/**
 * Middleware for for Application's resize functionality
 * @private
 * @class
 */ var ResizePlugin = function() {
    function ResizePlugin1() {
    }
    /**
     * Initialize the plugin with scope of application instance
     * @static
     * @private
     * @param {object} [options] - See application options
     */ ResizePlugin1.init = function(options) {
        var _this = this;
        Object.defineProperty(this, 'resizeTo', /**
         * The HTML element or window to automatically resize the
         * renderer's view element to match width and height.
         * @member {Window|HTMLElement}
         * @name resizeTo
         * @memberof PIXI.Application#
         */ {
            set: function(dom) {
                self.removeEventListener('resize', this.queueResize);
                this._resizeTo = dom;
                if (dom) {
                    self.addEventListener('resize', this.queueResize);
                    this.resize();
                }
            },
            get: function() {
                return this._resizeTo;
            }
        });
        /**
         * Resize is throttled, so it's safe to call this multiple times per frame and it'll
         * only be called once.
         *
         * @memberof PIXI.Application#
         * @method queueResize
         * @private
         */ this.queueResize = function() {
            if (!_this._resizeTo) return;
            _this.cancelResize();
            // // Throttle resize events per raf
            _this._resizeId = requestAnimationFrame(function() {
                return _this.resize();
            });
        };
        /**
         * Cancel the resize queue.
         *
         * @memberof PIXI.Application#
         * @method cancelResize
         * @private
         */ this.cancelResize = function() {
            if (_this._resizeId) {
                cancelAnimationFrame(_this._resizeId);
                _this._resizeId = null;
            }
        };
        /**
         * Execute an immediate resize on the renderer, this is not
         * throttled and can be expensive to call many times in a row.
         * Will resize only if `resizeTo` property is set.
         *
         * @memberof PIXI.Application#
         * @method resize
         */ this.resize = function() {
            if (!_this._resizeTo) return;
            // clear queue resize
            _this.cancelResize();
            var width;
            var height;
            // Resize to the window
            if (_this._resizeTo === self) {
                width = self.innerWidth;
                height = self.innerHeight;
            } else {
                var _a = _this._resizeTo, clientWidth = _a.clientWidth, clientHeight = _a.clientHeight;
                width = clientWidth;
                height = clientHeight;
            }
            _this.renderer.resize(width, height);
        };
        // On resize
        this._resizeId = null;
        this._resizeTo = null;
        this.resizeTo = options.resizeTo || null;
    };
    /**
     * Clean up the ticker, scoped to application
     *
     * @static
     * @private
     */ ResizePlugin1.destroy = function() {
        self.removeEventListener('resize', this.queueResize);
        this.cancelResize();
        this.cancelResize = null;
        this.queueResize = null;
        this.resizeTo = null;
        this.resize = null;
    };
    return ResizePlugin1;
}();
Application.registerPlugin(ResizePlugin);

},{"@pixi/display":"hQqz5","@pixi/core":"d0INm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d0INm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AbstractBatchRenderer", ()=>AbstractBatchRenderer1
);
parcelHelpers.export(exports, "AbstractMultiResource", ()=>AbstractMultiResource1
);
parcelHelpers.export(exports, "AbstractRenderer", ()=>AbstractRenderer1
);
parcelHelpers.export(exports, "ArrayResource", ()=>ArrayResource1
);
parcelHelpers.export(exports, "Attribute", ()=>Attribute
);
parcelHelpers.export(exports, "BaseImageResource", ()=>BaseImageResource1
);
parcelHelpers.export(exports, "BaseRenderTexture", ()=>BaseRenderTexture1
);
parcelHelpers.export(exports, "BaseTexture", ()=>BaseTexture1
);
parcelHelpers.export(exports, "BatchDrawCall", ()=>BatchDrawCall
);
parcelHelpers.export(exports, "BatchGeometry", ()=>BatchGeometry1
);
parcelHelpers.export(exports, "BatchPluginFactory", ()=>BatchPluginFactory
);
parcelHelpers.export(exports, "BatchRenderer", ()=>BatchRenderer
);
parcelHelpers.export(exports, "BatchShaderGenerator", ()=>BatchShaderGenerator
);
parcelHelpers.export(exports, "BatchSystem", ()=>BatchSystem
);
parcelHelpers.export(exports, "BatchTextureArray", ()=>BatchTextureArray
);
parcelHelpers.export(exports, "Buffer", ()=>Buffer
);
parcelHelpers.export(exports, "BufferResource", ()=>BufferResource1
);
parcelHelpers.export(exports, "CanvasResource", ()=>CanvasResource1
);
parcelHelpers.export(exports, "ContextSystem", ()=>ContextSystem
);
parcelHelpers.export(exports, "CubeResource", ()=>CubeResource1
);
parcelHelpers.export(exports, "Filter", ()=>Filter1
);
parcelHelpers.export(exports, "FilterState", ()=>FilterState
);
parcelHelpers.export(exports, "FilterSystem", ()=>FilterSystem
);
parcelHelpers.export(exports, "Framebuffer", ()=>Framebuffer
);
parcelHelpers.export(exports, "FramebufferSystem", ()=>FramebufferSystem
);
parcelHelpers.export(exports, "GLFramebuffer", ()=>GLFramebuffer
);
parcelHelpers.export(exports, "GLProgram", ()=>GLProgram
);
parcelHelpers.export(exports, "GLTexture", ()=>GLTexture
);
parcelHelpers.export(exports, "Geometry", ()=>Geometry
);
parcelHelpers.export(exports, "GeometrySystem", ()=>GeometrySystem
);
parcelHelpers.export(exports, "IGLUniformData", ()=>IGLUniformData
);
parcelHelpers.export(exports, "INSTALLED", ()=>INSTALLED
);
parcelHelpers.export(exports, "ImageBitmapResource", ()=>ImageBitmapResource1
);
parcelHelpers.export(exports, "ImageResource", ()=>ImageResource1
);
parcelHelpers.export(exports, "MaskData", ()=>MaskData
);
parcelHelpers.export(exports, "MaskSystem", ()=>MaskSystem
);
parcelHelpers.export(exports, "ObjectRenderer", ()=>ObjectRenderer
);
parcelHelpers.export(exports, "Program", ()=>Program
);
parcelHelpers.export(exports, "ProjectionSystem", ()=>ProjectionSystem
);
parcelHelpers.export(exports, "Quad", ()=>Quad1
);
parcelHelpers.export(exports, "QuadUv", ()=>QuadUv1
);
parcelHelpers.export(exports, "RenderTexture", ()=>RenderTexture1
);
parcelHelpers.export(exports, "RenderTexturePool", ()=>RenderTexturePool
);
parcelHelpers.export(exports, "RenderTextureSystem", ()=>RenderTextureSystem
);
parcelHelpers.export(exports, "Renderer", ()=>Renderer1
);
parcelHelpers.export(exports, "Resource", ()=>Resource
);
parcelHelpers.export(exports, "SVGResource", ()=>SVGResource1
);
parcelHelpers.export(exports, "ScissorSystem", ()=>ScissorSystem1
);
parcelHelpers.export(exports, "Shader", ()=>Shader
);
parcelHelpers.export(exports, "ShaderSystem", ()=>ShaderSystem
);
parcelHelpers.export(exports, "SpriteMaskFilter", ()=>SpriteMaskFilter1
);
parcelHelpers.export(exports, "State", ()=>State
);
parcelHelpers.export(exports, "StateSystem", ()=>StateSystem
);
parcelHelpers.export(exports, "StencilSystem", ()=>StencilSystem1
);
parcelHelpers.export(exports, "System", ()=>System
);
parcelHelpers.export(exports, "Texture", ()=>Texture1
);
parcelHelpers.export(exports, "TextureGCSystem", ()=>TextureGCSystem
);
parcelHelpers.export(exports, "TextureMatrix", ()=>TextureMatrix
);
parcelHelpers.export(exports, "TextureSystem", ()=>TextureSystem
);
parcelHelpers.export(exports, "TextureUvs", ()=>TextureUvs
);
parcelHelpers.export(exports, "UniformGroup", ()=>UniformGroup
);
parcelHelpers.export(exports, "VideoResource", ()=>VideoResource1
);
parcelHelpers.export(exports, "ViewableBuffer", ()=>ViewableBuffer
);
parcelHelpers.export(exports, "autoDetectRenderer", ()=>autoDetectRenderer
);
parcelHelpers.export(exports, "autoDetectResource", ()=>autoDetectResource
);
parcelHelpers.export(exports, "checkMaxIfStatementsInShader", ()=>checkMaxIfStatementsInShader
);
parcelHelpers.export(exports, "createUBOElements", ()=>createUBOElements
);
parcelHelpers.export(exports, "defaultFilterVertex", ()=>defaultFilterVertex
);
parcelHelpers.export(exports, "defaultVertex", ()=>defaultVertex$2
);
parcelHelpers.export(exports, "generateProgram", ()=>generateProgram
);
parcelHelpers.export(exports, "generateUniformBufferSync", ()=>generateUniformBufferSync
);
parcelHelpers.export(exports, "getTestContext", ()=>getTestContext
);
parcelHelpers.export(exports, "getUBOData", ()=>getUBOData
);
parcelHelpers.export(exports, "resources", ()=>resources
);
parcelHelpers.export(exports, "systems", ()=>systems
);
parcelHelpers.export(exports, "uniformParsers", ()=>uniformParsers
);
/*!
 * @pixi/core - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/core is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _settings = require("@pixi/settings");
var _constants = require("@pixi/constants");
var _utils = require("@pixi/utils");
var _runner = require("@pixi/runner");
var _ticker = require("@pixi/ticker");
var _math = require("@pixi/math");
/**
 * The maximum support for using WebGL. If a device does not
 * support WebGL version, for instance WebGL 2, it will still
 * attempt to fallback support to WebGL 1. If you want to
 * explicitly remove feature support to target a more stable
 * baseline, prefer a lower environment.
 *
 * Due to {@link https://bugs.chromium.org/p/chromium/issues/detail?id=934823|bug in chromium}
 * we disable webgl2 by default for all non-apple mobile devices.
 *
 * @static
 * @name PREFER_ENV
 * @memberof PIXI.settings
 * @type {number}
 * @default PIXI.ENV.WEBGL2
 */ _settings.settings.PREFER_ENV = _utils.isMobile.any ? _constants.ENV.WEBGL : _constants.ENV.WEBGL2;
/**
 * If set to `true`, *only* Textures and BaseTexture objects stored
 * in the caches ({@link PIXI.utils.TextureCache TextureCache} and
 * {@link PIXI.utils.BaseTextureCache BaseTextureCache}) can be
 * used when calling {@link PIXI.Texture.from Texture.from} or
 * {@link PIXI.BaseTexture.from BaseTexture.from}.
 * Otherwise, these `from` calls throw an exception. Using this property
 * can be useful if you want to enforce preloading all assets with
 * {@link PIXI.Loader Loader}.
 *
 * @static
 * @name STRICT_TEXTURE_CACHE
 * @memberof PIXI.settings
 * @type {boolean}
 * @default false
 */ _settings.settings.STRICT_TEXTURE_CACHE = false;
/**
 * Collection of installed resource types, class must extend {@link PIXI.Resource}.
 * @example
 * class CustomResource extends PIXI.Resource {
 *   // MUST have source, options constructor signature
 *   // for auto-detected resources to be created.
 *   constructor(source, options) {
 *     super();
 *   }
 *   upload(renderer, baseTexture, glTexture) {
 *     // upload with GL
 *     return true;
 *   }
 *   // used to auto-detect resource
 *   static test(source, extension) {
 *     return extension === 'xyz'|| source instanceof SomeClass;
 *   }
 * }
 * // Install the new resource type
 * PIXI.INSTALLED.push(CustomResource);
 *
 * @memberof PIXI
 * @type {Array<PIXI.IResourcePlugin>}
 * @static
 * @readonly
 */ var INSTALLED = [];
/**
 * Create a resource element from a single source element. This
 * auto-detects which type of resource to create. All resources that
 * are auto-detectable must have a static `test` method and a constructor
 * with the arguments `(source, options?)`. Currently, the supported
 * resources for auto-detection include:
 *  - {@link PIXI.ImageResource}
 *  - {@link PIXI.CanvasResource}
 *  - {@link PIXI.VideoResource}
 *  - {@link PIXI.SVGResource}
 *  - {@link PIXI.BufferResource}
 * @static
 * @memberof PIXI
 * @function autoDetectResource
 * @param {string|*} source - Resource source, this can be the URL to the resource,
 *        a typed-array (for BufferResource), HTMLVideoElement, SVG data-uri
 *        or any other resource that can be auto-detected. If not resource is
 *        detected, it's assumed to be an ImageResource.
 * @param {object} [options] - Pass-through options to use for Resource
 * @param {number} [options.width] - Width of BufferResource or SVG rasterization
 * @param {number} [options.height] - Height of BufferResource or SVG rasterization
 * @param {boolean} [options.autoLoad=true] - Image, SVG and Video flag to start loading
 * @param {number} [options.scale=1] - SVG source scale. Overridden by width, height
 * @param {boolean} [options.createBitmap=PIXI.settings.CREATE_IMAGE_BITMAP] - Image option to create Bitmap object
 * @param {boolean} [options.crossorigin=true] - Image and Video option to set crossOrigin
 * @param {boolean} [options.autoPlay=true] - Video option to start playing video immediately
 * @param {number} [options.updateFPS=0] - Video option to update how many times a second the
 *        texture should be updated from the video. Leave at 0 to update at every render
 * @return {PIXI.Resource} The created resource.
 */ function autoDetectResource(source, options) {
    if (!source) return null;
    var extension = '';
    if (typeof source === 'string') {
        // search for file extension: period, 3-4 chars, then ?, # or EOL
        var result = /\.(\w{3,4})(?:$|\?|#)/i.exec(source);
        if (result) extension = result[1].toLowerCase();
    }
    for(var i = INSTALLED.length - 1; i >= 0; --i){
        var ResourcePlugin = INSTALLED[i];
        if (ResourcePlugin.test && ResourcePlugin.test(source, extension)) return new ResourcePlugin(source, options);
    }
    throw new Error('Unrecognized source type to auto-detect Resource');
}
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var __assign = function() {
    __assign = Object.assign || function __assign1(t) {
        var arguments$1 = arguments;
        for(var s, i = 1, n = arguments.length; i < n; i++){
            s = arguments$1[i];
            for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
function __rest(s, e) {
    var t = {
    };
    for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function") {
        for(var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++)if (e.indexOf(p[i]) < 0) t[p[i]] = s[p[i]];
    }
    return t;
}
/**
 * Base resource class for textures that manages validation and uploading, depending on its type.
 *
 * Uploading of a base texture to the GPU is required.
 *
 * @class
 * @memberof PIXI
 */ var Resource = function() {
    /**
     * @param {number} [width=0] - Width of the resource
     * @param {number} [height=0] - Height of the resource
     */ function Resource1(width, height) {
        if (width === void 0) width = 0;
        if (height === void 0) height = 0;
        /**
         * Internal width of the resource
         * @member {number}
         * @protected
         */ this._width = width;
        /**
         * Internal height of the resource
         * @member {number}
         * @protected
         */ this._height = height;
        /**
         * If resource has been destroyed
         * @member {boolean}
         * @readonly
         * @default false
         */ this.destroyed = false;
        /**
         * `true` if resource is created by BaseTexture
         * useful for doing cleanup with BaseTexture destroy
         * and not cleaning up resources that were created
         * externally.
         * @member {boolean}
         * @protected
         */ this.internal = false;
        /**
         * Mini-runner for handling resize events
         * accepts 2 parameters: width, height
         *
         * @member {Runner}
         * @private
         */ this.onResize = new _runner.Runner('setRealSize');
        /**
         * Mini-runner for handling update events
         *
         * @member {Runner}
         * @private
         */ this.onUpdate = new _runner.Runner('update');
        /**
         * Handle internal errors, such as loading errors
         * accepts 1 param: error
         *
         * @member {Runner}
         * @private
         */ this.onError = new _runner.Runner('onError');
    }
    /**
     * Bind to a parent BaseTexture
     *
     * @param {PIXI.BaseTexture} baseTexture - Parent texture
     */ Resource1.prototype.bind = function(baseTexture) {
        this.onResize.add(baseTexture);
        this.onUpdate.add(baseTexture);
        this.onError.add(baseTexture);
        // Call a resize immediate if we already
        // have the width and height of the resource
        if (this._width || this._height) this.onResize.emit(this._width, this._height);
    };
    /**
     * Unbind to a parent BaseTexture
     *
     * @param {PIXI.BaseTexture} baseTexture - Parent texture
     */ Resource1.prototype.unbind = function(baseTexture) {
        this.onResize.remove(baseTexture);
        this.onUpdate.remove(baseTexture);
        this.onError.remove(baseTexture);
    };
    /**
     * Trigger a resize event
     * @param {number} width - X dimension
     * @param {number} height - Y dimension
     */ Resource1.prototype.resize = function(width, height) {
        if (width !== this._width || height !== this._height) {
            this._width = width;
            this._height = height;
            this.onResize.emit(width, height);
        }
    };
    Object.defineProperty(Resource1.prototype, "valid", {
        /**
         * Has been validated
         * @readonly
         * @member {boolean}
         */ get: function() {
            return !!this._width && !!this._height;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Has been updated trigger event
     */ Resource1.prototype.update = function() {
        if (!this.destroyed) this.onUpdate.emit();
    };
    /**
     * This can be overridden to start preloading a resource
     * or do any other prepare step.
     * @protected
     * @return {Promise<void>} Handle the validate event
     */ Resource1.prototype.load = function() {
        return Promise.resolve(this);
    };
    Object.defineProperty(Resource1.prototype, "width", {
        /**
         * The width of the resource.
         *
         * @member {number}
         * @readonly
         */ get: function() {
            return this._width;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Resource1.prototype, "height", {
        /**
         * The height of the resource.
         *
         * @member {number}
         * @readonly
         */ get: function() {
            return this._height;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Set the style, optional to override
     *
     * @param {PIXI.Renderer} renderer - yeah, renderer!
     * @param {PIXI.BaseTexture} baseTexture - the texture
     * @param {PIXI.GLTexture} glTexture - texture instance for this webgl context
     * @returns {boolean} `true` is success
     */ Resource1.prototype.style = function(_renderer, _baseTexture, _glTexture) {
        return false;
    };
    /**
     * Clean up anything, this happens when destroying is ready.
     *
     * @protected
     */ Resource1.prototype.dispose = function() {
    // override
    };
    /**
     * Call when destroying resource, unbind any BaseTexture object
     * before calling this method, as reference counts are maintained
     * internally.
     */ Resource1.prototype.destroy = function() {
        if (!this.destroyed) {
            this.destroyed = true;
            this.dispose();
            this.onError.removeAll();
            this.onError = null;
            this.onResize.removeAll();
            this.onResize = null;
            this.onUpdate.removeAll();
            this.onUpdate = null;
        }
    };
    /**
     * Abstract, used to auto-detect resource type
     *
     * @static
     * @param {*} source - The source object
     * @param {string} extension - The extension of source, if set
     */ Resource1.test = function(_source, _extension) {
        return false;
    };
    return Resource1;
}();
/**
 * @interface SharedArrayBuffer
 */ /**
 * Buffer resource with data of typed array.
 * @class
 * @extends PIXI.Resource
 * @memberof PIXI
 */ var BufferResource1 = function(_super) {
    __extends(BufferResource2, _super);
    /**
     * @param {Float32Array|Uint8Array|Uint32Array} source - Source buffer
     * @param {object} options - Options
     * @param {number} options.width - Width of the texture
     * @param {number} options.height - Height of the texture
     */ function BufferResource2(source, options) {
        var _this = this;
        var _a = options || {
        }, width = _a.width, height = _a.height;
        if (!width || !height) throw new Error('BufferResource width or height invalid');
        _this = _super.call(this, width, height) || this;
        /**
         * Source array
         * Cannot be ClampedUint8Array because it cant be uploaded to WebGL
         *
         * @member {Float32Array|Uint8Array|Uint32Array}
         */ _this.data = source;
        return _this;
    }
    /**
     * Upload the texture to the GPU.
     * @param {PIXI.Renderer} renderer - Upload to the renderer
     * @param {PIXI.BaseTexture} baseTexture - Reference to parent texture
     * @param {PIXI.GLTexture} glTexture - glTexture
     * @returns {boolean} true is success
     */ BufferResource2.prototype.upload = function(renderer, baseTexture, glTexture) {
        var gl = renderer.gl;
        gl.pixelStorei(gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, baseTexture.alphaMode === _constants.ALPHA_MODES.UNPACK);
        var width = baseTexture.realWidth;
        var height = baseTexture.realHeight;
        if (glTexture.width === width && glTexture.height === height) gl.texSubImage2D(baseTexture.target, 0, 0, 0, width, height, baseTexture.format, glTexture.type, this.data);
        else {
            glTexture.width = width;
            glTexture.height = height;
            gl.texImage2D(baseTexture.target, 0, glTexture.internalFormat, width, height, 0, baseTexture.format, glTexture.type, this.data);
        }
        return true;
    };
    /**
     * Destroy and don't use after this
     * @override
     */ BufferResource2.prototype.dispose = function() {
        this.data = null;
    };
    /**
     * Used to auto-detect the type of resource.
     *
     * @static
     * @param {*} source - The source object
     * @return {boolean} `true` if <canvas>
     */ BufferResource2.test = function(source) {
        return source instanceof Float32Array || source instanceof Uint8Array || source instanceof Uint32Array;
    };
    return BufferResource2;
}(Resource);
var defaultBufferOptions = {
    scaleMode: _constants.SCALE_MODES.NEAREST,
    format: _constants.FORMATS.RGBA,
    alphaMode: _constants.ALPHA_MODES.NPM
};
/**
 * A Texture stores the information that represents an image.
 * All textures have a base texture, which contains information about the source.
 * Therefore you can have many textures all using a single BaseTexture
 *
 * @class
 * @extends PIXI.utils.EventEmitter
 * @memberof PIXI
 * @typeParam R - The BaseTexture's Resource type.
 * @typeParam RO - The options for constructing resource.
 */ var BaseTexture1 = function(_super) {
    __extends(BaseTexture2, _super);
    /**
     * @param {PIXI.Resource|string|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement} [resource=null] -
     *        The current resource to use, for things that aren't Resource objects, will be converted
     *        into a Resource.
     * @param {Object} [options] - Collection of options
     * @param {PIXI.MIPMAP_MODES} [options.mipmap=PIXI.settings.MIPMAP_TEXTURES] - If mipmapping is enabled for texture
     * @param {number} [options.anisotropicLevel=PIXI.settings.ANISOTROPIC_LEVEL] - Anisotropic filtering level of texture
     * @param {PIXI.WRAP_MODES} [options.wrapMode=PIXI.settings.WRAP_MODE] - Wrap mode for textures
     * @param {PIXI.SCALE_MODES} [options.scaleMode=PIXI.settings.SCALE_MODE] - Default scale mode, linear, nearest
     * @param {PIXI.FORMATS} [options.format=PIXI.FORMATS.RGBA] - GL format type
     * @param {PIXI.TYPES} [options.type=PIXI.TYPES.UNSIGNED_BYTE] - GL data type
     * @param {PIXI.TARGETS} [options.target=PIXI.TARGETS.TEXTURE_2D] - GL texture target
     * @param {PIXI.ALPHA_MODES} [options.alphaMode=PIXI.ALPHA_MODES.UNPACK] - Pre multiply the image alpha
     * @param {number} [options.width=0] - Width of the texture
     * @param {number} [options.height=0] - Height of the texture
     * @param {number} [options.resolution=PIXI.settings.RESOLUTION] - Resolution of the base texture
     * @param {object} [options.resourceOptions] - Optional resource options,
     *        see {@link PIXI.autoDetectResource autoDetectResource}
     */ function BaseTexture2(resource, options) {
        if (resource === void 0) resource = null;
        if (options === void 0) options = null;
        var _this = _super.call(this) || this;
        options = options || {
        };
        var alphaMode = options.alphaMode, mipmap = options.mipmap, anisotropicLevel = options.anisotropicLevel, scaleMode = options.scaleMode, width = options.width, height = options.height, wrapMode = options.wrapMode, format = options.format, type = options.type, target = options.target, resolution = options.resolution, resourceOptions = options.resourceOptions;
        // Convert the resource to a Resource object
        if (resource && !(resource instanceof Resource)) {
            resource = autoDetectResource(resource, resourceOptions);
            resource.internal = true;
        }
        _this.resolution = resolution || _settings.settings.RESOLUTION;
        _this.width = Math.round((width || 0) * _this.resolution) / _this.resolution;
        _this.height = Math.round((height || 0) * _this.resolution) / _this.resolution;
        _this._mipmap = mipmap !== undefined ? mipmap : _settings.settings.MIPMAP_TEXTURES;
        _this.anisotropicLevel = anisotropicLevel !== undefined ? anisotropicLevel : _settings.settings.ANISOTROPIC_LEVEL;
        _this._wrapMode = wrapMode || _settings.settings.WRAP_MODE;
        _this._scaleMode = scaleMode !== undefined ? scaleMode : _settings.settings.SCALE_MODE;
        _this.format = format || _constants.FORMATS.RGBA;
        _this.type = type || _constants.TYPES.UNSIGNED_BYTE;
        _this.target = target || _constants.TARGETS.TEXTURE_2D;
        _this.alphaMode = alphaMode !== undefined ? alphaMode : _constants.ALPHA_MODES.UNPACK;
        _this.uid = _utils.uid();
        _this.touched = 0;
        _this.isPowerOfTwo = false;
        _this._refreshPOT();
        _this._glTextures = {
        };
        _this.dirtyId = 0;
        _this.dirtyStyleId = 0;
        _this.cacheId = null;
        _this.valid = width > 0 && height > 0;
        _this.textureCacheIds = [];
        _this.destroyed = false;
        _this.resource = null;
        _this._batchEnabled = 0;
        _this._batchLocation = 0;
        _this.parentTextureArray = null;
        /**
         * Fired when a not-immediately-available source finishes loading.
         *
         * @protected
         * @event PIXI.BaseTexture#loaded
         * @param {PIXI.BaseTexture} baseTexture - Resource loaded.
         */ /**
         * Fired when a not-immediately-available source fails to load.
         *
         * @protected
         * @event PIXI.BaseTexture#error
         * @param {PIXI.BaseTexture} baseTexture - Resource errored.
         * @param {ErrorEvent} event - Load error event.
         */ /**
         * Fired when BaseTexture is updated.
         *
         * @protected
         * @event PIXI.BaseTexture#loaded
         * @param {PIXI.BaseTexture} baseTexture - Resource loaded.
         */ /**
         * Fired when BaseTexture is updated.
         *
         * @protected
         * @event PIXI.BaseTexture#update
         * @param {PIXI.BaseTexture} baseTexture - Instance of texture being updated.
         */ /**
         * Fired when BaseTexture is destroyed.
         *
         * @protected
         * @event PIXI.BaseTexture#dispose
         * @param {PIXI.BaseTexture} baseTexture - Instance of texture being destroyed.
         */ // Set the resource
        _this.setResource(resource);
        return _this;
    }
    Object.defineProperty(BaseTexture2.prototype, "realWidth", {
        /**
         * Pixel width of the source of this texture
         *
         * @readonly
         * @member {number}
         */ get: function() {
            return Math.round(this.width * this.resolution);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BaseTexture2.prototype, "realHeight", {
        /**
         * Pixel height of the source of this texture
         *
         * @readonly
         * @member {number}
         */ get: function() {
            return Math.round(this.height * this.resolution);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BaseTexture2.prototype, "mipmap", {
        /**
         * Mipmap mode of the texture, affects downscaled images
         *
         * @member {PIXI.MIPMAP_MODES}
         * @default PIXI.settings.MIPMAP_TEXTURES
         */ get: function() {
            return this._mipmap;
        },
        set: function(value) {
            if (this._mipmap !== value) {
                this._mipmap = value;
                this.dirtyStyleId++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BaseTexture2.prototype, "scaleMode", {
        /**
         * The scale mode to apply when scaling this texture
         *
         * @member {PIXI.SCALE_MODES}
         * @default PIXI.settings.SCALE_MODE
         */ get: function() {
            return this._scaleMode;
        },
        set: function(value) {
            if (this._scaleMode !== value) {
                this._scaleMode = value;
                this.dirtyStyleId++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BaseTexture2.prototype, "wrapMode", {
        /**
         * How the texture wraps
         * @member {PIXI.WRAP_MODES}
         * @default PIXI.settings.WRAP_MODE
         */ get: function() {
            return this._wrapMode;
        },
        set: function(value) {
            if (this._wrapMode !== value) {
                this._wrapMode = value;
                this.dirtyStyleId++;
            }
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Changes style options of BaseTexture
     *
     * @param {PIXI.SCALE_MODES} [scaleMode] - Pixi scalemode
     * @param {PIXI.MIPMAP_MODES} [mipmap] - enable mipmaps
     * @returns {PIXI.BaseTexture} this
     */ BaseTexture2.prototype.setStyle = function(scaleMode, mipmap) {
        var dirty;
        if (scaleMode !== undefined && scaleMode !== this.scaleMode) {
            this.scaleMode = scaleMode;
            dirty = true;
        }
        if (mipmap !== undefined && mipmap !== this.mipmap) {
            this.mipmap = mipmap;
            dirty = true;
        }
        if (dirty) this.dirtyStyleId++;
        return this;
    };
    /**
     * Changes w/h/resolution. Texture becomes valid if width and height are greater than zero.
     *
     * @param {number} desiredWidth - Desired visual width
     * @param {number} desiredHeight - Desired visual height
     * @param {number} [resolution] - Optionally set resolution
     * @returns {PIXI.BaseTexture} this
     */ BaseTexture2.prototype.setSize = function(desiredWidth, desiredHeight, resolution) {
        resolution = resolution || this.resolution;
        return this.setRealSize(desiredWidth * resolution, desiredHeight * resolution, resolution);
    };
    /**
     * Sets real size of baseTexture, preserves current resolution.
     *
     * @param {number} realWidth - Full rendered width
     * @param {number} realHeight - Full rendered height
     * @param {number} [resolution] - Optionally set resolution
     * @returns {PIXI.BaseTexture} this
     */ BaseTexture2.prototype.setRealSize = function(realWidth, realHeight, resolution) {
        this.resolution = resolution || this.resolution;
        this.width = Math.round(realWidth) / this.resolution;
        this.height = Math.round(realHeight) / this.resolution;
        this._refreshPOT();
        this.update();
        return this;
    };
    /**
     * Refresh check for isPowerOfTwo texture based on size
     *
     * @private
     */ BaseTexture2.prototype._refreshPOT = function() {
        this.isPowerOfTwo = _utils.isPow2(this.realWidth) && _utils.isPow2(this.realHeight);
    };
    /**
     * Changes resolution
     *
     * @param {number} resolution - res
     * @returns {PIXI.BaseTexture} this
     */ BaseTexture2.prototype.setResolution = function(resolution) {
        var oldResolution = this.resolution;
        if (oldResolution === resolution) return this;
        this.resolution = resolution;
        if (this.valid) {
            this.width = Math.round(this.width * oldResolution) / resolution;
            this.height = Math.round(this.height * oldResolution) / resolution;
            this.emit('update', this);
        }
        this._refreshPOT();
        return this;
    };
    /**
     * Sets the resource if it wasn't set. Throws error if resource already present
     *
     * @param {PIXI.Resource} resource - that is managing this BaseTexture
     * @returns {PIXI.BaseTexture} this
     */ BaseTexture2.prototype.setResource = function(resource) {
        if (this.resource === resource) return this;
        if (this.resource) throw new Error('Resource can be set only once');
        resource.bind(this);
        this.resource = resource;
        return this;
    };
    /**
     * Invalidates the object. Texture becomes valid if width and height are greater than zero.
     */ BaseTexture2.prototype.update = function() {
        if (!this.valid) {
            if (this.width > 0 && this.height > 0) {
                this.valid = true;
                this.emit('loaded', this);
                this.emit('update', this);
            }
        } else {
            this.dirtyId++;
            this.dirtyStyleId++;
            this.emit('update', this);
        }
    };
    /**
     * Handle errors with resources.
     * @private
     * @param {ErrorEvent} event - Error event emitted.
     */ BaseTexture2.prototype.onError = function(event) {
        this.emit('error', this, event);
    };
    /**
     * Destroys this base texture.
     * The method stops if resource doesn't want this texture to be destroyed.
     * Removes texture from all caches.
     */ BaseTexture2.prototype.destroy = function() {
        // remove and destroy the resource
        if (this.resource) {
            this.resource.unbind(this);
            // only destroy resourced created internally
            if (this.resource.internal) this.resource.destroy();
            this.resource = null;
        }
        if (this.cacheId) {
            delete _utils.BaseTextureCache[this.cacheId];
            delete _utils.TextureCache[this.cacheId];
            this.cacheId = null;
        }
        // finally let the WebGL renderer know..
        this.dispose();
        BaseTexture2.removeFromCache(this);
        this.textureCacheIds = null;
        this.destroyed = true;
    };
    /**
     * Frees the texture from WebGL memory without destroying this texture object.
     * This means you can still use the texture later which will upload it to GPU
     * memory again.
     *
     * @fires PIXI.BaseTexture#dispose
     */ BaseTexture2.prototype.dispose = function() {
        this.emit('dispose', this);
    };
    /**
     * Utility function for BaseTexture|Texture cast
     */ BaseTexture2.prototype.castToBaseTexture = function() {
        return this;
    };
    /**
     * Helper function that creates a base texture based on the source you provide.
     * The source can be - image url, image element, canvas element. If the
     * source is an image url or an image element and not in the base texture
     * cache, it will be created and loaded.
     *
     * @static
     * @param {string|HTMLImageElement|HTMLCanvasElement|SVGElement|HTMLVideoElement} source - The
     *        source to create base texture from.
     * @param {object} [options] - See {@link PIXI.BaseTexture}'s constructor for options.
     * @param {string} [options.pixiIdPrefix=pixiid] - If a source has no id, this is the prefix of the generated id
     * @param {boolean} [strict] - Enforce strict-mode, see {@link PIXI.settings.STRICT_TEXTURE_CACHE}.
     * @returns {PIXI.BaseTexture} The new base texture.
     */ BaseTexture2.from = function(source, options, strict) {
        if (strict === void 0) strict = _settings.settings.STRICT_TEXTURE_CACHE;
        var isFrame = typeof source === 'string';
        var cacheId = null;
        if (isFrame) cacheId = source;
        else {
            if (!source._pixiId) {
                var prefix = options && options.pixiIdPrefix || 'pixiid';
                source._pixiId = prefix + "_" + _utils.uid();
            }
            cacheId = source._pixiId;
        }
        var baseTexture = _utils.BaseTextureCache[cacheId];
        // Strict-mode rejects invalid cacheIds
        if (isFrame && strict && !baseTexture) throw new Error("The cacheId \"" + cacheId + "\" does not exist in BaseTextureCache.");
        if (!baseTexture) {
            baseTexture = new BaseTexture2(source, options);
            baseTexture.cacheId = cacheId;
            BaseTexture2.addToCache(baseTexture, cacheId);
        }
        return baseTexture;
    };
    /**
     * Create a new BaseTexture with a BufferResource from a Float32Array.
     * RGBA values are floats from 0 to 1.
     * @static
     * @param {Float32Array|Uint8Array} buffer - The optional array to use, if no data
     *        is provided, a new Float32Array is created.
     * @param {number} width - Width of the resource
     * @param {number} height - Height of the resource
     * @param {object} [options] - See {@link PIXI.BaseTexture}'s constructor for options.
     * @return {PIXI.BaseTexture} The resulting new BaseTexture
     */ BaseTexture2.fromBuffer = function(buffer, width, height, options) {
        buffer = buffer || new Float32Array(width * height * 4);
        var resource = new BufferResource1(buffer, {
            width: width,
            height: height
        });
        var type = buffer instanceof Float32Array ? _constants.TYPES.FLOAT : _constants.TYPES.UNSIGNED_BYTE;
        return new BaseTexture2(resource, Object.assign(defaultBufferOptions, options || {
            width: width,
            height: height,
            type: type
        }));
    };
    /**
     * Adds a BaseTexture to the global BaseTextureCache. This cache is shared across the whole PIXI object.
     *
     * @static
     * @param {PIXI.BaseTexture} baseTexture - The BaseTexture to add to the cache.
     * @param {string} id - The id that the BaseTexture will be stored against.
     */ BaseTexture2.addToCache = function(baseTexture, id) {
        if (id) {
            if (baseTexture.textureCacheIds.indexOf(id) === -1) baseTexture.textureCacheIds.push(id);
            if (_utils.BaseTextureCache[id]) // eslint-disable-next-line no-console
            console.warn("BaseTexture added to the cache with an id [" + id + "] that already had an entry");
            _utils.BaseTextureCache[id] = baseTexture;
        }
    };
    /**
     * Remove a BaseTexture from the global BaseTextureCache.
     *
     * @static
     * @param {string|PIXI.BaseTexture} baseTexture - id of a BaseTexture to be removed, or a BaseTexture instance itself.
     * @return {PIXI.BaseTexture|null} The BaseTexture that was removed.
     */ BaseTexture2.removeFromCache = function(baseTexture) {
        if (typeof baseTexture === 'string') {
            var baseTextureFromCache = _utils.BaseTextureCache[baseTexture];
            if (baseTextureFromCache) {
                var index = baseTextureFromCache.textureCacheIds.indexOf(baseTexture);
                if (index > -1) baseTextureFromCache.textureCacheIds.splice(index, 1);
                delete _utils.BaseTextureCache[baseTexture];
                return baseTextureFromCache;
            }
        } else if (baseTexture && baseTexture.textureCacheIds) {
            for(var i = 0; i < baseTexture.textureCacheIds.length; ++i)delete _utils.BaseTextureCache[baseTexture.textureCacheIds[i]];
            baseTexture.textureCacheIds.length = 0;
            return baseTexture;
        }
        return null;
    };
    /**
     * Global number of the texture batch, used by multi-texture renderers
     *
     * @static
     * @member {number}
     */ BaseTexture2._globalBatch = 0;
    return BaseTexture2;
}(_utils.EventEmitter);
/**
 * Resource that can manage several resource (items) inside.
 * All resources need to have the same pixel size.
 * Parent class for CubeResource and ArrayResource
 *
 * @class
 * @extends PIXI.Resource
 * @memberof PIXI
 */ var AbstractMultiResource1 = function(_super) {
    __extends(AbstractMultiResource2, _super);
    /**
     * @param {number} length
     * @param {object} [options] - Options to for Resource constructor
     * @param {number} [options.width] - Width of the resource
     * @param {number} [options.height] - Height of the resource
     */ function AbstractMultiResource2(length, options) {
        var _this = this;
        var _a = options || {
        }, width = _a.width, height = _a.height;
        _this = _super.call(this, width, height) || this;
        /**
         * Collection of partial baseTextures that correspond to resources
         * @member {Array<PIXI.BaseTexture>}
         * @readonly
         */ _this.items = [];
        /**
         * Dirty IDs for each part
         * @member {Array<number>}
         * @readonly
         */ _this.itemDirtyIds = [];
        for(var i = 0; i < length; i++){
            var partTexture = new BaseTexture1();
            _this.items.push(partTexture);
            // -2 - first run of texture array upload
            // -1 - texture item was allocated
            // >=0 - texture item uploaded , in sync with items[i].dirtyId
            _this.itemDirtyIds.push(-2);
        }
        /**
         * Number of elements in array
         *
         * @member {number}
         * @readonly
         */ _this.length = length;
        /**
         * Promise when loading
         * @member {Promise}
         * @private
         * @default null
         */ _this._load = null;
        /**
         * Bound baseTexture, there can only be one
         * @member {PIXI.BaseTexture}
         */ _this.baseTexture = null;
        return _this;
    }
    /**
     * used from ArrayResource and CubeResource constructors
     * @param {Array<*>} resources - Can be resources, image elements, canvas, etc. ,
     *  length should be same as constructor length
     * @param {object} [options] - detect options for resources
     * @protected
     */ AbstractMultiResource2.prototype.initFromArray = function(resources, options) {
        for(var i = 0; i < this.length; i++){
            if (!resources[i]) continue;
            if (resources[i].castToBaseTexture) this.addBaseTextureAt(resources[i].castToBaseTexture(), i);
            else if (resources[i] instanceof Resource) this.addResourceAt(resources[i], i);
            else this.addResourceAt(autoDetectResource(resources[i], options), i);
        }
    };
    /**
     * Destroy this BaseImageResource
     * @override
     */ AbstractMultiResource2.prototype.dispose = function() {
        for(var i = 0, len = this.length; i < len; i++)this.items[i].destroy();
        this.items = null;
        this.itemDirtyIds = null;
        this._load = null;
    };
    /**
     * Set a resource by ID
     *
     * @param {PIXI.Resource} resource
     * @param {number} index - Zero-based index of resource to set
     * @return {PIXI.ArrayResource} Instance for chaining
     */ AbstractMultiResource2.prototype.addResourceAt = function(resource, index) {
        if (!this.items[index]) throw new Error("Index " + index + " is out of bounds");
        // Inherit the first resource dimensions
        if (resource.valid && !this.valid) this.resize(resource.width, resource.height);
        this.items[index].setResource(resource);
        return this;
    };
    /**
     * Set the parent base texture
     * @member {PIXI.BaseTexture}
     * @override
     */ AbstractMultiResource2.prototype.bind = function(baseTexture) {
        if (this.baseTexture !== null) throw new Error('Only one base texture per TextureArray is allowed');
        _super.prototype.bind.call(this, baseTexture);
        for(var i = 0; i < this.length; i++){
            this.items[i].parentTextureArray = baseTexture;
            this.items[i].on('update', baseTexture.update, baseTexture);
        }
    };
    /**
     * Unset the parent base texture
     * @member {PIXI.BaseTexture}
     * @override
     */ AbstractMultiResource2.prototype.unbind = function(baseTexture) {
        _super.prototype.unbind.call(this, baseTexture);
        for(var i = 0; i < this.length; i++){
            this.items[i].parentTextureArray = null;
            this.items[i].off('update', baseTexture.update, baseTexture);
        }
    };
    /**
     * Load all the resources simultaneously
     * @override
     * @return {Promise<void>} When load is resolved
     */ AbstractMultiResource2.prototype.load = function() {
        var _this = this;
        if (this._load) return this._load;
        var resources = this.items.map(function(item) {
            return item.resource;
        }).filter(function(item) {
            return item;
        });
        // TODO: also implement load part-by-part strategy
        var promises = resources.map(function(item) {
            return item.load();
        });
        this._load = Promise.all(promises).then(function() {
            var _a = _this.items[0], realWidth = _a.realWidth, realHeight = _a.realHeight;
            _this.resize(realWidth, realHeight);
            return Promise.resolve(_this);
        });
        return this._load;
    };
    return AbstractMultiResource2;
}(Resource);
/**
 * A resource that contains a number of sources.
 *
 * @class
 * @extends PIXI.Resource
 * @memberof PIXI
 */ var ArrayResource1 = function(_super) {
    __extends(ArrayResource2, _super);
    /**
     * @param {number|Array<*>} source - Number of items in array or the collection
     *        of image URLs to use. Can also be resources, image elements, canvas, etc.
     * @param {object} [options] - Options to apply to {@link PIXI.autoDetectResource}
     * @param {number} [options.width] - Width of the resource
     * @param {number} [options.height] - Height of the resource
     */ function ArrayResource2(source, options) {
        var _this = this;
        var _a = options || {
        }, width = _a.width, height = _a.height;
        var urls;
        var length;
        if (Array.isArray(source)) {
            urls = source;
            length = source.length;
        } else length = source;
        _this = _super.call(this, length, {
            width: width,
            height: height
        }) || this;
        if (urls) _this.initFromArray(urls, options);
        return _this;
    }
    /**
     * Set a baseTexture by ID,
     * ArrayResource just takes resource from it, nothing more
     *
     * @param {PIXI.BaseTexture} baseTexture
     * @param {number} index - Zero-based index of resource to set
     * @return {PIXI.ArrayResource} Instance for chaining
     */ ArrayResource2.prototype.addBaseTextureAt = function(baseTexture, index) {
        if (baseTexture.resource) this.addResourceAt(baseTexture.resource, index);
        else throw new Error('ArrayResource does not support RenderTexture');
        return this;
    };
    /**
     * Add binding
     * @member {PIXI.BaseTexture}
     * @override
     */ ArrayResource2.prototype.bind = function(baseTexture) {
        _super.prototype.bind.call(this, baseTexture);
        baseTexture.target = _constants.TARGETS.TEXTURE_2D_ARRAY;
    };
    /**
     * Upload the resources to the GPU.
     * @param {PIXI.Renderer} renderer
     * @param {PIXI.BaseTexture} texture
     * @param {PIXI.GLTexture} glTexture
     * @returns {boolean} whether texture was uploaded
     */ ArrayResource2.prototype.upload = function(renderer, texture, glTexture) {
        var _a = this, length = _a.length, itemDirtyIds = _a.itemDirtyIds, items = _a.items;
        var gl = renderer.gl;
        if (glTexture.dirtyId < 0) gl.texImage3D(gl.TEXTURE_2D_ARRAY, 0, glTexture.internalFormat, this._width, this._height, length, 0, texture.format, glTexture.type, null);
        for(var i = 0; i < length; i++){
            var item = items[i];
            if (itemDirtyIds[i] < item.dirtyId) {
                itemDirtyIds[i] = item.dirtyId;
                if (item.valid) gl.texSubImage3D(gl.TEXTURE_2D_ARRAY, 0, 0, 0, i, item.resource.width, item.resource.height, 1, texture.format, glTexture.type, item.resource.source);
            }
        }
        return true;
    };
    return ArrayResource2;
}(AbstractMultiResource1);
/**
 * Base for all the image/canvas resources
 * @class
 * @extends PIXI.Resource
 * @memberof PIXI
 */ var BaseImageResource1 = function(_super) {
    __extends(BaseImageResource2, _super);
    /**
     * @param {HTMLImageElement|HTMLCanvasElement|HTMLVideoElement|SVGElement} source
     */ function BaseImageResource2(source) {
        var _this = this;
        var sourceAny = source;
        var width = sourceAny.naturalWidth || sourceAny.videoWidth || sourceAny.width;
        var height = sourceAny.naturalHeight || sourceAny.videoHeight || sourceAny.height;
        _this = _super.call(this, width, height) || this;
        /**
         * The source element
         * @member {HTMLImageElement|HTMLCanvasElement|HTMLVideoElement|SVGElement}
         * @readonly
         */ _this.source = source;
        /**
         * If set to `true`, will force `texImage2D` over `texSubImage2D` for uploading.
         * Certain types of media (e.g. video) using `texImage2D` is more performant.
         * @member {boolean}
         * @default false
         * @private
         */ _this.noSubImage = false;
        return _this;
    }
    /**
     * Set cross origin based detecting the url and the crossorigin
     * @protected
     * @param {HTMLElement} element - Element to apply crossOrigin
     * @param {string} url - URL to check
     * @param {boolean|string} [crossorigin=true] - Cross origin value to use
     */ BaseImageResource2.crossOrigin = function(element, url, crossorigin) {
        if (crossorigin === undefined && url.indexOf('data:') !== 0) element.crossOrigin = _utils.determineCrossOrigin(url);
        else if (crossorigin !== false) element.crossOrigin = typeof crossorigin === 'string' ? crossorigin : 'anonymous';
    };
    /**
     * Upload the texture to the GPU.
     * @param {PIXI.Renderer} renderer - Upload to the renderer
     * @param {PIXI.BaseTexture} baseTexture - Reference to parent texture
     * @param {PIXI.GLTexture} glTexture
     * @param {HTMLImageElement|HTMLCanvasElement|HTMLVideoElement|SVGElement} [source] - (optional)
     * @returns {boolean} true is success
     */ BaseImageResource2.prototype.upload = function(renderer, baseTexture, glTexture, source) {
        var gl = renderer.gl;
        var width = baseTexture.realWidth;
        var height = baseTexture.realHeight;
        source = source || this.source;
        gl.pixelStorei(gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, baseTexture.alphaMode === _constants.ALPHA_MODES.UNPACK);
        if (!this.noSubImage && baseTexture.target === gl.TEXTURE_2D && glTexture.width === width && glTexture.height === height) gl.texSubImage2D(gl.TEXTURE_2D, 0, 0, 0, baseTexture.format, glTexture.type, source);
        else {
            glTexture.width = width;
            glTexture.height = height;
            gl.texImage2D(baseTexture.target, 0, glTexture.internalFormat, baseTexture.format, glTexture.type, source);
        }
        return true;
    };
    /**
     * Checks if source width/height was changed, resize can cause extra baseTexture update.
     * Triggers one update in any case.
     */ BaseImageResource2.prototype.update = function() {
        if (this.destroyed) return;
        var source = this.source;
        var width = source.naturalWidth || source.videoWidth || source.width;
        var height = source.naturalHeight || source.videoHeight || source.height;
        this.resize(width, height);
        _super.prototype.update.call(this);
    };
    /**
     * Destroy this BaseImageResource
     * @override
     */ BaseImageResource2.prototype.dispose = function() {
        this.source = null;
    };
    return BaseImageResource2;
}(Resource);
/**
 * @interface OffscreenCanvas
 */ /**
 * Resource type for HTMLCanvasElement.
 * @class
 * @extends PIXI.BaseImageResource
 * @memberof PIXI
 */ var CanvasResource1 = function(_super) {
    __extends(CanvasResource2, _super);
    /**
     * @param {HTMLCanvasElement} source - Canvas element to use
     */ // eslint-disable-next-line @typescript-eslint/no-useless-constructor
    function CanvasResource2(source) {
        return _super.call(this, source) || this;
    }
    /**
     * Used to auto-detect the type of resource.
     *
     * @static
     * @param {HTMLCanvasElement|OffscreenCanvas} source - The source object
     * @return {boolean} `true` if source is HTMLCanvasElement or OffscreenCanvas
     */ CanvasResource2.test = function(source) {
        var OffscreenCanvas1 = self.OffscreenCanvas;
        // Check for browsers that don't yet support OffscreenCanvas
        if (OffscreenCanvas1 && source instanceof OffscreenCanvas1) return true;
        return self.HTMLCanvasElement && source instanceof HTMLCanvasElement;
    };
    return CanvasResource2;
}(BaseImageResource1);
/**
 * Resource for a CubeTexture which contains six resources.
 *
 * @class
 * @extends PIXI.ArrayResource
 * @memberof PIXI
 */ var CubeResource1 = function(_super) {
    __extends(CubeResource2, _super);
    /**
     * @param {Array<string|PIXI.Resource>} [source] - Collection of URLs or resources
     *        to use as the sides of the cube.
     * @param {object} [options] - ImageResource options
     * @param {number} [options.width] - Width of resource
     * @param {number} [options.height] - Height of resource
     * @param {number} [options.autoLoad=true] - Whether to auto-load resources
     * @param {number} [options.linkBaseTexture=true] - In case BaseTextures are supplied,
     *   whether to copy them or use
     */ function CubeResource2(source, options) {
        var _this = this;
        var _a = options || {
        }, width = _a.width, height = _a.height, autoLoad = _a.autoLoad, linkBaseTexture = _a.linkBaseTexture;
        if (source && source.length !== CubeResource2.SIDES) throw new Error("Invalid length. Got " + source.length + ", expected 6");
        _this = _super.call(this, 6, {
            width: width,
            height: height
        }) || this;
        for(var i = 0; i < CubeResource2.SIDES; i++)_this.items[i].target = _constants.TARGETS.TEXTURE_CUBE_MAP_POSITIVE_X + i;
        /**
         * In case BaseTextures are supplied, whether to use same resource or bind baseTexture itself
         * @member {boolean}
         * @protected
         */ _this.linkBaseTexture = linkBaseTexture !== false;
        if (source) _this.initFromArray(source, options);
        if (autoLoad !== false) _this.load();
        return _this;
    }
    /**
     * Add binding
     *
     * @override
     * @param {PIXI.BaseTexture} baseTexture - parent base texture
     */ CubeResource2.prototype.bind = function(baseTexture) {
        _super.prototype.bind.call(this, baseTexture);
        baseTexture.target = _constants.TARGETS.TEXTURE_CUBE_MAP;
    };
    CubeResource2.prototype.addBaseTextureAt = function(baseTexture, index, linkBaseTexture) {
        if (linkBaseTexture === undefined) linkBaseTexture = this.linkBaseTexture;
        if (!this.items[index]) throw new Error("Index " + index + " is out of bounds");
        if (!this.linkBaseTexture || baseTexture.parentTextureArray || Object.keys(baseTexture._glTextures).length > 0) {
            // copy mode
            if (baseTexture.resource) this.addResourceAt(baseTexture.resource, index);
            else throw new Error("CubeResource does not support copying of renderTexture.");
        } else {
            // link mode, the difficult one!
            baseTexture.target = _constants.TARGETS.TEXTURE_CUBE_MAP_POSITIVE_X + index;
            baseTexture.parentTextureArray = this.baseTexture;
            this.items[index] = baseTexture;
        }
        if (baseTexture.valid && !this.valid) this.resize(baseTexture.realWidth, baseTexture.realHeight);
        this.items[index] = baseTexture;
        return this;
    };
    /**
     * Upload the resource
     *
     * @returns {boolean} true is success
     */ CubeResource2.prototype.upload = function(renderer, _baseTexture, glTexture) {
        var dirty = this.itemDirtyIds;
        for(var i = 0; i < CubeResource2.SIDES; i++){
            var side = this.items[i];
            if (dirty[i] < side.dirtyId) {
                if (side.valid && side.resource) {
                    side.resource.upload(renderer, side, glTexture);
                    dirty[i] = side.dirtyId;
                } else if (dirty[i] < -1) {
                    // either item is not valid yet, either its a renderTexture
                    // allocate the memory
                    renderer.gl.texImage2D(side.target, 0, glTexture.internalFormat, _baseTexture.realWidth, _baseTexture.realHeight, 0, _baseTexture.format, glTexture.type, null);
                    dirty[i] = -1;
                }
            }
        }
        return true;
    };
    /**
     * Used to auto-detect the type of resource.
     *
     * @static
     * @param {object} source - The source object
     * @return {boolean} `true` if source is an array of 6 elements
     */ CubeResource2.test = function(source) {
        return Array.isArray(source) && source.length === CubeResource2.SIDES;
    };
    /**
     * Number of texture sides to store for CubeResources
     *
     * @name PIXI.CubeResource.SIDES
     * @static
     * @member {number}
     * @default 6
     */ CubeResource2.SIDES = 6;
    return CubeResource2;
}(AbstractMultiResource1);
/**
 * Resource type for HTMLImageElement.
 * @class
 * @extends PIXI.BaseImageResource
 * @memberof PIXI
 */ var ImageResource1 = function(_super) {
    __extends(ImageResource2, _super);
    /**
     * @param {HTMLImageElement|string} source - image source or URL
     * @param {object} [options]
     * @param {boolean} [options.autoLoad=true] - start loading process
     * @param {boolean} [options.createBitmap=PIXI.settings.CREATE_IMAGE_BITMAP] - whether its required to create
     *        a bitmap before upload
     * @param {boolean} [options.crossorigin=true] - Load image using cross origin
     * @param {PIXI.ALPHA_MODES} [options.alphaMode=PIXI.ALPHA_MODES.UNPACK] - Premultiply image alpha in bitmap
     */ function ImageResource2(source, options) {
        var _this = this;
        options = options || {
        };
        if (!(source instanceof HTMLImageElement)) {
            var imageElement = new Image();
            BaseImageResource1.crossOrigin(imageElement, source, options.crossorigin);
            imageElement.src = source;
            source = imageElement;
        }
        _this = _super.call(this, source) || this;
        // FireFox 68, and possibly other versions, seems like setting the HTMLImageElement#width and #height
        // to non-zero values before its loading completes if images are in a cache.
        // Because of this, need to set the `_width` and the `_height` to zero to avoid uploading incomplete images.
        // Please refer to the issue #5968 (https://github.com/pixijs/pixi.js/issues/5968).
        if (!source.complete && !!_this._width && !!_this._height) {
            _this._width = 0;
            _this._height = 0;
        }
        /**
         * URL of the image source
         * @member {string}
         */ _this.url = source.src;
        /**
         * When process is completed
         * @member {Promise<void>}
         * @private
         */ _this._process = null;
        /**
         * If the image should be disposed after upload
         * @member {boolean}
         * @default false
         */ _this.preserveBitmap = false;
        /**
         * If capable, convert the image using createImageBitmap API
         * @member {boolean}
         * @default PIXI.settings.CREATE_IMAGE_BITMAP
         */ _this.createBitmap = (options.createBitmap !== undefined ? options.createBitmap : _settings.settings.CREATE_IMAGE_BITMAP) && !!self.createImageBitmap;
        /**
         * Controls texture alphaMode field
         * Copies from options
         * Default is `null`, copies option from baseTexture
         *
         * @member {PIXI.ALPHA_MODES|null}
         * @readonly
         */ _this.alphaMode = typeof options.alphaMode === 'number' ? options.alphaMode : null;
        /**
         * The ImageBitmap element created for HTMLImageElement
         * @member {ImageBitmap}
         * @default null
         */ _this.bitmap = null;
        /**
         * Promise when loading
         * @member {Promise<void>}
         * @private
         * @default null
         */ _this._load = null;
        if (options.autoLoad !== false) _this.load();
        return _this;
    }
    /**
     * returns a promise when image will be loaded and processed
     *
     * @param {boolean} [createBitmap] - whether process image into bitmap
     * @returns {Promise<void>}
     */ ImageResource2.prototype.load = function(createBitmap) {
        var _this = this;
        if (this._load) return this._load;
        if (createBitmap !== undefined) this.createBitmap = createBitmap;
        this._load = new Promise(function(resolve, reject) {
            var source = _this.source;
            _this.url = source.src;
            var completed = function() {
                if (_this.destroyed) return;
                source.onload = null;
                source.onerror = null;
                _this.resize(source.width, source.height);
                _this._load = null;
                if (_this.createBitmap) resolve(_this.process());
                else resolve(_this);
            };
            if (source.complete && source.src) completed();
            else {
                source.onload = completed;
                source.onerror = function(event) {
                    // Avoids Promise freezing when resource broken
                    reject(event);
                    _this.onError.emit(event);
                };
            }
        });
        return this._load;
    };
    /**
     * Called when we need to convert image into BitmapImage.
     * Can be called multiple times, real promise is cached inside.
     *
     * @returns {Promise<void>} cached promise to fill that bitmap
     */ ImageResource2.prototype.process = function() {
        var _this = this;
        var source = this.source;
        if (this._process !== null) return this._process;
        if (this.bitmap !== null || !self.createImageBitmap) return Promise.resolve(this);
        var createImageBitmap = self.createImageBitmap;
        var cors = !source.crossOrigin || source.crossOrigin === 'anonymous';
        this._process = fetch(source.src, {
            mode: cors ? 'cors' : 'no-cors'
        }).then(function(r) {
            return r.blob();
        }).then(function(blob) {
            return createImageBitmap(blob, 0, 0, source.width, source.height, {
                premultiplyAlpha: _this.alphaMode === _constants.ALPHA_MODES.UNPACK ? 'premultiply' : 'none'
            });
        }).then(function(bitmap) {
            if (_this.destroyed) return Promise.reject();
            _this.bitmap = bitmap;
            _this.update();
            _this._process = null;
            return Promise.resolve(_this);
        });
        return this._process;
    };
    /**
     * Upload the image resource to GPU.
     *
     * @param {PIXI.Renderer} renderer - Renderer to upload to
     * @param {PIXI.BaseTexture} baseTexture - BaseTexture for this resource
     * @param {PIXI.GLTexture} glTexture - GLTexture to use
     * @returns {boolean} true is success
     */ ImageResource2.prototype.upload = function(renderer, baseTexture, glTexture) {
        if (typeof this.alphaMode === 'number') // bitmap stores unpack premultiply flag, we dont have to notify texImage2D about it
        baseTexture.alphaMode = this.alphaMode;
        if (!this.createBitmap) return _super.prototype.upload.call(this, renderer, baseTexture, glTexture);
        if (!this.bitmap) {
            // yeah, ignore the output
            this.process();
            if (!this.bitmap) return false;
        }
        _super.prototype.upload.call(this, renderer, baseTexture, glTexture, this.bitmap);
        if (!this.preserveBitmap) {
            // checks if there are other renderers that possibly need this bitmap
            var flag = true;
            var glTextures = baseTexture._glTextures;
            for(var key in glTextures){
                var otherTex = glTextures[key];
                if (otherTex !== glTexture && otherTex.dirtyId !== baseTexture.dirtyId) {
                    flag = false;
                    break;
                }
            }
            if (flag) {
                if (this.bitmap.close) this.bitmap.close();
                this.bitmap = null;
            }
        }
        return true;
    };
    /**
     * Destroys this texture
     * @override
     */ ImageResource2.prototype.dispose = function() {
        this.source.onload = null;
        this.source.onerror = null;
        _super.prototype.dispose.call(this);
        if (this.bitmap) {
            this.bitmap.close();
            this.bitmap = null;
        }
        this._process = null;
        this._load = null;
    };
    /**
     * Used to auto-detect the type of resource.
     *
     * @static
     * @param {string|HTMLImageElement} source - The source object
     * @return {boolean} `true` if source is string or HTMLImageElement
     */ ImageResource2.test = function(source) {
        return typeof source === 'string' || source instanceof HTMLImageElement;
    };
    return ImageResource2;
}(BaseImageResource1);
/**
 * Resource type for SVG elements and graphics.
 * @class
 * @extends PIXI.BaseImageResource
 * @memberof PIXI
 */ var SVGResource1 = function(_super) {
    __extends(SVGResource2, _super);
    /**
     * @param {string} source - Base64 encoded SVG element or URL for SVG file.
     * @param {object} [options] - Options to use
     * @param {number} [options.scale=1] - Scale to apply to SVG. Overridden by...
     * @param {number} [options.width] - Rasterize SVG this wide. Aspect ratio preserved if height not specified.
     * @param {number} [options.height] - Rasterize SVG this high. Aspect ratio preserved if width not specified.
     * @param {boolean} [options.autoLoad=true] - Start loading right away.
     */ function SVGResource2(sourceBase64, options) {
        var _this = this;
        options = options || {
        };
        _this = _super.call(this, document.createElement('canvas')) || this;
        _this._width = 0;
        _this._height = 0;
        /**
         * Base64 encoded SVG element or URL for SVG file
         * @readonly
         * @member {string}
         */ _this.svg = sourceBase64;
        /**
         * The source scale to apply when rasterizing on load
         * @readonly
         * @member {number}
         */ _this.scale = options.scale || 1;
        /**
         * A width override for rasterization on load
         * @readonly
         * @member {number}
         */ _this._overrideWidth = options.width;
        /**
         * A height override for rasterization on load
         * @readonly
         * @member {number}
         */ _this._overrideHeight = options.height;
        /**
         * Call when completely loaded
         * @private
         * @member {function}
         */ _this._resolve = null;
        /**
         * Cross origin value to use
         * @private
         * @member {boolean|string}
         */ _this._crossorigin = options.crossorigin;
        /**
         * Promise when loading
         * @member {Promise<void>}
         * @private
         * @default null
         */ _this._load = null;
        if (options.autoLoad !== false) _this.load();
        return _this;
    }
    SVGResource2.prototype.load = function() {
        var _this = this;
        if (this._load) return this._load;
        this._load = new Promise(function(resolve) {
            // Save this until after load is finished
            _this._resolve = function() {
                _this.resize(_this.source.width, _this.source.height);
                resolve(_this);
            };
            // Convert SVG inline string to data-uri
            if (/^\<svg/.test(_this.svg.trim())) {
                if (!btoa) throw new Error('Your browser doesn\'t support base64 conversions.');
                _this.svg = "data:image/svg+xml;base64," + btoa(unescape(encodeURIComponent(_this.svg)));
            }
            _this._loadSvg();
        });
        return this._load;
    };
    /**
     * Loads an SVG image from `imageUrl` or `data URL`.
     *
     * @private
     */ SVGResource2.prototype._loadSvg = function() {
        var _this = this;
        var tempImage = new Image();
        BaseImageResource1.crossOrigin(tempImage, this.svg, this._crossorigin);
        tempImage.src = this.svg;
        tempImage.onerror = function(event) {
            if (!_this._resolve) return;
            tempImage.onerror = null;
            _this.onError.emit(event);
        };
        tempImage.onload = function() {
            if (!_this._resolve) return;
            var svgWidth = tempImage.width;
            var svgHeight = tempImage.height;
            if (!svgWidth || !svgHeight) throw new Error('The SVG image must have width and height defined (in pixels), canvas API needs them.');
            // Set render size
            var width = svgWidth * _this.scale;
            var height = svgHeight * _this.scale;
            if (_this._overrideWidth || _this._overrideHeight) {
                width = _this._overrideWidth || _this._overrideHeight / svgHeight * svgWidth;
                height = _this._overrideHeight || _this._overrideWidth / svgWidth * svgHeight;
            }
            width = Math.round(width);
            height = Math.round(height);
            // Create a canvas element
            var canvas = _this.source;
            canvas.width = width;
            canvas.height = height;
            canvas._pixiId = "canvas_" + _utils.uid();
            // Draw the Svg to the canvas
            canvas.getContext('2d').drawImage(tempImage, 0, 0, svgWidth, svgHeight, 0, 0, width, height);
            _this._resolve();
            _this._resolve = null;
        };
    };
    /**
     * Get size from an svg string using regexp.
     *
     * @method
     * @param {string} svgString - a serialized svg element
     * @return {PIXI.ISize} image extension
     */ SVGResource2.getSize = function(svgString) {
        var sizeMatch = SVGResource2.SVG_SIZE.exec(svgString);
        var size = {
        };
        if (sizeMatch) {
            size[sizeMatch[1]] = Math.round(parseFloat(sizeMatch[3]));
            size[sizeMatch[5]] = Math.round(parseFloat(sizeMatch[7]));
        }
        return size;
    };
    /**
     * Destroys this texture
     * @override
     */ SVGResource2.prototype.dispose = function() {
        _super.prototype.dispose.call(this);
        this._resolve = null;
        this._crossorigin = null;
    };
    /**
     * Used to auto-detect the type of resource.
     *
     * @static
     * @param {*} source - The source object
     * @param {string} extension - The extension of source, if set
     */ SVGResource2.test = function(source, extension) {
        // url file extension is SVG
        return extension === 'svg' || typeof source === 'string' && /^data:image\/svg\+xml(;(charset=utf8|utf8))?;base64/.test(source) || typeof source === 'string' && SVGResource2.SVG_XML.test(source);
    };
    /**
     * RegExp for SVG XML document.
     *
     * @example &lt;?xml version="1.0" encoding="utf-8" ?&gt;&lt;!-- image/svg --&gt;&lt;svg
     */ SVGResource2.SVG_XML = /^(<\?xml[^?]+\?>)?\s*(<!--[^(-->)]*-->)?\s*\<svg/m;
    /**
     * RegExp for SVG size.
     *
     * @static
     * @constant {RegExp|string} SVG_SIZE
     * @memberof PIXI.SVGResource
     * @example &lt;svg width="100" height="100"&gt;&lt;/svg&gt;
     */ SVGResource2.SVG_SIZE = /<svg[^>]*(?:\s(width|height)=('|")(\d*(?:\.\d+)?)(?:px)?('|"))[^>]*(?:\s(width|height)=('|")(\d*(?:\.\d+)?)(?:px)?('|"))[^>]*>/i; // eslint-disable-line max-len
    return SVGResource2;
}(BaseImageResource1);
/**
 * Resource type for HTMLVideoElement.
 * @class
 * @extends PIXI.BaseImageResource
 * @memberof PIXI
 */ var VideoResource1 = function(_super) {
    __extends(VideoResource2, _super);
    /**
     * @param {HTMLVideoElement|object|string|Array<string|object>} source - Video element to use.
     * @param {object} [options] - Options to use
     * @param {boolean} [options.autoLoad=true] - Start loading the video immediately
     * @param {boolean} [options.autoPlay=true] - Start playing video immediately
     * @param {number} [options.updateFPS=0] - How many times a second to update the texture from the video.
     * Leave at 0 to update at every render.
     * @param {boolean} [options.crossorigin=true] - Load image using cross origin
     */ function VideoResource2(source, options) {
        var _this = this;
        options = options || {
        };
        if (!(source instanceof HTMLVideoElement)) {
            var videoElement = document.createElement('video');
            // workaround for https://github.com/pixijs/pixi.js/issues/5996
            videoElement.setAttribute('preload', 'auto');
            videoElement.setAttribute('webkit-playsinline', '');
            videoElement.setAttribute('playsinline', '');
            if (typeof source === 'string') source = [
                source
            ];
            var firstSrc = source[0].src || source[0];
            BaseImageResource1.crossOrigin(videoElement, firstSrc, options.crossorigin);
            // array of objects or strings
            for(var i = 0; i < source.length; ++i){
                var sourceElement = document.createElement('source');
                var _a = source[i], src = _a.src, mime = _a.mime;
                src = src || source[i];
                var baseSrc = src.split('?').shift().toLowerCase();
                var ext = baseSrc.substr(baseSrc.lastIndexOf('.') + 1);
                mime = mime || VideoResource2.MIME_TYPES[ext] || "video/" + ext;
                sourceElement.src = src;
                sourceElement.type = mime;
                videoElement.appendChild(sourceElement);
            }
            // Override the source
            source = videoElement;
        }
        _this = _super.call(this, source) || this;
        _this.noSubImage = true;
        /**
         * `true` to use PIXI.Ticker.shared to auto update the base texture.
         *
         * @type {boolean}
         * @default true
         * @private
         */ _this._autoUpdate = true;
        /**
         * `true` if the instance is currently connected to PIXI.Ticker.shared to auto update the base texture.
         *
         * @type {boolean}
         * @default false
         * @private
         */ _this._isConnectedToTicker = false;
        _this._updateFPS = options.updateFPS || 0;
        _this._msToNextUpdate = 0;
        /**
         * When set to true will automatically play videos used by this texture once
         * they are loaded. If false, it will not modify the playing state.
         *
         * @member {boolean}
         * @default true
         */ _this.autoPlay = options.autoPlay !== false;
        /**
         * Promise when loading
         * @member {Promise<void>}
         * @private
         * @default null
         */ _this._load = null;
        /**
         * Callback when completed with load.
         * @member {function}
         * @private
         */ _this._resolve = null;
        // Bind for listeners
        _this._onCanPlay = _this._onCanPlay.bind(_this);
        _this._onError = _this._onError.bind(_this);
        if (options.autoLoad !== false) _this.load();
        return _this;
    }
    /**
     * Trigger updating of the texture
     *
     * @param {number} [deltaTime=0] - time delta since last tick
     */ VideoResource2.prototype.update = function(_deltaTime) {
        if (!this.destroyed) {
            // account for if video has had its playbackRate changed
            var elapsedMS = _ticker.Ticker.shared.elapsedMS * this.source.playbackRate;
            this._msToNextUpdate = Math.floor(this._msToNextUpdate - elapsedMS);
            if (!this._updateFPS || this._msToNextUpdate <= 0) {
                _super.prototype.update.call(this);
                this._msToNextUpdate = this._updateFPS ? Math.floor(1000 / this._updateFPS) : 0;
            }
        }
    };
    /**
     * Start preloading the video resource.
     *
     * @protected
     * @return {Promise<void>} Handle the validate event
     */ VideoResource2.prototype.load = function() {
        var _this = this;
        if (this._load) return this._load;
        var source = this.source;
        if ((source.readyState === source.HAVE_ENOUGH_DATA || source.readyState === source.HAVE_FUTURE_DATA) && source.width && source.height) source.complete = true;
        source.addEventListener('play', this._onPlayStart.bind(this));
        source.addEventListener('pause', this._onPlayStop.bind(this));
        if (!this._isSourceReady()) {
            source.addEventListener('canplay', this._onCanPlay);
            source.addEventListener('canplaythrough', this._onCanPlay);
            source.addEventListener('error', this._onError, true);
        } else this._onCanPlay();
        this._load = new Promise(function(resolve) {
            if (_this.valid) resolve(_this);
            else {
                _this._resolve = resolve;
                source.load();
            }
        });
        return this._load;
    };
    /**
     * Handle video error events.
     *
     * @private
     */ VideoResource2.prototype._onError = function(event) {
        this.source.removeEventListener('error', this._onError, true);
        this.onError.emit(event);
    };
    /**
     * Returns true if the underlying source is playing.
     *
     * @private
     * @return {boolean} True if playing.
     */ VideoResource2.prototype._isSourcePlaying = function() {
        var source = this.source;
        return source.currentTime > 0 && source.paused === false && source.ended === false && source.readyState > 2;
    };
    /**
     * Returns true if the underlying source is ready for playing.
     *
     * @private
     * @return {boolean} True if ready.
     */ VideoResource2.prototype._isSourceReady = function() {
        var source = this.source;
        return source.readyState === 3 || source.readyState === 4;
    };
    /**
     * Runs the update loop when the video is ready to play
     *
     * @private
     */ VideoResource2.prototype._onPlayStart = function() {
        // Just in case the video has not received its can play even yet..
        if (!this.valid) this._onCanPlay();
        if (this.autoUpdate && !this._isConnectedToTicker) {
            _ticker.Ticker.shared.add(this.update, this);
            this._isConnectedToTicker = true;
        }
    };
    /**
     * Fired when a pause event is triggered, stops the update loop
     *
     * @private
     */ VideoResource2.prototype._onPlayStop = function() {
        if (this._isConnectedToTicker) {
            _ticker.Ticker.shared.remove(this.update, this);
            this._isConnectedToTicker = false;
        }
    };
    /**
     * Fired when the video is loaded and ready to play
     *
     * @private
     */ VideoResource2.prototype._onCanPlay = function() {
        var source = this.source;
        source.removeEventListener('canplay', this._onCanPlay);
        source.removeEventListener('canplaythrough', this._onCanPlay);
        var valid = this.valid;
        this.resize(source.videoWidth, source.videoHeight);
        // prevent multiple loaded dispatches..
        if (!valid && this._resolve) {
            this._resolve(this);
            this._resolve = null;
        }
        if (this._isSourcePlaying()) this._onPlayStart();
        else if (this.autoPlay) source.play();
    };
    /**
     * Destroys this texture
     * @override
     */ VideoResource2.prototype.dispose = function() {
        if (this._isConnectedToTicker) {
            _ticker.Ticker.shared.remove(this.update, this);
            this._isConnectedToTicker = false;
        }
        var source = this.source;
        if (source) {
            source.removeEventListener('error', this._onError, true);
            source.pause();
            source.src = '';
            source.load();
        }
        _super.prototype.dispose.call(this);
    };
    Object.defineProperty(VideoResource2.prototype, "autoUpdate", {
        /**
         * Should the base texture automatically update itself, set to true by default
         *
         * @member {boolean}
         */ get: function() {
            return this._autoUpdate;
        },
        set: function(value) {
            if (value !== this._autoUpdate) {
                this._autoUpdate = value;
                if (!this._autoUpdate && this._isConnectedToTicker) {
                    _ticker.Ticker.shared.remove(this.update, this);
                    this._isConnectedToTicker = false;
                } else if (this._autoUpdate && !this._isConnectedToTicker && this._isSourcePlaying()) {
                    _ticker.Ticker.shared.add(this.update, this);
                    this._isConnectedToTicker = true;
                }
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(VideoResource2.prototype, "updateFPS", {
        /**
         * How many times a second to update the texture from the video. Leave at 0 to update at every render.
         * A lower fps can help performance, as updating the texture at 60fps on a 30ps video may not be efficient.
         *
         * @member {number}
         */ get: function() {
            return this._updateFPS;
        },
        set: function(value) {
            if (value !== this._updateFPS) this._updateFPS = value;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Used to auto-detect the type of resource.
     *
     * @static
     * @param {*} source - The source object
     * @param {string} extension - The extension of source, if set
     * @return {boolean} `true` if video source
     */ VideoResource2.test = function(source, extension) {
        return self.HTMLVideoElement && source instanceof HTMLVideoElement || VideoResource2.TYPES.indexOf(extension) > -1;
    };
    /**
     * List of common video file extensions supported by VideoResource.
     * @constant
     * @member {Array<string>}
     * @static
     * @readonly
     */ VideoResource2.TYPES = [
        'mp4',
        'm4v',
        'webm',
        'ogg',
        'ogv',
        'h264',
        'avi',
        'mov'
    ];
    /**
     * Map of video MIME types that can't be directly derived from file extensions.
     * @constant
     * @member {object}
     * @static
     * @readonly
     */ VideoResource2.MIME_TYPES = {
        ogv: 'video/ogg',
        mov: 'video/quicktime',
        m4v: 'video/mp4'
    };
    return VideoResource2;
}(BaseImageResource1);
/**
 * Resource type for ImageBitmap.
 * @class
 * @extends PIXI.BaseImageResource
 * @memberof PIXI
 */ var ImageBitmapResource1 = function(_super) {
    __extends(ImageBitmapResource2, _super);
    /**
     * @param {ImageBitmap} source - Image element to use
     */ // eslint-disable-next-line @typescript-eslint/no-useless-constructor
    function ImageBitmapResource2(source) {
        return _super.call(this, source) || this;
    }
    /**
     * Used to auto-detect the type of resource.
     *
     * @static
     * @param {ImageBitmap} source - The source object
     * @return {boolean} `true` if source is an ImageBitmap
     */ ImageBitmapResource2.test = function(source) {
        return !!self.createImageBitmap && source instanceof ImageBitmap;
    };
    return ImageBitmapResource2;
}(BaseImageResource1);
INSTALLED.push(ImageResource1, ImageBitmapResource1, CanvasResource1, VideoResource1, SVGResource1, BufferResource1, CubeResource1, ArrayResource1);
var _resources = {
    __proto__: null,
    Resource: Resource,
    BaseImageResource: BaseImageResource1,
    INSTALLED: INSTALLED,
    autoDetectResource: autoDetectResource,
    AbstractMultiResource: AbstractMultiResource1,
    ArrayResource: ArrayResource1,
    BufferResource: BufferResource1,
    CanvasResource: CanvasResource1,
    CubeResource: CubeResource1,
    ImageResource: ImageResource1,
    SVGResource: SVGResource1,
    VideoResource: VideoResource1,
    ImageBitmapResource: ImageBitmapResource1
};
/**
 * Resource type for DepthTexture.
 * @class
 * @extends PIXI.BufferResource
 * @memberof PIXI
 */ var DepthResource1 = function(_super) {
    __extends(DepthResource2, _super);
    function DepthResource2() {
        return _super !== null && _super.apply(this, arguments) || this;
    }
    /**
     * Upload the texture to the GPU.
     * @param {PIXI.Renderer} renderer - Upload to the renderer
     * @param {PIXI.BaseTexture} baseTexture - Reference to parent texture
     * @param {PIXI.GLTexture} glTexture - glTexture
     * @returns {boolean} true is success
     */ DepthResource2.prototype.upload = function(renderer, baseTexture, glTexture) {
        var gl = renderer.gl;
        gl.pixelStorei(gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, baseTexture.alphaMode === _constants.ALPHA_MODES.UNPACK);
        var width = baseTexture.realWidth;
        var height = baseTexture.realHeight;
        if (glTexture.width === width && glTexture.height === height) gl.texSubImage2D(baseTexture.target, 0, 0, 0, width, height, baseTexture.format, glTexture.type, this.data);
        else {
            glTexture.width = width;
            glTexture.height = height;
            gl.texImage2D(baseTexture.target, 0, glTexture.internalFormat, width, height, 0, baseTexture.format, glTexture.type, this.data);
        }
        return true;
    };
    return DepthResource2;
}(BufferResource1);
/**
 * A framebuffer can be used to render contents off of the screen. {@link PIXI.BaseRenderTexture} uses
 * one internally to render into itself. You can attach a depth or stencil buffer to a framebuffer.
 *
 * On WebGL 2 machines, shaders can output to multiple textures simultaneously with GLSL 300 ES.
 *
 * @class
 * @memberof PIXI
 */ var Framebuffer = function() {
    /**
     * @param {number} width - Width of the frame buffer
     * @param {number} height - Height of the frame buffer
     */ function Framebuffer1(width, height) {
        /**
         * Width of framebuffer in pixels
         * @member {number}
         */ this.width = Math.round(width || 100);
        /**
         * Height of framebuffer in pixels
         * @member {number}
         */ this.height = Math.round(height || 100);
        this.stencil = false;
        this.depth = false;
        this.dirtyId = 0;
        this.dirtyFormat = 0;
        this.dirtySize = 0;
        this.depthTexture = null;
        this.colorTextures = [];
        this.glFramebuffers = {
        };
        this.disposeRunner = new _runner.Runner('disposeFramebuffer');
        /**
         * Desired number of samples for antialiasing. 0 means AA should not be used.
         *
         * Experimental WebGL2 feature, allows to use antialiasing in individual renderTextures.
         * Antialiasing is the same as for main buffer with renderer `antialias:true` options.
         * Seriously affects GPU memory consumption and GPU performance.
         *
         *```js
         * renderTexture.framebuffer.multisample = PIXI.MSAA_QUALITY.HIGH;
         * //...
         * renderer.render(myContainer, {renderTexture});
         * renderer.framebuffer.blit(); // copies data from MSAA framebuffer to texture
         *  ```
         *
         * @member {PIXI.MSAA_QUALITY}
         * @default PIXI.MSAA_QUALITY.NONE
         */ this.multisample = _constants.MSAA_QUALITY.NONE;
    }
    Object.defineProperty(Framebuffer1.prototype, "colorTexture", {
        /**
         * Reference to the colorTexture.
         *
         * @member {PIXI.BaseTexture[]}
         * @readonly
         */ get: function() {
            return this.colorTextures[0];
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Add texture to the colorTexture array
     *
     * @param {number} [index=0] - Index of the array to add the texture to
     * @param {PIXI.BaseTexture} [texture] - Texture to add to the array
     */ Framebuffer1.prototype.addColorTexture = function(index, texture) {
        if (index === void 0) index = 0;
        // TODO add some validation to the texture - same width / height etc?
        this.colorTextures[index] = texture || new BaseTexture1(null, {
            scaleMode: _constants.SCALE_MODES.NEAREST,
            resolution: 1,
            mipmap: _constants.MIPMAP_MODES.OFF,
            width: this.width,
            height: this.height
        });
        this.dirtyId++;
        this.dirtyFormat++;
        return this;
    };
    /**
     * Add a depth texture to the frame buffer
     *
     * @param {PIXI.BaseTexture} [texture] - Texture to add
     */ Framebuffer1.prototype.addDepthTexture = function(texture) {
        /* eslint-disable max-len */ this.depthTexture = texture || new BaseTexture1(new DepthResource1(null, {
            width: this.width,
            height: this.height
        }), {
            scaleMode: _constants.SCALE_MODES.NEAREST,
            resolution: 1,
            width: this.width,
            height: this.height,
            mipmap: _constants.MIPMAP_MODES.OFF,
            format: _constants.FORMATS.DEPTH_COMPONENT,
            type: _constants.TYPES.UNSIGNED_SHORT
        });
        this.dirtyId++;
        this.dirtyFormat++;
        return this;
    };
    /**
     * Enable depth on the frame buffer
     */ Framebuffer1.prototype.enableDepth = function() {
        this.depth = true;
        this.dirtyId++;
        this.dirtyFormat++;
        return this;
    };
    /**
     * Enable stencil on the frame buffer
     */ Framebuffer1.prototype.enableStencil = function() {
        this.stencil = true;
        this.dirtyId++;
        this.dirtyFormat++;
        return this;
    };
    /**
     * Resize the frame buffer
     *
     * @param {number} width - Width of the frame buffer to resize to
     * @param {number} height - Height of the frame buffer to resize to
     */ Framebuffer1.prototype.resize = function(width, height) {
        width = Math.round(width);
        height = Math.round(height);
        if (width === this.width && height === this.height) return;
        this.width = width;
        this.height = height;
        this.dirtyId++;
        this.dirtySize++;
        for(var i = 0; i < this.colorTextures.length; i++){
            var texture = this.colorTextures[i];
            var resolution = texture.resolution;
            // take into account the fact the texture may have a different resolution..
            texture.setSize(width / resolution, height / resolution);
        }
        if (this.depthTexture) {
            var resolution = this.depthTexture.resolution;
            this.depthTexture.setSize(width / resolution, height / resolution);
        }
    };
    /**
     * Disposes WebGL resources that are connected to this geometry
     */ Framebuffer1.prototype.dispose = function() {
        this.disposeRunner.emit(this, false);
    };
    /**
     * Destroys and removes the depth texture added to this framebuffer.
     */ Framebuffer1.prototype.destroyDepthTexture = function() {
        if (this.depthTexture) {
            this.depthTexture.destroy();
            this.depthTexture = null;
            ++this.dirtyId;
            ++this.dirtyFormat;
        }
    };
    return Framebuffer1;
}();
/**
 * A BaseRenderTexture is a special texture that allows any PixiJS display object to be rendered to it.
 *
 * __Hint__: All DisplayObjects (i.e. Sprites) that render to a BaseRenderTexture should be preloaded
 * otherwise black rectangles will be drawn instead.
 *
 * A BaseRenderTexture takes a snapshot of any Display Object given to its render method. The position
 * and rotation of the given Display Objects is ignored. For example:
 *
 * ```js
 * let renderer = PIXI.autoDetectRenderer();
 * let baseRenderTexture = new PIXI.BaseRenderTexture({ width: 800, height: 600 });
 * let renderTexture = new PIXI.RenderTexture(baseRenderTexture);
 * let sprite = PIXI.Sprite.from("spinObj_01.png");
 *
 * sprite.position.x = 800/2;
 * sprite.position.y = 600/2;
 * sprite.anchor.x = 0.5;
 * sprite.anchor.y = 0.5;
 *
 * renderer.render(sprite, {renderTexture});
 * ```
 *
 * The Sprite in this case will be rendered using its local transform. To render this sprite at 0,0
 * you can clear the transform
 *
 * ```js
 *
 * sprite.setTransform()
 *
 * let baseRenderTexture = new PIXI.BaseRenderTexture({ width: 100, height: 100 });
 * let renderTexture = new PIXI.RenderTexture(baseRenderTexture);
 *
 * renderer.render(sprite, {renderTexture});  // Renders to center of RenderTexture
 * ```
 *
 * @class
 * @extends PIXI.BaseTexture
 * @memberof PIXI
 */ var BaseRenderTexture1 = function(_super) {
    __extends(BaseRenderTexture2, _super);
    /**
     * @param {object} [options]
     * @param {number} [options.width=100] - The width of the base render texture.
     * @param {number} [options.height=100] - The height of the base render texture.
     * @param {PIXI.SCALE_MODES} [options.scaleMode=PIXI.settings.SCALE_MODE] - See {@link PIXI.SCALE_MODES}
     *   for possible values.
     * @param {number} [options.resolution=PIXI.settings.RESOLUTION] - The resolution / device pixel ratio
     *   of the texture being generated.
     * @param {PIXI.MSAA_QUALITY} [options.multisample=PIXI.MSAA_QUALITY.NONE] - The number of samples of the frame buffer.
     */ function BaseRenderTexture2(options) {
        var _this = this;
        if (typeof options === 'number') {
            /* eslint-disable prefer-rest-params */ // Backward compatibility of signature
            var width = arguments[0];
            var height = arguments[1];
            var scaleMode = arguments[2];
            var resolution = arguments[3];
            options = {
                width: width,
                height: height,
                scaleMode: scaleMode,
                resolution: resolution
            };
        /* eslint-enable prefer-rest-params */ }
        options.width = options.width || 100;
        options.height = options.height || 100;
        options.multisample = options.multisample !== undefined ? options.multisample : _constants.MSAA_QUALITY.NONE;
        _this = _super.call(this, null, options) || this;
        // Set defaults
        _this.mipmap = _constants.MIPMAP_MODES.OFF;
        _this.valid = true;
        _this.clearColor = [
            0,
            0,
            0,
            0
        ];
        _this.framebuffer = new Framebuffer(_this.realWidth, _this.realHeight).addColorTexture(0, _this);
        _this.framebuffer.multisample = options.multisample;
        // TODO - could this be added the systems?
        /**
         * The data structure for the stencil masks.
         *
         * @member {PIXI.MaskData[]}
         */ _this.maskStack = [];
        /**
         * The data structure for the filters.
         *
         * @member {Object[]}
         */ _this.filterStack = [
            {
            }
        ];
        return _this;
    }
    /**
     * Resizes the BaseRenderTexture.
     *
     * @param {number} desiredWidth - The desired width to resize to.
     * @param {number} desiredHeight - The desired height to resize to.
     */ BaseRenderTexture2.prototype.resize = function(desiredWidth, desiredHeight) {
        this.framebuffer.resize(desiredWidth * this.resolution, desiredHeight * this.resolution);
        this.setRealSize(this.framebuffer.width, this.framebuffer.height);
    };
    /**
     * Frees the texture and framebuffer from WebGL memory without destroying this texture object.
     * This means you can still use the texture later which will upload it to GPU
     * memory again.
     *
     * @fires PIXI.BaseTexture#dispose
     */ BaseRenderTexture2.prototype.dispose = function() {
        this.framebuffer.dispose();
        _super.prototype.dispose.call(this);
    };
    /**
     * Destroys this texture.
     */ BaseRenderTexture2.prototype.destroy = function() {
        _super.prototype.destroy.call(this);
        this.framebuffer.destroyDepthTexture();
        this.framebuffer = null;
    };
    return BaseRenderTexture2;
}(BaseTexture1);
/**
 * Stores a texture's frame in UV coordinates, in
 * which everything lies in the rectangle `[(0,0), (1,0),
 * (1,1), (0,1)]`.
 *
 * | Corner       | Coordinates |
 * |--------------|-------------|
 * | Top-Left     | `(x0,y0)`   |
 * | Top-Right    | `(x1,y1)`   |
 * | Bottom-Right | `(x2,y2)`   |
 * | Bottom-Left  | `(x3,y3)`   |
 *
 * @class
 * @protected
 * @memberof PIXI
 */ var TextureUvs = function() {
    function TextureUvs1() {
        /**
         * X-component of top-left corner `(x0,y0)`.
         *
         * @member {number}
         */ this.x0 = 0;
        /**
         * Y-component of top-left corner `(x0,y0)`.
         *
         * @member {number}
         */ this.y0 = 0;
        /**
         * X-component of top-right corner `(x1,y1)`.
         *
         * @member {number}
         */ this.x1 = 1;
        /**
         * Y-component of top-right corner `(x1,y1)`.
         *
         * @member {number}
         */ this.y1 = 0;
        /**
         * X-component of bottom-right corner `(x2,y2)`.
         *
         * @member {number}
         */ this.x2 = 1;
        /**
         * Y-component of bottom-right corner `(x2,y2)`.
         *
         * @member {number}
         */ this.y2 = 1;
        /**
         * X-component of bottom-left corner `(x3,y3)`.
         *
         * @member {number}
         */ this.x3 = 0;
        /**
         * Y-component of bottom-right corner `(x3,y3)`.
         *
         * @member {number}
         */ this.y3 = 1;
        this.uvsFloat32 = new Float32Array(8);
    }
    /**
     * Sets the texture Uvs based on the given frame information.
     *
     * @protected
     * @param {PIXI.Rectangle} frame - The frame of the texture
     * @param {PIXI.Rectangle} baseFrame - The base frame of the texture
     * @param {number} rotate - Rotation of frame, see {@link PIXI.groupD8}
     */ TextureUvs1.prototype.set = function(frame, baseFrame, rotate) {
        var tw = baseFrame.width;
        var th = baseFrame.height;
        if (rotate) {
            // width and height div 2 div baseFrame size
            var w2 = frame.width / 2 / tw;
            var h2 = frame.height / 2 / th;
            // coordinates of center
            var cX = frame.x / tw + w2;
            var cY = frame.y / th + h2;
            rotate = _math.groupD8.add(rotate, _math.groupD8.NW); // NW is top-left corner
            this.x0 = cX + w2 * _math.groupD8.uX(rotate);
            this.y0 = cY + h2 * _math.groupD8.uY(rotate);
            rotate = _math.groupD8.add(rotate, 2); // rotate 90 degrees clockwise
            this.x1 = cX + w2 * _math.groupD8.uX(rotate);
            this.y1 = cY + h2 * _math.groupD8.uY(rotate);
            rotate = _math.groupD8.add(rotate, 2);
            this.x2 = cX + w2 * _math.groupD8.uX(rotate);
            this.y2 = cY + h2 * _math.groupD8.uY(rotate);
            rotate = _math.groupD8.add(rotate, 2);
            this.x3 = cX + w2 * _math.groupD8.uX(rotate);
            this.y3 = cY + h2 * _math.groupD8.uY(rotate);
        } else {
            this.x0 = frame.x / tw;
            this.y0 = frame.y / th;
            this.x1 = (frame.x + frame.width) / tw;
            this.y1 = frame.y / th;
            this.x2 = (frame.x + frame.width) / tw;
            this.y2 = (frame.y + frame.height) / th;
            this.x3 = frame.x / tw;
            this.y3 = (frame.y + frame.height) / th;
        }
        this.uvsFloat32[0] = this.x0;
        this.uvsFloat32[1] = this.y0;
        this.uvsFloat32[2] = this.x1;
        this.uvsFloat32[3] = this.y1;
        this.uvsFloat32[4] = this.x2;
        this.uvsFloat32[5] = this.y2;
        this.uvsFloat32[6] = this.x3;
        this.uvsFloat32[7] = this.y3;
    };
    TextureUvs1.prototype.toString = function() {
        return "[@pixi/core:TextureUvs " + ("x0=" + this.x0 + " y0=" + this.y0 + " ") + ("x1=" + this.x1 + " y1=" + this.y1 + " x2=" + this.x2 + " ") + ("y2=" + this.y2 + " x3=" + this.x3 + " y3=" + this.y3) + "]";
    };
    return TextureUvs1;
}();
var DEFAULT_UVS = new TextureUvs();
/**
 * A texture stores the information that represents an image or part of an image.
 *
 * It cannot be added to the display list directly; instead use it as the texture for a Sprite.
 * If no frame is provided for a texture, then the whole image is used.
 *
 * You can directly create a texture from an image and then reuse it multiple times like this :
 *
 * ```js
 * let texture = PIXI.Texture.from('assets/image.png');
 * let sprite1 = new PIXI.Sprite(texture);
 * let sprite2 = new PIXI.Sprite(texture);
 * ```
 *
 * If you didnt pass the texture frame to constructor, it enables `noFrame` mode:
 * it subscribes on baseTexture events, it automatically resizes at the same time as baseTexture.
 *
 * Textures made from SVGs, loaded or not, cannot be used before the file finishes processing.
 * You can check for this by checking the sprite's _textureID property.
 * ```js
 * var texture = PIXI.Texture.from('assets/image.svg');
 * var sprite1 = new PIXI.Sprite(texture);
 * //sprite1._textureID should not be undefined if the texture has finished processing the SVG file
 * ```
 * You can use a ticker or rAF to ensure your sprites load the finished textures after processing. See issue #3068.
 *
 * @class
 * @extends PIXI.utils.EventEmitter
 * @memberof PIXI
 * @typeParam R - The BaseTexture's Resource type.
 */ var Texture1 = function(_super) {
    __extends(Texture2, _super);
    /**
     * @param {PIXI.BaseTexture} baseTexture - The base texture source to create the texture from
     * @param {PIXI.Rectangle} [frame] - The rectangle frame of the texture to show
     * @param {PIXI.Rectangle} [orig] - The area of original texture
     * @param {PIXI.Rectangle} [trim] - Trimmed rectangle of original texture
     * @param {number} [rotate] - indicates how the texture was rotated by texture packer. See {@link PIXI.groupD8}
     * @param {PIXI.IPointData} [anchor] - Default anchor point used for sprite placement / rotation
     */ function Texture2(baseTexture, frame, orig, trim, rotate, anchor) {
        var _this = _super.call(this) || this;
        /**
         * Does this Texture have any frame data assigned to it?
         *
         * This mode is enabled automatically if no frame was passed inside constructor.
         *
         * In this mode texture is subscribed to baseTexture events, and fires `update` on any change.
         *
         * Beware, after loading or resize of baseTexture event can fired two times!
         * If you want more control, subscribe on baseTexture itself.
         *
         * ```js
         * texture.on('update', () => {});
         * ```
         *
         * Any assignment of `frame` switches off `noFrame` mode.
         *
         * @member {boolean}
         */ _this.noFrame = false;
        if (!frame) {
            _this.noFrame = true;
            frame = new _math.Rectangle(0, 0, 1, 1);
        }
        if (baseTexture instanceof Texture2) baseTexture = baseTexture.baseTexture;
        /**
         * The base texture that this texture uses.
         *
         * @member {PIXI.BaseTexture}
         */ _this.baseTexture = baseTexture;
        /**
         * This is the area of the BaseTexture image to actually copy to the Canvas / WebGL when rendering,
         * irrespective of the actual frame size or placement (which can be influenced by trimmed texture atlases)
         *
         * @member {PIXI.Rectangle}
         */ _this._frame = frame;
        /**
         * This is the trimmed area of original texture, before it was put in atlas
         * Please call `updateUvs()` after you change coordinates of `trim` manually.
         *
         * @member {PIXI.Rectangle}
         */ _this.trim = trim;
        /**
         * This will let the renderer know if the texture is valid. If it's not then it cannot be rendered.
         *
         * @member {boolean}
         */ _this.valid = false;
        /**
         * The WebGL UV data cache. Can be used as quad UV
         *
         * @member {PIXI.TextureUvs}
         * @protected
         */ _this._uvs = DEFAULT_UVS;
        /**
         * Default TextureMatrix instance for this texture
         * By default that object is not created because its heavy
         *
         * @member {PIXI.TextureMatrix}
         */ _this.uvMatrix = null;
        /**
         * This is the area of original texture, before it was put in atlas
         *
         * @member {PIXI.Rectangle}
         */ _this.orig = orig || frame; // new Rectangle(0, 0, 1, 1);
        _this._rotate = Number(rotate || 0);
        if (rotate === true) // this is old texturepacker legacy, some games/libraries are passing "true" for rotated textures
        _this._rotate = 2;
        else if (_this._rotate % 2 !== 0) throw new Error('attempt to use diamond-shaped UVs. If you are sure, set rotation manually');
        /**
         * Anchor point that is used as default if sprite is created with this texture.
         * Changing the `defaultAnchor` at a later point of time will not update Sprite's anchor point.
         * @member {PIXI.Point}
         * @default {0,0}
         */ _this.defaultAnchor = anchor ? new _math.Point(anchor.x, anchor.y) : new _math.Point(0, 0);
        /**
         * Update ID is observed by sprites and TextureMatrix instances.
         * Call updateUvs() to increment it.
         *
         * @member {number}
         * @protected
         */ _this._updateID = 0;
        /**
         * The ids under which this Texture has been added to the texture cache. This is
         * automatically set as long as Texture.addToCache is used, but may not be set if a
         * Texture is added directly to the TextureCache array.
         *
         * @member {string[]}
         */ _this.textureCacheIds = [];
        if (!baseTexture.valid) baseTexture.once('loaded', _this.onBaseTextureUpdated, _this);
        else if (_this.noFrame) // if there is no frame we should monitor for any base texture changes..
        {
            if (baseTexture.valid) _this.onBaseTextureUpdated(baseTexture);
        } else _this.frame = frame;
        if (_this.noFrame) baseTexture.on('update', _this.onBaseTextureUpdated, _this);
        return _this;
    }
    /**
     * Updates this texture on the gpu.
     *
     * Calls the TextureResource update.
     *
     * If you adjusted `frame` manually, please call `updateUvs()` instead.
     *
     */ Texture2.prototype.update = function() {
        if (this.baseTexture.resource) this.baseTexture.resource.update();
    };
    /**
     * Called when the base texture is updated
     *
     * @protected
     * @param {PIXI.BaseTexture} baseTexture - The base texture.
     */ Texture2.prototype.onBaseTextureUpdated = function(baseTexture) {
        if (this.noFrame) {
            if (!this.baseTexture.valid) return;
            this._frame.width = baseTexture.width;
            this._frame.height = baseTexture.height;
            this.valid = true;
            this.updateUvs();
        } else // TODO this code looks confusing.. boo to abusing getters and setters!
        // if user gave us frame that has bigger size than resized texture it can be a problem
        this.frame = this._frame;
        this.emit('update', this);
    };
    /**
     * Destroys this texture
     *
     * @param {boolean} [destroyBase=false] - Whether to destroy the base texture as well
     */ Texture2.prototype.destroy = function(destroyBase) {
        if (this.baseTexture) {
            if (destroyBase) {
                var resource = this.baseTexture.resource;
                // delete the texture if it exists in the texture cache..
                // this only needs to be removed if the base texture is actually destroyed too..
                if (resource && resource.url && _utils.TextureCache[resource.url]) Texture2.removeFromCache(resource.url);
                this.baseTexture.destroy();
            }
            this.baseTexture.off('loaded', this.onBaseTextureUpdated, this);
            this.baseTexture.off('update', this.onBaseTextureUpdated, this);
            this.baseTexture = null;
        }
        this._frame = null;
        this._uvs = null;
        this.trim = null;
        this.orig = null;
        this.valid = false;
        Texture2.removeFromCache(this);
        this.textureCacheIds = null;
    };
    /**
     * Creates a new texture object that acts the same as this one.
     *
     * @return {PIXI.Texture} The new texture
     */ Texture2.prototype.clone = function() {
        var clonedFrame = this._frame.clone();
        var clonedOrig = this._frame === this.orig ? clonedFrame : this.orig.clone();
        var clonedTexture = new Texture2(this.baseTexture, !this.noFrame && clonedFrame, clonedOrig, this.trim && this.trim.clone(), this.rotate, this.defaultAnchor);
        if (this.noFrame) clonedTexture._frame = clonedFrame;
        return clonedTexture;
    };
    /**
     * Updates the internal WebGL UV cache. Use it after you change `frame` or `trim` of the texture.
     * Call it after changing the frame
     */ Texture2.prototype.updateUvs = function() {
        if (this._uvs === DEFAULT_UVS) this._uvs = new TextureUvs();
        this._uvs.set(this._frame, this.baseTexture, this.rotate);
        this._updateID++;
    };
    /**
     * Helper function that creates a new Texture based on the source you provide.
     * The source can be - frame id, image url, video url, canvas element, video element, base texture
     *
     * @static
     * @param {string|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement|PIXI.BaseTexture} source -
     *        Source to create texture from
     * @param {object} [options] - See {@link PIXI.BaseTexture}'s constructor for options.
     * @param {string} [options.pixiIdPrefix=pixiid] - If a source has no id, this is the prefix of the generated id
     * @param {boolean} [strict] - Enforce strict-mode, see {@link PIXI.settings.STRICT_TEXTURE_CACHE}.
     * @return {PIXI.Texture} The newly created texture
     */ Texture2.from = function(source, options, strict) {
        if (options === void 0) options = {
        };
        if (strict === void 0) strict = _settings.settings.STRICT_TEXTURE_CACHE;
        var isFrame = typeof source === 'string';
        var cacheId = null;
        if (isFrame) cacheId = source;
        else {
            if (!source._pixiId) {
                var prefix = options && options.pixiIdPrefix || 'pixiid';
                source._pixiId = prefix + "_" + _utils.uid();
            }
            cacheId = source._pixiId;
        }
        var texture = _utils.TextureCache[cacheId];
        // Strict-mode rejects invalid cacheIds
        if (isFrame && strict && !texture) throw new Error("The cacheId \"" + cacheId + "\" does not exist in TextureCache.");
        if (!texture) {
            if (!options.resolution) options.resolution = _utils.getResolutionOfUrl(source);
            texture = new Texture2(new BaseTexture1(source, options));
            texture.baseTexture.cacheId = cacheId;
            BaseTexture1.addToCache(texture.baseTexture, cacheId);
            Texture2.addToCache(texture, cacheId);
        }
        // lets assume its a base texture!
        return texture;
    };
    /**
     * Useful for loading textures via URLs. Use instead of `Texture.from` because
     * it does a better job of handling failed URLs more effectively. This also ignores
     * `PIXI.settings.STRICT_TEXTURE_CACHE`. Works for Videos, SVGs, Images.
     * @param {string} url - The remote URL to load.
     * @param {object} [options] - Optional options to include
     * @return {Promise<PIXI.Texture>} A Promise that resolves to a Texture.
     */ Texture2.fromURL = function(url, options) {
        var resourceOptions = Object.assign({
            autoLoad: false
        }, options === null || options === void 0 ? void 0 : options.resourceOptions);
        var texture = Texture2.from(url, Object.assign({
            resourceOptions: resourceOptions
        }, options), false);
        var resource = texture.baseTexture.resource;
        // The texture was already loaded
        if (texture.baseTexture.valid) return Promise.resolve(texture);
        // Manually load the texture, this should allow users to handle load errors
        return resource.load().then(function() {
            return Promise.resolve(texture);
        });
    };
    /**
     * Create a new Texture with a BufferResource from a Float32Array.
     * RGBA values are floats from 0 to 1.
     * @static
     * @param {Float32Array|Uint8Array} buffer - The optional array to use, if no data
     *        is provided, a new Float32Array is created.
     * @param {number} width - Width of the resource
     * @param {number} height - Height of the resource
     * @param {object} [options] - See {@link PIXI.BaseTexture}'s constructor for options.
     * @return {PIXI.Texture} The resulting new BaseTexture
     */ Texture2.fromBuffer = function(buffer, width, height, options) {
        return new Texture2(BaseTexture1.fromBuffer(buffer, width, height, options));
    };
    /**
     * Create a texture from a source and add to the cache.
     *
     * @static
     * @param {HTMLImageElement|HTMLCanvasElement|string} source - The input source.
     * @param {String} imageUrl - File name of texture, for cache and resolving resolution.
     * @param {String} [name] - Human readable name for the texture cache. If no name is
     *        specified, only `imageUrl` will be used as the cache ID.
     * @return {PIXI.Texture} Output texture
     */ Texture2.fromLoader = function(source, imageUrl, name, options) {
        var baseTexture = new BaseTexture1(source, Object.assign({
            scaleMode: _settings.settings.SCALE_MODE,
            resolution: _utils.getResolutionOfUrl(imageUrl)
        }, options));
        var resource = baseTexture.resource;
        if (resource instanceof ImageResource1) resource.url = imageUrl;
        var texture = new Texture2(baseTexture);
        // No name, use imageUrl instead
        if (!name) name = imageUrl;
        // lets also add the frame to pixi's global cache for 'fromLoader' function
        BaseTexture1.addToCache(texture.baseTexture, name);
        Texture2.addToCache(texture, name);
        // also add references by url if they are different.
        if (name !== imageUrl) {
            BaseTexture1.addToCache(texture.baseTexture, imageUrl);
            Texture2.addToCache(texture, imageUrl);
        }
        // Generally images are valid right away
        if (texture.baseTexture.valid) return Promise.resolve(texture);
        // SVG assets need to be parsed async, let's wait
        return new Promise(function(resolve) {
            texture.baseTexture.once('loaded', function() {
                return resolve(texture);
            });
        });
    };
    /**
     * Adds a Texture to the global TextureCache. This cache is shared across the whole PIXI object.
     *
     * @static
     * @param {PIXI.Texture} texture - The Texture to add to the cache.
     * @param {string} id - The id that the Texture will be stored against.
     */ Texture2.addToCache = function(texture, id) {
        if (id) {
            if (texture.textureCacheIds.indexOf(id) === -1) texture.textureCacheIds.push(id);
            if (_utils.TextureCache[id]) // eslint-disable-next-line no-console
            console.warn("Texture added to the cache with an id [" + id + "] that already had an entry");
            _utils.TextureCache[id] = texture;
        }
    };
    /**
     * Remove a Texture from the global TextureCache.
     *
     * @static
     * @param {string|PIXI.Texture} texture - id of a Texture to be removed, or a Texture instance itself
     * @return {PIXI.Texture|null} The Texture that was removed
     */ Texture2.removeFromCache = function(texture) {
        if (typeof texture === 'string') {
            var textureFromCache = _utils.TextureCache[texture];
            if (textureFromCache) {
                var index = textureFromCache.textureCacheIds.indexOf(texture);
                if (index > -1) textureFromCache.textureCacheIds.splice(index, 1);
                delete _utils.TextureCache[texture];
                return textureFromCache;
            }
        } else if (texture && texture.textureCacheIds) {
            for(var i = 0; i < texture.textureCacheIds.length; ++i)// Check that texture matches the one being passed in before deleting it from the cache.
            if (_utils.TextureCache[texture.textureCacheIds[i]] === texture) delete _utils.TextureCache[texture.textureCacheIds[i]];
            texture.textureCacheIds.length = 0;
            return texture;
        }
        return null;
    };
    Object.defineProperty(Texture2.prototype, "resolution", {
        /**
         * Returns resolution of baseTexture
         *
         * @member {number}
         * @readonly
         */ get: function() {
            return this.baseTexture.resolution;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Texture2.prototype, "frame", {
        /**
         * The frame specifies the region of the base texture that this texture uses.
         * Please call `updateUvs()` after you change coordinates of `frame` manually.
         *
         * @member {PIXI.Rectangle}
         */ get: function() {
            return this._frame;
        },
        set: function(frame) {
            this._frame = frame;
            this.noFrame = false;
            var x = frame.x, y = frame.y, width = frame.width, height = frame.height;
            var xNotFit = x + width > this.baseTexture.width;
            var yNotFit = y + height > this.baseTexture.height;
            if (xNotFit || yNotFit) {
                var relationship = xNotFit && yNotFit ? 'and' : 'or';
                var errorX = "X: " + x + " + " + width + " = " + (x + width) + " > " + this.baseTexture.width;
                var errorY = "Y: " + y + " + " + height + " = " + (y + height) + " > " + this.baseTexture.height;
                throw new Error('Texture Error: frame does not fit inside the base Texture dimensions: ' + (errorX + " " + relationship + " " + errorY));
            }
            this.valid = width && height && this.baseTexture.valid;
            if (!this.trim && !this.rotate) this.orig = frame;
            if (this.valid) this.updateUvs();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Texture2.prototype, "rotate", {
        /**
         * Indicates whether the texture is rotated inside the atlas
         * set to 2 to compensate for texture packer rotation
         * set to 6 to compensate for spine packer rotation
         * can be used to rotate or mirror sprites
         * See {@link PIXI.groupD8} for explanation
         *
         * @member {number}
         */ get: function() {
            return this._rotate;
        },
        set: function(rotate) {
            this._rotate = rotate;
            if (this.valid) this.updateUvs();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Texture2.prototype, "width", {
        /**
         * The width of the Texture in pixels.
         *
         * @member {number}
         */ get: function() {
            return this.orig.width;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Texture2.prototype, "height", {
        /**
         * The height of the Texture in pixels.
         *
         * @member {number}
         */ get: function() {
            return this.orig.height;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Utility function for BaseTexture|Texture cast
     */ Texture2.prototype.castToBaseTexture = function() {
        return this.baseTexture;
    };
    return Texture2;
}(_utils.EventEmitter);
function createWhiteTexture() {
    var canvas = document.createElement('canvas');
    canvas.width = 16;
    canvas.height = 16;
    var context = canvas.getContext('2d');
    context.fillStyle = 'white';
    context.fillRect(0, 0, 16, 16);
    return new Texture1(new BaseTexture1(new CanvasResource1(canvas)));
}
function removeAllHandlers(tex) {
    tex.destroy = function _emptyDestroy() {
    };
    tex.on = function _emptyOn() {
    };
    tex.once = function _emptyOnce() {
    };
    tex.emit = function _emptyEmit() {
    };
}
/**
 * An empty texture, used often to not have to create multiple empty textures.
 * Can not be destroyed.
 *
 * @static
 * @constant
 * @member {PIXI.Texture}
 */ Texture1.EMPTY = new Texture1(new BaseTexture1());
removeAllHandlers(Texture1.EMPTY);
removeAllHandlers(Texture1.EMPTY.baseTexture);
/**
 * A white texture of 16x16 size, used for graphics and other things
 * Can not be destroyed.
 *
 * @static
 * @constant
 * @member {PIXI.Texture}
 */ Texture1.WHITE = createWhiteTexture();
removeAllHandlers(Texture1.WHITE);
removeAllHandlers(Texture1.WHITE.baseTexture);
/**
 * A RenderTexture is a special texture that allows any PixiJS display object to be rendered to it.
 *
 * __Hint__: All DisplayObjects (i.e. Sprites) that render to a RenderTexture should be preloaded
 * otherwise black rectangles will be drawn instead.
 *
 * __Hint-2__: The actual memory allocation will happen on first render.
 * You shouldn't create renderTextures each frame just to delete them after, try to reuse them.
 *
 * A RenderTexture takes a snapshot of any Display Object given to its render method. For example:
 *
 * ```js
 * let renderer = PIXI.autoDetectRenderer();
 * let renderTexture = PIXI.RenderTexture.create({ width: 800, height: 600 });
 * let sprite = PIXI.Sprite.from("spinObj_01.png");
 *
 * sprite.position.x = 800/2;
 * sprite.position.y = 600/2;
 * sprite.anchor.x = 0.5;
 * sprite.anchor.y = 0.5;
 *
 * renderer.render(sprite, {renderTexture});
 * ```
 * Note that you should not create a new renderer, but reuse the same one as the rest of the application.
 *
 * The Sprite in this case will be rendered using its local transform. To render this sprite at 0,0
 * you can clear the transform
 *
 * ```js
 *
 * sprite.setTransform()
 *
 * let renderTexture = new PIXI.RenderTexture.create({ width: 100, height: 100 });
 *
 * renderer.render(sprite, {renderTexture});  // Renders to center of RenderTexture
 * ```
 *
 * @class
 * @extends PIXI.Texture
 * @memberof PIXI
 */ var RenderTexture1 = function(_super) {
    __extends(RenderTexture2, _super);
    /**
     * @param {PIXI.BaseRenderTexture} baseRenderTexture - The base texture object that this texture uses
     * @param {PIXI.Rectangle} [frame] - The rectangle frame of the texture to show
     */ function RenderTexture2(baseRenderTexture, frame) {
        var _this = _super.call(this, baseRenderTexture, frame) || this;
        /**
         * This will let the renderer know if the texture is valid. If it's not then it cannot be rendered.
         *
         * @member {boolean}
         */ _this.valid = true;
        /**
         * Stores `sourceFrame` when this texture is inside current filter stack.
         * You can read it inside filters.
         *
         * @readonly
         * @member {PIXI.Rectangle}
         */ _this.filterFrame = null;
        /**
         * The key for pooled texture of FilterSystem
         * @protected
         * @member {string}
         */ _this.filterPoolKey = null;
        _this.updateUvs();
        return _this;
    }
    Object.defineProperty(RenderTexture2.prototype, "framebuffer", {
        /**
         * Shortcut to `this.baseTexture.framebuffer`, saves baseTexture cast.
         * @member {PIXI.Framebuffer}
         * @readonly
         */ get: function() {
            return this.baseTexture.framebuffer;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(RenderTexture2.prototype, "multisample", {
        /**
         * Shortcut to `this.framebuffer.multisample`.
         *
         * @member {PIXI.MSAA_QUALITY}
         * @default PIXI.MSAA_QUALITY.NONE
         */ get: function() {
            return this.framebuffer.multisample;
        },
        set: function(value) {
            this.framebuffer.multisample = value;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Resizes the RenderTexture.
     *
     * @param {number} desiredWidth - The desired width to resize to.
     * @param {number} desiredHeight - The desired height to resize to.
     * @param {boolean} [resizeBaseTexture=true] - Should the baseTexture.width and height values be resized as well?
     */ RenderTexture2.prototype.resize = function(desiredWidth, desiredHeight, resizeBaseTexture) {
        if (resizeBaseTexture === void 0) resizeBaseTexture = true;
        var resolution = this.baseTexture.resolution;
        var width = Math.round(desiredWidth * resolution) / resolution;
        var height = Math.round(desiredHeight * resolution) / resolution;
        // TODO - could be not required..
        this.valid = width > 0 && height > 0;
        this._frame.width = this.orig.width = width;
        this._frame.height = this.orig.height = height;
        if (resizeBaseTexture) this.baseTexture.resize(width, height);
        this.updateUvs();
    };
    /**
     * Changes the resolution of baseTexture, but does not change framebuffer size.
     *
     * @param {number} resolution - The new resolution to apply to RenderTexture
     */ RenderTexture2.prototype.setResolution = function(resolution) {
        var baseTexture = this.baseTexture;
        if (baseTexture.resolution === resolution) return;
        baseTexture.setResolution(resolution);
        this.resize(baseTexture.width, baseTexture.height, false);
    };
    RenderTexture2.create = function(options) {
        var arguments$1 = arguments;
        var rest = [];
        for(var _i = 1; _i < arguments.length; _i++)rest[_i - 1] = arguments$1[_i];
        // @deprecated fallback, old-style: create(width, height, scaleMode, resolution)
        if (typeof options === 'number') {
            _utils.deprecation('6.0.0', 'Arguments (width, height, scaleMode, resolution) have been deprecated.');
            /* eslint-disable prefer-rest-params */ options = {
                width: options,
                height: rest[0],
                scaleMode: rest[1],
                resolution: rest[2]
            };
        /* eslint-enable prefer-rest-params */ }
        return new RenderTexture2(new BaseRenderTexture1(options));
    };
    return RenderTexture2;
}(Texture1);
/**
 * Experimental!
 *
 * Texture pool, used by FilterSystem and plugins
 * Stores collection of temporary pow2 or screen-sized renderTextures
 *
 * If you use custom RenderTexturePool for your filters, you can use methods
 * `getFilterTexture` and `returnFilterTexture` same as in
 *
 * @class
 * @memberof PIXI
 */ var RenderTexturePool = function() {
    /**
     * @param {object} [textureOptions] - options that will be passed to BaseRenderTexture constructor
     * @param {PIXI.SCALE_MODES} [textureOptions.scaleMode] - See {@link PIXI.SCALE_MODES} for possible values.
     */ function RenderTexturePool1(textureOptions) {
        this.texturePool = {
        };
        this.textureOptions = textureOptions || {
        };
        /**
         * Allow renderTextures of the same size as screen, not just pow2
         *
         * Automatically sets to true after `setScreenSize`
         *
         * @member {boolean}
         * @default false
         */ this.enableFullScreen = false;
        this._pixelsWidth = 0;
        this._pixelsHeight = 0;
    }
    /**
     * creates of texture with params that were specified in pool constructor
     *
     * @param {number} realWidth - width of texture in pixels
     * @param {number} realHeight - height of texture in pixels
     * @param {PIXI.MSAA_QUALITY} [multisample=PIXI.MSAA_QUALITY.NONE] - number of samples of the framebuffer
     * @returns {RenderTexture}
     */ RenderTexturePool1.prototype.createTexture = function(realWidth, realHeight, multisample) {
        if (multisample === void 0) multisample = _constants.MSAA_QUALITY.NONE;
        var baseRenderTexture = new BaseRenderTexture1(Object.assign({
            width: realWidth,
            height: realHeight,
            resolution: 1,
            multisample: multisample
        }, this.textureOptions));
        return new RenderTexture1(baseRenderTexture);
    };
    /**
     * Gets a Power-of-Two render texture or fullScreen texture
     *
     * @protected
     * @param {number} minWidth - The minimum width of the render texture.
     * @param {number} minHeight - The minimum height of the render texture.
     * @param {number} [resolution=1] - The resolution of the render texture.
     * @param {PIXI.MSAA_QUALITY} [multisample=PIXI.MSAA_QUALITY.NONE] - Number of samples of the render texture.
     * @return {PIXI.RenderTexture} The new render texture.
     */ RenderTexturePool1.prototype.getOptimalTexture = function(minWidth, minHeight, resolution, multisample) {
        if (resolution === void 0) resolution = 1;
        if (multisample === void 0) multisample = _constants.MSAA_QUALITY.NONE;
        var key;
        minWidth = Math.ceil(minWidth * resolution);
        minHeight = Math.ceil(minHeight * resolution);
        if (!this.enableFullScreen || minWidth !== this._pixelsWidth || minHeight !== this._pixelsHeight) {
            minWidth = _utils.nextPow2(minWidth);
            minHeight = _utils.nextPow2(minHeight);
            key = ((minWidth & 65535) << 16 | minHeight & 65535) >>> 0;
            if (multisample > 1) key += multisample * 4294967296;
        } else key = multisample > 1 ? -multisample : -1;
        if (!this.texturePool[key]) this.texturePool[key] = [];
        var renderTexture = this.texturePool[key].pop();
        if (!renderTexture) renderTexture = this.createTexture(minWidth, minHeight, multisample);
        renderTexture.filterPoolKey = key;
        renderTexture.setResolution(resolution);
        return renderTexture;
    };
    /**
     * Gets extra texture of the same size as input renderTexture
     *
     * `getFilterTexture(input, 0.5)` or `getFilterTexture(0.5, input)`
     *
     * @param {PIXI.RenderTexture} input - renderTexture from which size and resolution will be copied
     * @param {number} [resolution] - override resolution of the renderTexture
     *  It overrides, it does not multiply
     * @param {PIXI.MSAA_QUALITY} [multisample=PIXI.MSAA_QUALITY.NONE] - number of samples of the renderTexture
     * @returns {PIXI.RenderTexture}
     */ RenderTexturePool1.prototype.getFilterTexture = function(input, resolution, multisample) {
        var filterTexture = this.getOptimalTexture(input.width, input.height, resolution || input.resolution, multisample || _constants.MSAA_QUALITY.NONE);
        filterTexture.filterFrame = input.filterFrame;
        return filterTexture;
    };
    /**
     * Place a render texture back into the pool.
     * @param {PIXI.RenderTexture} renderTexture - The renderTexture to free
     */ RenderTexturePool1.prototype.returnTexture = function(renderTexture) {
        var key = renderTexture.filterPoolKey;
        renderTexture.filterFrame = null;
        this.texturePool[key].push(renderTexture);
    };
    /**
     * Alias for returnTexture, to be compliant with FilterSystem interface
     * @param {PIXI.RenderTexture} renderTexture - The renderTexture to free
     */ RenderTexturePool1.prototype.returnFilterTexture = function(renderTexture) {
        this.returnTexture(renderTexture);
    };
    /**
     * Clears the pool
     *
     * @param {boolean} [destroyTextures=true] - destroy all stored textures
     */ RenderTexturePool1.prototype.clear = function(destroyTextures) {
        destroyTextures = destroyTextures !== false;
        if (destroyTextures) for(var i in this.texturePool){
            var textures = this.texturePool[i];
            if (textures) for(var j = 0; j < textures.length; j++)textures[j].destroy(true);
        }
        this.texturePool = {
        };
    };
    /**
     * If screen size was changed, drops all screen-sized textures,
     * sets new screen size, sets `enableFullScreen` to true
     *
     * Size is measured in pixels, `renderer.view` can be passed here, not `renderer.screen`
     *
     * @param {PIXI.ISize} size - Initial size of screen
     */ RenderTexturePool1.prototype.setScreenSize = function(size) {
        if (size.width === this._pixelsWidth && size.height === this._pixelsHeight) return;
        this.enableFullScreen = size.width > 0 && size.height > 0;
        for(var i in this.texturePool){
            if (!(Number(i) < 0)) continue;
            var textures = this.texturePool[i];
            if (textures) for(var j = 0; j < textures.length; j++)textures[j].destroy(true);
            this.texturePool[i] = [];
        }
        this._pixelsWidth = size.width;
        this._pixelsHeight = size.height;
    };
    /**
     * Key that is used to store fullscreen renderTextures in a pool
     *
     * @static
     * @const {number}
     */ RenderTexturePool1.SCREEN_KEY = -1;
    return RenderTexturePool1;
}();
/* eslint-disable max-len */ /**
 * Holds the information for a single attribute structure required to render geometry.
 *
 * This does not contain the actual data, but instead has a buffer id that maps to a {@link PIXI.Buffer}
 * This can include anything from positions, uvs, normals, colors etc.
 *
 * @class
 * @memberof PIXI
 */ var Attribute = function() {
    /**
     * @param {string} buffer - the id of the buffer that this attribute will look for
     * @param {Number} [size=0] - the size of the attribute. If you have 2 floats per vertex (eg position x and y) this would be 2.
     * @param {Boolean} [normalized=false] - should the data be normalized.
     * @param {PIXI.TYPES} [type=PIXI.TYPES.FLOAT] - what type of number is the attribute. Check {@link PIXI.TYPES} to see the ones available
     * @param {Number} [stride=0] - How far apart (in floats) the start of each value is. (used for interleaving data)
     * @param {Number} [start=0] - How far into the array to start reading values (used for interleaving data)
     */ function Attribute1(buffer, size, normalized, type, stride, start, instance) {
        if (size === void 0) size = 0;
        if (normalized === void 0) normalized = false;
        if (type === void 0) type = _constants.TYPES.FLOAT;
        this.buffer = buffer;
        this.size = size;
        this.normalized = normalized;
        this.type = type;
        this.stride = stride;
        this.start = start;
        this.instance = instance;
    }
    /**
     * Destroys the Attribute.
     */ Attribute1.prototype.destroy = function() {
        this.buffer = null;
    };
    /**
     * Helper function that creates an Attribute based on the information provided
     *
     * @static
     * @param {string} buffer - the id of the buffer that this attribute will look for
     * @param {Number} [size=0] - the size of the attribute. If you have 2 floats per vertex (eg position x and y) this would be 2
     * @param {Boolean} [normalized=false] - should the data be normalized.
     * @param {PIXI.TYPES} [type=PIXI.TYPES.FLOAT] - what type of number is the attribute. Check {@link PIXI.TYPES} to see the ones available
     * @param {Number} [stride=0] - How far apart (in floats) the start of each value is. (used for interleaving data)
     *
     * @returns {PIXI.Attribute} A new {@link PIXI.Attribute} based on the information provided
     */ Attribute1.from = function(buffer, size, normalized, type, stride) {
        return new Attribute1(buffer, size, normalized, type, stride);
    };
    return Attribute1;
}();
var UID = 0;
/**
 * A wrapper for data so that it can be used and uploaded by WebGL
 *
 * @class
 * @memberof PIXI
 */ var Buffer = function() {
    /**
     * @param {ArrayBuffer| SharedArrayBuffer|ArrayBufferView} data - the data to store in the buffer.
     * @param {boolean} [_static=true] - `true` for static buffer
     * @param {boolean} [index=false] - `true` for index buffer
     */ function Buffer1(data, _static, index) {
        if (_static === void 0) _static = true;
        if (index === void 0) index = false;
        /**
         * The data in the buffer, as a typed array
         *
         * @member {ArrayBuffer| SharedArrayBuffer | ArrayBufferView}
         */ this.data = data || new Float32Array(1);
        /**
         * A map of renderer IDs to webgl buffer
         *
         * @private
         * @member {object<number, GLBuffer>}
         */ this._glBuffers = {
        };
        this._updateID = 0;
        this.index = index;
        this.static = _static;
        this.id = UID++;
        this.disposeRunner = new _runner.Runner('disposeBuffer');
    }
    // TODO could explore flagging only a partial upload?
    /**
     * flags this buffer as requiring an upload to the GPU
     * @param {ArrayBuffer|SharedArrayBuffer|ArrayBufferView|number[]} [data] - the data to update in the buffer.
     */ Buffer1.prototype.update = function(data) {
        if (data instanceof Array) data = new Float32Array(data);
        this.data = data || this.data;
        this._updateID++;
    };
    /**
     * disposes WebGL resources that are connected to this geometry
     */ Buffer1.prototype.dispose = function() {
        this.disposeRunner.emit(this, false);
    };
    /**
     * Destroys the buffer
     */ Buffer1.prototype.destroy = function() {
        this.dispose();
        this.data = null;
    };
    Object.defineProperty(Buffer1.prototype, "index", {
        get: function() {
            return this.type === _constants.BUFFER_TYPE.ELEMENT_ARRAY_BUFFER;
        },
        /**
         * Flags whether this is an index buffer.
         *
         * Index buffers are of type `ELEMENT_ARRAY_BUFFER`. Note that setting this property to false will make
         * the buffer of type `ARRAY_BUFFER`.
         *
         * For backwards compatibility.
         */ set: function(value) {
            this.type = value ? _constants.BUFFER_TYPE.ELEMENT_ARRAY_BUFFER : _constants.BUFFER_TYPE.ARRAY_BUFFER;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Helper function that creates a buffer based on an array or TypedArray
     *
     * @static
     * @param {ArrayBufferView | number[]} data - the TypedArray that the buffer will store. If this is a regular Array it will be converted to a Float32Array.
     * @return {PIXI.Buffer} A new Buffer based on the data provided.
     */ Buffer1.from = function(data) {
        if (data instanceof Array) data = new Float32Array(data);
        return new Buffer1(data);
    };
    return Buffer1;
}();
/* eslint-disable object-shorthand */ var map = {
    Float32Array: Float32Array,
    Uint32Array: Uint32Array,
    Int32Array: Int32Array,
    Uint8Array: Uint8Array
};
function interleaveTypedArrays(arrays, sizes) {
    var outSize = 0;
    var stride = 0;
    var views = {
    };
    for(var i = 0; i < arrays.length; i++){
        stride += sizes[i];
        outSize += arrays[i].length;
    }
    var buffer = new ArrayBuffer(outSize * 4);
    var out = null;
    var littleOffset = 0;
    for(var i = 0; i < arrays.length; i++){
        var size = sizes[i];
        var array = arrays[i];
        var type = _utils.getBufferType(array);
        if (!views[type]) views[type] = new map[type](buffer);
        out = views[type];
        for(var j = 0; j < array.length; j++){
            var indexStart = (j / size | 0) * stride + littleOffset;
            var index = j % size;
            out[indexStart + index] = array[j];
        }
        littleOffset += size;
    }
    return new Float32Array(buffer);
}
var byteSizeMap = {
    5126: 4,
    5123: 2,
    5121: 1
};
var UID$1 = 0;
/* eslint-disable object-shorthand */ var map$1 = {
    Float32Array: Float32Array,
    Uint32Array: Uint32Array,
    Int32Array: Int32Array,
    Uint8Array: Uint8Array,
    Uint16Array: Uint16Array
};
/* eslint-disable max-len */ /**
 * The Geometry represents a model. It consists of two components:
 * - GeometryStyle - The structure of the model such as the attributes layout
 * - GeometryData - the data of the model - this consists of buffers.
 * This can include anything from positions, uvs, normals, colors etc.
 *
 * Geometry can be defined without passing in a style or data if required (thats how I prefer!)
 *
 * ```js
 * let geometry = new PIXI.Geometry();
 *
 * geometry.addAttribute('positions', [0, 0, 100, 0, 100, 100, 0, 100], 2);
 * geometry.addAttribute('uvs', [0,0,1,0,1,1,0,1],2)
 * geometry.addIndex([0,1,2,1,3,2])
 *
 * ```
 * @class
 * @memberof PIXI
 */ var Geometry = function() {
    /**
     * @param {PIXI.Buffer[]} [buffers] - an array of buffers. optional.
     * @param {object} [attributes] - of the geometry, optional structure of the attributes layout
     */ function Geometry1(buffers, attributes) {
        if (buffers === void 0) buffers = [];
        if (attributes === void 0) attributes = {
        };
        this.buffers = buffers;
        this.indexBuffer = null;
        this.attributes = attributes;
        /**
         * A map of renderer IDs to webgl VAOs
         *
         * @protected
         * @type {object}
         */ this.glVertexArrayObjects = {
        };
        this.id = UID$1++;
        this.instanced = false;
        /**
         * Number of instances in this geometry, pass it to `GeometrySystem.draw()`
         * @member {number}
         * @default 1
         */ this.instanceCount = 1;
        this.disposeRunner = new _runner.Runner('disposeGeometry');
        /**
         * Count of existing (not destroyed) meshes that reference this geometry
         * @member {number}
         */ this.refCount = 0;
    }
    /**
    *
    * Adds an attribute to the geometry
    * Note: `stride` and `start` should be `undefined` if you dont know them, not 0!
    *
    * @param {String} id - the name of the attribute (matching up to a shader)
    * @param {PIXI.Buffer|number[]} buffer - the buffer that holds the data of the attribute . You can also provide an Array and a buffer will be created from it.
    * @param {Number} [size=0] - the size of the attribute. If you have 2 floats per vertex (eg position x and y) this would be 2
    * @param {Boolean} [normalized=false] - should the data be normalized.
    * @param {PIXI.TYPES} [type=PIXI.TYPES.FLOAT] - what type of number is the attribute. Check {PIXI.TYPES} to see the ones available
    * @param {Number} [stride] - How far apart (in floats) the start of each value is. (used for interleaving data)
    * @param {Number} [start] - How far into the array to start reading values (used for interleaving data)
    * @param {boolean} [instance=false] - Instancing flag
    *
    * @return {PIXI.Geometry} returns self, useful for chaining.
    */ Geometry1.prototype.addAttribute = function(id, buffer, size, normalized, type, stride, start, instance) {
        if (size === void 0) size = 0;
        if (normalized === void 0) normalized = false;
        if (instance === void 0) instance = false;
        if (!buffer) throw new Error('You must pass a buffer when creating an attribute');
        // check if this is a buffer!
        if (!(buffer instanceof Buffer)) {
            // its an array!
            if (buffer instanceof Array) buffer = new Float32Array(buffer);
            buffer = new Buffer(buffer);
        }
        var ids = id.split('|');
        if (ids.length > 1) {
            for(var i = 0; i < ids.length; i++)this.addAttribute(ids[i], buffer, size, normalized, type);
            return this;
        }
        var bufferIndex = this.buffers.indexOf(buffer);
        if (bufferIndex === -1) {
            this.buffers.push(buffer);
            bufferIndex = this.buffers.length - 1;
        }
        this.attributes[id] = new Attribute(bufferIndex, size, normalized, type, stride, start, instance);
        // assuming that if there is instanced data then this will be drawn with instancing!
        this.instanced = this.instanced || instance;
        return this;
    };
    /**
     * returns the requested attribute
     *
     * @param {String} id - the name of the attribute required
     * @return {PIXI.Attribute} the attribute requested.
     */ Geometry1.prototype.getAttribute = function(id) {
        return this.attributes[id];
    };
    /**
     * returns the requested buffer
     *
     * @param {String} id - the name of the buffer required
     * @return {PIXI.Buffer} the buffer requested.
     */ Geometry1.prototype.getBuffer = function(id) {
        return this.buffers[this.getAttribute(id).buffer];
    };
    /**
    *
    * Adds an index buffer to the geometry
    * The index buffer contains integers, three for each triangle in the geometry, which reference the various attribute buffers (position, colour, UV coordinates, other UV coordinates, normal, …). There is only ONE index buffer.
    *
    * @param {PIXI.Buffer|number[]} [buffer] - the buffer that holds the data of the index buffer. You can also provide an Array and a buffer will be created from it.
    * @return {PIXI.Geometry} returns self, useful for chaining.
    */ Geometry1.prototype.addIndex = function(buffer) {
        if (!(buffer instanceof Buffer)) {
            // its an array!
            if (buffer instanceof Array) buffer = new Uint16Array(buffer);
            buffer = new Buffer(buffer);
        }
        buffer.type = _constants.BUFFER_TYPE.ELEMENT_ARRAY_BUFFER;
        this.indexBuffer = buffer;
        if (this.buffers.indexOf(buffer) === -1) this.buffers.push(buffer);
        return this;
    };
    /**
     * returns the index buffer
     *
     * @return {PIXI.Buffer} the index buffer.
     */ Geometry1.prototype.getIndex = function() {
        return this.indexBuffer;
    };
    /**
     * this function modifies the structure so that all current attributes become interleaved into a single buffer
     * This can be useful if your model remains static as it offers a little performance boost
     *
     * @return {PIXI.Geometry} returns self, useful for chaining.
     */ Geometry1.prototype.interleave = function() {
        // a simple check to see if buffers are already interleaved..
        if (this.buffers.length === 1 || this.buffers.length === 2 && this.indexBuffer) return this;
        // assume already that no buffers are interleaved
        var arrays = [];
        var sizes = [];
        var interleavedBuffer = new Buffer();
        var i;
        for(i in this.attributes){
            var attribute = this.attributes[i];
            var buffer = this.buffers[attribute.buffer];
            arrays.push(buffer.data);
            sizes.push(attribute.size * byteSizeMap[attribute.type] / 4);
            attribute.buffer = 0;
        }
        interleavedBuffer.data = interleaveTypedArrays(arrays, sizes);
        for(i = 0; i < this.buffers.length; i++)if (this.buffers[i] !== this.indexBuffer) this.buffers[i].destroy();
        this.buffers = [
            interleavedBuffer
        ];
        if (this.indexBuffer) this.buffers.push(this.indexBuffer);
        return this;
    };
    Geometry1.prototype.getSize = function() {
        for(var i in this.attributes){
            var attribute = this.attributes[i];
            var buffer = this.buffers[attribute.buffer];
            return buffer.data.length / (attribute.stride / 4 || attribute.size);
        }
        return 0;
    };
    /**
     * disposes WebGL resources that are connected to this geometry
     */ Geometry1.prototype.dispose = function() {
        this.disposeRunner.emit(this, false);
    };
    /**
     * Destroys the geometry.
     */ Geometry1.prototype.destroy = function() {
        this.dispose();
        this.buffers = null;
        this.indexBuffer = null;
        this.attributes = null;
    };
    /**
     * returns a clone of the geometry
     *
     * @returns {PIXI.Geometry} a new clone of this geometry
     */ Geometry1.prototype.clone = function() {
        var geometry = new Geometry1();
        for(var i = 0; i < this.buffers.length; i++)geometry.buffers[i] = new Buffer(this.buffers[i].data.slice(0));
        for(var i in this.attributes){
            var attrib = this.attributes[i];
            geometry.attributes[i] = new Attribute(attrib.buffer, attrib.size, attrib.normalized, attrib.type, attrib.stride, attrib.start, attrib.instance);
        }
        if (this.indexBuffer) {
            geometry.indexBuffer = geometry.buffers[this.buffers.indexOf(this.indexBuffer)];
            geometry.indexBuffer.type = _constants.BUFFER_TYPE.ELEMENT_ARRAY_BUFFER;
        }
        return geometry;
    };
    /**
     * merges an array of geometries into a new single one
     * geometry attribute styles must match for this operation to work
     *
     * @param {PIXI.Geometry[]} geometries - array of geometries to merge
     * @returns {PIXI.Geometry} shiny new geometry!
     */ Geometry1.merge = function(geometries) {
        // todo add a geometry check!
        // also a size check.. cant be too big!]
        var geometryOut = new Geometry1();
        var arrays = [];
        var sizes = [];
        var offsets = [];
        var geometry;
        // pass one.. get sizes..
        for(var i = 0; i < geometries.length; i++){
            geometry = geometries[i];
            for(var j = 0; j < geometry.buffers.length; j++){
                sizes[j] = sizes[j] || 0;
                sizes[j] += geometry.buffers[j].data.length;
                offsets[j] = 0;
            }
        }
        // build the correct size arrays..
        for(var i = 0; i < geometry.buffers.length; i++){
            // TODO types!
            arrays[i] = new map$1[_utils.getBufferType(geometry.buffers[i].data)](sizes[i]);
            geometryOut.buffers[i] = new Buffer(arrays[i]);
        }
        // pass to set data..
        for(var i = 0; i < geometries.length; i++){
            geometry = geometries[i];
            for(var j = 0; j < geometry.buffers.length; j++){
                arrays[j].set(geometry.buffers[j].data, offsets[j]);
                offsets[j] += geometry.buffers[j].data.length;
            }
        }
        geometryOut.attributes = geometry.attributes;
        if (geometry.indexBuffer) {
            geometryOut.indexBuffer = geometryOut.buffers[geometry.buffers.indexOf(geometry.indexBuffer)];
            geometryOut.indexBuffer.type = _constants.BUFFER_TYPE.ELEMENT_ARRAY_BUFFER;
            var offset = 0;
            var stride = 0;
            var offset2 = 0;
            var bufferIndexToCount = 0;
            // get a buffer
            for(var i = 0; i < geometry.buffers.length; i++)if (geometry.buffers[i] !== geometry.indexBuffer) {
                bufferIndexToCount = i;
                break;
            }
            // figure out the stride of one buffer..
            for(var i in geometry.attributes){
                var attribute = geometry.attributes[i];
                if ((attribute.buffer | 0) === bufferIndexToCount) stride += attribute.size * byteSizeMap[attribute.type] / 4;
            }
            // time to off set all indexes..
            for(var i = 0; i < geometries.length; i++){
                var indexBufferData = geometries[i].indexBuffer.data;
                for(var j = 0; j < indexBufferData.length; j++)geometryOut.indexBuffer.data[j + offset2] += offset;
                offset += geometries[i].buffers[bufferIndexToCount].data.length / stride;
                offset2 += indexBufferData.length;
            }
        }
        return geometryOut;
    };
    return Geometry1;
}();
/**
 * Helper class to create a quad
 *
 * @class
 * @memberof PIXI
 */ var Quad1 = function(_super) {
    __extends(Quad2, _super);
    function Quad2() {
        var _this = _super.call(this) || this;
        _this.addAttribute('aVertexPosition', new Float32Array([
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            1
        ])).addIndex([
            0,
            1,
            3,
            2
        ]);
        return _this;
    }
    return Quad2;
}(Geometry);
/**
 * Helper class to create a quad with uvs like in v4
 *
 * @class
 * @memberof PIXI
 * @extends PIXI.Geometry
 */ var QuadUv1 = function(_super) {
    __extends(QuadUv2, _super);
    function QuadUv2() {
        var _this = _super.call(this) || this;
        /**
         * An array of vertices
         *
         * @member {Float32Array}
         */ _this.vertices = new Float32Array([
            -1,
            -1,
            1,
            -1,
            1,
            1,
            -1,
            1
        ]);
        /**
         * The Uvs of the quad
         *
         * @member {Float32Array}
         */ _this.uvs = new Float32Array([
            0,
            0,
            1,
            0,
            1,
            1,
            0,
            1
        ]);
        _this.vertexBuffer = new Buffer(_this.vertices);
        _this.uvBuffer = new Buffer(_this.uvs);
        _this.addAttribute('aVertexPosition', _this.vertexBuffer).addAttribute('aTextureCoord', _this.uvBuffer).addIndex([
            0,
            1,
            2,
            0,
            2,
            3
        ]);
        return _this;
    }
    /**
     * Maps two Rectangle to the quad.
     *
     * @param {PIXI.Rectangle} targetTextureFrame - the first rectangle
     * @param {PIXI.Rectangle} destinationFrame - the second rectangle
     * @return {PIXI.Quad} Returns itself.
     */ QuadUv2.prototype.map = function(targetTextureFrame, destinationFrame) {
        var x = 0; // destinationFrame.x / targetTextureFrame.width;
        var y = 0; // destinationFrame.y / targetTextureFrame.height;
        this.uvs[0] = x;
        this.uvs[1] = y;
        this.uvs[2] = x + destinationFrame.width / targetTextureFrame.width;
        this.uvs[3] = y;
        this.uvs[4] = x + destinationFrame.width / targetTextureFrame.width;
        this.uvs[5] = y + destinationFrame.height / targetTextureFrame.height;
        this.uvs[6] = x;
        this.uvs[7] = y + destinationFrame.height / targetTextureFrame.height;
        x = destinationFrame.x;
        y = destinationFrame.y;
        this.vertices[0] = x;
        this.vertices[1] = y;
        this.vertices[2] = x + destinationFrame.width;
        this.vertices[3] = y;
        this.vertices[4] = x + destinationFrame.width;
        this.vertices[5] = y + destinationFrame.height;
        this.vertices[6] = x;
        this.vertices[7] = y + destinationFrame.height;
        this.invalidate();
        return this;
    };
    /**
     * legacy upload method, just marks buffers dirty
     * @returns {PIXI.QuadUv} Returns itself.
     */ QuadUv2.prototype.invalidate = function() {
        this.vertexBuffer._updateID++;
        this.uvBuffer._updateID++;
        return this;
    };
    return QuadUv2;
}(Geometry);
var UID$2 = 0;
/**
 * Uniform group holds uniform map and some ID's for work
 *
 * `UniformGroup` has two modes:
 *
 * 1: Normal mode
 * Normal mode will upload the uniforms with individual function calls as required
 *
 * 2: Uniform buffer mode
 * This mode will treat the uniforms as a uniform buffer. You can pass in either a buffer that you manually handle, or
 * or a generic object that PixiJS will automatically map to a buffer for you.
 * For maximum benefits, make Ubo UniformGroups static, and only update them each frame.
 *
 * Rules of UBOs:
 * - UBOs only work with WebGL2, so make sure you have a fallback!
 * - Only floats are supported (including vec[2,3,4], mat[2,3,4])
 * - Samplers cannot be used in ubo's (a GPU limitation)
 * - You must ensure that the object you pass in exactly matches in the shader ubo structure.
 * Otherwise, weirdness will ensue!
 * - The name of the ubo object added to the group must match exactly the name of the ubo in the shader.
 *
 * ```
 * // ubo in shader:
 * uniform myCoolData { // declaring a ubo..
 * mat4 uCoolMatrix;
 * float uFloatyMcFloatFace
 *
 *
 * // a new uniform buffer object..
 * const myCoolData = new UniformBufferGroup({
 *   uCoolMatrix: new Matrix(),
 *   uFloatyMcFloatFace: 23,
 * }}
 *
 * // build a shader...
 * const shader = Shader.from(srcVert, srcFrag, {
 *   myCoolData // name matches the ubo name in the shader. will be processed accordingly.
 * })
 *
 *  ```
 *
 * @class
 * @memberof PIXI
 */ var UniformGroup = function() {
    /**
     * @param {object | Buffer} [uniforms] - Custom uniforms to use to augment the built-in ones. Or a pixi buffer
     * @param {boolean} [isStatic] - Uniforms wont be changed after creation
     * @param {boolean} [isUbo] - if true, will treat this uniform group as a uniform buffer object
     */ function UniformGroup1(uniforms, isStatic, isUbo) {
        /**
         * Its a group and not a single uniforms
         * @member {boolean}
         * @readonly
         * @default true
         */ this.group = true;
        // lets generate this when the shader ?
        this.syncUniforms = {
        };
        /**
         * dirty version
         * @protected
         * @member {number}
         */ this.dirtyId = 0;
        /**
         * unique id
         * @protected
         * @member {number}
         */ this.id = UID$2++;
        /**
         * Uniforms wont be changed after creation
         * @member {boolean}
         */ this.static = !!isStatic;
        /**
         * Flags whether this group is treated like a uniform buffer object.
         * @member {boolean}
         */ this.ubo = !!isUbo;
        if (uniforms instanceof Buffer) {
            this.buffer = uniforms;
            this.buffer.type = _constants.BUFFER_TYPE.UNIFORM_BUFFER;
            this.autoManage = false;
            this.ubo = true;
        } else {
            /**
             * uniform values
             * @member {object}
             * @readonly
             */ this.uniforms = uniforms;
            if (this.ubo) {
                this.buffer = new Buffer(new Float32Array(1));
                this.buffer.type = _constants.BUFFER_TYPE.UNIFORM_BUFFER;
                this.autoManage = true;
            }
        }
    }
    UniformGroup1.prototype.update = function() {
        this.dirtyId++;
        if (!this.autoManage && this.buffer) this.buffer.update();
    };
    UniformGroup1.prototype.add = function(name, uniforms, _static) {
        if (!this.ubo) this.uniforms[name] = new UniformGroup1(uniforms, _static);
        else // eslint-disable-next-line max-len
        throw new Error('[UniformGroup] uniform groups in ubo mode cannot be modified, or have uniform groups nested in them');
    };
    UniformGroup1.from = function(uniforms, _static, _ubo) {
        return new UniformGroup1(uniforms, _static, _ubo);
    };
    /**
     * A short hand function for creating a static UBO UniformGroup.
     *
     * @param uniforms - the ubo item
     * @param _static - should this be updated each time it is used? defaults to true here!
     */ UniformGroup1.uboFrom = function(uniforms, _static) {
        return new UniformGroup1(uniforms, _static !== null && _static !== void 0 ? _static : true, true);
    };
    return UniformGroup1;
}();
/**
 * System plugin to the renderer to manage filter states.
 *
 * @class
 * @private
 */ var FilterState = function() {
    function FilterState1() {
        this.renderTexture = null;
        /**
         * Target of the filters
         * We store for case when custom filter wants to know the element it was applied on
         * @member {PIXI.DisplayObject}
         * @private
         */ this.target = null;
        /**
         * Compatibility with PixiJS v4 filters
         * @member {boolean}
         * @default false
         * @private
         */ this.legacy = false;
        /**
         * Resolution of filters
         * @member {number}
         * @default 1
         * @private
         */ this.resolution = 1;
        /**
         * Number of samples
         * @member {PIXI.MSAA_QUALITY}
         * @default MSAA_QUALITY.NONE
         * @private
         */ this.multisample = _constants.MSAA_QUALITY.NONE;
        // next three fields are created only for root
        // re-assigned for everything else
        /**
         * Source frame
         * @member {PIXI.Rectangle}
         * @private
         */ this.sourceFrame = new _math.Rectangle();
        /**
         * Destination frame
         * @member {PIXI.Rectangle}
         * @private
         */ this.destinationFrame = new _math.Rectangle();
        /**
         * Original render-target source frame
         * @private
         */ this.bindingSourceFrame = new _math.Rectangle();
        /**
         * Original render-target destination frame
         * @private
         */ this.bindingDestinationFrame = new _math.Rectangle();
        /**
         * Collection of filters
         * @member {PIXI.Filter[]}
         * @private
         */ this.filters = [];
        /**
         * Projection system transform saved by link.
         * @member {PIXI.Matrix}
         * @private
         */ this.transform = null;
    }
    /**
     * clears the state
     * @private
     */ FilterState1.prototype.clear = function() {
        this.target = null;
        this.filters = null;
        this.renderTexture = null;
    };
    return FilterState1;
}();
var tempPoints = [
    new _math.Point(),
    new _math.Point(),
    new _math.Point(),
    new _math.Point()
];
var tempMatrix = new _math.Matrix();
/**
 * System plugin to the renderer to manage filters.
 *
 * ## Pipeline
 *
 * The FilterSystem executes the filtering pipeline by rendering the display-object into a texture, applying its
 * [filters]{@link PIXI.Filter} in series, and the last filter outputs into the final render-target.
 *
 * The filter-frame is the rectangle in world space being filtered, and those contents are mapped into
 * `(0, 0, filterFrame.width, filterFrame.height)` into the filter render-texture. The filter-frame is also called
 * the source-frame, as it is used to bind the filter render-textures. The last filter outputs to the `filterFrame`
 * in the final render-target.
 *
 * ## Usage
 *
 * {@link PIXI.Container#renderAdvanced} is an example of how to use the filter system. It is a 3 step process:
 *
 * * **push**: Use {@link PIXI.FilterSystem#push} to push the set of filters to be applied on a filter-target.
 * * **render**: Render the contents to be filtered using the renderer. The filter-system will only capture the contents
 *      inside the bounds of the filter-target. NOTE: Using {@link PIXI.Renderer#render} is
 *      illegal during an existing render cycle, and it may reset the filter system.
 * * **pop**: Use {@link PIXI.FilterSystem#pop} to pop & execute the filters you initially pushed. It will apply them
 *      serially and output to the bounds of the filter-target.
 *
 * @class
 * @memberof PIXI
 * @extends PIXI.System
 */ var FilterSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function FilterSystem1(renderer) {
        this.renderer = renderer;
        /**
         * List of filters for the FilterSystem
         * @member {Object[]}
         * @readonly
         */ this.defaultFilterStack = [
            {
            }
        ];
        /**
         * stores a bunch of PO2 textures used for filtering
         * @member {Object}
         */ this.texturePool = new RenderTexturePool();
        this.texturePool.setScreenSize(renderer.view);
        /**
         * a pool for storing filter states, save us creating new ones each tick
         * @member {Object[]}
         */ this.statePool = [];
        /**
         * A very simple geometry used when drawing a filter effect to the screen
         * @member {PIXI.Quad}
         */ this.quad = new Quad1();
        /**
         * Quad UVs
         * @member {PIXI.QuadUv}
         */ this.quadUv = new QuadUv1();
        /**
         * Temporary rect for maths
         * @type {PIXI.Rectangle}
         */ this.tempRect = new _math.Rectangle();
        /**
         * Active state
         * @member {object}
         */ this.activeState = {
        };
        /**
         * This uniform group is attached to filter uniforms when used
         * @member {PIXI.UniformGroup}
         * @property {PIXI.Rectangle} outputFrame
         * @property {Float32Array} inputSize
         * @property {Float32Array} inputPixel
         * @property {Float32Array} inputClamp
         * @property {Number} resolution
         * @property {Float32Array} filterArea
         * @property {Float32Array} filterClamp
         */ this.globalUniforms = new UniformGroup({
            outputFrame: new _math.Rectangle(),
            inputSize: new Float32Array(4),
            inputPixel: new Float32Array(4),
            inputClamp: new Float32Array(4),
            resolution: 1,
            // legacy variables
            filterArea: new Float32Array(4),
            filterClamp: new Float32Array(4)
        }, true);
        /**
         * Whether to clear output renderTexture in AUTO/BLIT mode. See {@link PIXI.CLEAR_MODES}
         * @member {boolean}
         */ this.forceClear = false;
        /**
         * Old padding behavior is to use the max amount instead of sum padding.
         * Use this flag if you need the old behavior.
         * @member {boolean}
         * @default false
         */ this.useMaxPadding = false;
    }
    /**
     * Pushes a set of filters to be applied later to the system. This will redirect further rendering into an
     * input render-texture for the rest of the filtering pipeline.
     *
     * @param {PIXI.DisplayObject} target - The target of the filter to render.
     * @param {PIXI.Filter[]} filters - The filters to apply.
     */ FilterSystem1.prototype.push = function(target, filters) {
        var renderer = this.renderer;
        var filterStack = this.defaultFilterStack;
        var state = this.statePool.pop() || new FilterState();
        var renderTextureSystem = this.renderer.renderTexture;
        var resolution = filters[0].resolution;
        var multisample = filters[0].multisample;
        var padding = filters[0].padding;
        var autoFit = filters[0].autoFit;
        var legacy = filters[0].legacy;
        for(var i = 1; i < filters.length; i++){
            var filter = filters[i];
            // let's use the lowest resolution
            resolution = Math.min(resolution, filter.resolution);
            // let's use the lowest number of samples
            multisample = Math.min(multisample, filter.multisample);
            // figure out the padding required for filters
            padding = this.useMaxPadding ? Math.max(padding, filter.padding) : padding + filter.padding;
            // only auto fit if all filters are autofit
            autoFit = autoFit && filter.autoFit;
            legacy = legacy || filter.legacy;
        }
        if (filterStack.length === 1) this.defaultFilterStack[0].renderTexture = renderTextureSystem.current;
        filterStack.push(state);
        state.resolution = resolution;
        state.multisample = multisample;
        state.legacy = legacy;
        state.target = target;
        state.sourceFrame.copyFrom(target.filterArea || target.getBounds(true));
        state.sourceFrame.pad(padding);
        if (autoFit) {
            var sourceFrameProjected = this.tempRect.copyFrom(renderTextureSystem.sourceFrame);
            // Project source frame into world space (if projection is applied)
            if (renderer.projection.transform) this.transformAABB(tempMatrix.copyFrom(renderer.projection.transform).invert(), sourceFrameProjected);
            state.sourceFrame.fit(sourceFrameProjected);
        }
        // Round sourceFrame in screen space based on render-texture.
        this.roundFrame(state.sourceFrame, renderTextureSystem.current ? renderTextureSystem.current.resolution : renderer.resolution, renderTextureSystem.sourceFrame, renderTextureSystem.destinationFrame, renderer.projection.transform);
        state.renderTexture = this.getOptimalFilterTexture(state.sourceFrame.width, state.sourceFrame.height, resolution, multisample);
        state.filters = filters;
        state.destinationFrame.width = state.renderTexture.width;
        state.destinationFrame.height = state.renderTexture.height;
        var destinationFrame = this.tempRect;
        destinationFrame.x = 0;
        destinationFrame.y = 0;
        destinationFrame.width = state.sourceFrame.width;
        destinationFrame.height = state.sourceFrame.height;
        state.renderTexture.filterFrame = state.sourceFrame;
        state.bindingSourceFrame.copyFrom(renderTextureSystem.sourceFrame);
        state.bindingDestinationFrame.copyFrom(renderTextureSystem.destinationFrame);
        state.transform = renderer.projection.transform;
        renderer.projection.transform = null;
        renderTextureSystem.bind(state.renderTexture, state.sourceFrame, destinationFrame);
        renderer.framebuffer.clear(0, 0, 0, 0);
    };
    /**
     * Pops off the filter and applies it.
     */ FilterSystem1.prototype.pop = function() {
        var filterStack = this.defaultFilterStack;
        var state = filterStack.pop();
        var filters = state.filters;
        this.activeState = state;
        var globalUniforms = this.globalUniforms.uniforms;
        globalUniforms.outputFrame = state.sourceFrame;
        globalUniforms.resolution = state.resolution;
        var inputSize = globalUniforms.inputSize;
        var inputPixel = globalUniforms.inputPixel;
        var inputClamp = globalUniforms.inputClamp;
        inputSize[0] = state.destinationFrame.width;
        inputSize[1] = state.destinationFrame.height;
        inputSize[2] = 1 / inputSize[0];
        inputSize[3] = 1 / inputSize[1];
        inputPixel[0] = Math.round(inputSize[0] * state.resolution);
        inputPixel[1] = Math.round(inputSize[1] * state.resolution);
        inputPixel[2] = 1 / inputPixel[0];
        inputPixel[3] = 1 / inputPixel[1];
        inputClamp[0] = 0.5 * inputPixel[2];
        inputClamp[1] = 0.5 * inputPixel[3];
        inputClamp[2] = state.sourceFrame.width * inputSize[2] - 0.5 * inputPixel[2];
        inputClamp[3] = state.sourceFrame.height * inputSize[3] - 0.5 * inputPixel[3];
        // only update the rect if its legacy..
        if (state.legacy) {
            var filterArea = globalUniforms.filterArea;
            filterArea[0] = state.destinationFrame.width;
            filterArea[1] = state.destinationFrame.height;
            filterArea[2] = state.sourceFrame.x;
            filterArea[3] = state.sourceFrame.y;
            globalUniforms.filterClamp = globalUniforms.inputClamp;
        }
        this.globalUniforms.update();
        var lastState = filterStack[filterStack.length - 1];
        this.renderer.framebuffer.blit();
        if (filters.length === 1) {
            filters[0].apply(this, state.renderTexture, lastState.renderTexture, _constants.CLEAR_MODES.BLEND, state);
            this.returnFilterTexture(state.renderTexture);
        } else {
            var flip = state.renderTexture;
            var flop = this.getOptimalFilterTexture(flip.width, flip.height, state.resolution);
            flop.filterFrame = flip.filterFrame;
            var i = 0;
            for(i = 0; i < filters.length - 1; ++i){
                if (i === 1 && state.multisample > 1) {
                    flop = this.getOptimalFilterTexture(flip.width, flip.height, state.resolution);
                    flop.filterFrame = flip.filterFrame;
                }
                filters[i].apply(this, flip, flop, _constants.CLEAR_MODES.CLEAR, state);
                var t = flip;
                flip = flop;
                flop = t;
            }
            filters[i].apply(this, flip, lastState.renderTexture, _constants.CLEAR_MODES.BLEND, state);
            if (i > 1 && state.multisample > 1) this.returnFilterTexture(state.renderTexture);
            this.returnFilterTexture(flip);
            this.returnFilterTexture(flop);
        }
        // lastState.renderTexture is blitted when lastState is popped
        state.clear();
        this.statePool.push(state);
    };
    /**
     * Binds a renderTexture with corresponding `filterFrame`, clears it if mode corresponds.
     *
     * @param {PIXI.RenderTexture} filterTexture - renderTexture to bind, should belong to filter pool or filter stack
     * @param {PIXI.CLEAR_MODES} [clearMode] - clearMode, by default its CLEAR/YES. See {@link PIXI.CLEAR_MODES}
     */ FilterSystem1.prototype.bindAndClear = function(filterTexture, clearMode) {
        if (clearMode === void 0) clearMode = _constants.CLEAR_MODES.CLEAR;
        var _a = this.renderer, renderTextureSystem = _a.renderTexture, stateSystem = _a.state;
        if (filterTexture === this.defaultFilterStack[this.defaultFilterStack.length - 1].renderTexture) // Restore projection transform if rendering into the output render-target.
        this.renderer.projection.transform = this.activeState.transform;
        else // Prevent projection within filtering pipeline.
        this.renderer.projection.transform = null;
        if (filterTexture && filterTexture.filterFrame) {
            var destinationFrame = this.tempRect;
            destinationFrame.x = 0;
            destinationFrame.y = 0;
            destinationFrame.width = filterTexture.filterFrame.width;
            destinationFrame.height = filterTexture.filterFrame.height;
            renderTextureSystem.bind(filterTexture, filterTexture.filterFrame, destinationFrame);
        } else if (filterTexture !== this.defaultFilterStack[this.defaultFilterStack.length - 1].renderTexture) renderTextureSystem.bind(filterTexture);
        else // Restore binding for output render-target.
        this.renderer.renderTexture.bind(filterTexture, this.activeState.bindingSourceFrame, this.activeState.bindingDestinationFrame);
        // Clear the texture in BLIT mode if blending is disabled or the forceClear flag is set. The blending
        // is stored in the 0th bit of the state.
        var autoClear = stateSystem.stateId & 1 || this.forceClear;
        if (clearMode === _constants.CLEAR_MODES.CLEAR || clearMode === _constants.CLEAR_MODES.BLIT && autoClear) // Use framebuffer.clear because we want to clear the whole filter texture, not just the filtering
        // area over which the shaders are run. This is because filters may sampling outside of it (e.g. blur)
        // instead of clamping their arithmetic.
        this.renderer.framebuffer.clear(0, 0, 0, 0);
    };
    /**
     * Draws a filter.
     *
     * @param {PIXI.Filter} filter - The filter to draw.
     * @param {PIXI.RenderTexture} input - The input render target.
     * @param {PIXI.RenderTexture} output - The target to output to.
     * @param {PIXI.CLEAR_MODES} [clearMode] - Should the output be cleared before rendering to it
     */ FilterSystem1.prototype.applyFilter = function(filter, input, output, clearMode) {
        var renderer = this.renderer;
        // Set state before binding, so bindAndClear gets the blend mode.
        renderer.state.set(filter.state);
        this.bindAndClear(output, clearMode);
        // set the uniforms..
        filter.uniforms.uSampler = input;
        filter.uniforms.filterGlobals = this.globalUniforms;
        // TODO make it so that the order of this does not matter..
        // because it does at the moment cos of global uniforms.
        // they need to get resynced
        renderer.shader.bind(filter);
        // check to see if the filter is a legacy one..
        filter.legacy = !!filter.program.attributeData.aTextureCoord;
        if (filter.legacy) {
            this.quadUv.map(input._frame, input.filterFrame);
            renderer.geometry.bind(this.quadUv);
            renderer.geometry.draw(_constants.DRAW_MODES.TRIANGLES);
        } else {
            renderer.geometry.bind(this.quad);
            renderer.geometry.draw(_constants.DRAW_MODES.TRIANGLE_STRIP);
        }
    };
    /**
     * Multiply _input normalized coordinates_ to this matrix to get _sprite texture normalized coordinates_.
     *
     * Use `outputMatrix * vTextureCoord` in the shader.
     *
     * @param {PIXI.Matrix} outputMatrix - The matrix to output to.
     * @param {PIXI.Sprite} sprite - The sprite to map to.
     * @return {PIXI.Matrix} The mapped matrix.
     */ FilterSystem1.prototype.calculateSpriteMatrix = function(outputMatrix, sprite) {
        var _a = this.activeState, sourceFrame = _a.sourceFrame, destinationFrame = _a.destinationFrame;
        var orig = sprite._texture.orig;
        var mappedMatrix = outputMatrix.set(destinationFrame.width, 0, 0, destinationFrame.height, sourceFrame.x, sourceFrame.y);
        var worldTransform = sprite.worldTransform.copyTo(_math.Matrix.TEMP_MATRIX);
        worldTransform.invert();
        mappedMatrix.prepend(worldTransform);
        mappedMatrix.scale(1 / orig.width, 1 / orig.height);
        mappedMatrix.translate(sprite.anchor.x, sprite.anchor.y);
        return mappedMatrix;
    };
    /**
     * Destroys this Filter System.
     */ FilterSystem1.prototype.destroy = function() {
        this.renderer = null;
        // Those textures has to be destroyed by RenderTextureSystem or FramebufferSystem
        this.texturePool.clear(false);
    };
    /**
     * Gets a Power-of-Two render texture or fullScreen texture
     *
     * @protected
     * @param {number} minWidth - The minimum width of the render texture in real pixels.
     * @param {number} minHeight - The minimum height of the render texture in real pixels.
     * @param {number} [resolution=1] - The resolution of the render texture.
     * @param {PIXI.MSAA_QUALITY} [multisample=PIXI.MSAA_QUALITY.NONE] - Number of samples of the render texture.
     * @return {PIXI.RenderTexture} The new render texture.
     */ FilterSystem1.prototype.getOptimalFilterTexture = function(minWidth, minHeight, resolution, multisample) {
        if (resolution === void 0) resolution = 1;
        if (multisample === void 0) multisample = _constants.MSAA_QUALITY.NONE;
        return this.texturePool.getOptimalTexture(minWidth, minHeight, resolution, multisample);
    };
    /**
     * Gets extra render texture to use inside current filter
     * To be compliant with older filters, you can use params in any order
     *
     * @param {PIXI.RenderTexture} [input] - renderTexture from which size and resolution will be copied
     * @param {number} [resolution] - override resolution of the renderTexture
     * @param {PIXI.MSAA_QUALITY} [multisample=PIXI.MSAA_QUALITY.NONE] - number of samples of the renderTexture
     * @returns {PIXI.RenderTexture}
     */ FilterSystem1.prototype.getFilterTexture = function(input, resolution, multisample) {
        if (typeof input === 'number') {
            var swap = input;
            input = resolution;
            resolution = swap;
        }
        input = input || this.activeState.renderTexture;
        var filterTexture = this.texturePool.getOptimalTexture(input.width, input.height, resolution || input.resolution, multisample || _constants.MSAA_QUALITY.NONE);
        filterTexture.filterFrame = input.filterFrame;
        return filterTexture;
    };
    /**
     * Frees a render texture back into the pool.
     *
     * @param {PIXI.RenderTexture} renderTexture - The renderTarget to free
     */ FilterSystem1.prototype.returnFilterTexture = function(renderTexture) {
        this.texturePool.returnTexture(renderTexture);
    };
    /**
     * Empties the texture pool.
     */ FilterSystem1.prototype.emptyPool = function() {
        this.texturePool.clear(true);
    };
    /**
     * calls `texturePool.resize()`, affects fullScreen renderTextures
     */ FilterSystem1.prototype.resize = function() {
        this.texturePool.setScreenSize(this.renderer.view);
    };
    /**
     * @param {PIXI.Matrix} matrix - first param
     * @param {PIXI.Rectangle} rect - second param
     */ FilterSystem1.prototype.transformAABB = function(matrix, rect) {
        var lt = tempPoints[0];
        var lb = tempPoints[1];
        var rt = tempPoints[2];
        var rb = tempPoints[3];
        lt.set(rect.left, rect.top);
        lb.set(rect.left, rect.bottom);
        rt.set(rect.right, rect.top);
        rb.set(rect.right, rect.bottom);
        matrix.apply(lt, lt);
        matrix.apply(lb, lb);
        matrix.apply(rt, rt);
        matrix.apply(rb, rb);
        var x0 = Math.min(lt.x, lb.x, rt.x, rb.x);
        var y0 = Math.min(lt.y, lb.y, rt.y, rb.y);
        var x1 = Math.max(lt.x, lb.x, rt.x, rb.x);
        var y1 = Math.max(lt.y, lb.y, rt.y, rb.y);
        rect.x = x0;
        rect.y = y0;
        rect.width = x1 - x0;
        rect.height = y1 - y0;
    };
    FilterSystem1.prototype.roundFrame = function(frame, resolution, bindingSourceFrame, bindingDestinationFrame, transform) {
        if (transform) {
            var a = transform.a, b = transform.b, c = transform.c, d = transform.d;
            // Skip if skew/rotation present in matrix, except for multiple of 90° rotation. If rotation
            // is a multiple of 90°, then either pair of (b,c) or (a,d) will be (0,0).
            if ((Math.abs(b) > 0.0001 || Math.abs(c) > 0.0001) && (Math.abs(a) > 0.0001 || Math.abs(d) > 0.0001)) return;
        }
        transform = transform ? tempMatrix.copyFrom(transform) : tempMatrix.identity();
        // Get forward transform from world space to screen space
        transform.translate(-bindingSourceFrame.x, -bindingSourceFrame.y).scale(bindingDestinationFrame.width / bindingSourceFrame.width, bindingDestinationFrame.height / bindingSourceFrame.height).translate(bindingDestinationFrame.x, bindingDestinationFrame.y);
        // Convert frame to screen space
        this.transformAABB(transform, frame);
        // Round frame in screen space
        frame.ceil(resolution);
        // Project back into world space.
        this.transformAABB(transform.invert(), frame);
    };
    return FilterSystem1;
}();
/**
 * Base for a common object renderer that can be used as a
 * system renderer plugin.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var ObjectRenderer = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this manager works for.
     */ function ObjectRenderer1(renderer) {
        /**
         * The renderer this manager works for.
         *
         * @member {PIXI.Renderer}
         */ this.renderer = renderer;
    }
    /**
     * Stub method that should be used to empty the current
     * batch by rendering objects now.
     */ ObjectRenderer1.prototype.flush = function() {
    // flush!
    };
    /**
     * Generic destruction method that frees all resources. This
     * should be called by subclasses.
     */ ObjectRenderer1.prototype.destroy = function() {
        this.renderer = null;
    };
    /**
     * Stub method that initializes any state required before
     * rendering starts. It is different from the `prerender`
     * signal, which occurs every frame, in that it is called
     * whenever an object requests _this_ renderer specifically.
     */ ObjectRenderer1.prototype.start = function() {
    // set the shader..
    };
    /**
     * Stops the renderer. It should free up any state and
     * become dormant.
     */ ObjectRenderer1.prototype.stop = function() {
        this.flush();
    };
    /**
     * Keeps the object to render. It doesn't have to be
     * rendered immediately.
     *
     * @param {PIXI.DisplayObject} object - The object to render.
     */ ObjectRenderer1.prototype.render = function(_object) {
    // render the object
    };
    return ObjectRenderer1;
}();
/**
 * System plugin to the renderer to manage batching.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var BatchSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function BatchSystem1(renderer) {
        this.renderer = renderer;
        /**
         * An empty renderer.
         *
         * @member {PIXI.ObjectRenderer}
         */ this.emptyRenderer = new ObjectRenderer(renderer);
        /**
         * The currently active ObjectRenderer.
         *
         * @member {PIXI.ObjectRenderer}
         */ this.currentRenderer = this.emptyRenderer;
    }
    /**
     * Changes the current renderer to the one given in parameter
     *
     * @param {PIXI.ObjectRenderer} objectRenderer - The object renderer to use.
     */ BatchSystem1.prototype.setObjectRenderer = function(objectRenderer) {
        if (this.currentRenderer === objectRenderer) return;
        this.currentRenderer.stop();
        this.currentRenderer = objectRenderer;
        this.currentRenderer.start();
    };
    /**
     * This should be called if you wish to do some custom rendering
     * It will basically render anything that may be batched up such as sprites
     */ BatchSystem1.prototype.flush = function() {
        this.setObjectRenderer(this.emptyRenderer);
    };
    /**
     * Reset the system to an empty renderer
     */ BatchSystem1.prototype.reset = function() {
        this.setObjectRenderer(this.emptyRenderer);
    };
    /**
     * Handy function for batch renderers: copies bound textures in first maxTextures locations to array
     * sets actual _batchLocation for them
     *
     * @param {PIXI.BaseTexture[]} arr - arr copy destination
     * @param {number} maxTextures - number of copied elements
     */ BatchSystem1.prototype.copyBoundTextures = function(arr, maxTextures) {
        var boundTextures = this.renderer.texture.boundTextures;
        for(var i = maxTextures - 1; i >= 0; --i){
            arr[i] = boundTextures[i] || null;
            if (arr[i]) arr[i]._batchLocation = i;
        }
    };
    /**
     * Assigns batch locations to textures in array based on boundTextures state.
     * All textures in texArray should have `_batchEnabled = _batchId`,
     * and their count should be less than `maxTextures`.
     *
     * @param {PIXI.BatchTextureArray} texArray - textures to bound
     * @param {PIXI.BaseTexture[]} boundTextures - current state of bound textures
     * @param {number} batchId - marker for _batchEnabled param of textures in texArray
     * @param {number} maxTextures - number of texture locations to manipulate
     */ BatchSystem1.prototype.boundArray = function(texArray, boundTextures, batchId, maxTextures) {
        var elements = texArray.elements, ids = texArray.ids, count = texArray.count;
        var j = 0;
        for(var i = 0; i < count; i++){
            var tex = elements[i];
            var loc = tex._batchLocation;
            if (loc >= 0 && loc < maxTextures && boundTextures[loc] === tex) {
                ids[i] = loc;
                continue;
            }
            while(j < maxTextures){
                var bound = boundTextures[j];
                if (bound && bound._batchEnabled === batchId && bound._batchLocation === j) {
                    j++;
                    continue;
                }
                ids[i] = j;
                tex._batchLocation = j;
                boundTextures[j] = tex;
                break;
            }
        }
    };
    /**
     * @ignore
     */ BatchSystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    return BatchSystem1;
}();
var CONTEXT_UID_COUNTER = 0;
/**
 * System plugin to the renderer to manage the context.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var ContextSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function ContextSystem1(renderer) {
        this.renderer = renderer;
        /**
         * Either 1 or 2 to reflect the WebGL version being used
         * @member {number}
         * @readonly
         */ this.webGLVersion = 1;
        /**
         * Extensions being used
         * @member {object}
         * @readonly
         * @property {WEBGL_draw_buffers} drawBuffers - WebGL v1 extension
         * @property {WEBGL_depth_texture} depthTexture - WebGL v1 extension
         * @property {OES_texture_float} floatTexture - WebGL v1 extension
         * @property {WEBGL_lose_context} loseContext - WebGL v1 extension
         * @property {OES_vertex_array_object} vertexArrayObject - WebGL v1 extension
         * @property {EXT_texture_filter_anisotropic} anisotropicFiltering - WebGL v1 and v2 extension
         */ this.extensions = {
        };
        /**
         * Features supported by current context
         * @member {object}
         * @private
         * @readonly
         * @property {boolean} uint32Indices - Supports of 32-bit indices buffer
         */ this.supports = {
            uint32Indices: false
        };
        // Bind functions
        this.handleContextLost = this.handleContextLost.bind(this);
        this.handleContextRestored = this.handleContextRestored.bind(this);
        renderer.view.addEventListener('webglcontextlost', this.handleContextLost, false);
        renderer.view.addEventListener('webglcontextrestored', this.handleContextRestored, false);
    }
    Object.defineProperty(ContextSystem1.prototype, "isLost", {
        /**
         * `true` if the context is lost
         * @member {boolean}
         * @readonly
         */ get: function() {
            return !this.gl || this.gl.isContextLost();
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Handle the context change event
     * @param {WebGLRenderingContext} gl - new webgl context
     */ ContextSystem1.prototype.contextChange = function(gl) {
        this.gl = gl;
        this.renderer.gl = gl;
        this.renderer.CONTEXT_UID = CONTEXT_UID_COUNTER++;
        // restore a context if it was previously lost
        if (gl.isContextLost() && gl.getExtension('WEBGL_lose_context')) gl.getExtension('WEBGL_lose_context').restoreContext();
    };
    /**
     * Initialize the context
     *
     * @protected
     * @param {WebGLRenderingContext} gl - WebGL context
     */ ContextSystem1.prototype.initFromContext = function(gl) {
        this.gl = gl;
        this.validateContext(gl);
        this.renderer.gl = gl;
        this.renderer.CONTEXT_UID = CONTEXT_UID_COUNTER++;
        this.renderer.runners.contextChange.emit(gl);
    };
    /**
     * Initialize from context options
     *
     * @protected
     * @see https://developer.mozilla.org/en-US/docs/Web/API/HTMLCanvasElement/getContext
     * @param {object} options - context attributes
     */ ContextSystem1.prototype.initFromOptions = function(options) {
        var gl = this.createContext(this.renderer.view, options);
        this.initFromContext(gl);
    };
    /**
     * Helper class to create a WebGL Context
     *
     * @param {HTMLCanvasElement} canvas - the canvas element that we will get the context from
     * @param {object} options - An options object that gets passed in to the canvas element containing the
     *    context attributes
     * @see https://developer.mozilla.org/en/docs/Web/API/HTMLCanvasElement/getContext
     * @return {WebGLRenderingContext} the WebGL context
     */ ContextSystem1.prototype.createContext = function(canvas, options) {
        var gl;
        if (_settings.settings.PREFER_ENV >= _constants.ENV.WEBGL2) gl = canvas.getContext('webgl2', options);
        if (gl) this.webGLVersion = 2;
        else {
            this.webGLVersion = 1;
            gl = canvas.getContext('webgl', options) || canvas.getContext('experimental-webgl', options);
            if (!gl) // fail, not able to get a context
            throw new Error('This browser does not support WebGL. Try using the canvas renderer');
        }
        this.gl = gl;
        this.getExtensions();
        return this.gl;
    };
    /**
     * Auto-populate the extensions
     *
     * @protected
     */ ContextSystem1.prototype.getExtensions = function() {
        // time to set up default extensions that Pixi uses.
        var gl = this.gl;
        var common = {
            anisotropicFiltering: gl.getExtension('EXT_texture_filter_anisotropic'),
            floatTextureLinear: gl.getExtension('OES_texture_float_linear'),
            s3tc: gl.getExtension('WEBGL_compressed_texture_s3tc'),
            s3tc_sRGB: gl.getExtension('WEBGL_compressed_texture_s3tc_srgb'),
            etc: gl.getExtension('WEBGL_compressed_texture_etc'),
            etc1: gl.getExtension('WEBGL_compressed_texture_etc1'),
            pvrtc: gl.getExtension('WEBGL_compressed_texture_pvrtc') || gl.getExtension('WEBKIT_WEBGL_compressed_texture_pvrtc'),
            atc: gl.getExtension('WEBGL_compressed_texture_atc'),
            astc: gl.getExtension('WEBGL_compressed_texture_astc')
        };
        if (this.webGLVersion === 1) Object.assign(this.extensions, common, {
            drawBuffers: gl.getExtension('WEBGL_draw_buffers'),
            depthTexture: gl.getExtension('WEBGL_depth_texture'),
            loseContext: gl.getExtension('WEBGL_lose_context'),
            vertexArrayObject: gl.getExtension('OES_vertex_array_object') || gl.getExtension('MOZ_OES_vertex_array_object') || gl.getExtension('WEBKIT_OES_vertex_array_object'),
            uint32ElementIndex: gl.getExtension('OES_element_index_uint'),
            // Floats and half-floats
            floatTexture: gl.getExtension('OES_texture_float'),
            floatTextureLinear: gl.getExtension('OES_texture_float_linear'),
            textureHalfFloat: gl.getExtension('OES_texture_half_float'),
            textureHalfFloatLinear: gl.getExtension('OES_texture_half_float_linear')
        });
        else if (this.webGLVersion === 2) Object.assign(this.extensions, common, {
            // Floats and half-floats
            colorBufferFloat: gl.getExtension('EXT_color_buffer_float')
        });
    };
    /**
     * Handles a lost webgl context
     *
     * @protected
     * @param {WebGLContextEvent} event - The context lost event.
     */ ContextSystem1.prototype.handleContextLost = function(event) {
        event.preventDefault();
    };
    /**
     * Handles a restored webgl context
     *
     * @protected
     */ ContextSystem1.prototype.handleContextRestored = function() {
        this.renderer.runners.contextChange.emit(this.gl);
    };
    ContextSystem1.prototype.destroy = function() {
        var view = this.renderer.view;
        this.renderer = null;
        // remove listeners
        view.removeEventListener('webglcontextlost', this.handleContextLost);
        view.removeEventListener('webglcontextrestored', this.handleContextRestored);
        this.gl.useProgram(null);
        if (this.extensions.loseContext) this.extensions.loseContext.loseContext();
    };
    /**
     * Handle the post-render runner event
     *
     * @protected
     */ ContextSystem1.prototype.postrender = function() {
        if (this.renderer.renderingToScreen) this.gl.flush();
    };
    /**
     * Validate context
     *
     * @protected
     * @param {WebGLRenderingContext} gl - Render context
     */ ContextSystem1.prototype.validateContext = function(gl) {
        var attributes = gl.getContextAttributes();
        var isWebGl2 = 'WebGL2RenderingContext' in self && gl instanceof self.WebGL2RenderingContext;
        if (isWebGl2) this.webGLVersion = 2;
        // this is going to be fairly simple for now.. but at least we have room to grow!
        if (!attributes.stencil) /* eslint-disable max-len, no-console */ console.warn('Provided WebGL context does not have a stencil buffer, masks may not render correctly');
        var hasuint32 = isWebGl2 || !!gl.getExtension('OES_element_index_uint');
        this.supports.uint32Indices = hasuint32;
        if (!hasuint32) /* eslint-disable max-len, no-console */ console.warn('Provided WebGL context does not support 32 index buffer, complex graphics may not render correctly');
    };
    return ContextSystem1;
}();
/**
 * Internal framebuffer for WebGL context
 * @class
 * @memberof PIXI
 */ var GLFramebuffer = function() {
    function GLFramebuffer1(framebuffer) {
        /**
         * The WebGL framebuffer
         * @member {WebGLFramebuffer}
         */ this.framebuffer = framebuffer;
        /**
         * stencil+depth , usually costs 32bits per pixel
         * @member {WebGLRenderbuffer}
         */ this.stencil = null;
        /**
         * latest known version of framebuffer
         * @member {number}
         * @protected
         */ this.dirtyId = -1;
        /**
         * latest known version of framebuffer format
         * @member {number}
         * @protected
         */ this.dirtyFormat = -1;
        /**
         * latest known version of framebuffer size
         * @member {number}
         * @protected
         */ this.dirtySize = -1;
        /**
         * Detected AA samples number
         * @member {PIXI.MSAA_QUALITY}
         */ this.multisample = _constants.MSAA_QUALITY.NONE;
        /**
         * In case MSAA, we use this Renderbuffer instead of colorTextures[0] when we write info
         * @member {WebGLRenderbuffer}
         */ this.msaaBuffer = null;
        /**
         * In case we use MSAA, this is actual framebuffer that has colorTextures[0]
         * The contents of that framebuffer are read when we use that renderTexture in sprites
         * @member {PIXI.Framebuffer}
         */ this.blitFramebuffer = null;
        /**
         * store the current mipmap of the textures the framebuffer will write too.
         */ this.mipLevel = 0;
    }
    return GLFramebuffer1;
}();
var tempRectangle = new _math.Rectangle();
/**
 * System plugin to the renderer to manage framebuffers.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var FramebufferSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function FramebufferSystem1(renderer) {
        this.renderer = renderer;
        /**
         * A list of managed framebuffers
         * @member {PIXI.Framebuffer[]}
         * @readonly
         */ this.managedFramebuffers = [];
        /**
         * Framebuffer value that shows that we don't know what is bound
         * @member {Framebuffer}
         * @readonly
         */ this.unknownFramebuffer = new Framebuffer(10, 10);
        this.msaaSamples = null;
    }
    /**
     * Sets up the renderer context and necessary buffers.
     */ FramebufferSystem1.prototype.contextChange = function() {
        var gl = this.gl = this.renderer.gl;
        this.CONTEXT_UID = this.renderer.CONTEXT_UID;
        this.current = this.unknownFramebuffer;
        this.viewport = new _math.Rectangle();
        this.hasMRT = true;
        this.writeDepthTexture = true;
        this.disposeAll(true);
        // webgl2
        if (this.renderer.context.webGLVersion === 1) {
            // webgl 1!
            var nativeDrawBuffersExtension_1 = this.renderer.context.extensions.drawBuffers;
            var nativeDepthTextureExtension = this.renderer.context.extensions.depthTexture;
            if (_settings.settings.PREFER_ENV === _constants.ENV.WEBGL_LEGACY) {
                nativeDrawBuffersExtension_1 = null;
                nativeDepthTextureExtension = null;
            }
            if (nativeDrawBuffersExtension_1) gl.drawBuffers = function(activeTextures) {
                return nativeDrawBuffersExtension_1.drawBuffersWEBGL(activeTextures);
            };
            else {
                this.hasMRT = false;
                gl.drawBuffers = function() {
                // empty
                };
            }
            if (!nativeDepthTextureExtension) this.writeDepthTexture = false;
        } else // WebGL2
        // cache possible MSAA samples
        this.msaaSamples = gl.getInternalformatParameter(gl.RENDERBUFFER, gl.RGBA8, gl.SAMPLES);
    };
    /**
     * Bind a framebuffer
     *
     * @param {PIXI.Framebuffer} [framebuffer]
     * @param {PIXI.Rectangle} [frame] - frame, default is framebuffer size
     * @param {number} [mipLevel] - optional mip level to set on the framebuffer - defaults to 0
     */ FramebufferSystem1.prototype.bind = function(framebuffer, frame, mipLevel) {
        if (mipLevel === void 0) mipLevel = 0;
        var gl = this.gl;
        if (framebuffer) {
            // TODO caching layer!
            var fbo = framebuffer.glFramebuffers[this.CONTEXT_UID] || this.initFramebuffer(framebuffer);
            if (this.current !== framebuffer) {
                this.current = framebuffer;
                gl.bindFramebuffer(gl.FRAMEBUFFER, fbo.framebuffer);
            }
            // make sure all textures are unbound..
            if (fbo.mipLevel !== mipLevel) {
                framebuffer.dirtyId++;
                framebuffer.dirtyFormat++;
                fbo.mipLevel = mipLevel;
            }
            // now check for updates...
            if (fbo.dirtyId !== framebuffer.dirtyId) {
                fbo.dirtyId = framebuffer.dirtyId;
                if (fbo.dirtyFormat !== framebuffer.dirtyFormat) {
                    fbo.dirtyFormat = framebuffer.dirtyFormat;
                    fbo.dirtySize = framebuffer.dirtySize;
                    this.updateFramebuffer(framebuffer, mipLevel);
                } else if (fbo.dirtySize !== framebuffer.dirtySize) {
                    fbo.dirtySize = framebuffer.dirtySize;
                    this.resizeFramebuffer(framebuffer);
                }
            }
            for(var i = 0; i < framebuffer.colorTextures.length; i++){
                var tex = framebuffer.colorTextures[i];
                this.renderer.texture.unbind(tex.parentTextureArray || tex);
            }
            if (framebuffer.depthTexture) this.renderer.texture.unbind(framebuffer.depthTexture);
            if (frame) {
                var mipWidth = frame.width >> mipLevel;
                var mipHeight = frame.height >> mipLevel;
                var scale = mipWidth / frame.width;
                this.setViewport(frame.x * scale, frame.y * scale, mipWidth, mipHeight);
            } else {
                var mipWidth = framebuffer.width >> mipLevel;
                var mipHeight = framebuffer.height >> mipLevel;
                this.setViewport(0, 0, mipWidth, mipHeight);
            }
        } else {
            if (this.current) {
                this.current = null;
                gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            }
            if (frame) this.setViewport(frame.x, frame.y, frame.width, frame.height);
            else this.setViewport(0, 0, this.renderer.width, this.renderer.height);
        }
    };
    /**
     * Set the WebGLRenderingContext's viewport.
     *
     * @param {Number} x - X position of viewport
     * @param {Number} y - Y position of viewport
     * @param {Number} width - Width of viewport
     * @param {Number} height - Height of viewport
     */ FramebufferSystem1.prototype.setViewport = function(x, y, width, height) {
        var v = this.viewport;
        x = Math.round(x);
        y = Math.round(y);
        width = Math.round(width);
        height = Math.round(height);
        if (v.width !== width || v.height !== height || v.x !== x || v.y !== y) {
            v.x = x;
            v.y = y;
            v.width = width;
            v.height = height;
            this.gl.viewport(x, y, width, height);
        }
    };
    Object.defineProperty(FramebufferSystem1.prototype, "size", {
        /**
         * Get the size of the current width and height. Returns object with `width` and `height` values.
         *
         * @member {object}
         * @readonly
         */ get: function() {
            if (this.current) // TODO store temp
            return {
                x: 0,
                y: 0,
                width: this.current.width,
                height: this.current.height
            };
            return {
                x: 0,
                y: 0,
                width: this.renderer.width,
                height: this.renderer.height
            };
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Clear the color of the context
     *
     * @param {Number} r - Red value from 0 to 1
     * @param {Number} g - Green value from 0 to 1
     * @param {Number} b - Blue value from 0 to 1
     * @param {Number} a - Alpha value from 0 to 1
     * @param {PIXI.BUFFER_BITS} [mask=BUFFER_BITS.COLOR | BUFFER_BITS.DEPTH] - Bitwise OR of masks
     *  that indicate the buffers to be cleared, by default COLOR and DEPTH buffers.
     */ FramebufferSystem1.prototype.clear = function(r, g, b, a, mask) {
        if (mask === void 0) mask = _constants.BUFFER_BITS.COLOR | _constants.BUFFER_BITS.DEPTH;
        var gl = this.gl;
        // TODO clear color can be set only one right?
        gl.clearColor(r, g, b, a);
        gl.clear(mask);
    };
    /**
     * Initialize framebuffer for this context
     *
     * @protected
     * @param {PIXI.Framebuffer} framebuffer
     * @returns {PIXI.GLFramebuffer} created GLFramebuffer
     */ FramebufferSystem1.prototype.initFramebuffer = function(framebuffer) {
        var gl = this.gl;
        var fbo = new GLFramebuffer(gl.createFramebuffer());
        fbo.multisample = this.detectSamples(framebuffer.multisample);
        framebuffer.glFramebuffers[this.CONTEXT_UID] = fbo;
        this.managedFramebuffers.push(framebuffer);
        framebuffer.disposeRunner.add(this);
        return fbo;
    };
    /**
     * Resize the framebuffer
     *
     * @protected
     * @param {PIXI.Framebuffer} framebuffer
     */ FramebufferSystem1.prototype.resizeFramebuffer = function(framebuffer) {
        var gl = this.gl;
        var fbo = framebuffer.glFramebuffers[this.CONTEXT_UID];
        if (fbo.msaaBuffer) {
            gl.bindRenderbuffer(gl.RENDERBUFFER, fbo.msaaBuffer);
            gl.renderbufferStorageMultisample(gl.RENDERBUFFER, fbo.multisample, gl.RGBA8, framebuffer.width, framebuffer.height);
        }
        if (fbo.stencil) {
            gl.bindRenderbuffer(gl.RENDERBUFFER, fbo.stencil);
            if (fbo.msaaBuffer) gl.renderbufferStorageMultisample(gl.RENDERBUFFER, fbo.multisample, gl.DEPTH24_STENCIL8, framebuffer.width, framebuffer.height);
            else gl.renderbufferStorage(gl.RENDERBUFFER, gl.DEPTH_STENCIL, framebuffer.width, framebuffer.height);
        }
        var colorTextures = framebuffer.colorTextures;
        var count = colorTextures.length;
        if (!gl.drawBuffers) count = Math.min(count, 1);
        for(var i = 0; i < count; i++){
            var texture = colorTextures[i];
            var parentTexture = texture.parentTextureArray || texture;
            this.renderer.texture.bind(parentTexture, 0);
        }
        if (framebuffer.depthTexture && this.writeDepthTexture) this.renderer.texture.bind(framebuffer.depthTexture, 0);
    };
    /**
     * Update the framebuffer
     *
     * @protected
     * @param {PIXI.Framebuffer} framebuffer
     * @param {number} mipLevel
     */ FramebufferSystem1.prototype.updateFramebuffer = function(framebuffer, mipLevel) {
        var gl = this.gl;
        var fbo = framebuffer.glFramebuffers[this.CONTEXT_UID];
        // bind the color texture
        var colorTextures = framebuffer.colorTextures;
        var count = colorTextures.length;
        if (!gl.drawBuffers) count = Math.min(count, 1);
        if (fbo.multisample > 1 && this.canMultisampleFramebuffer(framebuffer)) {
            fbo.msaaBuffer = fbo.msaaBuffer || gl.createRenderbuffer();
            gl.bindRenderbuffer(gl.RENDERBUFFER, fbo.msaaBuffer);
            gl.renderbufferStorageMultisample(gl.RENDERBUFFER, fbo.multisample, gl.RGBA8, framebuffer.width, framebuffer.height);
            gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.RENDERBUFFER, fbo.msaaBuffer);
        } else if (fbo.msaaBuffer) {
            gl.deleteRenderbuffer(fbo.msaaBuffer);
            fbo.msaaBuffer = null;
            if (fbo.blitFramebuffer) {
                fbo.blitFramebuffer.dispose();
                fbo.blitFramebuffer = null;
            }
        }
        var activeTextures = [];
        for(var i = 0; i < count; i++){
            var texture = colorTextures[i];
            var parentTexture = texture.parentTextureArray || texture;
            this.renderer.texture.bind(parentTexture, 0);
            if (i === 0 && fbo.msaaBuffer) continue;
            gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0 + i, texture.target, parentTexture._glTextures[this.CONTEXT_UID].texture, mipLevel);
            activeTextures.push(gl.COLOR_ATTACHMENT0 + i);
        }
        if (activeTextures.length > 1) gl.drawBuffers(activeTextures);
        if (framebuffer.depthTexture) {
            var writeDepthTexture = this.writeDepthTexture;
            if (writeDepthTexture) {
                var depthTexture = framebuffer.depthTexture;
                this.renderer.texture.bind(depthTexture, 0);
                gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.DEPTH_ATTACHMENT, gl.TEXTURE_2D, depthTexture._glTextures[this.CONTEXT_UID].texture, mipLevel);
            }
        }
        if ((framebuffer.stencil || framebuffer.depth) && !(framebuffer.depthTexture && this.writeDepthTexture)) {
            fbo.stencil = fbo.stencil || gl.createRenderbuffer();
            gl.bindRenderbuffer(gl.RENDERBUFFER, fbo.stencil);
            if (fbo.msaaBuffer) gl.renderbufferStorageMultisample(gl.RENDERBUFFER, fbo.multisample, gl.DEPTH24_STENCIL8, framebuffer.width, framebuffer.height);
            else gl.renderbufferStorage(gl.RENDERBUFFER, gl.DEPTH_STENCIL, framebuffer.width, framebuffer.height);
            gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.DEPTH_STENCIL_ATTACHMENT, gl.RENDERBUFFER, fbo.stencil);
        } else if (fbo.stencil) {
            gl.deleteRenderbuffer(fbo.stencil);
            fbo.stencil = null;
        }
    };
    /**
     * Returns true if the frame buffer can be multisampled
     *
     * @protected
     * @param {PIXI.Framebuffer} framebuffer
     */ FramebufferSystem1.prototype.canMultisampleFramebuffer = function(framebuffer) {
        return this.renderer.context.webGLVersion !== 1 && framebuffer.colorTextures.length <= 1 && !framebuffer.depthTexture;
    };
    /**
     * Detects number of samples that is not more than a param but as close to it as possible
     *
     * @param {PIXI.MSAA_QUALITY} samples - number of samples
     * @returns {PIXI.MSAA_QUALITY} - recommended number of samples
     */ FramebufferSystem1.prototype.detectSamples = function(samples) {
        var msaaSamples = this.msaaSamples;
        var res = _constants.MSAA_QUALITY.NONE;
        if (samples <= 1 || msaaSamples === null) return res;
        for(var i = 0; i < msaaSamples.length; i++)if (msaaSamples[i] <= samples) {
            res = msaaSamples[i];
            break;
        }
        if (res === 1) res = _constants.MSAA_QUALITY.NONE;
        return res;
    };
    /**
     * Only works with WebGL2
     *
     * blits framebuffer to another of the same or bigger size
     * after that target framebuffer is bound
     *
     * Fails with WebGL warning if blits multisample framebuffer to different size
     *
     * @param {PIXI.Framebuffer} [framebuffer] - by default it blits "into itself", from renderBuffer to texture.
     * @param {PIXI.Rectangle} [sourcePixels] - source rectangle in pixels
     * @param {PIXI.Rectangle} [destPixels] - dest rectangle in pixels, assumed to be the same as sourcePixels
     */ FramebufferSystem1.prototype.blit = function(framebuffer, sourcePixels, destPixels) {
        var _a = this, current = _a.current, renderer = _a.renderer, gl = _a.gl, CONTEXT_UID = _a.CONTEXT_UID;
        if (renderer.context.webGLVersion !== 2) return;
        if (!current) return;
        var fbo = current.glFramebuffers[CONTEXT_UID];
        if (!fbo) return;
        if (!framebuffer) {
            if (!fbo.msaaBuffer) return;
            var colorTexture = current.colorTextures[0];
            if (!colorTexture) return;
            if (!fbo.blitFramebuffer) {
                fbo.blitFramebuffer = new Framebuffer(current.width, current.height);
                fbo.blitFramebuffer.addColorTexture(0, colorTexture);
            }
            framebuffer = fbo.blitFramebuffer;
            if (framebuffer.colorTextures[0] !== colorTexture) {
                framebuffer.colorTextures[0] = colorTexture;
                framebuffer.dirtyId++;
                framebuffer.dirtyFormat++;
            }
            if (framebuffer.width !== current.width || framebuffer.height !== current.height) {
                framebuffer.width = current.width;
                framebuffer.height = current.height;
                framebuffer.dirtyId++;
                framebuffer.dirtySize++;
            }
        }
        if (!sourcePixels) {
            sourcePixels = tempRectangle;
            sourcePixels.width = current.width;
            sourcePixels.height = current.height;
        }
        if (!destPixels) destPixels = sourcePixels;
        var sameSize = sourcePixels.width === destPixels.width && sourcePixels.height === destPixels.height;
        this.bind(framebuffer);
        gl.bindFramebuffer(gl.READ_FRAMEBUFFER, fbo.framebuffer);
        gl.blitFramebuffer(sourcePixels.x, sourcePixels.y, sourcePixels.width, sourcePixels.height, destPixels.x, destPixels.y, destPixels.width, destPixels.height, gl.COLOR_BUFFER_BIT, sameSize ? gl.NEAREST : gl.LINEAR);
    };
    /**
     * Disposes framebuffer
     * @param {PIXI.Framebuffer} framebuffer - framebuffer that has to be disposed of
     * @param {boolean} [contextLost=false] - If context was lost, we suppress all delete function calls
     */ FramebufferSystem1.prototype.disposeFramebuffer = function(framebuffer, contextLost) {
        var fbo = framebuffer.glFramebuffers[this.CONTEXT_UID];
        var gl = this.gl;
        if (!fbo) return;
        delete framebuffer.glFramebuffers[this.CONTEXT_UID];
        var index = this.managedFramebuffers.indexOf(framebuffer);
        if (index >= 0) this.managedFramebuffers.splice(index, 1);
        framebuffer.disposeRunner.remove(this);
        if (!contextLost) {
            gl.deleteFramebuffer(fbo.framebuffer);
            if (fbo.msaaBuffer) gl.deleteRenderbuffer(fbo.msaaBuffer);
            if (fbo.stencil) gl.deleteRenderbuffer(fbo.stencil);
        }
        if (fbo.blitFramebuffer) fbo.blitFramebuffer.dispose();
    };
    /**
     * Disposes all framebuffers, but not textures bound to them
     * @param {boolean} [contextLost=false] - If context was lost, we suppress all delete function calls
     */ FramebufferSystem1.prototype.disposeAll = function(contextLost) {
        var list = this.managedFramebuffers;
        this.managedFramebuffers = [];
        for(var i = 0; i < list.length; i++)this.disposeFramebuffer(list[i], contextLost);
    };
    /**
     * Forcing creation of stencil buffer for current framebuffer, if it wasn't done before.
     * Used by MaskSystem, when its time to use stencil mask for Graphics element.
     *
     * Its an alternative for public lazy `framebuffer.enableStencil`, in case we need stencil without rebind.
     *
     * @private
     */ FramebufferSystem1.prototype.forceStencil = function() {
        var framebuffer = this.current;
        if (!framebuffer) return;
        var fbo = framebuffer.glFramebuffers[this.CONTEXT_UID];
        if (!fbo || fbo.stencil) return;
        framebuffer.stencil = true;
        var w = framebuffer.width;
        var h = framebuffer.height;
        var gl = this.gl;
        var stencil = gl.createRenderbuffer();
        gl.bindRenderbuffer(gl.RENDERBUFFER, stencil);
        if (fbo.msaaBuffer) gl.renderbufferStorageMultisample(gl.RENDERBUFFER, fbo.multisample, gl.DEPTH24_STENCIL8, w, h);
        else gl.renderbufferStorage(gl.RENDERBUFFER, gl.DEPTH_STENCIL, w, h);
        fbo.stencil = stencil;
        gl.framebufferRenderbuffer(gl.FRAMEBUFFER, gl.DEPTH_STENCIL_ATTACHMENT, gl.RENDERBUFFER, stencil);
    };
    /**
     * resets framebuffer stored state, binds screen framebuffer
     *
     * should be called before renderTexture reset()
     */ FramebufferSystem1.prototype.reset = function() {
        this.current = this.unknownFramebuffer;
        this.viewport = new _math.Rectangle();
    };
    /**
     * @ignore
     */ FramebufferSystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    return FramebufferSystem1;
}();
var byteSizeMap$1 = {
    5126: 4,
    5123: 2,
    5121: 1
};
/**
 * System plugin to the renderer to manage geometry.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var GeometrySystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function GeometrySystem1(renderer) {
        this.renderer = renderer;
        this._activeGeometry = null;
        this._activeVao = null;
        /**
         * `true` if we has `*_vertex_array_object` extension
         * @member {boolean}
         * @readonly
         */ this.hasVao = true;
        /**
         * `true` if has `ANGLE_instanced_arrays` extension
         * @member {boolean}
         * @readonly
         */ this.hasInstance = true;
        /**
         * `true` if support `gl.UNSIGNED_INT` in `gl.drawElements` or `gl.drawElementsInstanced`
         * @member {boolean}
         * @readonly
         */ this.canUseUInt32ElementIndex = false;
        /**
         * Cache for all geometries by id, used in case renderer gets destroyed or for profiling
         * @member {object}
         * @readonly
         */ this.managedGeometries = {
        };
    }
    /**
     * Sets up the renderer context and necessary buffers.
     */ GeometrySystem1.prototype.contextChange = function() {
        this.disposeAll(true);
        var gl = this.gl = this.renderer.gl;
        var context = this.renderer.context;
        this.CONTEXT_UID = this.renderer.CONTEXT_UID;
        // webgl2
        if (context.webGLVersion !== 2) {
            // webgl 1!
            var nativeVaoExtension_1 = this.renderer.context.extensions.vertexArrayObject;
            if (_settings.settings.PREFER_ENV === _constants.ENV.WEBGL_LEGACY) nativeVaoExtension_1 = null;
            if (nativeVaoExtension_1) {
                gl.createVertexArray = function() {
                    return nativeVaoExtension_1.createVertexArrayOES();
                };
                gl.bindVertexArray = function(vao) {
                    return nativeVaoExtension_1.bindVertexArrayOES(vao);
                };
                gl.deleteVertexArray = function(vao) {
                    return nativeVaoExtension_1.deleteVertexArrayOES(vao);
                };
            } else {
                this.hasVao = false;
                gl.createVertexArray = function() {
                    return null;
                };
                gl.bindVertexArray = function() {
                    return null;
                };
                gl.deleteVertexArray = function() {
                    return null;
                };
            }
        }
        if (context.webGLVersion !== 2) {
            var instanceExt_1 = gl.getExtension('ANGLE_instanced_arrays');
            if (instanceExt_1) {
                gl.vertexAttribDivisor = function(a, b) {
                    return instanceExt_1.vertexAttribDivisorANGLE(a, b);
                };
                gl.drawElementsInstanced = function(a, b, c, d, e) {
                    return instanceExt_1.drawElementsInstancedANGLE(a, b, c, d, e);
                };
                gl.drawArraysInstanced = function(a, b, c, d) {
                    return instanceExt_1.drawArraysInstancedANGLE(a, b, c, d);
                };
            } else this.hasInstance = false;
        }
        this.canUseUInt32ElementIndex = context.webGLVersion === 2 || !!context.extensions.uint32ElementIndex;
    };
    /**
     * Binds geometry so that is can be drawn. Creating a Vao if required
     *
     * @param {PIXI.Geometry} geometry - instance of geometry to bind
     * @param {PIXI.Shader} [shader] - instance of shader to use vao for
     */ GeometrySystem1.prototype.bind = function(geometry, shader) {
        shader = shader || this.renderer.shader.shader;
        var gl = this.gl;
        // not sure the best way to address this..
        // currently different shaders require different VAOs for the same geometry
        // Still mulling over the best way to solve this one..
        // will likely need to modify the shader attribute locations at run time!
        var vaos = geometry.glVertexArrayObjects[this.CONTEXT_UID];
        var incRefCount = false;
        if (!vaos) {
            this.managedGeometries[geometry.id] = geometry;
            geometry.disposeRunner.add(this);
            geometry.glVertexArrayObjects[this.CONTEXT_UID] = vaos = {
            };
            incRefCount = true;
        }
        var vao = vaos[shader.program.id] || this.initGeometryVao(geometry, shader, incRefCount);
        this._activeGeometry = geometry;
        if (this._activeVao !== vao) {
            this._activeVao = vao;
            if (this.hasVao) gl.bindVertexArray(vao);
            else this.activateVao(geometry, shader.program);
        }
        // TODO - optimise later!
        // don't need to loop through if nothing changed!
        // maybe look to add an 'autoupdate' to geometry?
        this.updateBuffers();
    };
    /**
     * Reset and unbind any active VAO and geometry
     */ GeometrySystem1.prototype.reset = function() {
        this.unbind();
    };
    /**
     * Update buffers
     * @protected
     */ GeometrySystem1.prototype.updateBuffers = function() {
        var geometry = this._activeGeometry;
        var bufferSystem = this.renderer.buffer;
        for(var i = 0; i < geometry.buffers.length; i++){
            var buffer = geometry.buffers[i];
            bufferSystem.update(buffer);
        }
    };
    /**
     * Check compatibility between a geometry and a program
     * @protected
     * @param {PIXI.Geometry} geometry - Geometry instance
     * @param {PIXI.Program} program - Program instance
     */ GeometrySystem1.prototype.checkCompatibility = function(geometry, program) {
        // geometry must have at least all the attributes that the shader requires.
        var geometryAttributes = geometry.attributes;
        var shaderAttributes = program.attributeData;
        for(var j in shaderAttributes){
            if (!geometryAttributes[j]) throw new Error("shader and geometry incompatible, geometry missing the \"" + j + "\" attribute");
        }
    };
    /**
     * Takes a geometry and program and generates a unique signature for them.
     *
     * @param {PIXI.Geometry} geometry - to get signature from
     * @param {PIXI.Program} program - to test geometry against
     * @returns {String} Unique signature of the geometry and program
     * @protected
     */ GeometrySystem1.prototype.getSignature = function(geometry, program) {
        var attribs = geometry.attributes;
        var shaderAttributes = program.attributeData;
        var strings = [
            'g',
            geometry.id
        ];
        for(var i in attribs)if (shaderAttributes[i]) strings.push(i);
        return strings.join('-');
    };
    /**
     * Creates or gets Vao with the same structure as the geometry and stores it on the geometry.
     * If vao is created, it is bound automatically. We use a shader to infer what and how to set up the
     * attribute locations.
     *
     * @protected
     * @param {PIXI.Geometry} geometry - Instance of geometry to to generate Vao for
     * @param {PIXI.Shader} shader - Instance of the shader
     * @param {boolean} [incRefCount=false] - Increment refCount of all geometry buffers
     */ GeometrySystem1.prototype.initGeometryVao = function(geometry, shader, incRefCount) {
        if (incRefCount === void 0) incRefCount = true;
        var gl = this.gl;
        var CONTEXT_UID = this.CONTEXT_UID;
        var bufferSystem = this.renderer.buffer;
        var program = shader.program;
        if (!program.glPrograms[CONTEXT_UID]) this.renderer.shader.generateProgram(shader);
        this.checkCompatibility(geometry, program);
        var signature = this.getSignature(geometry, program);
        var vaoObjectHash = geometry.glVertexArrayObjects[this.CONTEXT_UID];
        var vao = vaoObjectHash[signature];
        if (vao) {
            // this will give us easy access to the vao
            vaoObjectHash[program.id] = vao;
            return vao;
        }
        var buffers = geometry.buffers;
        var attributes = geometry.attributes;
        var tempStride = {
        };
        var tempStart = {
        };
        for(var j in buffers){
            tempStride[j] = 0;
            tempStart[j] = 0;
        }
        for(var j in attributes){
            if (!attributes[j].size && program.attributeData[j]) attributes[j].size = program.attributeData[j].size;
            else if (!attributes[j].size) console.warn("PIXI Geometry attribute '" + j + "' size cannot be determined (likely the bound shader does not have the attribute)"); // eslint-disable-line
            tempStride[attributes[j].buffer] += attributes[j].size * byteSizeMap$1[attributes[j].type];
        }
        for(var j in attributes){
            var attribute = attributes[j];
            var attribSize = attribute.size;
            if (attribute.stride === undefined) {
                if (tempStride[attribute.buffer] === attribSize * byteSizeMap$1[attribute.type]) attribute.stride = 0;
                else attribute.stride = tempStride[attribute.buffer];
            }
            if (attribute.start === undefined) {
                attribute.start = tempStart[attribute.buffer];
                tempStart[attribute.buffer] += attribSize * byteSizeMap$1[attribute.type];
            }
        }
        vao = gl.createVertexArray();
        gl.bindVertexArray(vao);
        // first update - and create the buffers!
        // only create a gl buffer if it actually gets
        for(var i = 0; i < buffers.length; i++){
            var buffer = buffers[i];
            bufferSystem.bind(buffer);
            if (incRefCount) buffer._glBuffers[CONTEXT_UID].refCount++;
        }
        // TODO - maybe make this a data object?
        // lets wait to see if we need to first!
        this.activateVao(geometry, program);
        this._activeVao = vao;
        // add it to the cache!
        vaoObjectHash[program.id] = vao;
        vaoObjectHash[signature] = vao;
        return vao;
    };
    /**
     * Disposes geometry
     * @param {PIXI.Geometry} geometry - Geometry with buffers. Only VAO will be disposed
     * @param {boolean} [contextLost=false] - If context was lost, we suppress deleteVertexArray
     */ GeometrySystem1.prototype.disposeGeometry = function(geometry, contextLost) {
        var _a;
        if (!this.managedGeometries[geometry.id]) return;
        delete this.managedGeometries[geometry.id];
        var vaos = geometry.glVertexArrayObjects[this.CONTEXT_UID];
        var gl = this.gl;
        var buffers = geometry.buffers;
        var bufferSystem = (_a = this.renderer) === null || _a === void 0 ? void 0 : _a.buffer;
        geometry.disposeRunner.remove(this);
        if (!vaos) return;
        // bufferSystem may have already been destroyed..
        // if this is the case, there is no need to destroy the geometry buffers...
        // they already have been!
        if (bufferSystem) for(var i = 0; i < buffers.length; i++){
            var buf = buffers[i]._glBuffers[this.CONTEXT_UID];
            // my be null as context may have changed right before the dispose is called
            if (buf) {
                buf.refCount--;
                if (buf.refCount === 0 && !contextLost) bufferSystem.dispose(buffers[i], contextLost);
            }
        }
        if (!contextLost) {
            for(var vaoId in vaos)// delete only signatures, everything else are copies
            if (vaoId[0] === 'g') {
                var vao = vaos[vaoId];
                if (this._activeVao === vao) this.unbind();
                gl.deleteVertexArray(vao);
            }
        }
        delete geometry.glVertexArrayObjects[this.CONTEXT_UID];
    };
    /**
     * dispose all WebGL resources of all managed geometries
     * @param {boolean} [contextLost=false] - If context was lost, we suppress `gl.delete` calls
     */ GeometrySystem1.prototype.disposeAll = function(contextLost) {
        var all = Object.keys(this.managedGeometries);
        for(var i = 0; i < all.length; i++)this.disposeGeometry(this.managedGeometries[all[i]], contextLost);
    };
    /**
     * Activate vertex array object
     *
     * @protected
     * @param {PIXI.Geometry} geometry - Geometry instance
     * @param {PIXI.Program} program - Shader program instance
     */ GeometrySystem1.prototype.activateVao = function(geometry, program) {
        var gl = this.gl;
        var CONTEXT_UID = this.CONTEXT_UID;
        var bufferSystem = this.renderer.buffer;
        var buffers = geometry.buffers;
        var attributes = geometry.attributes;
        if (geometry.indexBuffer) // first update the index buffer if we have one..
        bufferSystem.bind(geometry.indexBuffer);
        var lastBuffer = null;
        // add a new one!
        for(var j in attributes){
            var attribute = attributes[j];
            var buffer = buffers[attribute.buffer];
            var glBuffer = buffer._glBuffers[CONTEXT_UID];
            if (program.attributeData[j]) {
                if (lastBuffer !== glBuffer) {
                    bufferSystem.bind(buffer);
                    lastBuffer = glBuffer;
                }
                var location = program.attributeData[j].location;
                // TODO introduce state again
                // we can optimise this for older devices that have no VAOs
                gl.enableVertexAttribArray(location);
                gl.vertexAttribPointer(location, attribute.size, attribute.type || gl.FLOAT, attribute.normalized, attribute.stride, attribute.start);
                if (attribute.instance) {
                    // TODO calculate instance count based of this...
                    if (this.hasInstance) gl.vertexAttribDivisor(location, 1);
                    else throw new Error('geometry error, GPU Instancing is not supported on this device');
                }
            }
        }
    };
    /**
     * Draw the geometry
     *
     * @param {Number} type - the type primitive to render
     * @param {Number} [size] - the number of elements to be rendered
     * @param {Number} [start] - Starting index
     * @param {Number} [instanceCount] - the number of instances of the set of elements to execute
     */ GeometrySystem1.prototype.draw = function(type, size, start, instanceCount) {
        var gl = this.gl;
        var geometry = this._activeGeometry;
        // TODO.. this should not change so maybe cache the function?
        if (geometry.indexBuffer) {
            var byteSize = geometry.indexBuffer.data.BYTES_PER_ELEMENT;
            var glType = byteSize === 2 ? gl.UNSIGNED_SHORT : gl.UNSIGNED_INT;
            if (byteSize === 2 || byteSize === 4 && this.canUseUInt32ElementIndex) {
                if (geometry.instanced) /* eslint-disable max-len */ gl.drawElementsInstanced(type, size || geometry.indexBuffer.data.length, glType, (start || 0) * byteSize, instanceCount || 1);
                else /* eslint-disable max-len */ gl.drawElements(type, size || geometry.indexBuffer.data.length, glType, (start || 0) * byteSize);
            } else console.warn('unsupported index buffer type: uint32');
        } else if (geometry.instanced) // TODO need a better way to calculate size..
        gl.drawArraysInstanced(type, start, size || geometry.getSize(), instanceCount || 1);
        else gl.drawArrays(type, start, size || geometry.getSize());
        return this;
    };
    /**
     * Unbind/reset everything
     * @protected
     */ GeometrySystem1.prototype.unbind = function() {
        this.gl.bindVertexArray(null);
        this._activeVao = null;
        this._activeGeometry = null;
    };
    /**
     * @ignore
     */ GeometrySystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    return GeometrySystem1;
}();
/**
 * Component for masked elements
 *
 * Holds mask mode and temporary data about current mask
 *
 * @class
 * @memberof PIXI
 */ var MaskData = function() {
    /**
     * Create MaskData
     *
     * @param {PIXI.DisplayObject} [maskObject=null] - object that describes the mask
     */ function MaskData1(maskObject) {
        if (maskObject === void 0) maskObject = null;
        /**
         * Mask type
         * @member {PIXI.MASK_TYPES}
         */ this.type = _constants.MASK_TYPES.NONE;
        /**
         * Whether we know the mask type beforehand
         * @member {boolean}
         * @default true
         */ this.autoDetect = true;
        /**
         * Which element we use to mask
         * @member {PIXI.DisplayObject}
         */ this.maskObject = maskObject || null;
        /**
         * Whether it belongs to MaskSystem pool
         * @member {boolean}
         */ this.pooled = false;
        /**
         * Indicator of the type
         * @member {boolean}
         */ this.isMaskData = true;
        /**
         * Resolution of the sprite mask filter.
         * If set to `null` or `0`, the resolution of the current render target is used.
         * @member {number}
         */ this.resolution = null;
        /**
         * Number of samples of the sprite mask filter.
         * If set to `null`, the sample count of the current render target is used.
         * @member {PIXI.MSAA_QUALITY}
         * @default {PIXI.settings.FILTER_MULTISAMPLE}
         */ this.multisample = _settings.settings.FILTER_MULTISAMPLE;
        /**
         * Stencil counter above the mask in stack
         * @member {number}
         * @private
         */ this._stencilCounter = 0;
        /**
         * Scissor counter above the mask in stack
         * @member {number}
         * @private
         */ this._scissorCounter = 0;
        /**
         * Scissor operation above the mask in stack.
         * Null if _scissorCounter is zero, rectangle instance if positive.
         * @member {PIXI.Rectangle}
         */ this._scissorRect = null;
        /**
         * Targeted element. Temporary variable set by MaskSystem
         * @member {PIXI.DisplayObject}
         * @private
         */ this._target = null;
    }
    /**
     * resets the mask data after popMask()
     */ MaskData1.prototype.reset = function() {
        if (this.pooled) {
            this.maskObject = null;
            this.type = _constants.MASK_TYPES.NONE;
            this.autoDetect = true;
        }
        this._target = null;
    };
    /**
     * copies counters from maskData above, called from pushMask()
     * @param {PIXI.MaskData|null} maskAbove
     */ MaskData1.prototype.copyCountersOrReset = function(maskAbove) {
        if (maskAbove) {
            this._stencilCounter = maskAbove._stencilCounter;
            this._scissorCounter = maskAbove._scissorCounter;
            this._scissorRect = maskAbove._scissorRect;
        } else {
            this._stencilCounter = 0;
            this._scissorCounter = 0;
            this._scissorRect = null;
        }
    };
    return MaskData1;
}();
/**
 * @private
 * @param {WebGLRenderingContext} gl - The current WebGL context {WebGLProgram}
 * @param {Number} type - the type, can be either VERTEX_SHADER or FRAGMENT_SHADER
 * @param {string} src - The vertex shader source as an array of strings.
 * @return {WebGLShader} the shader
 */ function compileShader(gl, type, src) {
    var shader = gl.createShader(type);
    gl.shaderSource(shader, src);
    gl.compileShader(shader);
    return shader;
}
/**
 * will log a shader error highlighting the lines with the error
 * also will add numbers along the side.
 *
 * @param gl - the WebGLContext
 * @param shader - the shader to log errors for
 */ function logPrettyShaderError(gl, shader) {
    var shaderSrc = gl.getShaderSource(shader).split('\n').map(function(line, index) {
        return index + ": " + line;
    });
    var shaderLog = gl.getShaderInfoLog(shader);
    var splitShader = shaderLog.split('\n');
    var dedupe = {
    };
    var lineNumbers = splitShader.map(function(line) {
        return parseFloat(line.replace(/^ERROR\: 0\:([\d]+)\:.*$/, '$1'));
    }).filter(function(n) {
        if (n && !dedupe[n]) {
            dedupe[n] = true;
            return true;
        }
        return false;
    });
    var logArgs = [
        ''
    ];
    lineNumbers.forEach(function(number) {
        shaderSrc[number - 1] = "%c" + shaderSrc[number - 1] + "%c";
        logArgs.push('background: #FF0000; color:#FFFFFF; font-size: 10px', 'font-size: 10px');
    });
    var fragmentSourceToLog = shaderSrc.join('\n');
    logArgs[0] = fragmentSourceToLog;
    console.error(shaderLog);
    // eslint-disable-next-line no-console
    console.groupCollapsed('click to view full shader code');
    console.warn.apply(console, logArgs);
    // eslint-disable-next-line no-console
    console.groupEnd();
}
/**
 *
 * logs out any program errors
 *
 * @param gl - The current WebGL context
 * @param program - the WebGL program to display errors for
 * @param vertexShader  - the fragment WebGL shader program
 * @param fragmentShader - the vertex WebGL shader program
 */ function logProgramError(gl, program, vertexShader, fragmentShader) {
    // if linking fails, then log and cleanup
    if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        if (!gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) logPrettyShaderError(gl, vertexShader);
        if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) logPrettyShaderError(gl, fragmentShader);
        console.error('PixiJS Error: Could not initialize shader.');
        // if there is a program info log, log it
        if (gl.getProgramInfoLog(program) !== '') console.warn('PixiJS Warning: gl.getProgramInfoLog()', gl.getProgramInfoLog(program));
    }
}
function booleanArray(size) {
    var array = new Array(size);
    for(var i = 0; i < array.length; i++)array[i] = false;
    return array;
}
/**
 * @method defaultValue
 * @memberof PIXI.glCore.shader
 * @param {string} type - Type of value
 * @param {number} size
 * @private
 */ function defaultValue(type, size) {
    switch(type){
        case 'float':
            return 0;
        case 'vec2':
            return new Float32Array(2 * size);
        case 'vec3':
            return new Float32Array(3 * size);
        case 'vec4':
            return new Float32Array(4 * size);
        case 'int':
        case 'uint':
        case 'sampler2D':
        case 'sampler2DArray':
            return 0;
        case 'ivec2':
            return new Int32Array(2 * size);
        case 'ivec3':
            return new Int32Array(3 * size);
        case 'ivec4':
            return new Int32Array(4 * size);
        case 'uvec2':
            return new Uint32Array(2 * size);
        case 'uvec3':
            return new Uint32Array(3 * size);
        case 'uvec4':
            return new Uint32Array(4 * size);
        case 'bool':
            return false;
        case 'bvec2':
            return booleanArray(2 * size);
        case 'bvec3':
            return booleanArray(3 * size);
        case 'bvec4':
            return booleanArray(4 * size);
        case 'mat2':
            return new Float32Array([
                1,
                0,
                0,
                1
            ]);
        case 'mat3':
            return new Float32Array([
                1,
                0,
                0,
                0,
                1,
                0,
                0,
                0,
                1
            ]);
        case 'mat4':
            return new Float32Array([
                1,
                0,
                0,
                0,
                0,
                1,
                0,
                0,
                0,
                0,
                1,
                0,
                0,
                0,
                0,
                1
            ]);
    }
    return null;
}
var unknownContext = {
};
var context = unknownContext;
/**
 * returns a little WebGL context to use for program inspection.
 *
 * @static
 * @private
 * @returns {WebGLRenderingContext} a gl context to test with
 */ function getTestContext() {
    if (context === unknownContext || context && context.isContextLost()) {
        var canvas = document.createElement('canvas');
        var gl = void 0;
        if (_settings.settings.PREFER_ENV >= _constants.ENV.WEBGL2) gl = canvas.getContext('webgl2', {
        });
        if (!gl) {
            gl = canvas.getContext('webgl', {
            }) || canvas.getContext('experimental-webgl', {
            });
            if (!gl) // fail, not able to get a context
            gl = null;
            else // for shader testing..
            gl.getExtension('WEBGL_draw_buffers');
        }
        context = gl;
    }
    return context;
}
var maxFragmentPrecision;
function getMaxFragmentPrecision() {
    if (!maxFragmentPrecision) {
        maxFragmentPrecision = _constants.PRECISION.MEDIUM;
        var gl = getTestContext();
        if (gl) {
            if (gl.getShaderPrecisionFormat) {
                var shaderFragment = gl.getShaderPrecisionFormat(gl.FRAGMENT_SHADER, gl.HIGH_FLOAT);
                maxFragmentPrecision = shaderFragment.precision ? _constants.PRECISION.HIGH : _constants.PRECISION.MEDIUM;
            }
        }
    }
    return maxFragmentPrecision;
}
/**
 * Sets the float precision on the shader, ensuring the device supports the request precision.
 * If the precision is already present, it just ensures that the device is able to handle it.
 *
 * @private
 * @param {string} src - The shader source
 * @param {PIXI.PRECISION} requestedPrecision - The request float precision of the shader.
 * @param {PIXI.PRECISION} maxSupportedPrecision - The maximum precision the shader supports.
 *
 * @return {string} modified shader source
 */ function setPrecision(src, requestedPrecision, maxSupportedPrecision) {
    if (src.substring(0, 9) !== 'precision') {
        // no precision supplied, so PixiJS will add the requested level.
        var precision = requestedPrecision;
        // If highp is requested but not supported, downgrade precision to a level all devices support.
        if (requestedPrecision === _constants.PRECISION.HIGH && maxSupportedPrecision !== _constants.PRECISION.HIGH) precision = _constants.PRECISION.MEDIUM;
        return "precision " + precision + " float;\n" + src;
    } else if (maxSupportedPrecision !== _constants.PRECISION.HIGH && src.substring(0, 15) === 'precision highp') // precision was supplied, but at a level this device does not support, so downgrading to mediump.
    return src.replace('precision highp', 'precision mediump');
    return src;
}
var GLSL_TO_SIZE = {
    float: 1,
    vec2: 2,
    vec3: 3,
    vec4: 4,
    int: 1,
    ivec2: 2,
    ivec3: 3,
    ivec4: 4,
    uint: 1,
    uvec2: 2,
    uvec3: 3,
    uvec4: 4,
    bool: 1,
    bvec2: 2,
    bvec3: 3,
    bvec4: 4,
    mat2: 4,
    mat3: 9,
    mat4: 16,
    sampler2D: 1
};
/**
 * @private
 * @method mapSize
 * @memberof PIXI.glCore.shader
 * @param {String} type
 * @return {Number}
 */ function mapSize(type) {
    return GLSL_TO_SIZE[type];
}
var GL_TABLE = null;
var GL_TO_GLSL_TYPES = {
    FLOAT: 'float',
    FLOAT_VEC2: 'vec2',
    FLOAT_VEC3: 'vec3',
    FLOAT_VEC4: 'vec4',
    INT: 'int',
    INT_VEC2: 'ivec2',
    INT_VEC3: 'ivec3',
    INT_VEC4: 'ivec4',
    UNSIGNED_INT: 'uint',
    UNSIGNED_INT_VEC2: 'uvec2',
    UNSIGNED_INT_VEC3: 'uvec3',
    UNSIGNED_INT_VEC4: 'uvec4',
    BOOL: 'bool',
    BOOL_VEC2: 'bvec2',
    BOOL_VEC3: 'bvec3',
    BOOL_VEC4: 'bvec4',
    FLOAT_MAT2: 'mat2',
    FLOAT_MAT3: 'mat3',
    FLOAT_MAT4: 'mat4',
    SAMPLER_2D: 'sampler2D',
    INT_SAMPLER_2D: 'sampler2D',
    UNSIGNED_INT_SAMPLER_2D: 'sampler2D',
    SAMPLER_CUBE: 'samplerCube',
    INT_SAMPLER_CUBE: 'samplerCube',
    UNSIGNED_INT_SAMPLER_CUBE: 'samplerCube',
    SAMPLER_2D_ARRAY: 'sampler2DArray',
    INT_SAMPLER_2D_ARRAY: 'sampler2DArray',
    UNSIGNED_INT_SAMPLER_2D_ARRAY: 'sampler2DArray'
};
// eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types
function mapType(gl, type) {
    if (!GL_TABLE) {
        var typeNames = Object.keys(GL_TO_GLSL_TYPES);
        GL_TABLE = {
        };
        for(var i = 0; i < typeNames.length; ++i){
            var tn = typeNames[i];
            GL_TABLE[gl[tn]] = GL_TO_GLSL_TYPES[tn];
        }
    }
    return GL_TABLE[type];
}
/* eslint-disable @typescript-eslint/explicit-module-boundary-types */ // Parsers, each one of these will take a look at the type of shader property and uniform.
// if they pass the test function then the code function is called that returns a the shader upload code for that uniform.
// Shader upload code is automagically generated with these parsers.
// If no parser is valid then the default upload functions are used.
// exposing Parsers means that custom upload logic can be added to pixi's shaders.
// A good example would be a pixi rectangle can be directly set on a uniform.
// If the shader sees it it knows how to upload the rectangle structure as a vec4
// format is as follows:
//
// {
//     test: (data, uniform) => {} <--- test is this code should be used for this uniform
//     code: (name, uniform) => {} <--- returns the string of the piece of code that uploads the uniform
//     codeUbo: (name, uniform) => {} <--- returns the string of the piece of code that uploads the
//                                         uniform to a uniform buffer
// }
var uniformParsers = [
    // a float cache layer
    {
        test: function(data) {
            return data.type === 'float' && data.size === 1;
        },
        code: function(name) {
            return "\n            if(uv[\"" + name + "\"] !== ud[\"" + name + "\"].value)\n            {\n                ud[\"" + name + "\"].value = uv[\"" + name + "\"]\n                gl.uniform1f(ud[\"" + name + "\"].location, uv[\"" + name + "\"])\n            }\n            ";
        }
    },
    // handling samplers
    {
        test: function(data) {
            // eslint-disable-next-line max-len
            return (data.type === 'sampler2D' || data.type === 'samplerCube' || data.type === 'sampler2DArray') && data.size === 1 && !data.isArray;
        },
        code: function(name) {
            return "t = syncData.textureCount++;\n\n            renderer.texture.bind(uv[\"" + name + "\"], t);\n\n            if(ud[\"" + name + "\"].value !== t)\n            {\n                ud[\"" + name + "\"].value = t;\n                gl.uniform1i(ud[\"" + name + "\"].location, t);\n; // eslint-disable-line max-len\n            }";
        }
    },
    // uploading pixi matrix object to mat3
    {
        test: function(data, uniform) {
            return data.type === 'mat3' && data.size === 1 && uniform.a !== undefined;
        },
        code: function(name) {
            // TODO and some smart caching dirty ids here!
            return "\n            gl.uniformMatrix3fv(ud[\"" + name + "\"].location, false, uv[\"" + name + "\"].toArray(true));\n            ";
        },
        codeUbo: function(name) {
            return "\n                var " + name + "_matrix = uv." + name + ".toArray(true);\n\n                data[offset] = " + name + "_matrix[0];\n                data[offset+1] = " + name + "_matrix[1];\n                data[offset+2] = " + name + "_matrix[2];\n        \n                data[offset + 4] = " + name + "_matrix[3];\n                data[offset + 5] = " + name + "_matrix[4];\n                data[offset + 6] = " + name + "_matrix[5];\n        \n                data[offset + 8] = " + name + "_matrix[6];\n                data[offset + 9] = " + name + "_matrix[7];\n                data[offset + 10] = " + name + "_matrix[8];\n            ";
        }
    },
    // uploading a pixi point as a vec2 with caching layer
    {
        test: function(data, uniform) {
            return data.type === 'vec2' && data.size === 1 && uniform.x !== undefined;
        },
        code: function(name) {
            return "\n                cv = ud[\"" + name + "\"].value;\n                v = uv[\"" + name + "\"];\n\n                if(cv[0] !== v.x || cv[1] !== v.y)\n                {\n                    cv[0] = v.x;\n                    cv[1] = v.y;\n                    gl.uniform2f(ud[\"" + name + "\"].location, v.x, v.y);\n                }";
        },
        codeUbo: function(name) {
            return "\n                v = uv." + name + ";\n\n                data[offset] = v.x;\n                data[offset+1] = v.y;\n            ";
        }
    },
    // caching layer for a vec2
    {
        test: function(data) {
            return data.type === 'vec2' && data.size === 1;
        },
        code: function(name) {
            return "\n                cv = ud[\"" + name + "\"].value;\n                v = uv[\"" + name + "\"];\n\n                if(cv[0] !== v[0] || cv[1] !== v[1])\n                {\n                    cv[0] = v[0];\n                    cv[1] = v[1];\n                    gl.uniform2f(ud[\"" + name + "\"].location, v[0], v[1]);\n                }\n            ";
        }
    },
    // upload a pixi rectangle as a vec4 with caching layer
    {
        test: function(data, uniform) {
            return data.type === 'vec4' && data.size === 1 && uniform.width !== undefined;
        },
        code: function(name) {
            return "\n                cv = ud[\"" + name + "\"].value;\n                v = uv[\"" + name + "\"];\n\n                if(cv[0] !== v.x || cv[1] !== v.y || cv[2] !== v.width || cv[3] !== v.height)\n                {\n                    cv[0] = v.x;\n                    cv[1] = v.y;\n                    cv[2] = v.width;\n                    cv[3] = v.height;\n                    gl.uniform4f(ud[\"" + name + "\"].location, v.x, v.y, v.width, v.height)\n                }";
        },
        codeUbo: function(name) {
            return "\n                    v = uv." + name + ";\n\n                    data[offset] = v.x;\n                    data[offset+1] = v.y;\n                    data[offset+2] = v.width;\n                    data[offset+3] = v.height;\n                ";
        }
    },
    // a caching layer for vec4 uploading
    {
        test: function(data) {
            return data.type === 'vec4' && data.size === 1;
        },
        code: function(name) {
            return "\n                cv = ud[\"" + name + "\"].value;\n                v = uv[\"" + name + "\"];\n\n                if(cv[0] !== v[0] || cv[1] !== v[1] || cv[2] !== v[2] || cv[3] !== v[3])\n                {\n                    cv[0] = v[0];\n                    cv[1] = v[1];\n                    cv[2] = v[2];\n                    cv[3] = v[3];\n\n                    gl.uniform4f(ud[\"" + name + "\"].location, v[0], v[1], v[2], v[3])\n                }";
        }
    }
];
// cv = CachedValue
// v = value
// ud = uniformData
// uv = uniformValue
// l = location
var GLSL_TO_SINGLE_SETTERS_CACHED = {
    float: "\n    if(cv !== v)\n    {\n        cv.v = v;\n        gl.uniform1f(location, v)\n    }",
    vec2: "\n    if(cv[0] !== v[0] || cv[1] !== v[1])\n    {\n        cv[0] = v[0];\n        cv[1] = v[1];\n        gl.uniform2f(location, v[0], v[1])\n    }",
    vec3: "\n    if(cv[0] !== v[0] || cv[1] !== v[1] || cv[2] !== v[2])\n    {\n        cv[0] = v[0];\n        cv[1] = v[1];\n        cv[2] = v[2];\n\n        gl.uniform3f(location, v[0], v[1], v[2])\n    }",
    vec4: 'gl.uniform4f(location, v[0], v[1], v[2], v[3])',
    int: 'gl.uniform1i(location, v)',
    ivec2: 'gl.uniform2i(location, v[0], v[1])',
    ivec3: 'gl.uniform3i(location, v[0], v[1], v[2])',
    ivec4: 'gl.uniform4i(location, v[0], v[1], v[2], v[3])',
    uint: 'gl.uniform1ui(location, v)',
    uvec2: 'gl.uniform2ui(location, v[0], v[1])',
    uvec3: 'gl.uniform3ui(location, v[0], v[1], v[2])',
    uvec4: 'gl.uniform4ui(location, v[0], v[1], v[2], v[3])',
    bool: "\n    if(cv !== v)\n    {\n        cv.v = v;\n        gl.uniform1i(location, v)\n    }",
    bvec2: 'gl.uniform2i(location, v[0], v[1])',
    bvec3: 'gl.uniform3i(location, v[0], v[1], v[2])',
    bvec4: 'gl.uniform4i(location, v[0], v[1], v[2], v[3])',
    mat2: 'gl.uniformMatrix2fv(location, false, v)',
    mat3: 'gl.uniformMatrix3fv(location, false, v)',
    mat4: 'gl.uniformMatrix4fv(location, false, v)',
    sampler2D: 'gl.uniform1i(location, v)',
    samplerCube: 'gl.uniform1i(location, v)',
    sampler2DArray: 'gl.uniform1i(location, v)'
};
var GLSL_TO_ARRAY_SETTERS = {
    float: "gl.uniform1fv(location, v)",
    vec2: "gl.uniform2fv(location, v)",
    vec3: "gl.uniform3fv(location, v)",
    vec4: 'gl.uniform4fv(location, v)',
    mat4: 'gl.uniformMatrix4fv(location, false, v)',
    mat3: 'gl.uniformMatrix3fv(location, false, v)',
    mat2: 'gl.uniformMatrix2fv(location, false, v)',
    int: 'gl.uniform1iv(location, v)',
    ivec2: 'gl.uniform2iv(location, v)',
    ivec3: 'gl.uniform3iv(location, v)',
    ivec4: 'gl.uniform4iv(location, v)',
    uint: 'gl.uniform1uiv(location, v)',
    uvec2: 'gl.uniform2uiv(location, v)',
    uvec3: 'gl.uniform3uiv(location, v)',
    uvec4: 'gl.uniform4uiv(location, v)',
    bool: 'gl.uniform1iv(location, v)',
    bvec2: 'gl.uniform2iv(location, v)',
    bvec3: 'gl.uniform3iv(location, v)',
    bvec4: 'gl.uniform4iv(location, v)',
    sampler2D: 'gl.uniform1iv(location, v)',
    samplerCube: 'gl.uniform1iv(location, v)',
    sampler2DArray: 'gl.uniform1iv(location, v)'
};
function generateUniformsSync(group, uniformData) {
    var funcFragments = [
        "\n        var v = null;\n        var cv = null\n        var t = 0;\n        var gl = renderer.gl\n    "
    ];
    for(var i in group.uniforms){
        var data = uniformData[i];
        if (!data) {
            if (group.uniforms[i].group) {
                if (group.uniforms[i].ubo) funcFragments.push("\n                        renderer.shader.syncUniformBufferGroup(uv." + i + ", '" + i + "');\n                    ");
                else funcFragments.push("\n                        renderer.shader.syncUniformGroup(uv." + i + ", syncData);\n                    ");
            }
            continue;
        }
        var uniform = group.uniforms[i];
        var parsed = false;
        for(var j = 0; j < uniformParsers.length; j++)if (uniformParsers[j].test(data, uniform)) {
            funcFragments.push(uniformParsers[j].code(i, uniform));
            parsed = true;
            break;
        }
        if (!parsed) {
            var templateType = data.size === 1 ? GLSL_TO_SINGLE_SETTERS_CACHED : GLSL_TO_ARRAY_SETTERS;
            var template = templateType[data.type].replace('location', "ud[\"" + i + "\"].location");
            funcFragments.push("\n            cv = ud[\"" + i + "\"].value;\n            v = uv[\"" + i + "\"];\n            " + template + ";");
        }
    }
    /*
     * the introduction of syncData is to solve an issue where textures in uniform groups are not set correctly
     * the texture count was always starting from 0 in each group. This needs to increment each time a texture is used
     * no matter which group is being used
     *
     */ // eslint-disable-next-line no-new-func
    return new Function('ud', 'uv', 'renderer', 'syncData', funcFragments.join('\n'));
}
var fragTemplate = [
    'precision mediump float;',
    'void main(void){',
    'float test = 0.1;',
    '%forloop%',
    'gl_FragColor = vec4(0.0);',
    '}'
].join('\n');
function generateIfTestSrc(maxIfs) {
    var src = '';
    for(var i = 0; i < maxIfs; ++i){
        if (i > 0) src += '\nelse ';
        if (i < maxIfs - 1) src += "if(test == " + i + ".0){}";
    }
    return src;
}
function checkMaxIfStatementsInShader(maxIfs, gl) {
    if (maxIfs === 0) throw new Error('Invalid value of `0` passed to `checkMaxIfStatementsInShader`');
    var shader = gl.createShader(gl.FRAGMENT_SHADER);
    while(true){
        var fragmentSrc = fragTemplate.replace(/%forloop%/gi, generateIfTestSrc(maxIfs));
        gl.shaderSource(shader, fragmentSrc);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) maxIfs = maxIfs / 2 | 0;
        else break;
    }
    return maxIfs;
}
// Cache the result to prevent running this over and over
var unsafeEval;
/**
 * Not all platforms allow to generate function code (e.g., `new Function`).
 * this provides the platform-level detection.
 *
 * @private
 * @returns {boolean}
 */ function unsafeEvalSupported() {
    if (typeof unsafeEval === 'boolean') return unsafeEval;
    try {
        /* eslint-disable no-new-func */ var func = new Function('param1', 'param2', 'param3', 'return param1[param2] === param3;');
        /* eslint-enable no-new-func */ unsafeEval = func({
            a: 'b'
        }, 'a', 'b') === true;
    } catch (e) {
        unsafeEval = false;
    }
    return unsafeEval;
}
var defaultFragment = "varying vec2 vTextureCoord;\n\nuniform sampler2D uSampler;\n\nvoid main(void){\n   gl_FragColor *= texture2D(uSampler, vTextureCoord);\n}";
var defaultVertex = "attribute vec2 aVertexPosition;\nattribute vec2 aTextureCoord;\n\nuniform mat3 projectionMatrix;\n\nvarying vec2 vTextureCoord;\n\nvoid main(void){\n   gl_Position = vec4((projectionMatrix * vec3(aVertexPosition, 1.0)).xy, 0.0, 1.0);\n   vTextureCoord = aTextureCoord;\n}\n";
var UID$3 = 0;
var nameCache = {
};
/**
 * Helper class to create a shader program.
 *
 * @class
 * @memberof PIXI
 */ var Program = function() {
    /**
     * @param {string} [vertexSrc] - The source of the vertex shader.
     * @param {string} [fragmentSrc] - The source of the fragment shader.
     * @param {string} [name] - Name for shader
     */ function Program1(vertexSrc, fragmentSrc, name) {
        if (name === void 0) name = 'pixi-shader';
        this.id = UID$3++;
        /**
         * The vertex shader.
         *
         * @member {string}
         */ this.vertexSrc = vertexSrc || Program1.defaultVertexSrc;
        /**
         * The fragment shader.
         *
         * @member {string}
         */ this.fragmentSrc = fragmentSrc || Program1.defaultFragmentSrc;
        this.vertexSrc = this.vertexSrc.trim();
        this.fragmentSrc = this.fragmentSrc.trim();
        if (this.vertexSrc.substring(0, 8) !== '#version') {
            name = name.replace(/\s+/g, '-');
            if (nameCache[name]) {
                nameCache[name]++;
                name += "-" + nameCache[name];
            } else nameCache[name] = 1;
            this.vertexSrc = "#define SHADER_NAME " + name + "\n" + this.vertexSrc;
            this.fragmentSrc = "#define SHADER_NAME " + name + "\n" + this.fragmentSrc;
            this.vertexSrc = setPrecision(this.vertexSrc, _settings.settings.PRECISION_VERTEX, _constants.PRECISION.HIGH);
            this.fragmentSrc = setPrecision(this.fragmentSrc, _settings.settings.PRECISION_FRAGMENT, getMaxFragmentPrecision());
        }
        // currently this does not extract structs only default types
        // this is where we store shader references..
        this.glPrograms = {
        };
        this.syncUniforms = null;
    }
    Object.defineProperty(Program1, "defaultVertexSrc", {
        /**
         * The default vertex shader source
         *
         * @static
         * @constant
         * @member {string}
         */ get: function() {
            return defaultVertex;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Program1, "defaultFragmentSrc", {
        /**
         * The default fragment shader source
         *
         * @static
         * @constant
         * @member {string}
         */ get: function() {
            return defaultFragment;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * A short hand function to create a program based of a vertex and fragment shader
     * this method will also check to see if there is a cached program.
     *
     * @param {string} [vertexSrc] - The source of the vertex shader.
     * @param {string} [fragmentSrc] - The source of the fragment shader.
     * @param {string} [name=pixi-shader] - Name for shader
     *
     * @returns {PIXI.Program} an shiny new Pixi shader!
     */ Program1.from = function(vertexSrc, fragmentSrc, name) {
        var key = vertexSrc + fragmentSrc;
        var program = _utils.ProgramCache[key];
        if (!program) _utils.ProgramCache[key] = program = new Program1(vertexSrc, fragmentSrc, name);
        return program;
    };
    return Program1;
}();
/**
 * A helper class for shaders
 *
 * @class
 * @memberof PIXI
 */ var Shader = function() {
    /**
     * @param {PIXI.Program} [program] - The program the shader will use.
     * @param {object} [uniforms] - Custom uniforms to use to augment the built-in ones.
     */ function Shader1(program, uniforms) {
        /**
         * used internally to bind uniform buffer objects
         * @ignore
         */ this.uniformBindCount = 0;
        /**
         * Program that the shader uses
         *
         * @member {PIXI.Program}
         */ this.program = program;
        // lets see whats been passed in
        // uniforms should be converted to a uniform group
        if (uniforms) {
            if (uniforms instanceof UniformGroup) this.uniformGroup = uniforms;
            else this.uniformGroup = new UniformGroup(uniforms);
        } else this.uniformGroup = new UniformGroup({
        });
    }
    // TODO move to shader system..
    Shader1.prototype.checkUniformExists = function(name, group) {
        if (group.uniforms[name]) return true;
        for(var i in group.uniforms){
            var uniform = group.uniforms[i];
            if (uniform.group) {
                if (this.checkUniformExists(name, uniform)) return true;
            }
        }
        return false;
    };
    Shader1.prototype.destroy = function() {
        // usage count on programs?
        // remove if not used!
        this.uniformGroup = null;
    };
    Object.defineProperty(Shader1.prototype, "uniforms", {
        /**
         * Shader uniform values, shortcut for `uniformGroup.uniforms`
         * @readonly
         * @member {object}
         */ get: function() {
            return this.uniformGroup.uniforms;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * A short hand function to create a shader based of a vertex and fragment shader
     *
     * @param {string} [vertexSrc] - The source of the vertex shader.
     * @param {string} [fragmentSrc] - The source of the fragment shader.
     * @param {object} [uniforms] - Custom uniforms to use to augment the built-in ones.
     *
     * @returns {PIXI.Shader} an shiny new Pixi shader!
     */ Shader1.from = function(vertexSrc, fragmentSrc, uniforms) {
        var program = Program.from(vertexSrc, fragmentSrc);
        return new Shader1(program, uniforms);
    };
    return Shader1;
}();
/* eslint-disable max-len */ var BLEND = 0;
var OFFSET = 1;
var CULLING = 2;
var DEPTH_TEST = 3;
var WINDING = 4;
var DEPTH_MASK = 5;
/**
 * This is a WebGL state, and is is passed The WebGL StateManager.
 *
 * Each mesh rendered may require WebGL to be in a different state.
 * For example you may want different blend mode or to enable polygon offsets
 *
 * @class
 * @memberof PIXI
 */ var State = function() {
    function State1() {
        this.data = 0;
        this.blendMode = _constants.BLEND_MODES.NORMAL;
        this.polygonOffset = 0;
        this.blend = true;
        this.depthMask = true;
    //  this.depthTest = true;
    }
    Object.defineProperty(State1.prototype, "blend", {
        /**
         * Activates blending of the computed fragment color values
         *
         * @member {boolean}
         */ get: function() {
            return !!(this.data & 1 << BLEND);
        },
        set: function(value) {
            if (!!(this.data & 1 << BLEND) !== value) this.data ^= 1 << BLEND;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(State1.prototype, "offsets", {
        /**
         * Activates adding an offset to depth values of polygon's fragments
         *
         * @member {boolean}
         * @default false
         */ get: function() {
            return !!(this.data & 1 << OFFSET);
        },
        set: function(value) {
            if (!!(this.data & 1 << OFFSET) !== value) this.data ^= 1 << OFFSET;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(State1.prototype, "culling", {
        /**
         * Activates culling of polygons.
         *
         * @member {boolean}
         * @default false
         */ get: function() {
            return !!(this.data & 1 << CULLING);
        },
        set: function(value) {
            if (!!(this.data & 1 << CULLING) !== value) this.data ^= 1 << CULLING;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(State1.prototype, "depthTest", {
        /**
         * Activates depth comparisons and updates to the depth buffer.
         *
         * @member {boolean}
         * @default false
         */ get: function() {
            return !!(this.data & 1 << DEPTH_TEST);
        },
        set: function(value) {
            if (!!(this.data & 1 << DEPTH_TEST) !== value) this.data ^= 1 << DEPTH_TEST;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(State1.prototype, "depthMask", {
        /**
         * Enables or disables writing to the depth buffer.
         *
         * @member {boolean}
         * @default true
         */ get: function() {
            return !!(this.data & 1 << DEPTH_MASK);
        },
        set: function(value) {
            if (!!(this.data & 1 << DEPTH_MASK) !== value) this.data ^= 1 << DEPTH_MASK;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(State1.prototype, "clockwiseFrontFace", {
        /**
         * Specifies whether or not front or back-facing polygons can be culled.
         * @member {boolean}
         * @default false
         */ get: function() {
            return !!(this.data & 1 << WINDING);
        },
        set: function(value) {
            if (!!(this.data & 1 << WINDING) !== value) this.data ^= 1 << WINDING;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(State1.prototype, "blendMode", {
        /**
         * The blend mode to be applied when this state is set. Apply a value of `PIXI.BLEND_MODES.NORMAL` to reset the blend mode.
         * Setting this mode to anything other than NO_BLEND will automatically switch blending on.
         *
         * @member {number}
         * @default PIXI.BLEND_MODES.NORMAL
         * @see PIXI.BLEND_MODES
         */ get: function() {
            return this._blendMode;
        },
        set: function(value) {
            this.blend = value !== _constants.BLEND_MODES.NONE;
            this._blendMode = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(State1.prototype, "polygonOffset", {
        /**
         * The polygon offset. Setting this property to anything other than 0 will automatically enable polygon offset fill.
         *
         * @member {number}
         * @default 0
         */ get: function() {
            return this._polygonOffset;
        },
        set: function(value) {
            this.offsets = !!value;
            this._polygonOffset = value;
        },
        enumerable: false,
        configurable: true
    });
    State1.prototype.toString = function() {
        return "[@pixi/core:State " + ("blendMode=" + this.blendMode + " ") + ("clockwiseFrontFace=" + this.clockwiseFrontFace + " ") + ("culling=" + this.culling + " ") + ("depthMask=" + this.depthMask + " ") + ("polygonOffset=" + this.polygonOffset) + "]";
    };
    State1.for2d = function() {
        var state = new State1();
        state.depthTest = false;
        state.blend = true;
        return state;
    };
    return State1;
}();
var defaultVertex$1 = "attribute vec2 aVertexPosition;\n\nuniform mat3 projectionMatrix;\n\nvarying vec2 vTextureCoord;\n\nuniform vec4 inputSize;\nuniform vec4 outputFrame;\n\nvec4 filterVertexPosition( void )\n{\n    vec2 position = aVertexPosition * max(outputFrame.zw, vec2(0.)) + outputFrame.xy;\n\n    return vec4((projectionMatrix * vec3(position, 1.0)).xy, 0.0, 1.0);\n}\n\nvec2 filterTextureCoord( void )\n{\n    return aVertexPosition * (outputFrame.zw * inputSize.zw);\n}\n\nvoid main(void)\n{\n    gl_Position = filterVertexPosition();\n    vTextureCoord = filterTextureCoord();\n}\n";
var defaultFragment$1 = "varying vec2 vTextureCoord;\n\nuniform sampler2D uSampler;\n\nvoid main(void){\n   gl_FragColor = texture2D(uSampler, vTextureCoord);\n}\n";
/**
 * A filter is a special shader that applies post-processing effects to an input texture and writes into an output
 * render-target.
 *
 * {@link http://pixijs.io/examples/#/filters/blur-filter.js Example} of the
 * {@link PIXI.filters.BlurFilter BlurFilter}.
 *
 * ### Usage
 * Filters can be applied to any DisplayObject or Container.
 * PixiJS' `FilterSystem` renders the container into temporary Framebuffer,
 * then filter renders it to the screen.
 * Multiple filters can be added to the `filters` array property and stacked on each other.
 *
 * ```
 * const filter = new PIXI.Filter(myShaderVert, myShaderFrag, { myUniform: 0.5 });
 * const container = new PIXI.Container();
 * container.filters = [filter];
 * ```
 *
 * ### Previous Version Differences
 *
 * In PixiJS **v3**, a filter was always applied to _whole screen_.
 *
 * In PixiJS **v4**, a filter can be applied _only part of the screen_.
 * Developers had to create a set of uniforms to deal with coordinates.
 *
 * In PixiJS **v5** combines _both approaches_.
 * Developers can use normal coordinates of v3 and then allow filter to use partial Framebuffers,
 * bringing those extra uniforms into account.
 *
 * Also be aware that we have changed default vertex shader, please consult
 * {@link https://github.com/pixijs/pixi.js/wiki/v5-Creating-filters Wiki}.
 *
 * ### Frames
 *
 * The following table summarizes the coordinate spaces used in the filtering pipeline:
 *
 * <table>
 * <thead>
 *   <tr>
 *     <th>Coordinate Space</th>
 *     <th>Description</th>
 *   </tr>
 * </thead>
 * <tbody>
 *   <tr>
 *     <td>Texture Coordinates</td>
 *     <td>
 *         The texture (or UV) coordinates in the input base-texture's space. These are normalized into the (0,1) range along
 *         both axes.
 *     </td>
 *   </tr>
 *   <tr>
 *     <td>World Space</td>
 *     <td>
 *         A point in the same space as the world bounds of any display-object (i.e. in the scene graph's space).
 *     </td>
 *   </tr>
 *   <tr>
 *     <td>Physical Pixels</td>
 *     <td>
 *         This is base-texture's space with the origin on the top-left. You can calculate these by multiplying the texture
 *         coordinates by the dimensions of the texture.
 *     </td>
 *   </tr>
 * </tbody>
 * </table>
 *
 * ### Built-in Uniforms
 *
 * PixiJS viewport uses screen (CSS) coordinates, `(0, 0, renderer.screen.width, renderer.screen.height)`,
 * and `projectionMatrix` uniform maps it to the gl viewport.
 *
 * **uSampler**
 *
 * The most important uniform is the input texture that container was rendered into.
 * _Important note: as with all Framebuffers in PixiJS, both input and output are
 * premultiplied by alpha._
 *
 * By default, input normalized coordinates are passed to fragment shader with `vTextureCoord`.
 * Use it to sample the input.
 *
 * ```
 * const fragment = `
 * varying vec2 vTextureCoord;
 * uniform sampler2D uSampler;
 * void main(void)
 * {
 *    gl_FragColor = texture2D(uSampler, vTextureCoord);
 * }
 * `;
 *
 * const myFilter = new PIXI.Filter(null, fragment);
 * ```
 *
 * This filter is just one uniform less than {@link PIXI.filters.AlphaFilter AlphaFilter}.
 *
 * **outputFrame**
 *
 * The `outputFrame` holds the rectangle where filter is applied in screen (CSS) coordinates.
 * It's the same as `renderer.screen` for a fullscreen filter.
 * Only a part of  `outputFrame.zw` size of temporary Framebuffer is used,
 * `(0, 0, outputFrame.width, outputFrame.height)`,
 *
 * Filters uses this quad to normalized (0-1) space, its passed into `aVertexPosition` attribute.
 * To calculate vertex position in screen space using normalized (0-1) space:
 *
 * ```
 * vec4 filterVertexPosition( void )
 * {
 *     vec2 position = aVertexPosition * max(outputFrame.zw, vec2(0.)) + outputFrame.xy;
 *     return vec4((projectionMatrix * vec3(position, 1.0)).xy, 0.0, 1.0);
 * }
 * ```
 *
 * **inputSize**
 *
 * Temporary framebuffer is different, it can be either the size of screen, either power-of-two.
 * The `inputSize.xy` are size of temporary framebuffer that holds input.
 * The `inputSize.zw` is inverted, it's a shortcut to evade division inside the shader.
 *
 * Set `inputSize.xy = outputFrame.zw` for a fullscreen filter.
 *
 * To calculate input normalized coordinate, you have to map it to filter normalized space.
 * Multiply by `outputFrame.zw` to get input coordinate.
 * Divide by `inputSize.xy` to get input normalized coordinate.
 *
 * ```
 * vec2 filterTextureCoord( void )
 * {
 *     return aVertexPosition * (outputFrame.zw * inputSize.zw); // same as /inputSize.xy
 * }
 * ```
 * **resolution**
 *
 * The `resolution` is the ratio of screen (CSS) pixels to real pixels.
 *
 * **inputPixel**
 *
 * `inputPixel.xy` is the size of framebuffer in real pixels, same as `inputSize.xy * resolution`
 * `inputPixel.zw` is inverted `inputPixel.xy`.
 *
 * It's handy for filters that use neighbour pixels, like {@link PIXI.filters.FXAAFilter FXAAFilter}.
 *
 * **inputClamp**
 *
 * If you try to get info from outside of used part of Framebuffer - you'll get undefined behaviour.
 * For displacements, coordinates has to be clamped.
 *
 * The `inputClamp.xy` is left-top pixel center, you may ignore it, because we use left-top part of Framebuffer
 * `inputClamp.zw` is bottom-right pixel center.
 *
 * ```
 * vec4 color = texture2D(uSampler, clamp(modifiedTextureCoord, inputClamp.xy, inputClamp.zw))
 * ```
 * OR
 * ```
 * vec4 color = texture2D(uSampler, min(modifigedTextureCoord, inputClamp.zw))
 * ```
 *
 * ### Additional Information
 *
 * Complete documentation on Filter usage is located in the
 * {@link https://github.com/pixijs/pixi.js/wiki/v5-Creating-filters Wiki}.
 *
 * Since PixiJS only had a handful of built-in filters, additional filters can be downloaded
 * {@link https://github.com/pixijs/pixi-filters here} from the PixiJS Filters repository.
 *
 * @class
 * @memberof PIXI
 * @extends PIXI.Shader
 */ var Filter1 = function(_super) {
    __extends(Filter2, _super);
    /**
     * @param {string} [vertexSrc] - The source of the vertex shader.
     * @param {string} [fragmentSrc] - The source of the fragment shader.
     * @param {object} [uniforms] - Custom uniforms to use to augment the built-in ones.
     */ function Filter2(vertexSrc, fragmentSrc, uniforms) {
        var _this = this;
        var program = Program.from(vertexSrc || Filter2.defaultVertexSrc, fragmentSrc || Filter2.defaultFragmentSrc);
        _this = _super.call(this, program, uniforms) || this;
        /**
         * The padding of the filter. Some filters require extra space to breath such as a blur.
         * Increasing this will add extra width and height to the bounds of the object that the
         * filter is applied to.
         *
         * @member {number}
         */ _this.padding = 0;
        _this.resolution = _settings.settings.FILTER_RESOLUTION;
        /**
         * The samples of the filter.
         *
         * @member {PIXI.MSAA_QUALITY}
         */ _this.multisample = _settings.settings.FILTER_MULTISAMPLE;
        /**
         * If enabled is true the filter is applied, if false it will not.
         *
         * @member {boolean}
         */ _this.enabled = true;
        /**
         * If enabled, PixiJS will fit the filter area into boundaries for better performance.
         * Switch it off if it does not work for specific shader.
         *
         * @member {boolean}
         */ _this.autoFit = true;
        /**
         * The WebGL state the filter requires to render
         * @member {PIXI.State}
         */ _this.state = new State();
        return _this;
    }
    /**
     * Applies the filter
     *
     * @param {PIXI.FilterSystem} filterManager - The renderer to retrieve the filter from
     * @param {PIXI.RenderTexture} input - The input render target.
     * @param {PIXI.RenderTexture} output - The target to output to.
     * @param {PIXI.CLEAR_MODES} [clearMode] - Should the output be cleared before rendering to it.
     * @param {object} [currentState] - It's current state of filter.
     *        There are some useful properties in the currentState :
     *        target, filters, sourceFrame, destinationFrame, renderTarget, resolution
     */ Filter2.prototype.apply = function(filterManager, input, output, clearMode, _currentState) {
        // do as you please!
        filterManager.applyFilter(this, input, output, clearMode);
    // or just do a regular render..
    };
    Object.defineProperty(Filter2.prototype, "blendMode", {
        /**
         * Sets the blendmode of the filter
         *
         * @member {number}
         * @default PIXI.BLEND_MODES.NORMAL
         */ get: function() {
            return this.state.blendMode;
        },
        set: function(value) {
            this.state.blendMode = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Filter2.prototype, "resolution", {
        /**
         * The resolution of the filter. Setting this to be lower will lower the quality but
         * increase the performance of the filter.
         *
         * @member {number}
         */ get: function() {
            return this._resolution;
        },
        set: function(value) {
            this._resolution = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Filter2, "defaultVertexSrc", {
        /**
         * The default vertex shader source
         *
         * @static
         * @type {string}
         * @constant
         */ get: function() {
            return defaultVertex$1;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Filter2, "defaultFragmentSrc", {
        /**
         * The default fragment shader source
         *
         * @static
         * @type {string}
         * @constant
         */ get: function() {
            return defaultFragment$1;
        },
        enumerable: false,
        configurable: true
    });
    return Filter2;
}(Shader);
var vertex = "attribute vec2 aVertexPosition;\nattribute vec2 aTextureCoord;\n\nuniform mat3 projectionMatrix;\nuniform mat3 otherMatrix;\n\nvarying vec2 vMaskCoord;\nvarying vec2 vTextureCoord;\n\nvoid main(void)\n{\n    gl_Position = vec4((projectionMatrix * vec3(aVertexPosition, 1.0)).xy, 0.0, 1.0);\n\n    vTextureCoord = aTextureCoord;\n    vMaskCoord = ( otherMatrix * vec3( aTextureCoord, 1.0)  ).xy;\n}\n";
var fragment = "varying vec2 vMaskCoord;\nvarying vec2 vTextureCoord;\n\nuniform sampler2D uSampler;\nuniform sampler2D mask;\nuniform float alpha;\nuniform float npmAlpha;\nuniform vec4 maskClamp;\n\nvoid main(void)\n{\n    float clip = step(3.5,\n        step(maskClamp.x, vMaskCoord.x) +\n        step(maskClamp.y, vMaskCoord.y) +\n        step(vMaskCoord.x, maskClamp.z) +\n        step(vMaskCoord.y, maskClamp.w));\n\n    vec4 original = texture2D(uSampler, vTextureCoord);\n    vec4 masky = texture2D(mask, vMaskCoord);\n    float alphaMul = 1.0 - npmAlpha * (1.0 - masky.a);\n\n    original *= (alphaMul * masky.r * alpha * clip);\n\n    gl_FragColor = original;\n}\n";
var tempMat = new _math.Matrix();
/**
 * Class controls uv mapping from Texture normal space to BaseTexture normal space.
 *
 * Takes `trim` and `rotate` into account. May contain clamp settings for Meshes and TilingSprite.
 *
 * Can be used in Texture `uvMatrix` field, or separately, you can use different clamp settings on the same texture.
 * If you want to add support for texture region of certain feature or filter, that's what you're looking for.
 *
 * Takes track of Texture changes through `_lastTextureID` private field.
 * Use `update()` method call to track it from outside.
 *
 * @see PIXI.Texture
 * @see PIXI.Mesh
 * @see PIXI.TilingSprite
 * @class
 * @memberof PIXI
 */ var TextureMatrix = function() {
    /**
     *
     * @param {PIXI.Texture} texture - observed texture
     * @param {number} [clampMargin] - Changes frame clamping, 0.5 by default. Use -0.5 for extra border.
     * @constructor
     */ function TextureMatrix1(texture, clampMargin) {
        this._texture = texture;
        /**
         * Matrix operation that converts texture region coords to texture coords
         * @member {PIXI.Matrix}
         * @readonly
         */ this.mapCoord = new _math.Matrix();
        /**
         * Clamp region for normalized coords, left-top pixel center in xy , bottom-right in zw.
         * Calculated based on clampOffset.
         * @member {Float32Array}
         * @readonly
         */ this.uClampFrame = new Float32Array(4);
        /**
         * Normalized clamp offset.
         * Calculated based on clampOffset.
         * @member {Float32Array}
         * @readonly
         */ this.uClampOffset = new Float32Array(2);
        /**
         * Tracks Texture frame changes
         * @member {number}
         * @protected
         */ this._textureID = -1;
        /**
         * Tracks Texture frame changes
         * @member {number}
         * @protected
         */ this._updateID = 0;
        /**
         * Changes frame clamping
         * Works with TilingSprite and Mesh
         * Change to 1.5 if you texture has repeated right and bottom lines, that leads to smoother borders
         *
         * @default 0
         * @member {number}
         */ this.clampOffset = 0;
        /**
         * Changes frame clamping
         * Works with TilingSprite and Mesh
         * Change to -0.5 to add a pixel to the edge, recommended for transparent trimmed textures in atlas
         *
         * @default 0.5
         * @member {number}
         */ this.clampMargin = typeof clampMargin === 'undefined' ? 0.5 : clampMargin;
        /**
         * If texture size is the same as baseTexture
         * @member {boolean}
         * @default false
         * @readonly
         */ this.isSimple = false;
    }
    Object.defineProperty(TextureMatrix1.prototype, "texture", {
        /**
         * texture property
         * @member {PIXI.Texture}
         */ get: function() {
            return this._texture;
        },
        set: function(value) {
            this._texture = value;
            this._textureID = -1;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Multiplies uvs array to transform
     * @param {Float32Array} uvs - mesh uvs
     * @param {Float32Array} [out=uvs] - output
     * @returns {Float32Array} output
     */ TextureMatrix1.prototype.multiplyUvs = function(uvs, out) {
        if (out === undefined) out = uvs;
        var mat = this.mapCoord;
        for(var i = 0; i < uvs.length; i += 2){
            var x = uvs[i];
            var y = uvs[i + 1];
            out[i] = x * mat.a + y * mat.c + mat.tx;
            out[i + 1] = x * mat.b + y * mat.d + mat.ty;
        }
        return out;
    };
    /**
     * updates matrices if texture was changed
     * @param {boolean} [forceUpdate=false] - if true, matrices will be updated any case
     * @returns {boolean} whether or not it was updated
     */ TextureMatrix1.prototype.update = function(forceUpdate) {
        var tex = this._texture;
        if (!tex || !tex.valid) return false;
        if (!forceUpdate && this._textureID === tex._updateID) return false;
        this._textureID = tex._updateID;
        this._updateID++;
        var uvs = tex._uvs;
        this.mapCoord.set(uvs.x1 - uvs.x0, uvs.y1 - uvs.y0, uvs.x3 - uvs.x0, uvs.y3 - uvs.y0, uvs.x0, uvs.y0);
        var orig = tex.orig;
        var trim = tex.trim;
        if (trim) {
            tempMat.set(orig.width / trim.width, 0, 0, orig.height / trim.height, -trim.x / trim.width, -trim.y / trim.height);
            this.mapCoord.append(tempMat);
        }
        var texBase = tex.baseTexture;
        var frame = this.uClampFrame;
        var margin = this.clampMargin / texBase.resolution;
        var offset = this.clampOffset;
        frame[0] = (tex._frame.x + margin + offset) / texBase.width;
        frame[1] = (tex._frame.y + margin + offset) / texBase.height;
        frame[2] = (tex._frame.x + tex._frame.width - margin + offset) / texBase.width;
        frame[3] = (tex._frame.y + tex._frame.height - margin + offset) / texBase.height;
        this.uClampOffset[0] = offset / texBase.realWidth;
        this.uClampOffset[1] = offset / texBase.realHeight;
        this.isSimple = tex._frame.width === texBase.width && tex._frame.height === texBase.height && tex.rotate === 0;
        return true;
    };
    return TextureMatrix1;
}();
/**
 * This handles a Sprite acting as a mask, as opposed to a Graphic.
 *
 * WebGL only.
 *
 * @class
 * @extends PIXI.Filter
 * @memberof PIXI
 */ var SpriteMaskFilter1 = function(_super) {
    __extends(SpriteMaskFilter2, _super);
    /**
     * @param {PIXI.Sprite} sprite - the target sprite
     */ function SpriteMaskFilter2(sprite) {
        var _this = this;
        var maskMatrix = new _math.Matrix();
        _this = _super.call(this, vertex, fragment) || this;
        sprite.renderable = false;
        /**
         * Sprite mask
         * @member {PIXI.Sprite}
         */ _this.maskSprite = sprite;
        /**
         * Mask matrix
         * @member {PIXI.Matrix}
         */ _this.maskMatrix = maskMatrix;
        return _this;
    }
    /**
     * Applies the filter
     *
     * @param {PIXI.FilterSystem} filterManager - The renderer to retrieve the filter from
     * @param {PIXI.RenderTexture} input - The input render target.
     * @param {PIXI.RenderTexture} output - The target to output to.
     * @param {PIXI.CLEAR_MODES} clearMode - Should the output be cleared before rendering to it.
     */ SpriteMaskFilter2.prototype.apply = function(filterManager, input, output, clearMode) {
        var maskSprite = this.maskSprite;
        var tex = maskSprite._texture;
        if (!tex.valid) return;
        if (!tex.uvMatrix) // margin = 0.0, let it bleed a bit, shader code becomes easier
        // assuming that atlas textures were made with 1-pixel padding
        tex.uvMatrix = new TextureMatrix(tex, 0);
        tex.uvMatrix.update();
        this.uniforms.npmAlpha = tex.baseTexture.alphaMode ? 0 : 1;
        this.uniforms.mask = tex;
        // get _normalized sprite texture coords_ and convert them to _normalized atlas texture coords_ with `prepend`
        this.uniforms.otherMatrix = filterManager.calculateSpriteMatrix(this.maskMatrix, maskSprite).prepend(tex.uvMatrix.mapCoord);
        this.uniforms.alpha = maskSprite.worldAlpha;
        this.uniforms.maskClamp = tex.uvMatrix.uClampFrame;
        filterManager.applyFilter(this, input, output, clearMode);
    };
    return SpriteMaskFilter2;
}(Filter1);
/**
 * System plugin to the renderer to manage masks.
 *
 * There are three built-in types of masking:
 * * **Scissor Masking**: Scissor masking discards pixels that are outside of a rectangle called the scissor box. It is
 *  the most performant as the scissor test is inexpensive. However, it can only be used when the mask is rectangular.
 * * **Stencil Masking**: Stencil masking discards pixels that don't overlap with the pixels rendered into the stencil
 *  buffer. It is the next fastest option as it does not require rendering into a separate framebuffer. However, it does
 *  cause the mask to be rendered **twice** for each masking operation; hence, minimize the rendering cost of your masks.
 * * **Sprite Mask Filtering**: Sprite mask filtering discards pixels based on the red channel of the sprite-mask's
 *  texture. (Generally, the masking texture is grayscale). Using advanced techniques, you might be able to embed this
 *  type of masking in a custom shader - and hence, bypassing the masking system fully for performance wins.
 *
 * The best type of masking is auto-detected when you `push` one. To use scissor masking, you must pass in a `Graphics`
 * object with just a rectangle drawn.
 *
 * ## Mask Stacks
 *
 * In the scene graph, masks can be applied recursively, i.e. a mask can be applied during a masking operation. The mask
 * stack stores the currently applied masks in order. Each {@link PIXI.BaseRenderTexture} holds its own mask stack, i.e.
 * when you switch render-textures, the old masks only applied when you switch back to rendering to the old render-target.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var MaskSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function MaskSystem1(renderer) {
        this.renderer = renderer;
        /**
         * Enable scissor masking.
         *
         * @member {boolean}
         * @readonly
         */ this.enableScissor = true;
        /**
         * Pool of used sprite mask filters
         * @member {PIXI.SpriteMaskFilter[]}
         * @readonly
         */ this.alphaMaskPool = [];
        /**
         * Pool of mask data
         * @member {PIXI.MaskData[]}
         * @readonly
         */ this.maskDataPool = [];
        this.maskStack = [];
        /**
         * Current index of alpha mask pool
         * @member {number}
         * @default 0
         * @readonly
         */ this.alphaMaskIndex = 0;
    }
    /**
     * Changes the mask stack that is used by this System.
     *
     * @param {PIXI.MaskData[]} maskStack - The mask stack
     */ MaskSystem1.prototype.setMaskStack = function(maskStack) {
        this.maskStack = maskStack;
        this.renderer.scissor.setMaskStack(maskStack);
        this.renderer.stencil.setMaskStack(maskStack);
    };
    /**
     * Enables the mask and appends it to the current mask stack.
     *
     * NOTE: The batch renderer should be flushed beforehand to prevent pending renders from being masked.
     *
     * @param {PIXI.DisplayObject} target - Display Object to push the mask to
     * @param {PIXI.MaskData|PIXI.Sprite|PIXI.Graphics|PIXI.DisplayObject} maskData - The masking data.
     */ MaskSystem1.prototype.push = function(target, maskDataOrTarget) {
        var maskData = maskDataOrTarget;
        if (!maskData.isMaskData) {
            var d = this.maskDataPool.pop() || new MaskData();
            d.pooled = true;
            d.maskObject = maskDataOrTarget;
            maskData = d;
        }
        if (maskData.autoDetect) this.detect(maskData);
        maskData.copyCountersOrReset(this.maskStack[this.maskStack.length - 1]);
        maskData._target = target;
        switch(maskData.type){
            case _constants.MASK_TYPES.SCISSOR:
                this.maskStack.push(maskData);
                this.renderer.scissor.push(maskData);
                break;
            case _constants.MASK_TYPES.STENCIL:
                this.maskStack.push(maskData);
                this.renderer.stencil.push(maskData);
                break;
            case _constants.MASK_TYPES.SPRITE:
                maskData.copyCountersOrReset(null);
                this.pushSpriteMask(maskData);
                this.maskStack.push(maskData);
                break;
        }
    };
    /**
     * Removes the last mask from the mask stack and doesn't return it.
     *
     * NOTE: The batch renderer should be flushed beforehand to render the masked contents before the mask is removed.
     *
     * @param {PIXI.DisplayObject} target - Display Object to pop the mask from
     */ MaskSystem1.prototype.pop = function(target) {
        var maskData = this.maskStack.pop();
        if (!maskData || maskData._target !== target) // TODO: add an assert when we have it
        return;
        switch(maskData.type){
            case _constants.MASK_TYPES.SCISSOR:
                this.renderer.scissor.pop();
                break;
            case _constants.MASK_TYPES.STENCIL:
                this.renderer.stencil.pop(maskData.maskObject);
                break;
            case _constants.MASK_TYPES.SPRITE:
                this.popSpriteMask();
                break;
        }
        maskData.reset();
        if (maskData.pooled) this.maskDataPool.push(maskData);
    };
    /**
     * Sets type of MaskData based on its maskObject
     * @param {PIXI.MaskData} maskData
     */ MaskSystem1.prototype.detect = function(maskData) {
        var maskObject = maskData.maskObject;
        if (maskObject.isSprite) {
            maskData.type = _constants.MASK_TYPES.SPRITE;
            return;
        }
        maskData.type = _constants.MASK_TYPES.STENCIL;
        // detect scissor in graphics
        if (this.enableScissor && maskObject.isFastRect && maskObject.isFastRect()) {
            var matrix = maskObject.worldTransform;
            // TODO: move the check to the matrix itself
            // we are checking that its orthogonal and x rotation is 0 90 180 or 270
            var rotX = Math.atan2(matrix.b, matrix.a);
            var rotXY = Math.atan2(matrix.d, matrix.c);
            // use the nearest degree to 0.01
            rotX = Math.round(rotX * (180 / Math.PI) * 100);
            rotXY = Math.round(rotXY * (180 / Math.PI) * 100) - rotX;
            rotX = (rotX % 9000 + 9000) % 9000;
            rotXY = (rotXY % 18000 + 18000) % 18000;
            if (rotX === 0 && rotXY === 9000) maskData.type = _constants.MASK_TYPES.SCISSOR;
        }
    };
    /**
     * Applies the Mask and adds it to the current filter stack.
     *
     * @param {PIXI.MaskData} maskData - Sprite to be used as the mask
     */ MaskSystem1.prototype.pushSpriteMask = function(maskData) {
        var _a, _b;
        var maskObject = maskData.maskObject;
        var target = maskData._target;
        var alphaMaskFilter = this.alphaMaskPool[this.alphaMaskIndex];
        if (!alphaMaskFilter) alphaMaskFilter = this.alphaMaskPool[this.alphaMaskIndex] = [
            new SpriteMaskFilter1(maskObject)
        ];
        var renderer = this.renderer;
        var renderTextureSystem = renderer.renderTexture;
        var resolution;
        var multisample;
        if (renderTextureSystem.current) {
            var renderTexture = renderTextureSystem.current;
            resolution = maskData.resolution || renderTexture.resolution;
            multisample = (_a = maskData.multisample) !== null && _a !== void 0 ? _a : renderTexture.multisample;
        } else {
            resolution = maskData.resolution || renderer.resolution;
            multisample = (_b = maskData.multisample) !== null && _b !== void 0 ? _b : renderer.multisample;
        }
        alphaMaskFilter[0].resolution = resolution;
        alphaMaskFilter[0].multisample = multisample;
        alphaMaskFilter[0].maskSprite = maskObject;
        var stashFilterArea = target.filterArea;
        target.filterArea = maskObject.getBounds(true);
        renderer.filter.push(target, alphaMaskFilter);
        target.filterArea = stashFilterArea;
        this.alphaMaskIndex++;
    };
    /**
     * Removes the last filter from the filter stack and doesn't return it.
     */ MaskSystem1.prototype.popSpriteMask = function() {
        this.renderer.filter.pop();
        this.alphaMaskIndex--;
    };
    /**
     * @ignore
     */ MaskSystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    return MaskSystem1;
}();
/**
 * System plugin to the renderer to manage specific types of masking operations.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var AbstractMaskSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function AbstractMaskSystem1(renderer) {
        this.renderer = renderer;
        /**
         * The mask stack
         * @member {PIXI.MaskData[]}
         */ this.maskStack = [];
        /**
         * Constant for gl.enable
         * @member {number}
         * @private
         */ this.glConst = 0;
    }
    /**
     * gets count of masks of certain type
     * @returns {number}
     */ AbstractMaskSystem1.prototype.getStackLength = function() {
        return this.maskStack.length;
    };
    /**
     * Changes the mask stack that is used by this System.
     *
     * @param {PIXI.MaskData[]} maskStack - The mask stack
     */ AbstractMaskSystem1.prototype.setMaskStack = function(maskStack) {
        var gl = this.renderer.gl;
        var curStackLen = this.getStackLength();
        this.maskStack = maskStack;
        var newStackLen = this.getStackLength();
        if (newStackLen !== curStackLen) {
            if (newStackLen === 0) gl.disable(this.glConst);
            else {
                gl.enable(this.glConst);
                this._useCurrent();
            }
        }
    };
    /**
     * Setup renderer to use the current mask data.
     * @private
     */ AbstractMaskSystem1.prototype._useCurrent = function() {
    // OVERWRITE;
    };
    /**
     * Destroys the mask stack.
     *
     */ AbstractMaskSystem1.prototype.destroy = function() {
        this.renderer = null;
        this.maskStack = null;
    };
    return AbstractMaskSystem1;
}();
/**
 * System plugin to the renderer to manage scissor masking.
 *
 * Scissor masking discards pixels outside of a rectangle called the scissor box. The scissor box is in the framebuffer
 * viewport's space; however, the mask's rectangle is projected from world-space to viewport space automatically
 * by this system.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var ScissorSystem1 = function(_super) {
    __extends(ScissorSystem2, _super);
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function ScissorSystem2(renderer) {
        var _this = _super.call(this, renderer) || this;
        _this.glConst = WebGLRenderingContext.SCISSOR_TEST;
        return _this;
    }
    ScissorSystem2.prototype.getStackLength = function() {
        var maskData = this.maskStack[this.maskStack.length - 1];
        if (maskData) return maskData._scissorCounter;
        return 0;
    };
    /**
     * Applies the Mask and adds it to the current stencil stack.
     *
     * @author alvin
     * @param {PIXI.MaskData} maskData - The mask data
     */ ScissorSystem2.prototype.push = function(maskData) {
        var maskObject = maskData.maskObject;
        maskObject.renderable = true;
        var prevData = maskData._scissorRect;
        var bounds = maskObject.getBounds(true);
        var gl = this.renderer.gl;
        maskObject.renderable = false;
        if (prevData) bounds.fit(prevData);
        else gl.enable(gl.SCISSOR_TEST);
        maskData._scissorCounter++;
        maskData._scissorRect = bounds;
        this._useCurrent();
    };
    /**
     * This should be called after a mask is popped off the mask stack. It will rebind the scissor box to be latest with the
     * last mask in the stack.
     *
     * This can also be called when you directly modify the scissor box and want to restore PixiJS state.
     */ ScissorSystem2.prototype.pop = function() {
        var gl = this.renderer.gl;
        if (this.getStackLength() > 0) this._useCurrent();
        else gl.disable(gl.SCISSOR_TEST);
    };
    /**
     * Setup renderer to use the current scissor data.
     * @private
     */ ScissorSystem2.prototype._useCurrent = function() {
        var rect = this.maskStack[this.maskStack.length - 1]._scissorRect;
        var rt = this.renderer.renderTexture.current;
        var _a = this.renderer.projection, transform = _a.transform, sourceFrame = _a.sourceFrame, destinationFrame = _a.destinationFrame;
        var resolution = rt ? rt.resolution : this.renderer.resolution;
        var sx = destinationFrame.width / sourceFrame.width;
        var sy = destinationFrame.height / sourceFrame.height;
        var x = ((rect.x - sourceFrame.x) * sx + destinationFrame.x) * resolution;
        var y = ((rect.y - sourceFrame.y) * sy + destinationFrame.y) * resolution;
        var width = rect.width * sx * resolution;
        var height = rect.height * sy * resolution;
        if (transform) {
            x += transform.tx * resolution;
            y += transform.ty * resolution;
        }
        if (!rt) // flipY. In future we'll have it over renderTextures as an option
        y = this.renderer.height - height - y;
        x = Math.round(x);
        y = Math.round(y);
        width = Math.round(width);
        height = Math.round(height);
        this.renderer.gl.scissor(x, y, width, height);
    };
    return ScissorSystem2;
}(AbstractMaskSystem);
/**
 * System plugin to the renderer to manage stencils (used for masks).
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var StencilSystem1 = function(_super) {
    __extends(StencilSystem2, _super);
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function StencilSystem2(renderer) {
        var _this = _super.call(this, renderer) || this;
        _this.glConst = WebGLRenderingContext.STENCIL_TEST;
        return _this;
    }
    StencilSystem2.prototype.getStackLength = function() {
        var maskData = this.maskStack[this.maskStack.length - 1];
        if (maskData) return maskData._stencilCounter;
        return 0;
    };
    /**
     * Applies the Mask and adds it to the current stencil stack.
     *
     * @param {PIXI.MaskData} maskData - The mask data
     */ StencilSystem2.prototype.push = function(maskData) {
        var maskObject = maskData.maskObject;
        var gl = this.renderer.gl;
        var prevMaskCount = maskData._stencilCounter;
        if (prevMaskCount === 0) {
            // force use stencil texture in current framebuffer
            this.renderer.framebuffer.forceStencil();
            gl.enable(gl.STENCIL_TEST);
        }
        maskData._stencilCounter++;
        // Increment the reference stencil value where the new mask overlaps with the old ones.
        gl.colorMask(false, false, false, false);
        gl.stencilFunc(gl.EQUAL, prevMaskCount, 4294967295);
        gl.stencilOp(gl.KEEP, gl.KEEP, gl.INCR);
        maskObject.renderable = true;
        maskObject.render(this.renderer);
        this.renderer.batch.flush();
        maskObject.renderable = false;
        this._useCurrent();
    };
    /**
     * Pops stencil mask. MaskData is already removed from stack
     *
     * @param {PIXI.DisplayObject} maskObject - object of popped mask data
     */ StencilSystem2.prototype.pop = function(maskObject) {
        var gl = this.renderer.gl;
        if (this.getStackLength() === 0) {
            // the stack is empty!
            gl.disable(gl.STENCIL_TEST);
            gl.clearStencil(0);
            gl.clear(gl.STENCIL_BUFFER_BIT);
        } else {
            // Decrement the reference stencil value where the popped mask overlaps with the other ones
            gl.colorMask(false, false, false, false);
            gl.stencilOp(gl.KEEP, gl.KEEP, gl.DECR);
            maskObject.renderable = true;
            maskObject.render(this.renderer);
            this.renderer.batch.flush();
            maskObject.renderable = false;
            this._useCurrent();
        }
    };
    /**
     * Setup renderer to use the current stencil data.
     * @private
     */ StencilSystem2.prototype._useCurrent = function() {
        var gl = this.renderer.gl;
        gl.colorMask(true, true, true, true);
        gl.stencilFunc(gl.EQUAL, this.getStackLength(), 4294967295);
        gl.stencilOp(gl.KEEP, gl.KEEP, gl.KEEP);
    };
    return StencilSystem2;
}(AbstractMaskSystem);
/**
 * System plugin to the renderer to manage the projection matrix.
 *
 * The `projectionMatrix` is a global uniform provided to all shaders. It is used to transform points in world space to
 * normalized device coordinates.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var ProjectionSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function ProjectionSystem1(renderer) {
        this.renderer = renderer;
        /**
         * The destination frame used to calculate the current projection matrix.
         *
         * The destination frame is the rectangle in the render-target into which contents are rendered. If rendering
         * to the screen, the origin is on the top-left. If rendering to a framebuffer, the origin is on the
         * bottom-left. This "flipping" phenomenon is because of WebGL convention for (shader) texture coordinates, where
         * the bottom-left corner is (0,0). It allows display-objects to map their (0,0) position in local-space (top-left)
         * to (0,0) in texture space (bottom-left). In other words, a sprite's top-left corner actually renders the
         * texture's bottom-left corner. You will also notice this when using a tool like SpectorJS to view your textures
         * at runtime.
         *
         * The destination frame's dimensions (width,height) should be equal to the source frame. This is because,
         * otherwise, the contents will be scaled to fill the destination frame. Similarly, the destination frame's (x,y)
         * coordinates are (0,0) unless you know what you're doing.
         *
         *
         * @member {PIXI.Rectangle}
         * @readonly
         */ this.destinationFrame = null;
        /**
         * The source frame used to calculate the current projection matrix.
         *
         * The source frame is the rectangle in world space containing the contents to be rendered.
         *
         * @member {PIXI.Rectangle}
         * @readonly
         */ this.sourceFrame = null;
        /**
         * Default destination frame
         *
         * This is not used internally. It is not advised to use this feature specifically unless you know what
         * you're doing. The `update` method will default to this frame if you do not pass the destination frame.
         *
         * @member {PIXI.Rectangle}
         * @readonly
         */ this.defaultFrame = null;
        /**
         * Projection matrix
         *
         * This matrix can be used to transform points from world space to normalized device coordinates, and is calculated
         * from the sourceFrame → destinationFrame mapping provided.
         *
         * The renderer's `globalUniforms` keeps a reference to this, and so it is available for all shaders to use as a
         * uniform.
         *
         * @member {PIXI.Matrix}
         * @readonly
         */ this.projectionMatrix = new _math.Matrix();
        /**
         * A transform to be appended to the projection matrix.
         *
         * This can be used to transform points in world-space one last time before they are outputted by the shader. You can
         * use to rotate the whole scene, for example. Remember to clear it once you've rendered everything.
         *
         * @member {PIXI.Matrix}
         */ this.transform = null;
    }
    /**
     * Updates the projection-matrix based on the sourceFrame → destinationFrame mapping provided.
     *
     * NOTE: It is expected you call `renderer.framebuffer.setViewport(destinationFrame)` after this. This is because
     * the framebuffer viewport converts shader vertex output in normalized device coordinates to window coordinates.
     *
     * NOTE-2: {@link RenderTextureSystem#bind} updates the projection-matrix when you bind a render-texture. It is expected
     * that you dirty the current bindings when calling this manually.
     *
     * @param {PIXI.Rectangle} destinationFrame - The rectangle in the render-target to render the contents
     *  into. If rendering to the canvas, the origin is on the top-left; if rendering to a render-texture, the origin
     *  is on the bottom-left.
     * @param {PIXI.Rectangle} sourceFrame - The rectangle in world space that contains the contents being rendered.
     * @param {Number} resolution - The resolution of the render-target, which is the ratio of world-space (or CSS) pixels
     *  to physical pixels.
     * @param {boolean} root - Whether the render-target is the screen. This is required because rendering to textures
     *  is y-flipped (i.e. upside down relative to the screen).
     */ ProjectionSystem1.prototype.update = function(destinationFrame, sourceFrame, resolution, root) {
        this.destinationFrame = destinationFrame || this.destinationFrame || this.defaultFrame;
        this.sourceFrame = sourceFrame || this.sourceFrame || destinationFrame;
        // Calculate object-space to clip-space projection
        this.calculateProjection(this.destinationFrame, this.sourceFrame, resolution, root);
        if (this.transform) this.projectionMatrix.append(this.transform);
        var renderer = this.renderer;
        renderer.globalUniforms.uniforms.projectionMatrix = this.projectionMatrix;
        renderer.globalUniforms.update();
        // this will work for now
        // but would be sweet to stick and even on the global uniforms..
        if (renderer.shader.shader) renderer.shader.syncUniformGroup(renderer.shader.shader.uniforms.globals);
    };
    /**
     * Calculates the `projectionMatrix` to map points inside `sourceFrame` to inside `destinationFrame`.
     *
     * @param {PIXI.Rectangle} destinationFrame - The destination frame in the render-target.
     * @param {PIXI.Rectangle} sourceFrame - The source frame in world space.
     * @param {Number} resolution - The render-target's resolution, i.e. ratio of CSS to physical pixels.
     * @param {boolean} root - Whether rendering into the screen. Otherwise, if rendering to a framebuffer, the projection
     *  is y-flipped.
     */ ProjectionSystem1.prototype.calculateProjection = function(_destinationFrame, sourceFrame, _resolution, root) {
        var pm = this.projectionMatrix;
        var sign = !root ? 1 : -1;
        pm.identity();
        pm.a = 1 / sourceFrame.width * 2;
        pm.d = sign * (1 / sourceFrame.height * 2);
        pm.tx = -1 - sourceFrame.x * pm.a;
        pm.ty = -sign - sourceFrame.y * pm.d;
    };
    /**
     * Sets the transform of the active render target to the given matrix
     *
     * @param {PIXI.Matrix} matrix - The transformation matrix
     */ ProjectionSystem1.prototype.setTransform = function(_matrix) {
    // this._activeRenderTarget.transform = matrix;
    };
    /**
     * @ignore
     */ ProjectionSystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    return ProjectionSystem1;
}();
// Temporary rectangle for assigned sourceFrame or destinationFrame
var tempRect = new _math.Rectangle();
// Temporary rectangle for renderTexture destinationFrame
var tempRect2 = new _math.Rectangle();
/* eslint-disable max-len */ /**
 * System plugin to the renderer to manage render textures.
 *
 * Should be added after FramebufferSystem
 *
 * ### Frames
 *
 * The `RenderTextureSystem` holds a sourceFrame → destinationFrame projection. The following table explains the different
 * coordinate spaces used:
 *
 * | Frame                  | Description                                                      | Coordinate System                                       |
 * | ---------------------- | ---------------------------------------------------------------- | ------------------------------------------------------- |
 * | sourceFrame            | The rectangle inside of which display-objects are being rendered | **World Space**: The origin on the top-left             |
 * | destinationFrame       | The rectangle in the render-target (canvas or texture) into which contents should be rendered | If rendering to the canvas, this is in screen space and the origin is on the top-left. If rendering to a render-texture, this is in its base-texture's space with the origin on the bottom-left.  |
 * | viewportFrame          | The framebuffer viewport corresponding to the destination-frame  | **Window Coordinates**: The origin is always on the bottom-left. |
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var RenderTextureSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function RenderTextureSystem1(renderer) {
        this.renderer = renderer;
        /**
         * The clear background color as rgba
         * @member {number[]}
         */ this.clearColor = renderer._backgroundColorRgba;
        // TODO move this property somewhere else!
        /**
         * List of masks for the StencilSystem
         * @member {PIXI.Graphics[]}
         * @readonly
         */ this.defaultMaskStack = [];
        // empty render texture?
        /**
         * Render texture
         * @member {PIXI.RenderTexture}
         * @readonly
         */ this.current = null;
        /**
         * The source frame for the render-target's projection mapping.
         *
         * See {@link PIXI.ProjectionSystem#sourceFrame} for more details.
         *
         * @member {PIXI.Rectangle}
         * @readonly
         */ this.sourceFrame = new _math.Rectangle();
        /**
         * The destination frame for the render-target's projection mapping.
         *
         * See {@link PIXI.Projection#destinationFrame} for more details.
         *
         * @member {PIXI.Rectangle}
         * @readonly
         */ this.destinationFrame = new _math.Rectangle();
        /**
         * The viewport frame for the render-target's viewport binding. This is equal to the destination-frame
         * for render-textures, while it is y-flipped when rendering to the screen (i.e. its origin is always on
         * the bottom-left).
         *
         * @member {PIXI.Rectangle}
         * @readonly
         */ this.viewportFrame = new _math.Rectangle();
    }
    /**
     * Bind the current render texture
     *
     * @param {PIXI.RenderTexture} [renderTexture] - RenderTexture to bind, by default its `null`, the screen
     * @param {PIXI.Rectangle} [sourceFrame] - part of screen that is mapped to the renderTexture
     * @param {PIXI.Rectangle} [destinationFrame] - part of renderTexture, by default it has the same size as sourceFrame
     */ RenderTextureSystem1.prototype.bind = function(renderTexture, sourceFrame, destinationFrame) {
        if (renderTexture === void 0) renderTexture = null;
        var renderer = this.renderer;
        this.current = renderTexture;
        var baseTexture;
        var framebuffer;
        var resolution;
        if (renderTexture) {
            baseTexture = renderTexture.baseTexture;
            resolution = baseTexture.resolution;
            if (!sourceFrame) {
                tempRect.width = renderTexture.frame.width;
                tempRect.height = renderTexture.frame.height;
                sourceFrame = tempRect;
            }
            if (!destinationFrame) {
                tempRect2.x = renderTexture.frame.x;
                tempRect2.y = renderTexture.frame.y;
                tempRect2.width = sourceFrame.width;
                tempRect2.height = sourceFrame.height;
                destinationFrame = tempRect2;
            }
            framebuffer = baseTexture.framebuffer;
        } else {
            resolution = renderer.resolution;
            if (!sourceFrame) {
                tempRect.width = renderer.screen.width;
                tempRect.height = renderer.screen.height;
                sourceFrame = tempRect;
            }
            if (!destinationFrame) {
                destinationFrame = tempRect;
                destinationFrame.width = sourceFrame.width;
                destinationFrame.height = sourceFrame.height;
            }
        }
        var viewportFrame = this.viewportFrame;
        viewportFrame.x = destinationFrame.x * resolution;
        viewportFrame.y = destinationFrame.y * resolution;
        viewportFrame.width = destinationFrame.width * resolution;
        viewportFrame.height = destinationFrame.height * resolution;
        if (!renderTexture) viewportFrame.y = renderer.view.height - (viewportFrame.y + viewportFrame.height);
        viewportFrame.ceil();
        this.renderer.framebuffer.bind(framebuffer, viewportFrame);
        this.renderer.projection.update(destinationFrame, sourceFrame, resolution, !framebuffer);
        if (renderTexture) this.renderer.mask.setMaskStack(baseTexture.maskStack);
        else this.renderer.mask.setMaskStack(this.defaultMaskStack);
        this.sourceFrame.copyFrom(sourceFrame);
        this.destinationFrame.copyFrom(destinationFrame);
    };
    /**
     * Erases the render texture and fills the drawing area with a colour
     *
     * @param {number[]} [clearColor] - The color as rgba, default to use the renderer backgroundColor
     * @param {PIXI.BUFFER_BITS} [mask=BUFFER_BITS.COLOR | BUFFER_BITS.DEPTH] - Bitwise OR of masks
     *  that indicate the buffers to be cleared, by default COLOR and DEPTH buffers.
     * @return {PIXI.Renderer} Returns itself.
     */ RenderTextureSystem1.prototype.clear = function(clearColor, mask) {
        if (this.current) clearColor = clearColor || this.current.baseTexture.clearColor;
        else clearColor = clearColor || this.clearColor;
        var destinationFrame = this.destinationFrame;
        var baseFrame = this.current ? this.current.baseTexture : this.renderer.screen;
        var clearMask = destinationFrame.width !== baseFrame.width || destinationFrame.height !== baseFrame.height;
        if (clearMask) {
            var _a = this.viewportFrame, x = _a.x, y = _a.y, width = _a.width, height = _a.height;
            x = Math.round(x);
            y = Math.round(y);
            width = Math.round(width);
            height = Math.round(height);
            // TODO: ScissorSystem should cache whether the scissor test is enabled or not.
            this.renderer.gl.enable(this.renderer.gl.SCISSOR_TEST);
            this.renderer.gl.scissor(x, y, width, height);
        }
        this.renderer.framebuffer.clear(clearColor[0], clearColor[1], clearColor[2], clearColor[3], mask);
        if (clearMask) // Restore the scissor box
        this.renderer.scissor.pop();
    };
    RenderTextureSystem1.prototype.resize = function() {
        // resize the root only!
        this.bind(null);
    };
    /**
     * Resets renderTexture state
     */ RenderTextureSystem1.prototype.reset = function() {
        this.bind(null);
    };
    /**
     * @ignore
     */ RenderTextureSystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    return RenderTextureSystem1;
}();
function uboUpdate(_ud, _uv, _renderer, _syncData, buffer) {
    _renderer.buffer.update(buffer);
}
// cv = CachedValue
// v = value
// ud = uniformData
// uv = uniformValue
// l = location
var UBO_TO_SINGLE_SETTERS = {
    float: "\n        data[offset] = v;\n    ",
    vec2: "\n        data[offset] = v[0];\n        data[offset+1] = v[1];\n    ",
    vec3: "\n        data[offset] = v[0];\n        data[offset+1] = v[1];\n        data[offset+2] = v[2];\n\n    ",
    vec4: "\n        data[offset] = v[0];\n        data[offset+1] = v[1];\n        data[offset+2] = v[2];\n        data[offset+3] = v[3];\n    ",
    mat2: "\n        data[offset] = v[0];\n        data[offset+1] = v[1];\n\n        data[offset+4] = v[2];\n        data[offset+5] = v[3];\n    ",
    mat3: "\n        data[offset] = v[0];\n        data[offset+1] = v[1];\n        data[offset+2] = v[2];\n\n        data[offset + 4] = v[3];\n        data[offset + 5] = v[4];\n        data[offset + 6] = v[5];\n\n        data[offset + 8] = v[6];\n        data[offset + 9] = v[7];\n        data[offset + 10] = v[8];\n    ",
    mat4: "\n        for(var i = 0; i < 16; i++)\n        {\n            data[offset + i] = v[i];\n        }\n    "
};
var GLSL_TO_STD40_SIZE = {
    float: 4,
    vec2: 8,
    vec3: 12,
    vec4: 16,
    int: 4,
    ivec2: 8,
    ivec3: 12,
    ivec4: 16,
    uint: 4,
    uvec2: 8,
    uvec3: 12,
    uvec4: 16,
    bool: 4,
    bvec2: 8,
    bvec3: 12,
    bvec4: 16,
    mat2: 32,
    mat3: 48,
    mat4: 64
};
/**
 * @ignore
 *
 * logic originally from here: https://github.com/sketchpunk/FunWithWebGL2/blob/master/lesson_022/Shaders.js
 * rewrote it, but this was a great starting point to get a solid understanding of whats going on :)
 *
 * @param uniformData
 */ function createUBOElements(uniformData) {
    var uboElements = uniformData.map(function(data) {
        return {
            data: data,
            offset: 0,
            dataLen: 0,
            dirty: 0
        };
    });
    var size = 0;
    var chunkSize = 0;
    var offset = 0;
    for(var i = 0; i < uboElements.length; i++){
        var uboElement = uboElements[i];
        size = GLSL_TO_STD40_SIZE[uboElement.data.type];
        if (uboElement.data.size > 1) size = Math.max(size, 16) * uboElement.data.size;
        uboElement.dataLen = size;
        // add some size offset..
        // must align to the nearest 16 bytes or internally nearest round size
        if (chunkSize % size !== 0 && chunkSize < 16) {
            // diff required to line up..
            var lineUpValue = chunkSize % size % 16;
            chunkSize += lineUpValue;
            offset += lineUpValue;
        }
        if (chunkSize + size > 16) {
            offset = Math.ceil(offset / 16) * 16;
            uboElement.offset = offset;
            offset += size;
            chunkSize = size;
        } else {
            uboElement.offset = offset;
            chunkSize += size;
            offset += size;
        }
    }
    offset = Math.ceil(offset / 16) * 16;
    return {
        uboElements: uboElements,
        size: offset
    };
}
function getUBOData(uniforms, uniformData) {
    var usedUniformDatas = [];
    // build..
    for(var i in uniforms)if (uniformData[i]) usedUniformDatas.push(uniformData[i]);
    // sort them out by index!
    usedUniformDatas.sort(function(a, b) {
        return a.index - b.index;
    });
    return usedUniformDatas;
}
function generateUniformBufferSync(group, uniformData) {
    if (!group.autoManage) // if the group is nott automatically managed, we don't need to generate a special function for it...
    return {
        size: 0,
        syncFunc: uboUpdate
    };
    var usedUniformDatas = getUBOData(group.uniforms, uniformData);
    var _a = createUBOElements(usedUniformDatas), uboElements = _a.uboElements, size = _a.size;
    var funcFragments = [
        "\n    var v = null;\n    var v2 = null;\n    var cv = null;\n    var t = 0;\n    var gl = renderer.gl\n    var index = 0;\n    var data = buffer.data;\n    "
    ];
    for(var i = 0; i < uboElements.length; i++){
        var uboElement = uboElements[i];
        var uniform = group.uniforms[uboElement.data.name];
        var name = uboElement.data.name;
        var parsed = false;
        for(var j = 0; j < uniformParsers.length; j++){
            var uniformParser = uniformParsers[j];
            if (uniformParser.codeUbo && uniformParser.test(uboElement.data, uniform)) {
                funcFragments.push("offset = " + uboElement.offset / 4 + ";", uniformParsers[j].codeUbo(uboElement.data.name, uniform));
                parsed = true;
                break;
            }
        }
        if (!parsed) {
            if (uboElement.data.size > 1) {
                var size_1 = mapSize(uboElement.data.type);
                var rowSize = Math.max(GLSL_TO_STD40_SIZE[uboElement.data.type] / 16, 1);
                var elementSize = size_1 / rowSize;
                var remainder = (4 - elementSize % 4) % 4;
                funcFragments.push("\n                cv = ud." + name + ".value;\n                v = uv." + name + ";\n                offset = " + uboElement.offset / 4 + ";\n\n                t = 0;\n\n                for(var i=0; i < " + uboElement.data.size * rowSize + "; i++)\n                {\n                    for(var j = 0; j < " + elementSize + "; j++)\n                    {\n                        data[offset++] = v[t++];\n                    }\n                    offset += " + remainder + ";\n                }\n\n                ");
            } else {
                var template = UBO_TO_SINGLE_SETTERS[uboElement.data.type];
                funcFragments.push("\n                cv = ud." + name + ".value;\n                v = uv." + name + ";\n                offset = " + uboElement.offset / 4 + ";\n                " + template + ";\n                ");
            }
        }
    }
    funcFragments.push("\n       renderer.buffer.update(buffer);\n    ");
    return {
        size: size,
        // eslint-disable-next-line no-new-func
        syncFunc: new Function('ud', 'uv', 'renderer', 'syncData', 'buffer', funcFragments.join('\n'))
    };
}
/**
 * @private
 */ var IGLUniformData = function() {
    function IGLUniformData1() {
    }
    return IGLUniformData1;
}();
/**
 * Helper class to create a WebGL Program
 *
 * @class
 * @memberof PIXI
 */ var GLProgram = function() {
    /**
     * Makes a new Pixi program
     *
     * @param {WebGLProgram} program - webgl program
     * @param {Object} uniformData - uniforms
     */ function GLProgram1(program, uniformData) {
        /**
         * The shader program
         *
         * @member {WebGLProgram}
         */ this.program = program;
        /**
         * holds the uniform data which contains uniform locations
         * and current uniform values used for caching and preventing unneeded GPU commands
         * @member {Object}
         */ this.uniformData = uniformData;
        /**
         * uniformGroups holds the various upload functions for the shader. Each uniform group
         * and program have a unique upload function generated.
         * @member {Object}
         */ this.uniformGroups = {
        };
        this.uniformDirtyGroups = {
        };
        this.uniformBufferBindings = {
        };
    }
    /**
     * Destroys this program
     */ GLProgram1.prototype.destroy = function() {
        this.uniformData = null;
        this.uniformGroups = null;
        this.uniformDirtyGroups = null;
        this.uniformBufferBindings = null;
        this.program = null;
    };
    return GLProgram1;
}();
/**
 * returns the attribute data from the program
 * @private
 *
 * @param {WebGLProgram} [program] - the WebGL program
 * @param {WebGLRenderingContext} [gl] - the WebGL context
 *
 * @returns {object} the attribute data for this program
 */ function getAttributeData(program, gl) {
    var attributes = {
    };
    var totalAttributes = gl.getProgramParameter(program, gl.ACTIVE_ATTRIBUTES);
    for(var i = 0; i < totalAttributes; i++){
        var attribData = gl.getActiveAttrib(program, i);
        if (attribData.name.indexOf('gl_') === 0) continue;
        var type = mapType(gl, attribData.type);
        var data = {
            type: type,
            name: attribData.name,
            size: mapSize(type),
            location: i
        };
        attributes[attribData.name] = data;
    }
    return attributes;
}
/**
 * returns the uniform data from the program
 * @private
 *
 * @param program - the webgl program
 * @param gl - the WebGL context
 *
 * @returns {object} the uniform data for this program
 */ function getUniformData(program, gl) {
    var uniforms = {
    };
    var totalUniforms = gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS);
    for(var i = 0; i < totalUniforms; i++){
        var uniformData = gl.getActiveUniform(program, i);
        var name = uniformData.name.replace(/\[.*?\]$/, '');
        var isArray = !!uniformData.name.match(/\[.*?\]$/);
        var type = mapType(gl, uniformData.type);
        uniforms[name] = {
            name: name,
            index: i,
            type: type,
            size: uniformData.size,
            isArray: isArray,
            value: defaultValue(type, uniformData.size)
        };
    }
    return uniforms;
}
/**
 * generates a WebGL Program object from a high level Pixi Program.
 *
 * @param gl - a rendering context on which to generate the program
 * @param program - the high level Pixi Program.
 */ function generateProgram(gl, program) {
    var glVertShader = compileShader(gl, gl.VERTEX_SHADER, program.vertexSrc);
    var glFragShader = compileShader(gl, gl.FRAGMENT_SHADER, program.fragmentSrc);
    var webGLProgram = gl.createProgram();
    gl.attachShader(webGLProgram, glVertShader);
    gl.attachShader(webGLProgram, glFragShader);
    gl.linkProgram(webGLProgram);
    if (!gl.getProgramParameter(webGLProgram, gl.LINK_STATUS)) logProgramError(gl, webGLProgram, glVertShader, glFragShader);
    program.attributeData = getAttributeData(webGLProgram, gl);
    program.uniformData = getUniformData(webGLProgram, gl);
    var keys = Object.keys(program.attributeData);
    keys.sort(function(a, b) {
        return a > b ? 1 : -1;
    }); // eslint-disable-line no-confusing-arrow
    for(var i = 0; i < keys.length; i++){
        program.attributeData[keys[i]].location = i;
        gl.bindAttribLocation(webGLProgram, i, keys[i]);
    }
    gl.linkProgram(webGLProgram);
    gl.deleteShader(glVertShader);
    gl.deleteShader(glFragShader);
    var uniformData = {
    };
    for(var i in program.uniformData){
        var data = program.uniformData[i];
        uniformData[i] = {
            location: gl.getUniformLocation(webGLProgram, i),
            value: defaultValue(data.type, data.size)
        };
    }
    var glProgram = new GLProgram(webGLProgram, uniformData);
    return glProgram;
}
var UID$4 = 0;
// default sync data so we don't create a new one each time!
var defaultSyncData = {
    textureCount: 0,
    uboCount: 0
};
/**
 * System plugin to the renderer to manage shaders.
 *
 * @class
 * @memberof PIXI
 * @extends PIXI.System
 */ var ShaderSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function ShaderSystem1(renderer) {
        this.destroyed = false;
        this.renderer = renderer;
        // Validation check that this environment support `new Function`
        this.systemCheck();
        /**
         * The current WebGL rendering context
         *
         * @member {WebGLRenderingContext}
         */ this.gl = null;
        this.shader = null;
        this.program = null;
        /**
         * Cache to holds the generated functions. Stored against UniformObjects unique signature
         * @type {Object}
         * @private
         */ this.cache = {
        };
        this._uboCache = {
        };
        this.id = UID$4++;
    }
    /**
     * Overrideable function by `@pixi/unsafe-eval` to silence
     * throwing an error if platform doesn't support unsafe-evals.
     *
     * @private
     */ ShaderSystem1.prototype.systemCheck = function() {
        if (!unsafeEvalSupported()) throw new Error("Current environment does not allow unsafe-eval, please use @pixi/unsafe-eval module to enable support.");
    };
    ShaderSystem1.prototype.contextChange = function(gl) {
        this.gl = gl;
        this.reset();
    };
    /**
     * Changes the current shader to the one given in parameter
     *
     * @param {PIXI.Shader} shader - the new shader
     * @param {boolean} [dontSync] - false if the shader should automatically sync its uniforms.
     * @returns {PIXI.GLProgram} the glProgram that belongs to the shader.
     */ ShaderSystem1.prototype.bind = function(shader, dontSync) {
        shader.uniforms.globals = this.renderer.globalUniforms;
        var program = shader.program;
        var glProgram = program.glPrograms[this.renderer.CONTEXT_UID] || this.generateProgram(shader);
        this.shader = shader;
        // TODO - some current Pixi plugins bypass this.. so it not safe to use yet..
        if (this.program !== program) {
            this.program = program;
            this.gl.useProgram(glProgram.program);
        }
        if (!dontSync) {
            defaultSyncData.textureCount = 0;
            defaultSyncData.uboCount = 0;
            this.syncUniformGroup(shader.uniformGroup, defaultSyncData);
        }
        return glProgram;
    };
    /**
     * Uploads the uniforms values to the currently bound shader.
     *
     * @param {object} uniforms - the uniforms values that be applied to the current shader
     */ ShaderSystem1.prototype.setUniforms = function(uniforms) {
        var shader = this.shader.program;
        var glProgram = shader.glPrograms[this.renderer.CONTEXT_UID];
        shader.syncUniforms(glProgram.uniformData, uniforms, this.renderer);
    };
    /* eslint-disable @typescript-eslint/explicit-module-boundary-types */ /**
     *
     * syncs uniforms on the group
     * @param group - the uniform group to sync
     * @param syncData - this is data that is passed to the sync function and any nested sync functions
     */ ShaderSystem1.prototype.syncUniformGroup = function(group, syncData) {
        var glProgram = this.getGlProgram();
        if (!group.static || group.dirtyId !== glProgram.uniformDirtyGroups[group.id]) {
            glProgram.uniformDirtyGroups[group.id] = group.dirtyId;
            this.syncUniforms(group, glProgram, syncData);
        }
    };
    /**
     * Overrideable by the @pixi/unsafe-eval package to use static
     * syncUniforms instead.
     *
     * @private
     */ ShaderSystem1.prototype.syncUniforms = function(group, glProgram, syncData) {
        var syncFunc = group.syncUniforms[this.shader.program.id] || this.createSyncGroups(group);
        syncFunc(glProgram.uniformData, group.uniforms, this.renderer, syncData);
    };
    ShaderSystem1.prototype.createSyncGroups = function(group) {
        var id = this.getSignature(group, this.shader.program.uniformData, 'u');
        if (!this.cache[id]) this.cache[id] = generateUniformsSync(group, this.shader.program.uniformData);
        group.syncUniforms[this.shader.program.id] = this.cache[id];
        return group.syncUniforms[this.shader.program.id];
    };
    /**
     * Syncs uniform buffers
     *
     * @param group - the uniform buffer group to sync
     * @param name - the name of the uniform buffer
     */ ShaderSystem1.prototype.syncUniformBufferGroup = function(group, name) {
        var glProgram = this.getGlProgram();
        if (!group.static || group.dirtyId !== 0 || !glProgram.uniformGroups[group.id]) {
            group.dirtyId = 0;
            var syncFunc = glProgram.uniformGroups[group.id] || this.createSyncBufferGroup(group, glProgram, name);
            // TODO wrap update in a cache??
            group.buffer.update();
            syncFunc(glProgram.uniformData, group.uniforms, this.renderer, defaultSyncData, group.buffer);
        }
        this.renderer.buffer.bindBufferBase(group.buffer, glProgram.uniformBufferBindings[name]);
    };
    /**
     * Will create a function that uploads a uniform buffer using the STD140 standard.
     * The upload function will then be cached for future calls
     * If a group is manually managed, then a simple upload function is generated
     *
     * @param group - the uniform buffer group to sync
     * @param glProgram - the gl program to attach the uniform bindings to
     * @param name - the name of the uniform buffer (must exist on the shader)
     */ ShaderSystem1.prototype.createSyncBufferGroup = function(group, glProgram, name) {
        var gl = this.renderer.gl;
        this.renderer.buffer.bind(group.buffer);
        // bind them...
        var uniformBlockIndex = this.gl.getUniformBlockIndex(glProgram.program, name);
        glProgram.uniformBufferBindings[name] = this.shader.uniformBindCount;
        gl.uniformBlockBinding(glProgram.program, uniformBlockIndex, this.shader.uniformBindCount);
        this.shader.uniformBindCount++;
        var id = this.getSignature(group, this.shader.program.uniformData, 'ubo');
        var uboData = this._uboCache[id];
        if (!uboData) uboData = this._uboCache[id] = generateUniformBufferSync(group, this.shader.program.uniformData);
        if (group.autoManage) {
            var data = new Float32Array(uboData.size / 4);
            group.buffer.update(data);
        }
        glProgram.uniformGroups[group.id] = uboData.syncFunc;
        return glProgram.uniformGroups[group.id];
    };
    /**
     * Takes a uniform group and data and generates a unique signature for them.
     *
     * @param {PIXI.UniformGroup} group - the uniform group to get signature of
     * @param {Object} uniformData - uniform information generated by the shader
     * @returns {String} Unique signature of the uniform group
     * @private
     */ ShaderSystem1.prototype.getSignature = function(group, uniformData, preFix) {
        var uniforms = group.uniforms;
        var strings = [
            preFix + "-"
        ];
        for(var i in uniforms){
            strings.push(i);
            if (uniformData[i]) strings.push(uniformData[i].type);
        }
        return strings.join('-');
    };
    /**
     * Returns the underlying GLShade rof the currently bound shader.
     * This can be handy for when you to have a little more control over the setting of your uniforms.
     *
     * @return {PIXI.GLProgram} the glProgram for the currently bound Shader for this context
     */ ShaderSystem1.prototype.getGlProgram = function() {
        if (this.shader) return this.shader.program.glPrograms[this.renderer.CONTEXT_UID];
        return null;
    };
    /**
     * Generates a glProgram version of the Shader provided.
     *
     * @private
     * @param {PIXI.Shader} shader - the shader that the glProgram will be based on.
     * @return {PIXI.GLProgram} A shiny new glProgram!
     */ ShaderSystem1.prototype.generateProgram = function(shader) {
        var gl = this.gl;
        var program = shader.program;
        var glProgram = generateProgram(gl, program);
        program.glPrograms[this.renderer.CONTEXT_UID] = glProgram;
        return glProgram;
    };
    /**
     * Resets ShaderSystem state, does not affect WebGL state
     */ ShaderSystem1.prototype.reset = function() {
        this.program = null;
        this.shader = null;
    };
    /**
     * Destroys this System and removes all its textures
     */ ShaderSystem1.prototype.destroy = function() {
        this.renderer = null;
        // TODO implement destroy method for ShaderSystem
        this.destroyed = true;
    };
    return ShaderSystem1;
}();
/**
 * Maps gl blend combinations to WebGL.
 *
 * @memberof PIXI
 * @function mapWebGLBlendModesToPixi
 * @private
 * @param {WebGLRenderingContext} gl - The rendering context.
 * @param {number[][]} [array=[]] - The array to output into.
 * @return {number[][]} Mapped modes.
 */ function mapWebGLBlendModesToPixi(gl, array) {
    if (array === void 0) array = [];
    // TODO - premultiply alpha would be different.
    // add a boolean for that!
    array[_constants.BLEND_MODES.NORMAL] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.ADD] = [
        gl.ONE,
        gl.ONE
    ];
    array[_constants.BLEND_MODES.MULTIPLY] = [
        gl.DST_COLOR,
        gl.ONE_MINUS_SRC_ALPHA,
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.SCREEN] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_COLOR,
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.OVERLAY] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.DARKEN] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.LIGHTEN] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.COLOR_DODGE] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.COLOR_BURN] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.HARD_LIGHT] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.SOFT_LIGHT] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.DIFFERENCE] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.EXCLUSION] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.HUE] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.SATURATION] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.COLOR] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.LUMINOSITY] = [
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.NONE] = [
        0,
        0
    ];
    // not-premultiplied blend modes
    array[_constants.BLEND_MODES.NORMAL_NPM] = [
        gl.SRC_ALPHA,
        gl.ONE_MINUS_SRC_ALPHA,
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.ADD_NPM] = [
        gl.SRC_ALPHA,
        gl.ONE,
        gl.ONE,
        gl.ONE
    ];
    array[_constants.BLEND_MODES.SCREEN_NPM] = [
        gl.SRC_ALPHA,
        gl.ONE_MINUS_SRC_COLOR,
        gl.ONE,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    // composite operations
    array[_constants.BLEND_MODES.SRC_IN] = [
        gl.DST_ALPHA,
        gl.ZERO
    ];
    array[_constants.BLEND_MODES.SRC_OUT] = [
        gl.ONE_MINUS_DST_ALPHA,
        gl.ZERO
    ];
    array[_constants.BLEND_MODES.SRC_ATOP] = [
        gl.DST_ALPHA,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.DST_OVER] = [
        gl.ONE_MINUS_DST_ALPHA,
        gl.ONE
    ];
    array[_constants.BLEND_MODES.DST_IN] = [
        gl.ZERO,
        gl.SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.DST_OUT] = [
        gl.ZERO,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.DST_ATOP] = [
        gl.ONE_MINUS_DST_ALPHA,
        gl.SRC_ALPHA
    ];
    array[_constants.BLEND_MODES.XOR] = [
        gl.ONE_MINUS_DST_ALPHA,
        gl.ONE_MINUS_SRC_ALPHA
    ];
    // SUBTRACT from flash
    array[_constants.BLEND_MODES.SUBTRACT] = [
        gl.ONE,
        gl.ONE,
        gl.ONE,
        gl.ONE,
        gl.FUNC_REVERSE_SUBTRACT,
        gl.FUNC_ADD
    ];
    return array;
}
var BLEND$1 = 0;
var OFFSET$1 = 1;
var CULLING$1 = 2;
var DEPTH_TEST$1 = 3;
var WINDING$1 = 4;
var DEPTH_MASK$1 = 5;
/**
 * System plugin to the renderer to manage WebGL state machines.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var StateSystem = function() {
    function StateSystem1() {
        /**
         * GL context
         * @member {WebGLRenderingContext}
         * @readonly
         */ this.gl = null;
        /**
         * State ID
         * @member {number}
         * @readonly
         */ this.stateId = 0;
        /**
         * Polygon offset
         * @member {number}
         * @readonly
         */ this.polygonOffset = 0;
        /**
         * Blend mode
         * @member {number}
         * @default PIXI.BLEND_MODES.NONE
         * @readonly
         */ this.blendMode = _constants.BLEND_MODES.NONE;
        /**
         * Whether current blend equation is different
         * @member {boolean}
         * @protected
         */ this._blendEq = false;
        /**
         * Collection of calls
         * @member {function[]}
         * @readonly
         */ this.map = [];
        // map functions for when we set state..
        this.map[BLEND$1] = this.setBlend;
        this.map[OFFSET$1] = this.setOffset;
        this.map[CULLING$1] = this.setCullFace;
        this.map[DEPTH_TEST$1] = this.setDepthTest;
        this.map[WINDING$1] = this.setFrontFace;
        this.map[DEPTH_MASK$1] = this.setDepthMask;
        /**
         * Collection of check calls
         * @member {function[]}
         * @readonly
         */ this.checks = [];
        /**
         * Default WebGL State
         * @member {PIXI.State}
         * @readonly
         */ this.defaultState = new State();
        this.defaultState.blend = true;
    }
    StateSystem1.prototype.contextChange = function(gl) {
        this.gl = gl;
        this.blendModes = mapWebGLBlendModesToPixi(gl);
        this.set(this.defaultState);
        this.reset();
    };
    /**
     * Sets the current state
     *
     * @param {*} state - The state to set.
     */ StateSystem1.prototype.set = function(state) {
        state = state || this.defaultState;
        // TODO maybe to an object check? ( this.state === state )?
        if (this.stateId !== state.data) {
            var diff = this.stateId ^ state.data;
            var i = 0;
            // order from least to most common
            while(diff){
                if (diff & 1) // state change!
                this.map[i].call(this, !!(state.data & 1 << i));
                diff = diff >> 1;
                i++;
            }
            this.stateId = state.data;
        }
        // based on the above settings we check for specific modes..
        // for example if blend is active we check and set the blend modes
        // or of polygon offset is active we check the poly depth.
        for(var i = 0; i < this.checks.length; i++)this.checks[i](this, state);
    };
    /**
     * Sets the state, when previous state is unknown
     *
     * @param {*} state - The state to set
     */ StateSystem1.prototype.forceState = function(state) {
        state = state || this.defaultState;
        for(var i = 0; i < this.map.length; i++)this.map[i].call(this, !!(state.data & 1 << i));
        for(var i = 0; i < this.checks.length; i++)this.checks[i](this, state);
        this.stateId = state.data;
    };
    /**
     * Enables or disabled blending.
     *
     * @param {boolean} value - Turn on or off webgl blending.
     */ StateSystem1.prototype.setBlend = function(value) {
        this.updateCheck(StateSystem1.checkBlendMode, value);
        this.gl[value ? 'enable' : 'disable'](this.gl.BLEND);
    };
    /**
     * Enables or disable polygon offset fill
     *
     * @param {boolean} value - Turn on or off webgl polygon offset testing.
     */ StateSystem1.prototype.setOffset = function(value) {
        this.updateCheck(StateSystem1.checkPolygonOffset, value);
        this.gl[value ? 'enable' : 'disable'](this.gl.POLYGON_OFFSET_FILL);
    };
    /**
     * Sets whether to enable or disable depth test.
     *
     * @param {boolean} value - Turn on or off webgl depth testing.
     */ StateSystem1.prototype.setDepthTest = function(value) {
        this.gl[value ? 'enable' : 'disable'](this.gl.DEPTH_TEST);
    };
    /**
     * Sets whether to enable or disable depth mask.
     *
     * @param {boolean} value - Turn on or off webgl depth mask.
     */ StateSystem1.prototype.setDepthMask = function(value) {
        this.gl.depthMask(value);
    };
    /**
     * Sets whether to enable or disable cull face.
     *
     * @param {boolean} value - Turn on or off webgl cull face.
     */ StateSystem1.prototype.setCullFace = function(value) {
        this.gl[value ? 'enable' : 'disable'](this.gl.CULL_FACE);
    };
    /**
     * Sets the gl front face.
     *
     * @param {boolean} value - true is clockwise and false is counter-clockwise
     */ StateSystem1.prototype.setFrontFace = function(value) {
        this.gl.frontFace(this.gl[value ? 'CW' : 'CCW']);
    };
    /**
     * Sets the blend mode.
     *
     * @param {number} value - The blend mode to set to.
     */ StateSystem1.prototype.setBlendMode = function(value) {
        if (value === this.blendMode) return;
        this.blendMode = value;
        var mode = this.blendModes[value];
        var gl = this.gl;
        if (mode.length === 2) gl.blendFunc(mode[0], mode[1]);
        else gl.blendFuncSeparate(mode[0], mode[1], mode[2], mode[3]);
        if (mode.length === 6) {
            this._blendEq = true;
            gl.blendEquationSeparate(mode[4], mode[5]);
        } else if (this._blendEq) {
            this._blendEq = false;
            gl.blendEquationSeparate(gl.FUNC_ADD, gl.FUNC_ADD);
        }
    };
    /**
     * Sets the polygon offset.
     *
     * @param {number} value - the polygon offset
     * @param {number} scale - the polygon offset scale
     */ StateSystem1.prototype.setPolygonOffset = function(value, scale) {
        this.gl.polygonOffset(value, scale);
    };
    // used
    /**
     * Resets all the logic and disables the vaos
     */ StateSystem1.prototype.reset = function() {
        this.gl.pixelStorei(this.gl.UNPACK_FLIP_Y_WEBGL, false);
        this.forceState(this.defaultState);
        this._blendEq = true;
        this.blendMode = -1;
        this.setBlendMode(0);
    };
    /**
     * checks to see which updates should be checked based on which settings have been activated.
     * For example, if blend is enabled then we should check the blend modes each time the state is changed
     * or if polygon fill is activated then we need to check if the polygon offset changes.
     * The idea is that we only check what we have too.
     *
     * @param {Function} func - the checking function to add or remove
     * @param {boolean} value - should the check function be added or removed.
     */ StateSystem1.prototype.updateCheck = function(func, value) {
        var index = this.checks.indexOf(func);
        if (value && index === -1) this.checks.push(func);
        else if (!value && index !== -1) this.checks.splice(index, 1);
    };
    /**
     * A private little wrapper function that we call to check the blend mode.
     *
     * @static
     * @private
     * @param {PIXI.StateSystem} System - the System to perform the state check on
     * @param {PIXI.State} state - the state that the blendMode will pulled from
     */ StateSystem1.checkBlendMode = function(system, state) {
        system.setBlendMode(state.blendMode);
    };
    /**
     * A private little wrapper function that we call to check the polygon offset.
     *
     * @static
     * @private
     * @param {PIXI.StateSystem} System - the System to perform the state check on
     * @param {PIXI.State} state - the state that the blendMode will pulled from
     */ StateSystem1.checkPolygonOffset = function(system, state) {
        system.setPolygonOffset(1, state.polygonOffset);
    };
    /**
     * @ignore
     */ StateSystem1.prototype.destroy = function() {
        this.gl = null;
    };
    return StateSystem1;
}();
/**
 * System plugin to the renderer to manage texture garbage collection on the GPU,
 * ensuring that it does not get clogged up with textures that are no longer being used.
 *
 * @class
 * @memberof PIXI
 * @extends PIXI.System
 */ var TextureGCSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function TextureGCSystem1(renderer) {
        this.renderer = renderer;
        /**
         * Count
         * @member {number}
         * @readonly
         */ this.count = 0;
        /**
         * Check count
         * @member {number}
         * @readonly
         */ this.checkCount = 0;
        /**
         * Maximum idle time, in seconds
         * @member {number}
         * @see PIXI.settings.GC_MAX_IDLE
         */ this.maxIdle = _settings.settings.GC_MAX_IDLE;
        /**
         * Maximum number of item to check
         * @member {number}
         * @see PIXI.settings.GC_MAX_CHECK_COUNT
         */ this.checkCountMax = _settings.settings.GC_MAX_CHECK_COUNT;
        /**
         * Current garbage collection mode
         * @member {PIXI.GC_MODES}
         * @see PIXI.settings.GC_MODE
         */ this.mode = _settings.settings.GC_MODE;
    }
    /**
     * Checks to see when the last time a texture was used
     * if the texture has not been used for a specified amount of time it will be removed from the GPU
     */ TextureGCSystem1.prototype.postrender = function() {
        if (!this.renderer.renderingToScreen) return;
        this.count++;
        if (this.mode === _constants.GC_MODES.MANUAL) return;
        this.checkCount++;
        if (this.checkCount > this.checkCountMax) {
            this.checkCount = 0;
            this.run();
        }
    };
    /**
     * Checks to see when the last time a texture was used
     * if the texture has not been used for a specified amount of time it will be removed from the GPU
     */ TextureGCSystem1.prototype.run = function() {
        var tm = this.renderer.texture;
        var managedTextures = tm.managedTextures;
        var wasRemoved = false;
        for(var i = 0; i < managedTextures.length; i++){
            var texture = managedTextures[i];
            // only supports non generated textures at the moment!
            if (!texture.framebuffer && this.count - texture.touched > this.maxIdle) {
                tm.destroyTexture(texture, true);
                managedTextures[i] = null;
                wasRemoved = true;
            }
        }
        if (wasRemoved) {
            var j = 0;
            for(var i = 0; i < managedTextures.length; i++)if (managedTextures[i] !== null) managedTextures[j++] = managedTextures[i];
            managedTextures.length = j;
        }
    };
    /**
     * Removes all the textures within the specified displayObject and its children from the GPU
     *
     * @param {PIXI.DisplayObject} displayObject - the displayObject to remove the textures from.
     */ TextureGCSystem1.prototype.unload = function(displayObject) {
        var tm = this.renderer.texture;
        var texture = displayObject._texture;
        // only destroy non generated textures
        if (texture && !texture.framebuffer) tm.destroyTexture(texture);
        for(var i = displayObject.children.length - 1; i >= 0; i--)this.unload(displayObject.children[i]);
    };
    /**
     * @ignore
     */ TextureGCSystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    return TextureGCSystem1;
}();
/**
 * Returns a lookup table that maps each type-format pair to a compatible internal format.
 *
 * @memberof PIXI
 * @function mapTypeAndFormatToInternalFormat
 * @private
 * @param {WebGLRenderingContext} gl - The rendering context.
 * @return {{ [type: number]: { [format: number]: number } }} Lookup table.
 */ function mapTypeAndFormatToInternalFormat(gl) {
    var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x;
    var table;
    if ('WebGL2RenderingContext' in self && gl instanceof self.WebGL2RenderingContext) table = (_a = {
    }, _a[_constants.TYPES.UNSIGNED_BYTE] = (_b = {
    }, _b[_constants.FORMATS.RGBA] = gl.RGBA8, _b[_constants.FORMATS.RGB] = gl.RGB8, _b[_constants.FORMATS.RG] = gl.RG8, _b[_constants.FORMATS.RED] = gl.R8, _b[_constants.FORMATS.RGBA_INTEGER] = gl.RGBA8UI, _b[_constants.FORMATS.RGB_INTEGER] = gl.RGB8UI, _b[_constants.FORMATS.RG_INTEGER] = gl.RG8UI, _b[_constants.FORMATS.RED_INTEGER] = gl.R8UI, _b[_constants.FORMATS.ALPHA] = gl.ALPHA, _b[_constants.FORMATS.LUMINANCE] = gl.LUMINANCE, _b[_constants.FORMATS.LUMINANCE_ALPHA] = gl.LUMINANCE_ALPHA, _b), _a[_constants.TYPES.BYTE] = (_c = {
    }, _c[_constants.FORMATS.RGBA] = gl.RGBA8_SNORM, _c[_constants.FORMATS.RGB] = gl.RGB8_SNORM, _c[_constants.FORMATS.RG] = gl.RG8_SNORM, _c[_constants.FORMATS.RED] = gl.R8_SNORM, _c[_constants.FORMATS.RGBA_INTEGER] = gl.RGBA8I, _c[_constants.FORMATS.RGB_INTEGER] = gl.RGB8I, _c[_constants.FORMATS.RG_INTEGER] = gl.RG8I, _c[_constants.FORMATS.RED_INTEGER] = gl.R8I, _c), _a[_constants.TYPES.UNSIGNED_SHORT] = (_d = {
    }, _d[_constants.FORMATS.RGBA_INTEGER] = gl.RGBA16UI, _d[_constants.FORMATS.RGB_INTEGER] = gl.RGB16UI, _d[_constants.FORMATS.RG_INTEGER] = gl.RG16UI, _d[_constants.FORMATS.RED_INTEGER] = gl.R16UI, _d[_constants.FORMATS.DEPTH_COMPONENT] = gl.DEPTH_COMPONENT16, _d), _a[_constants.TYPES.SHORT] = (_e = {
    }, _e[_constants.FORMATS.RGBA_INTEGER] = gl.RGBA16I, _e[_constants.FORMATS.RGB_INTEGER] = gl.RGB16I, _e[_constants.FORMATS.RG_INTEGER] = gl.RG16I, _e[_constants.FORMATS.RED_INTEGER] = gl.R16I, _e), _a[_constants.TYPES.UNSIGNED_INT] = (_f = {
    }, _f[_constants.FORMATS.RGBA_INTEGER] = gl.RGBA32UI, _f[_constants.FORMATS.RGB_INTEGER] = gl.RGB32UI, _f[_constants.FORMATS.RG_INTEGER] = gl.RG32UI, _f[_constants.FORMATS.RED_INTEGER] = gl.R32UI, _f[_constants.FORMATS.DEPTH_COMPONENT] = gl.DEPTH_COMPONENT24, _f), _a[_constants.TYPES.INT] = (_g = {
    }, _g[_constants.FORMATS.RGBA_INTEGER] = gl.RGBA32I, _g[_constants.FORMATS.RGB_INTEGER] = gl.RGB32I, _g[_constants.FORMATS.RG_INTEGER] = gl.RG32I, _g[_constants.FORMATS.RED_INTEGER] = gl.R32I, _g), _a[_constants.TYPES.FLOAT] = (_h = {
    }, _h[_constants.FORMATS.RGBA] = gl.RGBA32F, _h[_constants.FORMATS.RGB] = gl.RGB32F, _h[_constants.FORMATS.RG] = gl.RG32F, _h[_constants.FORMATS.RED] = gl.R32F, _h[_constants.FORMATS.DEPTH_COMPONENT] = gl.DEPTH_COMPONENT32F, _h), _a[_constants.TYPES.HALF_FLOAT] = (_j = {
    }, _j[_constants.FORMATS.RGBA] = gl.RGBA16F, _j[_constants.FORMATS.RGB] = gl.RGB16F, _j[_constants.FORMATS.RG] = gl.RG16F, _j[_constants.FORMATS.RED] = gl.R16F, _j), _a[_constants.TYPES.UNSIGNED_SHORT_5_6_5] = (_k = {
    }, _k[_constants.FORMATS.RGB] = gl.RGB565, _k), _a[_constants.TYPES.UNSIGNED_SHORT_4_4_4_4] = (_l = {
    }, _l[_constants.FORMATS.RGBA] = gl.RGBA4, _l), _a[_constants.TYPES.UNSIGNED_SHORT_5_5_5_1] = (_m = {
    }, _m[_constants.FORMATS.RGBA] = gl.RGB5_A1, _m), _a[_constants.TYPES.UNSIGNED_INT_2_10_10_10_REV] = (_o = {
    }, _o[_constants.FORMATS.RGBA] = gl.RGB10_A2, _o[_constants.FORMATS.RGBA_INTEGER] = gl.RGB10_A2UI, _o), _a[_constants.TYPES.UNSIGNED_INT_10F_11F_11F_REV] = (_p = {
    }, _p[_constants.FORMATS.RGB] = gl.R11F_G11F_B10F, _p), _a[_constants.TYPES.UNSIGNED_INT_5_9_9_9_REV] = (_q = {
    }, _q[_constants.FORMATS.RGB] = gl.RGB9_E5, _q), _a[_constants.TYPES.UNSIGNED_INT_24_8] = (_r = {
    }, _r[_constants.FORMATS.DEPTH_STENCIL] = gl.DEPTH24_STENCIL8, _r), _a[_constants.TYPES.FLOAT_32_UNSIGNED_INT_24_8_REV] = (_s = {
    }, _s[_constants.FORMATS.DEPTH_STENCIL] = gl.DEPTH32F_STENCIL8, _s), _a);
    else table = (_t = {
    }, _t[_constants.TYPES.UNSIGNED_BYTE] = (_u = {
    }, _u[_constants.FORMATS.RGBA] = gl.RGBA, _u[_constants.FORMATS.RGB] = gl.RGB, _u[_constants.FORMATS.ALPHA] = gl.ALPHA, _u[_constants.FORMATS.LUMINANCE] = gl.LUMINANCE, _u[_constants.FORMATS.LUMINANCE_ALPHA] = gl.LUMINANCE_ALPHA, _u), _t[_constants.TYPES.UNSIGNED_SHORT_5_6_5] = (_v = {
    }, _v[_constants.FORMATS.RGB] = gl.RGB, _v), _t[_constants.TYPES.UNSIGNED_SHORT_4_4_4_4] = (_w = {
    }, _w[_constants.FORMATS.RGBA] = gl.RGBA, _w), _t[_constants.TYPES.UNSIGNED_SHORT_5_5_5_1] = (_x = {
    }, _x[_constants.FORMATS.RGBA] = gl.RGBA, _x), _t);
    return table;
}
/**
 * Internal texture for WebGL context
 * @class
 * @memberof PIXI
 */ var GLTexture = function() {
    function GLTexture1(texture) {
        /**
         * The WebGL texture
         * @member {WebGLTexture}
         */ this.texture = texture;
        /**
         * Width of texture that was used in texImage2D
         * @member {number}
         */ this.width = -1;
        /**
         * Height of texture that was used in texImage2D
         * @member {number}
         */ this.height = -1;
        /**
         * Texture contents dirty flag
         * @member {number}
         */ this.dirtyId = -1;
        /**
         * Texture style dirty flag
         * @member {number}
         */ this.dirtyStyleId = -1;
        /**
         * Whether mip levels has to be generated
         * @member {boolean}
         */ this.mipmap = false;
        /**
         * WrapMode copied from baseTexture
         * @member {number}
         */ this.wrapMode = 33071;
        /**
         * Type copied from baseTexture
         * @member {number}
         */ this.type = _constants.TYPES.UNSIGNED_BYTE;
        /**
         * Type copied from baseTexture
         * @member {number}
         */ this.internalFormat = _constants.FORMATS.RGBA;
        this.samplerType = 0;
    }
    return GLTexture1;
}();
/**
 * System plugin to the renderer to manage textures.
 *
 * @class
 * @extends PIXI.System
 * @memberof PIXI
 */ var TextureSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function TextureSystem1(renderer) {
        this.renderer = renderer;
        // TODO set to max textures...
        /**
         * Bound textures
         * @member {PIXI.BaseTexture[]}
         * @readonly
         */ this.boundTextures = [];
        /**
         * Current location
         * @member {number}
         * @readonly
         */ this.currentLocation = -1;
        /**
         * List of managed textures
         * @member {PIXI.BaseTexture[]}
         * @readonly
         */ this.managedTextures = [];
        /**
         * Did someone temper with textures state? We'll overwrite them when we need to unbind something.
         * @member {boolean}
         * @private
         */ this._unknownBoundTextures = false;
        /**
         * BaseTexture value that shows that we don't know what is bound
         * @member {PIXI.BaseTexture}
         * @readonly
         */ this.unknownTexture = new BaseTexture1();
        this.hasIntegerTextures = false;
    }
    /**
     * Sets up the renderer context and necessary buffers.
     */ TextureSystem1.prototype.contextChange = function() {
        var gl = this.gl = this.renderer.gl;
        this.CONTEXT_UID = this.renderer.CONTEXT_UID;
        this.webGLVersion = this.renderer.context.webGLVersion;
        this.internalFormats = mapTypeAndFormatToInternalFormat(gl);
        var maxTextures = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);
        this.boundTextures.length = maxTextures;
        for(var i = 0; i < maxTextures; i++)this.boundTextures[i] = null;
        // TODO move this.. to a nice make empty textures class..
        this.emptyTextures = {
        };
        var emptyTexture2D = new GLTexture(gl.createTexture());
        gl.bindTexture(gl.TEXTURE_2D, emptyTexture2D.texture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, new Uint8Array(4));
        this.emptyTextures[gl.TEXTURE_2D] = emptyTexture2D;
        this.emptyTextures[gl.TEXTURE_CUBE_MAP] = new GLTexture(gl.createTexture());
        gl.bindTexture(gl.TEXTURE_CUBE_MAP, this.emptyTextures[gl.TEXTURE_CUBE_MAP].texture);
        for(var i = 0; i < 6; i++)gl.texImage2D(gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
        gl.texParameteri(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
        for(var i = 0; i < this.boundTextures.length; i++)this.bind(null, i);
    };
    /**
     * Bind a texture to a specific location
     *
     * If you want to unbind something, please use `unbind(texture)` instead of `bind(null, textureLocation)`
     *
     * @param {PIXI.Texture|PIXI.BaseTexture} texture_ - Texture to bind
     * @param {number} [location=0] - Location to bind at
     */ TextureSystem1.prototype.bind = function(texture, location) {
        if (location === void 0) location = 0;
        var gl = this.gl;
        texture = texture === null || texture === void 0 ? void 0 : texture.castToBaseTexture();
        // cannot bind partial texture
        // TODO: report a warning
        if (texture && texture.valid && !texture.parentTextureArray) {
            texture.touched = this.renderer.textureGC.count;
            var glTexture = texture._glTextures[this.CONTEXT_UID] || this.initTexture(texture);
            if (this.boundTextures[location] !== texture) {
                if (this.currentLocation !== location) {
                    this.currentLocation = location;
                    gl.activeTexture(gl.TEXTURE0 + location);
                }
                gl.bindTexture(texture.target, glTexture.texture);
            }
            if (glTexture.dirtyId !== texture.dirtyId) {
                if (this.currentLocation !== location) {
                    this.currentLocation = location;
                    gl.activeTexture(gl.TEXTURE0 + location);
                }
                this.updateTexture(texture);
            }
            this.boundTextures[location] = texture;
        } else {
            if (this.currentLocation !== location) {
                this.currentLocation = location;
                gl.activeTexture(gl.TEXTURE0 + location);
            }
            gl.bindTexture(gl.TEXTURE_2D, this.emptyTextures[gl.TEXTURE_2D].texture);
            this.boundTextures[location] = null;
        }
    };
    /**
     * Resets texture location and bound textures
     *
     * Actual `bind(null, i)` calls will be performed at next `unbind()` call
     */ TextureSystem1.prototype.reset = function() {
        this._unknownBoundTextures = true;
        this.hasIntegerTextures = false;
        this.currentLocation = -1;
        for(var i = 0; i < this.boundTextures.length; i++)this.boundTextures[i] = this.unknownTexture;
    };
    /**
     * Unbind a texture
     * @param {PIXI.BaseTexture} texture - Texture to bind
     */ TextureSystem1.prototype.unbind = function(texture) {
        var _a = this, gl = _a.gl, boundTextures = _a.boundTextures;
        if (this._unknownBoundTextures) {
            this._unknownBoundTextures = false;
            // someone changed webGL state,
            // we have to be sure that our texture does not appear in multi-texture renderer samplers
            for(var i = 0; i < boundTextures.length; i++)if (boundTextures[i] === this.unknownTexture) this.bind(null, i);
        }
        for(var i = 0; i < boundTextures.length; i++)if (boundTextures[i] === texture) {
            if (this.currentLocation !== i) {
                gl.activeTexture(gl.TEXTURE0 + i);
                this.currentLocation = i;
            }
            gl.bindTexture(texture.target, this.emptyTextures[texture.target].texture);
            boundTextures[i] = null;
        }
    };
    /**
     * Ensures that current boundTextures all have FLOAT sampler type,
     * see {@link PIXI.SAMPLER_TYPES} for explanation.
     *
     * @param maxTextures - number of locations to check
     */ TextureSystem1.prototype.ensureSamplerType = function(maxTextures) {
        var _a = this, boundTextures = _a.boundTextures, hasIntegerTextures = _a.hasIntegerTextures, CONTEXT_UID = _a.CONTEXT_UID;
        if (!hasIntegerTextures) return;
        for(var i = maxTextures - 1; i >= 0; --i){
            var tex = boundTextures[i];
            if (tex) {
                var glTexture = tex._glTextures[CONTEXT_UID];
                if (glTexture.samplerType !== _constants.SAMPLER_TYPES.FLOAT) this.renderer.texture.unbind(tex);
            }
        }
    };
    /**
     * Initialize a texture
     *
     * @private
     * @param {PIXI.BaseTexture} texture - Texture to initialize
     */ TextureSystem1.prototype.initTexture = function(texture) {
        var glTexture = new GLTexture(this.gl.createTexture());
        // guarantee an update..
        glTexture.dirtyId = -1;
        texture._glTextures[this.CONTEXT_UID] = glTexture;
        this.managedTextures.push(texture);
        texture.on('dispose', this.destroyTexture, this);
        return glTexture;
    };
    TextureSystem1.prototype.initTextureType = function(texture, glTexture) {
        var _a, _b;
        glTexture.internalFormat = (_b = (_a = this.internalFormats[texture.type]) === null || _a === void 0 ? void 0 : _a[texture.format]) !== null && _b !== void 0 ? _b : texture.format;
        if (this.webGLVersion === 2 && texture.type === _constants.TYPES.HALF_FLOAT) // TYPES.HALF_FLOAT is WebGL1 HALF_FLOAT_OES
        // we have to convert it to WebGL HALF_FLOAT
        glTexture.type = this.gl.HALF_FLOAT;
        else glTexture.type = texture.type;
    };
    /**
     * Update a texture
     *
     * @private
     * @param {PIXI.BaseTexture} texture - Texture to initialize
     */ TextureSystem1.prototype.updateTexture = function(texture) {
        var glTexture = texture._glTextures[this.CONTEXT_UID];
        if (!glTexture) return;
        var renderer = this.renderer;
        this.initTextureType(texture, glTexture);
        if (texture.resource && texture.resource.upload(renderer, texture, glTexture)) // texture is uploaded, dont do anything!
        {
            if (glTexture.samplerType !== _constants.SAMPLER_TYPES.FLOAT) this.hasIntegerTextures = true;
        } else {
            // default, renderTexture-like logic
            var width = texture.realWidth;
            var height = texture.realHeight;
            var gl = renderer.gl;
            if (glTexture.width !== width || glTexture.height !== height || glTexture.dirtyId < 0) {
                glTexture.width = width;
                glTexture.height = height;
                gl.texImage2D(texture.target, 0, glTexture.internalFormat, width, height, 0, texture.format, glTexture.type, null);
            }
        }
        // lets only update what changes..
        if (texture.dirtyStyleId !== glTexture.dirtyStyleId) this.updateTextureStyle(texture);
        glTexture.dirtyId = texture.dirtyId;
    };
    /**
     * Deletes the texture from WebGL
     *
     * @private
     * @param {PIXI.BaseTexture|PIXI.Texture} texture_ - the texture to destroy
     * @param {boolean} [skipRemove=false] - Whether to skip removing the texture from the TextureManager.
     */ TextureSystem1.prototype.destroyTexture = function(texture, skipRemove) {
        var gl = this.gl;
        texture = texture.castToBaseTexture();
        if (texture._glTextures[this.CONTEXT_UID]) {
            this.unbind(texture);
            gl.deleteTexture(texture._glTextures[this.CONTEXT_UID].texture);
            texture.off('dispose', this.destroyTexture, this);
            delete texture._glTextures[this.CONTEXT_UID];
            if (!skipRemove) {
                var i = this.managedTextures.indexOf(texture);
                if (i !== -1) _utils.removeItems(this.managedTextures, i, 1);
            }
        }
    };
    /**
     * Update texture style such as mipmap flag
     *
     * @private
     * @param {PIXI.BaseTexture} texture - Texture to update
     */ TextureSystem1.prototype.updateTextureStyle = function(texture) {
        var glTexture = texture._glTextures[this.CONTEXT_UID];
        if (!glTexture) return;
        if ((texture.mipmap === _constants.MIPMAP_MODES.POW2 || this.webGLVersion !== 2) && !texture.isPowerOfTwo) glTexture.mipmap = false;
        else glTexture.mipmap = texture.mipmap >= 1;
        if (this.webGLVersion !== 2 && !texture.isPowerOfTwo) glTexture.wrapMode = _constants.WRAP_MODES.CLAMP;
        else glTexture.wrapMode = texture.wrapMode;
        if (texture.resource && texture.resource.style(this.renderer, texture, glTexture)) ;
        else this.setStyle(texture, glTexture);
        glTexture.dirtyStyleId = texture.dirtyStyleId;
    };
    /**
     * Set style for texture
     *
     * @private
     * @param {PIXI.BaseTexture} texture - Texture to update
     * @param {PIXI.GLTexture} glTexture
     */ TextureSystem1.prototype.setStyle = function(texture, glTexture) {
        var gl = this.gl;
        if (glTexture.mipmap && texture.mipmap !== _constants.MIPMAP_MODES.ON_MANUAL) gl.generateMipmap(texture.target);
        gl.texParameteri(texture.target, gl.TEXTURE_WRAP_S, glTexture.wrapMode);
        gl.texParameteri(texture.target, gl.TEXTURE_WRAP_T, glTexture.wrapMode);
        if (glTexture.mipmap) {
            /* eslint-disable max-len */ gl.texParameteri(texture.target, gl.TEXTURE_MIN_FILTER, texture.scaleMode === _constants.SCALE_MODES.LINEAR ? gl.LINEAR_MIPMAP_LINEAR : gl.NEAREST_MIPMAP_NEAREST);
            /* eslint-disable max-len */ var anisotropicExt = this.renderer.context.extensions.anisotropicFiltering;
            if (anisotropicExt && texture.anisotropicLevel > 0 && texture.scaleMode === _constants.SCALE_MODES.LINEAR) {
                var level = Math.min(texture.anisotropicLevel, gl.getParameter(anisotropicExt.MAX_TEXTURE_MAX_ANISOTROPY_EXT));
                gl.texParameterf(texture.target, anisotropicExt.TEXTURE_MAX_ANISOTROPY_EXT, level);
            }
        } else gl.texParameteri(texture.target, gl.TEXTURE_MIN_FILTER, texture.scaleMode === _constants.SCALE_MODES.LINEAR ? gl.LINEAR : gl.NEAREST);
        gl.texParameteri(texture.target, gl.TEXTURE_MAG_FILTER, texture.scaleMode === _constants.SCALE_MODES.LINEAR ? gl.LINEAR : gl.NEAREST);
    };
    /**
     * @ignore
     */ TextureSystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    return TextureSystem1;
}();
var _systems = {
    __proto__: null,
    FilterSystem: FilterSystem,
    BatchSystem: BatchSystem,
    ContextSystem: ContextSystem,
    FramebufferSystem: FramebufferSystem,
    GeometrySystem: GeometrySystem,
    MaskSystem: MaskSystem,
    ScissorSystem: ScissorSystem1,
    StencilSystem: StencilSystem1,
    ProjectionSystem: ProjectionSystem,
    RenderTextureSystem: RenderTextureSystem,
    ShaderSystem: ShaderSystem,
    StateSystem: StateSystem,
    TextureGCSystem: TextureGCSystem,
    TextureSystem: TextureSystem
};
var tempMatrix$1 = new _math.Matrix();
/**
 * The AbstractRenderer is the base for a PixiJS Renderer. It is extended by the {@link PIXI.CanvasRenderer}
 * and {@link PIXI.Renderer} which can be used for rendering a PixiJS scene.
 *
 * @abstract
 * @class
 * @extends PIXI.utils.EventEmitter
 * @memberof PIXI
 */ var AbstractRenderer1 = function(_super) {
    __extends(AbstractRenderer2, _super);
    /**
     * @param system - The name of the system this renderer is for.
     * @param [options] - The optional renderer parameters.
     * @param {number} [options.width=800] - The width of the screen.
     * @param {number} [options.height=600] - The height of the screen.
     * @param {HTMLCanvasElement} [options.view] - The canvas to use as a view, optional.
     * @param {boolean} [options.useContextAlpha=true] - Pass-through value for canvas' context `alpha` property.
     *   If you want to set transparency, please use `backgroundAlpha`. This option is for cases where the
     *   canvas needs to be opaque, possibly for performance reasons on some older devices.
     * @param {boolean} [options.autoDensity=false] - Resizes renderer view in CSS pixels to allow for
     *   resolutions other than 1.
     * @param {boolean} [options.antialias=false] - Sets antialias
     * @param {number} [options.resolution=PIXI.settings.RESOLUTION] - The resolution / device pixel ratio of the renderer.
     * @param {boolean} [options.preserveDrawingBuffer=false] - Enables drawing buffer preservation,
     *  enable this if you need to call toDataUrl on the WebGL context.
     * @param {boolean} [options.clearBeforeRender=true] - This sets if the renderer will clear the canvas or
     *      not before the new render pass.
     * @param {number} [options.backgroundColor=0x000000] - The background color of the rendered area
     *  (shown if not transparent).
     * @param {number} [options.backgroundAlpha=1] - Value from 0 (fully transparent) to 1 (fully opaque).
     */ function AbstractRenderer2(type, options) {
        if (type === void 0) type = _constants.RENDERER_TYPE.UNKNOWN;
        var _this = _super.call(this) || this;
        // Add the default render options
        options = Object.assign({
        }, _settings.settings.RENDER_OPTIONS, options);
        /**
         * The supplied constructor options.
         *
         * @member {Object}
         * @readOnly
         */ _this.options = options;
        /**
         * The type of the renderer.
         *
         * @member {number}
         * @default PIXI.RENDERER_TYPE.UNKNOWN
         * @see PIXI.RENDERER_TYPE
         */ _this.type = type;
        /**
         * Measurements of the screen. (0, 0, screenWidth, screenHeight).
         *
         * Its safe to use as filterArea or hitArea for the whole stage.
         *
         * @member {PIXI.Rectangle}
         */ _this.screen = new _math.Rectangle(0, 0, options.width, options.height);
        /**
         * The canvas element that everything is drawn to.
         *
         * @member {HTMLCanvasElement}
         */ _this.view = options.view || document.createElement('canvas');
        /**
         * The resolution / device pixel ratio of the renderer.
         *
         * @member {number}
         * @default PIXI.settings.RESOLUTION
         */ _this.resolution = options.resolution || _settings.settings.RESOLUTION;
        /**
         * Pass-thru setting for the the canvas' context `alpha` property. This is typically
         * not something you need to fiddle with. If you want transparency, use `backgroundAlpha`.
         *
         * @member {boolean}
         */ _this.useContextAlpha = options.useContextAlpha;
        /**
         * Whether CSS dimensions of canvas view should be resized to screen dimensions automatically.
         *
         * @member {boolean}
         */ _this.autoDensity = !!options.autoDensity;
        /**
         * The value of the preserveDrawingBuffer flag affects whether or not the contents of
         * the stencil buffer is retained after rendering.
         *
         * @member {boolean}
         */ _this.preserveDrawingBuffer = options.preserveDrawingBuffer;
        /**
         * This sets if the CanvasRenderer will clear the canvas or not before the new render pass.
         * If the scene is NOT transparent PixiJS will use a canvas sized fillRect operation every
         * frame to set the canvas background color. If the scene is transparent PixiJS will use clearRect
         * to clear the canvas every frame. Disable this by setting this to false. For example, if
         * your game has a canvas filling background image you often don't need this set.
         *
         * @member {boolean}
         * @default
         */ _this.clearBeforeRender = options.clearBeforeRender;
        /**
         * The background color as a number.
         *
         * @member {number}
         * @protected
         */ _this._backgroundColor = 0;
        /**
         * The background color as an [R, G, B, A] array.
         *
         * @member {number[]}
         * @protected
         */ _this._backgroundColorRgba = [
            0,
            0,
            0,
            1
        ];
        /**
         * The background color as a string.
         *
         * @member {string}
         * @protected
         */ _this._backgroundColorString = '#000000';
        _this.backgroundColor = options.backgroundColor || _this._backgroundColor; // run bg color setter
        _this.backgroundAlpha = options.backgroundAlpha;
        // @deprecated
        if (options.transparent !== undefined) {
            _utils.deprecation('6.0.0', 'Option transparent is deprecated, please use backgroundAlpha instead.');
            _this.useContextAlpha = options.transparent;
            _this.backgroundAlpha = options.transparent ? 0 : 1;
        }
        /**
         * The last root object that the renderer tried to render.
         *
         * @member {PIXI.DisplayObject}
         * @protected
         */ _this._lastObjectRendered = null;
        /**
         * Collection of plugins.
         * @readonly
         * @member {object}
         */ _this.plugins = {
        };
        return _this;
    }
    /**
     * Initialize the plugins.
     *
     * @protected
     * @param {object} staticMap - The dictionary of statically saved plugins.
     */ AbstractRenderer2.prototype.initPlugins = function(staticMap) {
        for(var o in staticMap)this.plugins[o] = new staticMap[o](this);
    };
    Object.defineProperty(AbstractRenderer2.prototype, "width", {
        /**
         * Same as view.width, actual number of pixels in the canvas by horizontal.
         *
         * @member {number}
         * @readonly
         * @default 800
         */ get: function() {
            return this.view.width;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(AbstractRenderer2.prototype, "height", {
        /**
         * Same as view.height, actual number of pixels in the canvas by vertical.
         *
         * @member {number}
         * @readonly
         * @default 600
         */ get: function() {
            return this.view.height;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Resizes the screen and canvas as close as possible to the specified width and height.
     * Canvas dimensions are multiplied by resolution and rounded to the nearest integers.
     * The new canvas dimensions divided by the resolution become the new screen dimensions.
     *
     * @param desiredScreenWidth - The desired width of the screen.
     * @param desiredScreenHeight - The desired height of the screen.
     */ AbstractRenderer2.prototype.resize = function(desiredScreenWidth, desiredScreenHeight) {
        this.view.width = Math.round(desiredScreenWidth * this.resolution);
        this.view.height = Math.round(desiredScreenHeight * this.resolution);
        var screenWidth = this.view.width / this.resolution;
        var screenHeight = this.view.height / this.resolution;
        this.screen.width = screenWidth;
        this.screen.height = screenHeight;
        if (this.autoDensity) {
            this.view.style.width = screenWidth + "px";
            this.view.style.height = screenHeight + "px";
        }
        /**
         * Fired after view has been resized.
         *
         * @event PIXI.Renderer#resize
         * @param {number} screenWidth - The new width of the screen.
         * @param {number} screenHeight - The new height of the screen.
         */ this.emit('resize', screenWidth, screenHeight);
    };
    /**
     * @ignore
     */ AbstractRenderer2.prototype.generateTexture = function(displayObject, options, resolution, region) {
        if (options === void 0) options = {
        };
        // @deprecated parameters spread, use options instead
        if (typeof options === 'number') {
            _utils.deprecation('6.1.0', 'generateTexture options (scaleMode, resolution, region) are now object options.');
            options = {
                scaleMode: options,
                resolution: resolution,
                region: region
            };
        }
        var manualRegion = options.region, textureOptions = __rest(options, [
            "region"
        ]);
        region = manualRegion || displayObject.getLocalBounds(null, true);
        // minimum texture size is 1x1, 0x0 will throw an error
        if (region.width === 0) region.width = 1;
        if (region.height === 0) region.height = 1;
        var renderTexture = RenderTexture1.create(__assign({
            width: region.width,
            height: region.height
        }, textureOptions));
        tempMatrix$1.tx = -region.x;
        tempMatrix$1.ty = -region.y;
        this.render(displayObject, {
            renderTexture: renderTexture,
            clear: false,
            transform: tempMatrix$1,
            skipUpdateTransform: !!displayObject.parent
        });
        return renderTexture;
    };
    /**
     * Removes everything from the renderer and optionally removes the Canvas DOM element.
     *
     * @param [removeView=false] - Removes the Canvas element from the DOM.
     */ AbstractRenderer2.prototype.destroy = function(removeView) {
        for(var o in this.plugins){
            this.plugins[o].destroy();
            this.plugins[o] = null;
        }
        if (removeView && this.view.parentNode) this.view.parentNode.removeChild(this.view);
        var thisAny = this;
        // null-ing all objects, that's a tradition!
        thisAny.plugins = null;
        thisAny.type = _constants.RENDERER_TYPE.UNKNOWN;
        thisAny.view = null;
        thisAny.screen = null;
        thisAny._tempDisplayObjectParent = null;
        thisAny.options = null;
        this._backgroundColorRgba = null;
        this._backgroundColorString = null;
        this._lastObjectRendered = null;
    };
    Object.defineProperty(AbstractRenderer2.prototype, "backgroundColor", {
        /**
         * The background color to fill if not transparent
         *
         * @member {number}
         */ get: function() {
            return this._backgroundColor;
        },
        set: function(value) {
            this._backgroundColor = value;
            this._backgroundColorString = _utils.hex2string(value);
            _utils.hex2rgb(value, this._backgroundColorRgba);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(AbstractRenderer2.prototype, "backgroundAlpha", {
        /**
         * The background color alpha. Setting this to 0 will make the canvas transparent.
         *
         * @member {number}
         */ get: function() {
            return this._backgroundColorRgba[3];
        },
        set: function(value) {
            this._backgroundColorRgba[3] = value;
        },
        enumerable: false,
        configurable: true
    });
    return AbstractRenderer2;
}(_utils.EventEmitter);
var GLBuffer = function() {
    function GLBuffer1(buffer) {
        this.buffer = buffer || null;
        this.updateID = -1;
        this.byteLength = -1;
        this.refCount = 0;
    }
    return GLBuffer1;
}();
/**
 * System plugin to the renderer to manage buffers.
 *
 * WebGL uses Buffers as a way to store objects to the GPU.
 * This system makes working with them a lot easier.
 *
 * Buffers are used in three main places in WebGL
 * - geometry information
 * - Uniform information (via uniform buffer objects - a WebGL 2 only feature)
 * - Transform feedback information. (WebGL 2 only feature)
 *
 * This system will handle the binding of buffers to the GPU as well as uploading
 * them. With this system, you never need to work directly with GPU buffers, but instead work with
 * the PIXI.Buffer class.
 *
 *
 * @class
 * @memberof PIXI
 */ var BufferSystem = function() {
    /**
     * @param {PIXI.Renderer} renderer - The renderer this System works for.
     */ function BufferSystem1(renderer) {
        this.renderer = renderer;
        this.managedBuffers = {
        };
        this.boundBufferBases = {
        };
    }
    /**
     * @ignore
     */ BufferSystem1.prototype.destroy = function() {
        this.renderer = null;
    };
    /**
     * Sets up the renderer context and necessary buffers.
     */ BufferSystem1.prototype.contextChange = function() {
        this.disposeAll(true);
        this.gl = this.renderer.gl;
        // TODO fill out...
        this.CONTEXT_UID = this.renderer.CONTEXT_UID;
    };
    /**
     * This binds specified buffer. On first run, it will create the webGL buffers for the context too
     *
     * @param buffer - the buffer to bind to the renderer
     */ BufferSystem1.prototype.bind = function(buffer) {
        var _a = this, gl = _a.gl, CONTEXT_UID = _a.CONTEXT_UID;
        var glBuffer = buffer._glBuffers[CONTEXT_UID] || this.createGLBuffer(buffer);
        gl.bindBuffer(buffer.type, glBuffer.buffer);
    };
    /**
     * Binds an uniform buffer to at the given index.
     *
     * A cache is used so a buffer will not be bound again if already bound.
     *
     * @param buffer - the buffer to bind
     * @param index - the base index to bind it to.
     */ BufferSystem1.prototype.bindBufferBase = function(buffer, index) {
        var _a = this, gl = _a.gl, CONTEXT_UID = _a.CONTEXT_UID;
        if (this.boundBufferBases[index] !== buffer) {
            var glBuffer = buffer._glBuffers[CONTEXT_UID] || this.createGLBuffer(buffer);
            this.boundBufferBases[index] = buffer;
            gl.bindBufferBase(gl.UNIFORM_BUFFER, index, glBuffer.buffer);
        }
    };
    /**
     * Binds a buffer whilst also binding its range.
     * This will make the buffer start from the offset supplied rather than 0 when it is read.
     *
     * @param buffer - the buffer to bind
     * @param index - the base index to bind at, defaults to 0
     * @param offset - the offset to bind at (this is blocks of 256). 0 = 0, 1 = 256, 2 = 512 etc
     */ BufferSystem1.prototype.bindBufferRange = function(buffer, index, offset) {
        var _a = this, gl = _a.gl, CONTEXT_UID = _a.CONTEXT_UID;
        offset = offset || 0;
        var glBuffer = buffer._glBuffers[CONTEXT_UID] || this.createGLBuffer(buffer);
        gl.bindBufferRange(gl.UNIFORM_BUFFER, index || 0, glBuffer.buffer, offset * 256, 256);
    };
    /**
     * Will ensure sure the the data in the buffer is uploaded to the GPU.
     *
     * @param {PIXI.Buffer} buffer - the buffer to update
     */ BufferSystem1.prototype.update = function(buffer) {
        var _a = this, gl = _a.gl, CONTEXT_UID = _a.CONTEXT_UID;
        var glBuffer = buffer._glBuffers[CONTEXT_UID];
        if (buffer._updateID === glBuffer.updateID) return;
        glBuffer.updateID = buffer._updateID;
        gl.bindBuffer(buffer.type, glBuffer.buffer);
        if (glBuffer.byteLength >= buffer.data.byteLength) // offset is always zero for now!
        gl.bufferSubData(buffer.type, 0, buffer.data);
        else {
            var drawType = buffer.static ? gl.STATIC_DRAW : gl.DYNAMIC_DRAW;
            glBuffer.byteLength = buffer.data.byteLength;
            gl.bufferData(buffer.type, buffer.data, drawType);
        }
    };
    /**
     * Disposes buffer
     * @param {PIXI.Buffer} buffer - buffer with data
     * @param {boolean} [contextLost=false] - If context was lost, we suppress deleteVertexArray
     */ BufferSystem1.prototype.dispose = function(buffer, contextLost) {
        if (!this.managedBuffers[buffer.id]) return;
        delete this.managedBuffers[buffer.id];
        var glBuffer = buffer._glBuffers[this.CONTEXT_UID];
        var gl = this.gl;
        buffer.disposeRunner.remove(this);
        if (!glBuffer) return;
        if (!contextLost) gl.deleteBuffer(glBuffer.buffer);
        delete buffer._glBuffers[this.CONTEXT_UID];
    };
    /**
     * dispose all WebGL resources of all managed buffers
     * @param {boolean} [contextLost=false] - If context was lost, we suppress `gl.delete` calls
     */ BufferSystem1.prototype.disposeAll = function(contextLost) {
        var all = Object.keys(this.managedBuffers);
        for(var i = 0; i < all.length; i++)this.dispose(this.managedBuffers[all[i]], contextLost);
    };
    /**
     * creates and attaches a GLBuffer object tied to the current context.
     * @protected
     */ BufferSystem1.prototype.createGLBuffer = function(buffer) {
        var _a = this, CONTEXT_UID = _a.CONTEXT_UID, gl = _a.gl;
        buffer._glBuffers[CONTEXT_UID] = new GLBuffer(gl.createBuffer());
        this.managedBuffers[buffer.id] = buffer;
        buffer.disposeRunner.add(this);
        return buffer._glBuffers[CONTEXT_UID];
    };
    return BufferSystem1;
}();
/**
 * The Renderer draws the scene and all its content onto a WebGL enabled canvas.
 *
 * This renderer should be used for browsers that support WebGL.
 *
 * This renderer works by automatically managing WebGLBatchesm, so no need for Sprite Batches or Sprite Clouds.
 * Don't forget to add the view to your DOM or you will not see anything!
 *
 * Renderer is composed of systems that manage specific tasks. The following systems are added by default
 * whenever you create a renderer:
 *
 * | System                               | Description                                                                   |
 * | ------------------------------------ | ----------------------------------------------------------------------------- |
 * | {@link PIXI.BatchSystem}             | This manages object renderers that defer rendering until a flush.             |
 * | {@link PIXI.ContextSystem}           | This manages the WebGL context and extensions.                                |
 * | {@link PIXI.EventSystem}             | This manages UI events.                                                       |
 * | {@link PIXI.FilterSystem}            | This manages the filtering pipeline for post-processing effects.              |
 * | {@link PIXI.FramebufferSystem}       | This manages framebuffers, which are used for offscreen rendering.            |
 * | {@link PIXI.GeometrySystem}          | This manages geometries & buffers, which are used to draw object meshes.      |
 * | {@link PIXI.MaskSystem}              | This manages masking operations.                                              |
 * | {@link PIXI.ProjectionSystem}        | This manages the `projectionMatrix`, used by shaders to get NDC coordinates.  |
 * | {@link PIXI.RenderTextureSystem}     | This manages render-textures, which are an abstraction over framebuffers.     |
 * | {@link PIXI.ScissorSystem}           | This handles scissor masking, and is used internally by {@link MaskSystem}    |
 * | {@link PIXI.ShaderSystem}            | This manages shaders, programs that run on the GPU to calculate 'em pixels.   |
 * | {@link PIXI.StateSystem}             | This manages the WebGL state variables like blend mode, depth testing, etc.   |
 * | {@link PIXI.StencilSystem}           | This handles stencil masking, and is used internally by {@link MaskSystem}    |
 * | {@link PIXI.TextureSystem}           | This manages textures and their resources on the GPU.                         |
 * | {@link PIXI.TextureGCSystem}         | This will automatically remove textures from the GPU if they are not used.    |
 *
 * The breadth of the API surface provided by the renderer is contained within these systems.
 *
 * @class
 * @memberof PIXI
 * @extends PIXI.AbstractRenderer
 */ var Renderer1 = function(_super) {
    __extends(Renderer2, _super);
    /**
     * @param [options] - The optional renderer parameters.
     * @param {number} [options.width=800] - The width of the screen.
     * @param {number} [options.height=600] - The height of the screen.
     * @param {HTMLCanvasElement} [options.view] - The canvas to use as a view, optional.
     * @param {boolean} [options.useContextAlpha=true] - Pass-through value for canvas' context `alpha` property.
     *   If you want to set transparency, please use `backgroundAlpha`. This option is for cases where the
     *   canvas needs to be opaque, possibly for performance reasons on some older devices.
     * @param {boolean} [options.autoDensity=false] - Resizes renderer view in CSS pixels to allow for
     *   resolutions other than 1.
     * @param {boolean} [options.antialias=false] - Sets antialias. If not available natively then FXAA
     *  antialiasing is used.
     * @param {number} [options.resolution=PIXI.settings.RESOLUTION] - The resolution / device pixel ratio of the renderer.
     * @param {boolean} [options.clearBeforeRender=true] - This sets if the renderer will clear
     *  the canvas or not before the new render pass. If you wish to set this to false, you *must* set
     *  preserveDrawingBuffer to `true`.
     * @param {boolean} [options.preserveDrawingBuffer=false] - Enables drawing buffer preservation,
     *  enable this if you need to call toDataUrl on the WebGL context.
     * @param {number} [options.backgroundColor=0x000000] - The background color of the rendered area
     *  (shown if not transparent).
     * @param {number} [options.backgroundAlpha=1] - Value from 0 (fully transparent) to 1 (fully opaque).
     * @param {string} [options.powerPreference] - Parameter passed to WebGL context, set to "high-performance"
     *  for devices with dual graphics card.
     * @param {object} [options.context] - If WebGL context already exists, all parameters must be taken from it.
     * @public
     */ function Renderer2(options) {
        var _this = _super.call(this, _constants.RENDERER_TYPE.WEBGL, options) || this;
        // the options will have been modified here in the super constructor with pixi's default settings..
        options = _this.options;
        /**
         * WebGL context, set by the contextSystem (this.context)
         *
         * @readonly
         * @member {WebGLRenderingContext}
         */ _this.gl = null;
        _this.CONTEXT_UID = 0;
        /**
         * Internal signal instances of **runner**, these
         * are assigned to each system created.
         * @see PIXI.Runner
         * @name runners
         * @private
         * @type {object}
         * @readonly
         * @property {PIXI.Runner} destroy - Destroy runner
         * @property {PIXI.Runner} contextChange - Context change runner
         * @property {PIXI.Runner} reset - Reset runner
         * @property {PIXI.Runner} update - Update runner
         * @property {PIXI.Runner} postrender - Post-render runner
         * @property {PIXI.Runner} prerender - Pre-render runner
         * @property {PIXI.Runner} resize - Resize runner
         */ _this.runners = {
            destroy: new _runner.Runner('destroy'),
            contextChange: new _runner.Runner('contextChange'),
            reset: new _runner.Runner('reset'),
            update: new _runner.Runner('update'),
            postrender: new _runner.Runner('postrender'),
            prerender: new _runner.Runner('prerender'),
            resize: new _runner.Runner('resize')
        };
        _this.runners.contextChange.add(_this);
        /**
         * Global uniforms
         * @member {PIXI.UniformGroup}
         */ _this.globalUniforms = new UniformGroup({
            projectionMatrix: new _math.Matrix()
        }, true);
        /**
         * Mask system instance
         * @member {PIXI.MaskSystem} mask
         * @memberof PIXI.Renderer#
         * @readonly
         */ _this.addSystem(MaskSystem, 'mask')/**
             * Context system instance
             * @member {PIXI.ContextSystem} context
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(ContextSystem, 'context')/**
             * State system instance
             * @member {PIXI.StateSystem} state
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(StateSystem, 'state')/**
             * Shader system instance
             * @member {PIXI.ShaderSystem} shader
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(ShaderSystem, 'shader')/**
             * Texture system instance
             * @member {PIXI.TextureSystem} texture
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(TextureSystem, 'texture')/**
             * Geometry system instance
             * @member {PIXI.systems.BufferSystem} buffer
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(BufferSystem, 'buffer')/**
             * Geometry system instance
             * @member {PIXI.systems.GeometrySystem} geometry
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(GeometrySystem, 'geometry')/**
             * Framebuffer system instance
             * @member {PIXI.FramebufferSystem} framebuffer
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(FramebufferSystem, 'framebuffer')/**
             * Scissor system instance
             * @member {PIXI.ScissorSystem} scissor
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(ScissorSystem1, 'scissor')/**
             * Stencil system instance
             * @member {PIXI.StencilSystem} stencil
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(StencilSystem1, 'stencil')/**
             * Projection system instance
             * @member {PIXI.ProjectionSystem} projection
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(ProjectionSystem, 'projection')/**
             * Texture garbage collector system instance
             * @member {PIXI.TextureGCSystem} textureGC
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(TextureGCSystem, 'textureGC')/**
             * Filter system instance
             * @member {PIXI.FilterSystem} filter
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(FilterSystem, 'filter')/**
             * RenderTexture system instance
             * @member {PIXI.RenderTextureSystem} renderTexture
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(RenderTextureSystem, 'renderTexture')/**
             * Batch system instance
             * @member {PIXI.BatchSystem} batch
             * @memberof PIXI.Renderer#
             * @readonly
             */ .addSystem(BatchSystem, 'batch');
        _this.initPlugins(Renderer2.__plugins);
        /**
         * The number of msaa samples of the canvas.
         * @member {PIXI.MSAA_QUALITY}
         * @readonly
         */ _this.multisample = undefined;
        /*
         * The options passed in to create a new WebGL context.
         */ if (options.context) _this.context.initFromContext(options.context);
        else _this.context.initFromOptions({
            alpha: !!_this.useContextAlpha,
            antialias: options.antialias,
            premultipliedAlpha: _this.useContextAlpha && _this.useContextAlpha !== 'notMultiplied',
            stencil: true,
            preserveDrawingBuffer: options.preserveDrawingBuffer,
            powerPreference: _this.options.powerPreference
        });
        /**
         * Flag if we are rendering to the screen vs renderTexture
         * @member {boolean}
         * @readonly
         * @default true
         */ _this.renderingToScreen = true;
        _utils.sayHello(_this.context.webGLVersion === 2 ? 'WebGL 2' : 'WebGL 1');
        _this.resize(_this.options.width, _this.options.height);
        return _this;
    }
    /**
     * Create renderer if WebGL is available. Overrideable
     * by the **@pixi/canvas-renderer** package to allow fallback.
     * throws error if WebGL is not available.
     * @static
     * @private
     */ Renderer2.create = function(options) {
        if (_utils.isWebGLSupported()) return new Renderer2(options);
        throw new Error('WebGL unsupported in this browser, use "pixi.js-legacy" for fallback canvas2d support.');
    };
    Renderer2.prototype.contextChange = function() {
        var gl = this.gl;
        var samples;
        if (this.context.webGLVersion === 1) {
            var framebuffer = gl.getParameter(gl.FRAMEBUFFER_BINDING);
            gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            samples = gl.getParameter(gl.SAMPLES);
            gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
        } else {
            var framebuffer = gl.getParameter(gl.DRAW_FRAMEBUFFER_BINDING);
            gl.bindFramebuffer(gl.DRAW_FRAMEBUFFER, null);
            samples = gl.getParameter(gl.SAMPLES);
            gl.bindFramebuffer(gl.DRAW_FRAMEBUFFER, framebuffer);
        }
        if (samples >= _constants.MSAA_QUALITY.HIGH) this.multisample = _constants.MSAA_QUALITY.HIGH;
        else if (samples >= _constants.MSAA_QUALITY.MEDIUM) this.multisample = _constants.MSAA_QUALITY.MEDIUM;
        else if (samples >= _constants.MSAA_QUALITY.LOW) this.multisample = _constants.MSAA_QUALITY.LOW;
        else this.multisample = _constants.MSAA_QUALITY.NONE;
    };
    /**
     * Add a new system to the renderer.
     * @param ClassRef - Class reference
     * @param [name] - Property name for system, if not specified
     *        will use a static `name` property on the class itself. This
     *        name will be assigned as s property on the Renderer so make
     *        sure it doesn't collide with properties on Renderer.
     * @return {PIXI.Renderer} Return instance of renderer
     */ Renderer2.prototype.addSystem = function(ClassRef, name) {
        var system = new ClassRef(this);
        if (this[name]) throw new Error("Whoops! The name \"" + name + "\" is already in use");
        this[name] = system;
        for(var i in this.runners)this.runners[i].add(system);
        /**
         * Fired after rendering finishes.
         *
         * @event PIXI.Renderer#postrender
         */ /**
         * Fired before rendering starts.
         *
         * @event PIXI.Renderer#prerender
         */ /**
         * Fired when the WebGL context is set.
         *
         * @event PIXI.Renderer#context
         * @param {WebGLRenderingContext} gl - WebGL context.
         */ return this;
    };
    /**
     * @ignore
     */ Renderer2.prototype.render = function(displayObject, options) {
        var renderTexture;
        var clear;
        var transform;
        var skipUpdateTransform;
        if (options) {
            if (options instanceof RenderTexture1) {
                _utils.deprecation('6.0.0', 'Renderer#render arguments changed, use options instead.');
                /* eslint-disable prefer-rest-params */ renderTexture = options;
                clear = arguments[2];
                transform = arguments[3];
                skipUpdateTransform = arguments[4];
            /* eslint-enable prefer-rest-params */ } else {
                renderTexture = options.renderTexture;
                clear = options.clear;
                transform = options.transform;
                skipUpdateTransform = options.skipUpdateTransform;
            }
        }
        // can be handy to know!
        this.renderingToScreen = !renderTexture;
        this.runners.prerender.emit();
        this.emit('prerender');
        // apply a transform at a GPU level
        this.projection.transform = transform;
        // no point rendering if our context has been blown up!
        if (this.context.isLost) return;
        if (!renderTexture) this._lastObjectRendered = displayObject;
        if (!skipUpdateTransform) {
            // update the scene graph
            var cacheParent = displayObject.enableTempParent();
            displayObject.updateTransform();
            displayObject.disableTempParent(cacheParent);
        // displayObject.hitArea = //TODO add a temp hit area
        }
        this.renderTexture.bind(renderTexture);
        this.batch.currentRenderer.start();
        if (clear !== undefined ? clear : this.clearBeforeRender) this.renderTexture.clear();
        displayObject.render(this);
        // apply transform..
        this.batch.currentRenderer.flush();
        if (renderTexture) renderTexture.baseTexture.update();
        this.runners.postrender.emit();
        // reset transform after render
        this.projection.transform = null;
        this.emit('postrender');
    };
    /**
     * @override
     * @ignore
     */ Renderer2.prototype.generateTexture = function(displayObject, options, resolution, region) {
        if (options === void 0) options = {
        };
        var renderTexture = _super.prototype.generateTexture.call(this, displayObject, options, resolution, region);
        this.framebuffer.blit();
        return renderTexture;
    };
    /**
     * Resizes the WebGL view to the specified width and height.
     *
     * @param desiredScreenWidth - The desired width of the screen.
     * @param desiredScreenHeight - The desired height of the screen.
     */ Renderer2.prototype.resize = function(desiredScreenWidth, desiredScreenHeight) {
        _super.prototype.resize.call(this, desiredScreenWidth, desiredScreenHeight);
        this.runners.resize.emit(this.screen.height, this.screen.width);
    };
    /**
     * Resets the WebGL state so you can render things however you fancy!
     *
     * @return {PIXI.Renderer} Returns itself.
     */ Renderer2.prototype.reset = function() {
        this.runners.reset.emit();
        return this;
    };
    /**
     * Clear the frame buffer
     */ Renderer2.prototype.clear = function() {
        this.renderTexture.bind();
        this.renderTexture.clear();
    };
    /**
     * Removes everything from the renderer (event listeners, spritebatch, etc...)
     *
     * @param [removeView=false] - Removes the Canvas element from the DOM.
     *  See: https://github.com/pixijs/pixi.js/issues/2233
     */ Renderer2.prototype.destroy = function(removeView) {
        this.runners.destroy.emit();
        for(var r in this.runners)this.runners[r].destroy();
        // call base destroy
        _super.prototype.destroy.call(this, removeView);
        // TODO nullify all the managers..
        this.gl = null;
    };
    Object.defineProperty(Renderer2.prototype, "extract", {
        /**
         * Please use `plugins.extract` instead.
         * @member {PIXI.Extract} extract
         * @deprecated since 6.0.0
         * @readonly
         */ get: function() {
            _utils.deprecation('6.0.0', 'Renderer#extract has been deprecated, please use Renderer#plugins.extract instead.');
            return this.plugins.extract;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Adds a plugin to the renderer.
     *
     * @method
     * @param pluginName - The name of the plugin.
     * @param ctor - The constructor function or class for the plugin.
     */ Renderer2.registerPlugin = function(pluginName, ctor) {
        Renderer2.__plugins = Renderer2.__plugins || {
        };
        Renderer2.__plugins[pluginName] = ctor;
    };
    return Renderer2;
}(AbstractRenderer1);
/**
 * This helper function will automatically detect which renderer you should be using.
 * WebGL is the preferred renderer as it is a lot faster. If WebGL is not supported by
 * the browser then this function will return a canvas renderer
 *
 * @memberof PIXI
 * @function autoDetectRenderer
 * @param {object} [options] - The optional renderer parameters
 * @param {number} [options.width=800] - the width of the renderers view
 * @param {number} [options.height=600] - the height of the renderers view
 * @param {HTMLCanvasElement} [options.view] - the canvas to use as a view, optional
 * @param {boolean} [options.useContextAlpha=true] - Pass-through value for canvas' context `alpha` property.
 *   If you want to set transparency, please use `backgroundAlpha`. This option is for cases where the
 *   canvas needs to be opaque, possibly for performance reasons on some older devices.
 * @param {boolean} [options.autoDensity=false] - Resizes renderer view in CSS pixels to allow for
 *   resolutions other than 1
 * @param {boolean} [options.antialias=false] - sets antialias
 * @param {boolean} [options.preserveDrawingBuffer=false] - enables drawing buffer preservation, enable this if you
 *  need to call toDataUrl on the webgl context
 * @param {number} [options.backgroundColor=0x000000] - The background color of the rendered area
 *  (shown if not transparent).
 * @param {number} [options.backgroundAlpha=1] - Value from 0 (fully transparent) to 1 (fully opaque).
 * @param {boolean} [options.clearBeforeRender=true] - This sets if the renderer will clear the canvas or
 *   not before the new render pass.
 * @param {number} [options.resolution=PIXI.settings.RESOLUTION] - The resolution / device pixel ratio of the renderer.
 * @param {boolean} [options.forceCanvas=false] - prevents selection of WebGL renderer, even if such is present, this
 *   option only is available when using **pixi.js-legacy** or **@pixi/canvas-renderer** modules, otherwise
 *   it is ignored.
 * @param {string} [options.powerPreference] - Parameter passed to webgl context, set to "high-performance"
 *  for devices with dual graphics card **webgl only**
 * @return {PIXI.Renderer|PIXI.CanvasRenderer} Returns WebGL renderer if available, otherwise CanvasRenderer
 */ function autoDetectRenderer(options) {
    return Renderer1.create(options);
}
var $defaultVertex = "attribute vec2 aVertexPosition;\nattribute vec2 aTextureCoord;\n\nuniform mat3 projectionMatrix;\n\nvarying vec2 vTextureCoord;\n\nvoid main(void)\n{\n    gl_Position = vec4((projectionMatrix * vec3(aVertexPosition, 1.0)).xy, 0.0, 1.0);\n    vTextureCoord = aTextureCoord;\n}";
var $defaultFilterVertex = "attribute vec2 aVertexPosition;\n\nuniform mat3 projectionMatrix;\n\nvarying vec2 vTextureCoord;\n\nuniform vec4 inputSize;\nuniform vec4 outputFrame;\n\nvec4 filterVertexPosition( void )\n{\n    vec2 position = aVertexPosition * max(outputFrame.zw, vec2(0.)) + outputFrame.xy;\n\n    return vec4((projectionMatrix * vec3(position, 1.0)).xy, 0.0, 1.0);\n}\n\nvec2 filterTextureCoord( void )\n{\n    return aVertexPosition * (outputFrame.zw * inputSize.zw);\n}\n\nvoid main(void)\n{\n    gl_Position = filterVertexPosition();\n    vTextureCoord = filterTextureCoord();\n}\n";
/**
 * Default vertex shader
 * @memberof PIXI
 * @member {string} defaultVertex
 */ /**
 * Default filter vertex shader
 * @memberof PIXI
 * @member {string} defaultFilterVertex
 */ // NOTE: This black magic is so that @microsoft/api-extractor does not complain! This explicitly specifies the types
// of defaultVertex, defaultFilterVertex.
var defaultVertex$2 = $defaultVertex;
var defaultFilterVertex = $defaultFilterVertex;
/**
 * Use the ISystem interface instead.
 * @deprecated since 6.1.0
 * @memberof PIXI
 */ var System = function() {
    /**
     * @param renderer - Reference to Renderer
     */ function System1(renderer) {
        _utils.deprecation('6.1.0', 'System class is deprecated, implemement ISystem interface instead.');
        this.renderer = renderer;
    }
    /** Destroy and don't use after this. */ System1.prototype.destroy = function() {
        this.renderer = null;
    };
    return System1;
}();
/**
 * Used by the batcher to draw batches.
 * Each one of these contains all information required to draw a bound geometry.
 *
 * @class
 * @memberof PIXI
 */ var BatchDrawCall = function() {
    function BatchDrawCall1() {
        this.texArray = null;
        this.blend = 0;
        this.type = _constants.DRAW_MODES.TRIANGLES;
        this.start = 0;
        this.size = 0;
        /**
         * data for uniforms or custom webgl state
         * @member {object}
         */ this.data = null;
    }
    return BatchDrawCall1;
}();
/**
 * Used by the batcher to build texture batches.
 * Holds list of textures and their respective locations.
 *
 * @class
 * @memberof PIXI
 */ var BatchTextureArray = function() {
    function BatchTextureArray1() {
        /**
         * inside textures array
         * @member {PIXI.BaseTexture[]}
         */ this.elements = [];
        /**
         * Respective locations for textures
         * @member {number[]}
         */ this.ids = [];
        /**
         * number of filled elements
         * @member {number}
         */ this.count = 0;
    }
    BatchTextureArray1.prototype.clear = function() {
        for(var i = 0; i < this.count; i++)this.elements[i] = null;
        this.count = 0;
    };
    return BatchTextureArray1;
}();
/**
 * Flexible wrapper around `ArrayBuffer` that also provides typed array views on demand.
 *
 * @class
 * @memberof PIXI
 */ var ViewableBuffer = function() {
    function ViewableBuffer1(sizeOrBuffer) {
        if (typeof sizeOrBuffer === 'number') /**
             * Underlying `ArrayBuffer` that holds all the data and is of capacity `this.size`.
             *
             * @member {ArrayBuffer}
             */ this.rawBinaryData = new ArrayBuffer(sizeOrBuffer);
        else if (sizeOrBuffer instanceof Uint8Array) this.rawBinaryData = sizeOrBuffer.buffer;
        else this.rawBinaryData = sizeOrBuffer;
        /**
         * View on the raw binary data as a `Uint32Array`.
         *
         * @member {Uint32Array}
         */ this.uint32View = new Uint32Array(this.rawBinaryData);
        /**
         * View on the raw binary data as a `Float32Array`.
         *
         * @member {Float32Array}
         */ this.float32View = new Float32Array(this.rawBinaryData);
    }
    Object.defineProperty(ViewableBuffer1.prototype, "int8View", {
        /**
         * View on the raw binary data as a `Int8Array`.
         *
         * @member {Int8Array}
         */ get: function() {
            if (!this._int8View) this._int8View = new Int8Array(this.rawBinaryData);
            return this._int8View;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ViewableBuffer1.prototype, "uint8View", {
        /**
         * View on the raw binary data as a `Uint8Array`.
         *
         * @member {Uint8Array}
         */ get: function() {
            if (!this._uint8View) this._uint8View = new Uint8Array(this.rawBinaryData);
            return this._uint8View;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ViewableBuffer1.prototype, "int16View", {
        /**
         * View on the raw binary data as a `Int16Array`.
         *
         * @member {Int16Array}
         */ get: function() {
            if (!this._int16View) this._int16View = new Int16Array(this.rawBinaryData);
            return this._int16View;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ViewableBuffer1.prototype, "uint16View", {
        /**
         * View on the raw binary data as a `Uint16Array`.
         *
         * @member {Uint16Array}
         */ get: function() {
            if (!this._uint16View) this._uint16View = new Uint16Array(this.rawBinaryData);
            return this._uint16View;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ViewableBuffer1.prototype, "int32View", {
        /**
         * View on the raw binary data as a `Int32Array`.
         *
         * @member {Int32Array}
         */ get: function() {
            if (!this._int32View) this._int32View = new Int32Array(this.rawBinaryData);
            return this._int32View;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Returns the view of the given type.
     *
     * @param {string} type - One of `int8`, `uint8`, `int16`,
     *    `uint16`, `int32`, `uint32`, and `float32`.
     * @return {object} typed array of given type
     */ ViewableBuffer1.prototype.view = function(type) {
        return this[type + "View"];
    };
    /**
     * Destroys all buffer references. Do not use after calling
     * this.
     */ ViewableBuffer1.prototype.destroy = function() {
        this.rawBinaryData = null;
        this._int8View = null;
        this._uint8View = null;
        this._int16View = null;
        this._uint16View = null;
        this._int32View = null;
        this.uint32View = null;
        this.float32View = null;
    };
    ViewableBuffer1.sizeOf = function(type) {
        switch(type){
            case 'int8':
            case 'uint8':
                return 1;
            case 'int16':
            case 'uint16':
                return 2;
            case 'int32':
            case 'uint32':
            case 'float32':
                return 4;
            default:
                throw new Error(type + " isn't a valid view type");
        }
    };
    return ViewableBuffer1;
}();
/**
 * Renderer dedicated to drawing and batching sprites.
 *
 * This is the default batch renderer. It buffers objects
 * with texture-based geometries and renders them in
 * batches. It uploads multiple textures to the GPU to
 * reduce to the number of draw calls.
 *
 * @class
 * @protected
 * @memberof PIXI
 * @extends PIXI.ObjectRenderer
 */ var AbstractBatchRenderer1 = function(_super) {
    __extends(AbstractBatchRenderer2, _super);
    /**
     * This will hook onto the renderer's `contextChange`
     * and `prerender` signals.
     *
     * @param {PIXI.Renderer} renderer - The renderer this works for.
     */ function AbstractBatchRenderer2(renderer) {
        var _this = _super.call(this, renderer) || this;
        /**
         * This is used to generate a shader that can
         * color each vertex based on a `aTextureId`
         * attribute that points to an texture in `uSampler`.
         *
         * This enables the objects with different textures
         * to be drawn in the same draw call.
         *
         * You can customize your shader by creating your
         * custom shader generator.
         *
         * @member {PIXI.BatchShaderGenerator}
         * @protected
         */ _this.shaderGenerator = null;
        /**
         * The class that represents the geometry of objects
         * that are going to be batched with this.
         *
         * @member {object}
         * @default PIXI.BatchGeometry
         * @protected
         */ _this.geometryClass = null;
        /**
         * Size of data being buffered per vertex in the
         * attribute buffers (in floats). By default, the
         * batch-renderer plugin uses 6:
         *
         * | aVertexPosition | 2 |
         * |-----------------|---|
         * | aTextureCoords  | 2 |
         * | aColor          | 1 |
         * | aTextureId      | 1 |
         *
         * @member {number}
         * @readonly
         */ _this.vertexSize = null;
        /**
         * The WebGL state in which this renderer will work.
         *
         * @member {PIXI.State}
         * @readonly
         */ _this.state = State.for2d();
        /**
         * The number of bufferable objects before a flush
         * occurs automatically.
         *
         * @member {number}
         * @default settings.SPRITE_BATCH_SIZE * 4
         */ _this.size = _settings.settings.SPRITE_BATCH_SIZE * 4;
        /**
         * Total count of all vertices used by the currently
         * buffered objects.
         *
         * @member {number}
         * @private
         */ _this._vertexCount = 0;
        /**
         * Total count of all indices used by the currently
         * buffered objects.
         *
         * @member {number}
         * @private
         */ _this._indexCount = 0;
        /**
         * Buffer of objects that are yet to be rendered.
         *
         * @member {PIXI.DisplayObject[]}
         * @private
         */ _this._bufferedElements = [];
        /**
         * Data for texture batch builder, helps to save a bit of CPU on a pass.
         * @type {PIXI.BaseTexture[]}
         * @private
         */ _this._bufferedTextures = [];
        /**
         * Number of elements that are buffered and are
         * waiting to be flushed.
         *
         * @member {number}
         * @private
         */ _this._bufferSize = 0;
        /**
         * This shader is generated by `this.shaderGenerator`.
         *
         * It is generated specifically to handle the required
         * number of textures being batched together.
         *
         * @member {PIXI.Shader}
         * @protected
         */ _this._shader = null;
        /**
         * Pool of `this.geometryClass` geometry objects
         * that store buffers. They are used to pass data
         * to the shader on each draw call.
         *
         * These are never re-allocated again, unless a
         * context change occurs; however, the pool may
         * be expanded if required.
         *
         * @member {PIXI.Geometry[]}
         * @private
         * @see PIXI.AbstractBatchRenderer.contextChange
         */ _this._packedGeometries = [];
        /**
         * Size of `this._packedGeometries`. It can be expanded
         * if more than `this._packedGeometryPoolSize` flushes
         * occur in a single frame.
         *
         * @member {number}
         * @private
         */ _this._packedGeometryPoolSize = 2;
        /**
         * A flush may occur multiple times in a single
         * frame. On iOS devices or when
         * `settings.CAN_UPLOAD_SAME_BUFFER` is false, the
         * batch renderer does not upload data to the same
         * `WebGLBuffer` for performance reasons.
         *
         * This is the index into `packedGeometries` that points to
         * geometry holding the most recent buffers.
         *
         * @member {number}
         * @private
         */ _this._flushId = 0;
        /**
         * Pool of `ViewableBuffer` objects that are sorted in
         * order of increasing size. The flush method uses
         * the buffer with the least size above the amount
         * it requires. These are used for passing attributes.
         *
         * The first buffer has a size of 8; each subsequent
         * buffer has double capacity of its previous.
         *
         * @member {PIXI.ViewableBuffer[]}
         * @private
         * @see PIXI.AbstractBatchRenderer#getAttributeBuffer
         */ _this._aBuffers = {
        };
        /**
         * Pool of `Uint16Array` objects that are sorted in
         * order of increasing size. The flush method uses
         * the buffer with the least size above the amount
         * it requires. These are used for passing indices.
         *
         * The first buffer has a size of 12; each subsequent
         * buffer has double capacity of its previous.
         *
         * @member {Uint16Array[]}
         * @private
         * @see PIXI.AbstractBatchRenderer#getIndexBuffer
         */ _this._iBuffers = {
        };
        /**
         * Maximum number of textures that can be uploaded to
         * the GPU under the current context. It is initialized
         * properly in `this.contextChange`.
         *
         * @member {number}
         * @see PIXI.AbstractBatchRenderer#contextChange
         * @readonly
         */ _this.MAX_TEXTURES = 1;
        _this.renderer.on('prerender', _this.onPrerender, _this);
        renderer.runners.contextChange.add(_this);
        _this._dcIndex = 0;
        _this._aIndex = 0;
        _this._iIndex = 0;
        _this._attributeBuffer = null;
        _this._indexBuffer = null;
        _this._tempBoundTextures = [];
        return _this;
    }
    /**
     * Handles the `contextChange` signal.
     *
     * It calculates `this.MAX_TEXTURES` and allocating the
     * packed-geometry object pool.
     */ AbstractBatchRenderer2.prototype.contextChange = function() {
        var gl = this.renderer.gl;
        if (_settings.settings.PREFER_ENV === _constants.ENV.WEBGL_LEGACY) this.MAX_TEXTURES = 1;
        else {
            // step 1: first check max textures the GPU can handle.
            this.MAX_TEXTURES = Math.min(gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS), _settings.settings.SPRITE_MAX_TEXTURES);
            // step 2: check the maximum number of if statements the shader can have too..
            this.MAX_TEXTURES = checkMaxIfStatementsInShader(this.MAX_TEXTURES, gl);
        }
        this._shader = this.shaderGenerator.generateShader(this.MAX_TEXTURES);
        // we use the second shader as the first one depending on your browser
        // may omit aTextureId as it is not used by the shader so is optimized out.
        for(var i = 0; i < this._packedGeometryPoolSize; i++)/* eslint-disable max-len */ this._packedGeometries[i] = new this.geometryClass();
        this.initFlushBuffers();
    };
    /**
     * Makes sure that static and dynamic flush pooled objects have correct dimensions
     */ AbstractBatchRenderer2.prototype.initFlushBuffers = function() {
        var _drawCallPool = AbstractBatchRenderer2._drawCallPool, _textureArrayPool = AbstractBatchRenderer2._textureArrayPool;
        // max draw calls
        var MAX_SPRITES = this.size / 4;
        // max texture arrays
        var MAX_TA = Math.floor(MAX_SPRITES / this.MAX_TEXTURES) + 1;
        while(_drawCallPool.length < MAX_SPRITES)_drawCallPool.push(new BatchDrawCall());
        while(_textureArrayPool.length < MAX_TA)_textureArrayPool.push(new BatchTextureArray());
        for(var i = 0; i < this.MAX_TEXTURES; i++)this._tempBoundTextures[i] = null;
    };
    /**
     * Handles the `prerender` signal.
     *
     * It ensures that flushes start from the first geometry
     * object again.
     */ AbstractBatchRenderer2.prototype.onPrerender = function() {
        this._flushId = 0;
    };
    /**
     * Buffers the "batchable" object. It need not be rendered
     * immediately.
     *
     * @param {PIXI.DisplayObject} element - the element to render when
     *    using this renderer
     */ AbstractBatchRenderer2.prototype.render = function(element) {
        if (!element._texture.valid) return;
        if (this._vertexCount + element.vertexData.length / 2 > this.size) this.flush();
        this._vertexCount += element.vertexData.length / 2;
        this._indexCount += element.indices.length;
        this._bufferedTextures[this._bufferSize] = element._texture.baseTexture;
        this._bufferedElements[this._bufferSize++] = element;
    };
    AbstractBatchRenderer2.prototype.buildTexturesAndDrawCalls = function() {
        var _a = this, textures = _a._bufferedTextures, MAX_TEXTURES = _a.MAX_TEXTURES;
        var textureArrays = AbstractBatchRenderer2._textureArrayPool;
        var batch = this.renderer.batch;
        var boundTextures = this._tempBoundTextures;
        var touch = this.renderer.textureGC.count;
        var TICK = ++BaseTexture1._globalBatch;
        var countTexArrays = 0;
        var texArray = textureArrays[0];
        var start = 0;
        batch.copyBoundTextures(boundTextures, MAX_TEXTURES);
        for(var i = 0; i < this._bufferSize; ++i){
            var tex = textures[i];
            textures[i] = null;
            if (tex._batchEnabled === TICK) continue;
            if (texArray.count >= MAX_TEXTURES) {
                batch.boundArray(texArray, boundTextures, TICK, MAX_TEXTURES);
                this.buildDrawCalls(texArray, start, i);
                start = i;
                texArray = textureArrays[++countTexArrays];
                ++TICK;
            }
            tex._batchEnabled = TICK;
            tex.touched = touch;
            texArray.elements[texArray.count++] = tex;
        }
        if (texArray.count > 0) {
            batch.boundArray(texArray, boundTextures, TICK, MAX_TEXTURES);
            this.buildDrawCalls(texArray, start, this._bufferSize);
            ++countTexArrays;
            ++TICK;
        }
        // Clean-up
        for(var i = 0; i < boundTextures.length; i++)boundTextures[i] = null;
        BaseTexture1._globalBatch = TICK;
    };
    /**
     * Populating drawcalls for rendering
     *
     * @param {PIXI.BatchTextureArray} texArray
     * @param {number} start
     * @param {number} finish
     */ AbstractBatchRenderer2.prototype.buildDrawCalls = function(texArray, start, finish) {
        var _a = this, elements = _a._bufferedElements, _attributeBuffer = _a._attributeBuffer, _indexBuffer = _a._indexBuffer, vertexSize = _a.vertexSize;
        var drawCalls = AbstractBatchRenderer2._drawCallPool;
        var dcIndex = this._dcIndex;
        var aIndex = this._aIndex;
        var iIndex = this._iIndex;
        var drawCall = drawCalls[dcIndex];
        drawCall.start = this._iIndex;
        drawCall.texArray = texArray;
        for(var i = start; i < finish; ++i){
            var sprite = elements[i];
            var tex = sprite._texture.baseTexture;
            var spriteBlendMode = _utils.premultiplyBlendMode[tex.alphaMode ? 1 : 0][sprite.blendMode];
            elements[i] = null;
            if (start < i && drawCall.blend !== spriteBlendMode) {
                drawCall.size = iIndex - drawCall.start;
                start = i;
                drawCall = drawCalls[++dcIndex];
                drawCall.texArray = texArray;
                drawCall.start = iIndex;
            }
            this.packInterleavedGeometry(sprite, _attributeBuffer, _indexBuffer, aIndex, iIndex);
            aIndex += sprite.vertexData.length / 2 * vertexSize;
            iIndex += sprite.indices.length;
            drawCall.blend = spriteBlendMode;
        }
        if (start < finish) {
            drawCall.size = iIndex - drawCall.start;
            ++dcIndex;
        }
        this._dcIndex = dcIndex;
        this._aIndex = aIndex;
        this._iIndex = iIndex;
    };
    /**
     * Bind textures for current rendering
     *
     * @param {PIXI.BatchTextureArray} texArray
     */ AbstractBatchRenderer2.prototype.bindAndClearTexArray = function(texArray) {
        var textureSystem = this.renderer.texture;
        for(var j = 0; j < texArray.count; j++){
            textureSystem.bind(texArray.elements[j], texArray.ids[j]);
            texArray.elements[j] = null;
        }
        texArray.count = 0;
    };
    AbstractBatchRenderer2.prototype.updateGeometry = function() {
        var _a = this, packedGeometries = _a._packedGeometries, attributeBuffer = _a._attributeBuffer, indexBuffer = _a._indexBuffer;
        if (!_settings.settings.CAN_UPLOAD_SAME_BUFFER) {
            if (this._packedGeometryPoolSize <= this._flushId) {
                this._packedGeometryPoolSize++;
                packedGeometries[this._flushId] = new this.geometryClass();
            }
            packedGeometries[this._flushId]._buffer.update(attributeBuffer.rawBinaryData);
            packedGeometries[this._flushId]._indexBuffer.update(indexBuffer);
            this.renderer.geometry.bind(packedGeometries[this._flushId]);
            this.renderer.geometry.updateBuffers();
            this._flushId++;
        } else {
            // lets use the faster option, always use buffer number 0
            packedGeometries[this._flushId]._buffer.update(attributeBuffer.rawBinaryData);
            packedGeometries[this._flushId]._indexBuffer.update(indexBuffer);
            this.renderer.geometry.updateBuffers();
        }
    };
    AbstractBatchRenderer2.prototype.drawBatches = function() {
        var dcCount = this._dcIndex;
        var _a = this.renderer, gl = _a.gl, stateSystem = _a.state;
        var drawCalls = AbstractBatchRenderer2._drawCallPool;
        var curTexArray = null;
        // Upload textures and do the draw calls
        for(var i = 0; i < dcCount; i++){
            var _b = drawCalls[i], texArray = _b.texArray, type = _b.type, size = _b.size, start = _b.start, blend = _b.blend;
            if (curTexArray !== texArray) {
                curTexArray = texArray;
                this.bindAndClearTexArray(texArray);
            }
            this.state.blendMode = blend;
            stateSystem.set(this.state);
            gl.drawElements(type, size, gl.UNSIGNED_SHORT, start * 2);
        }
    };
    /**
     * Renders the content _now_ and empties the current batch.
     */ AbstractBatchRenderer2.prototype.flush = function() {
        if (this._vertexCount === 0) return;
        this._attributeBuffer = this.getAttributeBuffer(this._vertexCount);
        this._indexBuffer = this.getIndexBuffer(this._indexCount);
        this._aIndex = 0;
        this._iIndex = 0;
        this._dcIndex = 0;
        this.buildTexturesAndDrawCalls();
        this.updateGeometry();
        this.drawBatches();
        // reset elements buffer for the next flush
        this._bufferSize = 0;
        this._vertexCount = 0;
        this._indexCount = 0;
    };
    /**
     * Starts a new sprite batch.
     */ AbstractBatchRenderer2.prototype.start = function() {
        this.renderer.state.set(this.state);
        this.renderer.texture.ensureSamplerType(this.MAX_TEXTURES);
        this.renderer.shader.bind(this._shader);
        if (_settings.settings.CAN_UPLOAD_SAME_BUFFER) // bind buffer #0, we don't need others
        this.renderer.geometry.bind(this._packedGeometries[this._flushId]);
    };
    /**
     * Stops and flushes the current batch.
     */ AbstractBatchRenderer2.prototype.stop = function() {
        this.flush();
    };
    /**
     * Destroys this `AbstractBatchRenderer`. It cannot be used again.
     */ AbstractBatchRenderer2.prototype.destroy = function() {
        for(var i = 0; i < this._packedGeometryPoolSize; i++)if (this._packedGeometries[i]) this._packedGeometries[i].destroy();
        this.renderer.off('prerender', this.onPrerender, this);
        this._aBuffers = null;
        this._iBuffers = null;
        this._packedGeometries = null;
        this._attributeBuffer = null;
        this._indexBuffer = null;
        if (this._shader) {
            this._shader.destroy();
            this._shader = null;
        }
        _super.prototype.destroy.call(this);
    };
    /**
     * Fetches an attribute buffer from `this._aBuffers` that
     * can hold atleast `size` floats.
     *
     * @param {number} size - minimum capacity required
     * @return {ViewableBuffer} - buffer than can hold atleast `size` floats
     * @private
     */ AbstractBatchRenderer2.prototype.getAttributeBuffer = function(size) {
        // 8 vertices is enough for 2 quads
        var roundedP2 = _utils.nextPow2(Math.ceil(size / 8));
        var roundedSizeIndex = _utils.log2(roundedP2);
        var roundedSize = roundedP2 * 8;
        if (this._aBuffers.length <= roundedSizeIndex) this._iBuffers.length = roundedSizeIndex + 1;
        var buffer = this._aBuffers[roundedSize];
        if (!buffer) this._aBuffers[roundedSize] = buffer = new ViewableBuffer(roundedSize * this.vertexSize * 4);
        return buffer;
    };
    /**
     * Fetches an index buffer from `this._iBuffers` that can
     * have at least `size` capacity.
     *
     * @param {number} size - minimum required capacity
     * @return {Uint16Array} - buffer that can fit `size`
     *    indices.
     * @private
     */ AbstractBatchRenderer2.prototype.getIndexBuffer = function(size) {
        // 12 indices is enough for 2 quads
        var roundedP2 = _utils.nextPow2(Math.ceil(size / 12));
        var roundedSizeIndex = _utils.log2(roundedP2);
        var roundedSize = roundedP2 * 12;
        if (this._iBuffers.length <= roundedSizeIndex) this._iBuffers.length = roundedSizeIndex + 1;
        var buffer = this._iBuffers[roundedSizeIndex];
        if (!buffer) this._iBuffers[roundedSizeIndex] = buffer = new Uint16Array(roundedSize);
        return buffer;
    };
    /**
     * Takes the four batching parameters of `element`, interleaves
     * and pushes them into the batching attribute/index buffers given.
     *
     * It uses these properties: `vertexData` `uvs`, `textureId` and
     * `indicies`. It also uses the "tint" of the base-texture, if
     * present.
     *
     * @param {PIXI.Sprite} element - element being rendered
     * @param {PIXI.ViewableBuffer} attributeBuffer - attribute buffer.
     * @param {Uint16Array} indexBuffer - index buffer
     * @param {number} aIndex - number of floats already in the attribute buffer
     * @param {number} iIndex - number of indices already in `indexBuffer`
     */ AbstractBatchRenderer2.prototype.packInterleavedGeometry = function(element, attributeBuffer, indexBuffer, aIndex, iIndex) {
        var uint32View = attributeBuffer.uint32View, float32View = attributeBuffer.float32View;
        var packedVertices = aIndex / this.vertexSize;
        var uvs = element.uvs;
        var indicies = element.indices;
        var vertexData = element.vertexData;
        var textureId = element._texture.baseTexture._batchLocation;
        var alpha = Math.min(element.worldAlpha, 1);
        var argb = alpha < 1 && element._texture.baseTexture.alphaMode ? _utils.premultiplyTint(element._tintRGB, alpha) : element._tintRGB + (alpha * 255 << 24);
        // lets not worry about tint! for now..
        for(var i = 0; i < vertexData.length; i += 2){
            float32View[aIndex++] = vertexData[i];
            float32View[aIndex++] = vertexData[i + 1];
            float32View[aIndex++] = uvs[i];
            float32View[aIndex++] = uvs[i + 1];
            uint32View[aIndex++] = argb;
            float32View[aIndex++] = textureId;
        }
        for(var i = 0; i < indicies.length; i++)indexBuffer[iIndex++] = packedVertices + indicies[i];
    };
    /**
     * Pool of `BatchDrawCall` objects that `flush` used
     * to create "batches" of the objects being rendered.
     *
     * These are never re-allocated again.
     * Shared between all batch renderers because it can be only one "flush" working at the moment.
     *
     * @static
     * @member {PIXI.BatchDrawCall[]}
     */ AbstractBatchRenderer2._drawCallPool = [];
    /**
     * Pool of `BatchDrawCall` objects that `flush` used
     * to create "batches" of the objects being rendered.
     *
     * These are never re-allocated again.
     * Shared between all batch renderers because it can be only one "flush" working at the moment.
     *
     * @static
     * @member {PIXI.BatchTextureArray[]}
     */ AbstractBatchRenderer2._textureArrayPool = [];
    return AbstractBatchRenderer2;
}(ObjectRenderer);
/**
 * Helper that generates batching multi-texture shader. Use it with your new BatchRenderer
 *
 * @class
 * @memberof PIXI
 */ var BatchShaderGenerator = function() {
    /**
     * @param {string} vertexSrc - Vertex shader
     * @param {string} fragTemplate - Fragment shader template
     */ function BatchShaderGenerator1(vertexSrc, fragTemplate1) {
        /**
         * Reference to the vertex shader source.
         *
         * @member {string}
         */ this.vertexSrc = vertexSrc;
        /**
         * Reference to the fragment shader template. Must contain "%count%" and "%forloop%".
         *
         * @member {string}
         */ this.fragTemplate = fragTemplate1;
        this.programCache = {
        };
        this.defaultGroupCache = {
        };
        if (fragTemplate1.indexOf('%count%') < 0) throw new Error('Fragment template must contain "%count%".');
        if (fragTemplate1.indexOf('%forloop%') < 0) throw new Error('Fragment template must contain "%forloop%".');
    }
    BatchShaderGenerator1.prototype.generateShader = function(maxTextures) {
        if (!this.programCache[maxTextures]) {
            var sampleValues = new Int32Array(maxTextures);
            for(var i = 0; i < maxTextures; i++)sampleValues[i] = i;
            this.defaultGroupCache[maxTextures] = UniformGroup.from({
                uSamplers: sampleValues
            }, true);
            var fragmentSrc = this.fragTemplate;
            fragmentSrc = fragmentSrc.replace(/%count%/gi, "" + maxTextures);
            fragmentSrc = fragmentSrc.replace(/%forloop%/gi, this.generateSampleSrc(maxTextures));
            this.programCache[maxTextures] = new Program(this.vertexSrc, fragmentSrc);
        }
        var uniforms = {
            tint: new Float32Array([
                1,
                1,
                1,
                1
            ]),
            translationMatrix: new _math.Matrix(),
            default: this.defaultGroupCache[maxTextures]
        };
        return new Shader(this.programCache[maxTextures], uniforms);
    };
    BatchShaderGenerator1.prototype.generateSampleSrc = function(maxTextures) {
        var src = '';
        src += '\n';
        src += '\n';
        for(var i = 0; i < maxTextures; i++){
            if (i > 0) src += '\nelse ';
            if (i < maxTextures - 1) src += "if(vTextureId < " + i + ".5)";
            src += '\n{';
            src += "\n\tcolor = texture2D(uSamplers[" + i + "], vTextureCoord);";
            src += '\n}';
        }
        src += '\n';
        src += '\n';
        return src;
    };
    return BatchShaderGenerator1;
}();
/**
 * Geometry used to batch standard PIXI content (e.g. Mesh, Sprite, Graphics objects).
 *
 * @class
 * @memberof PIXI
 */ var BatchGeometry1 = function(_super) {
    __extends(BatchGeometry2, _super);
    /**
     * @param {boolean} [_static=false] - Optimization flag, where `false`
     *        is updated every frame, `true` doesn't change frame-to-frame.
     */ function BatchGeometry2(_static) {
        if (_static === void 0) _static = false;
        var _this = _super.call(this) || this;
        /**
         * Buffer used for position, color, texture IDs
         *
         * @member {PIXI.Buffer}
         * @protected
         */ _this._buffer = new Buffer(null, _static, false);
        /**
         * Index buffer data
         *
         * @member {PIXI.Buffer}
         * @protected
         */ _this._indexBuffer = new Buffer(null, _static, true);
        _this.addAttribute('aVertexPosition', _this._buffer, 2, false, _constants.TYPES.FLOAT).addAttribute('aTextureCoord', _this._buffer, 2, false, _constants.TYPES.FLOAT).addAttribute('aColor', _this._buffer, 4, true, _constants.TYPES.UNSIGNED_BYTE).addAttribute('aTextureId', _this._buffer, 1, true, _constants.TYPES.FLOAT).addIndex(_this._indexBuffer);
        return _this;
    }
    return BatchGeometry2;
}(Geometry);
var defaultVertex$3 = "precision highp float;\nattribute vec2 aVertexPosition;\nattribute vec2 aTextureCoord;\nattribute vec4 aColor;\nattribute float aTextureId;\n\nuniform mat3 projectionMatrix;\nuniform mat3 translationMatrix;\nuniform vec4 tint;\n\nvarying vec2 vTextureCoord;\nvarying vec4 vColor;\nvarying float vTextureId;\n\nvoid main(void){\n    gl_Position = vec4((projectionMatrix * translationMatrix * vec3(aVertexPosition, 1.0)).xy, 0.0, 1.0);\n\n    vTextureCoord = aTextureCoord;\n    vTextureId = aTextureId;\n    vColor = aColor * tint;\n}\n";
var defaultFragment$2 = "varying vec2 vTextureCoord;\nvarying vec4 vColor;\nvarying float vTextureId;\nuniform sampler2D uSamplers[%count%];\n\nvoid main(void){\n    vec4 color;\n    %forloop%\n    gl_FragColor = color * vColor;\n}\n";
/**
 * @class
 * @memberof PIXI
 * @hideconstructor
 */ var BatchPluginFactory = function() {
    function BatchPluginFactory1() {
    }
    /**
     * Create a new BatchRenderer plugin for Renderer. this convenience can provide an easy way
     * to extend BatchRenderer with all the necessary pieces.
     * @example
     * const fragment = `
     * varying vec2 vTextureCoord;
     * varying vec4 vColor;
     * varying float vTextureId;
     * uniform sampler2D uSamplers[%count%];
     *
     * void main(void){
     *     vec4 color;
     *     %forloop%
     *     gl_FragColor = vColor * vec4(color.a - color.rgb, color.a);
     * }
     * `;
     * const InvertBatchRenderer = PIXI.BatchPluginFactory.create({ fragment });
     * PIXI.Renderer.registerPlugin('invert', InvertBatchRenderer);
     * const sprite = new PIXI.Sprite();
     * sprite.pluginName = 'invert';
     *
     * @static
     * @param {object} [options]
     * @param {string} [options.vertex=PIXI.BatchPluginFactory.defaultVertexSrc] - Vertex shader source
     * @param {string} [options.fragment=PIXI.BatchPluginFactory.defaultFragmentTemplate] - Fragment shader template
     * @param {number} [options.vertexSize=6] - Vertex size
     * @param {object} [options.geometryClass=PIXI.BatchGeometry]
     * @return {*} New batch renderer plugin
     */ BatchPluginFactory1.create = function(options) {
        var _a = Object.assign({
            vertex: defaultVertex$3,
            fragment: defaultFragment$2,
            geometryClass: BatchGeometry1,
            vertexSize: 6
        }, options), vertex1 = _a.vertex, fragment1 = _a.fragment, vertexSize = _a.vertexSize, geometryClass = _a.geometryClass;
        return (function(_super) {
            __extends(BatchPlugin, _super);
            function BatchPlugin(renderer) {
                var _this = _super.call(this, renderer) || this;
                _this.shaderGenerator = new BatchShaderGenerator(vertex1, fragment1);
                _this.geometryClass = geometryClass;
                _this.vertexSize = vertexSize;
                return _this;
            }
            return BatchPlugin;
        })(AbstractBatchRenderer1);
    };
    Object.defineProperty(BatchPluginFactory1, "defaultVertexSrc", {
        /**
         * The default vertex shader source
         *
         * @static
         * @type {string}
         * @constant
         */ get: function() {
            return defaultVertex$3;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BatchPluginFactory1, "defaultFragmentTemplate", {
        /**
         * The default fragment shader source
         *
         * @static
         * @type {string}
         * @constant
         */ get: function() {
            return defaultFragment$2;
        },
        enumerable: false,
        configurable: true
    });
    return BatchPluginFactory1;
}();
// Setup the default BatchRenderer plugin, this is what
// we'll actually export at the root level
var BatchRenderer = BatchPluginFactory.create();
/**
 * @memberof PIXI
 * @namespace resources
 * @see PIXI
 * @deprecated since 6.0.0
 */ var resources = {
};
var _loop_1 = function(name) {
    Object.defineProperty(resources, name, {
        get: function() {
            _utils.deprecation('6.0.0', "PIXI.systems." + name + " has moved to PIXI." + name);
            return _resources[name];
        }
    });
};
for(var name in _resources)_loop_1(name);
/**
 * @memberof PIXI
 * @namespace systems
 * @see PIXI
 * @deprecated since 6.0.0
 */ var systems = {
};
var _loop_2 = function(name1) {
    Object.defineProperty(systems, name1, {
        get: function() {
            _utils.deprecation('6.0.0', "PIXI.resources." + name1 + " has moved to PIXI." + name1);
            return _systems[name1];
        }
    });
};
for(var name in _systems)_loop_2(name);

},{"@pixi/settings":"habh9","@pixi/constants":"lqjFh","@pixi/utils":"joR65","@pixi/runner":"9dm4Q","@pixi/ticker":"5j6Uq","@pixi/math":"1qR3C","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9dm4Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Runner", ()=>Runner
);
/*!
 * @pixi/runner - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/runner is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ /**
 * A Runner is a highly performant and simple alternative to signals. Best used in situations
 * where events are dispatched to many objects at high frequency (say every frame!)
 *
 *
 * like a signal..
 * ```
 * import { Runner } from '@pixi/runner';
 *
 * const myObject = {
 *     loaded: new Runner('loaded')
 * }
 *
 * const listener = {
 *     loaded: function(){
 *         // thin
 *     }
 * }
 *
 * myObject.loaded.add(listener);
 *
 * myObject.loaded.emit();
 * ```
 *
 * Or for handling calling the same function on many items
 * ```
 * import { Runner } from '@pixi/runner';
 *
 * const myGame = {
 *     update: new Runner('update')
 * }
 *
 * const gameObject = {
 *     update: function(time){
 *         // update my gamey state
 *     }
 * }
 *
 * myGame.update.add(gameObject);
 *
 * myGame.update.emit(time);
 * ```
 * @class
 * @memberof PIXI
 */ var Runner = function() {
    /**
     *  @param {string} name - the function name that will be executed on the listeners added to this Runner.
     */ function Runner1(name) {
        this.items = [];
        this._name = name;
        this._aliasCount = 0;
    }
    /**
     * Dispatch/Broadcast Runner to all listeners added to the queue.
     * @param {...any} params - optional parameters to pass to each listener
     * @return {PIXI.Runner}
     */ Runner1.prototype.emit = function(a0, a1, a2, a3, a4, a5, a6, a7) {
        if (arguments.length > 8) throw new Error('max arguments reached');
        var _a = this, name = _a.name, items = _a.items;
        this._aliasCount++;
        for(var i = 0, len = items.length; i < len; i++)items[i][name](a0, a1, a2, a3, a4, a5, a6, a7);
        if (items === this.items) this._aliasCount--;
        return this;
    };
    Runner1.prototype.ensureNonAliasedItems = function() {
        if (this._aliasCount > 0 && this.items.length > 1) {
            this._aliasCount = 0;
            this.items = this.items.slice(0);
        }
    };
    /**
     * Add a listener to the Runner
     *
     * Runners do not need to have scope or functions passed to them.
     * All that is required is to pass the listening object and ensure that it has contains a function that has the same name
     * as the name provided to the Runner when it was created.
     *
     * Eg A listener passed to this Runner will require a 'complete' function.
     *
     * ```
     * import { Runner } from '@pixi/runner';
     *
     * const complete = new Runner('complete');
     * ```
     *
     * The scope used will be the object itself.
     *
     * @param {any} item - The object that will be listening.
     * @return {PIXI.Runner}
     */ Runner1.prototype.add = function(item) {
        if (item[this._name]) {
            this.ensureNonAliasedItems();
            this.remove(item);
            this.items.push(item);
        }
        return this;
    };
    /**
     * Remove a single listener from the dispatch queue.
     * @param {any} item - The listener that you would like to remove.
     * @return {PIXI.Runner}
     */ Runner1.prototype.remove = function(item) {
        var index = this.items.indexOf(item);
        if (index !== -1) {
            this.ensureNonAliasedItems();
            this.items.splice(index, 1);
        }
        return this;
    };
    /**
     * Check to see if the listener is already in the Runner
     * @param {any} item - The listener that you would like to check.
     */ Runner1.prototype.contains = function(item) {
        return this.items.indexOf(item) !== -1;
    };
    /**
     * Remove all listeners from the Runner
     * @return {PIXI.Runner}
     */ Runner1.prototype.removeAll = function() {
        this.ensureNonAliasedItems();
        this.items.length = 0;
        return this;
    };
    /**
     * Remove all references, don't use after this.
     */ Runner1.prototype.destroy = function() {
        this.removeAll();
        this.items = null;
        this._name = null;
    };
    Object.defineProperty(Runner1.prototype, "empty", {
        /**
         * `true` if there are no this Runner contains no listeners
         *
         * @member {boolean}
         * @readonly
         */ get: function() {
            return this.items.length === 0;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Runner1.prototype, "name", {
        /**
         * The name of the runner.
         *
         * @member {string}
         * @readonly
         */ get: function() {
            return this._name;
        },
        enumerable: false,
        configurable: true
    });
    return Runner1;
}();
Object.defineProperties(Runner.prototype, {
    /**
     * Alias for `emit`
     * @memberof PIXI.Runner#
     * @method dispatch
     * @see PIXI.Runner#emit
     */ dispatch: {
        value: Runner.prototype.emit
    },
    /**
     * Alias for `emit`
     * @memberof PIXI.Runner#
     * @method run
     * @see PIXI.Runner#emit
     */ run: {
        value: Runner.prototype.emit
    }
});

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8UvLW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Extract", ()=>Extract
);
/*!
 * @pixi/extract - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/extract is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _utils = require("@pixi/utils");
var _math = require("@pixi/math");
var _core = require("@pixi/core");
var TEMP_RECT = new _math.Rectangle();
var BYTES_PER_PIXEL = 4;
/**
 * This class provides renderer-specific plugins for exporting content from a renderer.
 * For instance, these plugins can be used for saving an Image, Canvas element or for exporting the raw image data (pixels).
 *
 * Do not instantiate these plugins directly. It is available from the `renderer.plugins` property.
 * See {@link PIXI.CanvasRenderer#plugins} or {@link PIXI.Renderer#plugins}.
 * @example
 * // Create a new app (will auto-add extract plugin to renderer)
 * const app = new PIXI.Application();
 *
 * // Draw a red circle
 * const graphics = new PIXI.Graphics()
 *     .beginFill(0xFF0000)
 *     .drawCircle(0, 0, 50);
 *
 * // Render the graphics as an HTMLImageElement
 * const image = app.renderer.plugins.extract.image(graphics);
 * document.body.appendChild(image);
 * @class
 * @memberof PIXI
 */ var Extract = function() {
    /**
     * @param {PIXI.Renderer} renderer - A reference to the current renderer
     */ function Extract1(renderer) {
        this.renderer = renderer;
    }
    /**
     * Will return a HTML Image of the target
     *
     * @param {PIXI.DisplayObject|PIXI.RenderTexture} target - A displayObject or renderTexture
     *  to convert. If left empty will use the main renderer
     * @param {string} [format] - Image format, e.g. "image/jpeg" or "image/webp".
     * @param {number} [quality] - JPEG or Webp compression from 0 to 1. Default is 0.92.
     * @return {HTMLImageElement} HTML Image of the target
     */ Extract1.prototype.image = function(target, format, quality) {
        var image = new Image();
        image.src = this.base64(target, format, quality);
        return image;
    };
    /**
     * Will return a a base64 encoded string of this target. It works by calling
     *  `Extract.getCanvas` and then running toDataURL on that.
     *
     * @param {PIXI.DisplayObject|PIXI.RenderTexture} target - A displayObject or renderTexture
     *  to convert. If left empty will use the main renderer
     * @param {string} [format] - Image format, e.g. "image/jpeg" or "image/webp".
     * @param {number} [quality] - JPEG or Webp compression from 0 to 1. Default is 0.92.
     * @return {string} A base64 encoded string of the texture.
     */ Extract1.prototype.base64 = function(target, format, quality) {
        return this.canvas(target).toDataURL(format, quality);
    };
    /**
     * Creates a Canvas element, renders this target to it and then returns it.
     *
     * @param {PIXI.DisplayObject|PIXI.RenderTexture} target - A displayObject or renderTexture
     *  to convert. If left empty will use the main renderer
     * @return {HTMLCanvasElement} A Canvas element with the texture rendered on.
     */ Extract1.prototype.canvas = function(target) {
        var renderer = this.renderer;
        var resolution;
        var frame;
        var flipY = false;
        var renderTexture;
        var generated = false;
        if (target) {
            if (target instanceof _core.RenderTexture) renderTexture = target;
            else {
                renderTexture = this.renderer.generateTexture(target);
                generated = true;
            }
        }
        if (renderTexture) {
            resolution = renderTexture.baseTexture.resolution;
            frame = renderTexture.frame;
            flipY = false;
            renderer.renderTexture.bind(renderTexture);
        } else {
            resolution = this.renderer.resolution;
            flipY = true;
            frame = TEMP_RECT;
            frame.width = this.renderer.width;
            frame.height = this.renderer.height;
            renderer.renderTexture.bind(null);
        }
        var width = Math.floor(frame.width * resolution + 0.0001);
        var height = Math.floor(frame.height * resolution + 0.0001);
        var canvasBuffer = new _utils.CanvasRenderTarget(width, height, 1);
        var webglPixels = new Uint8Array(BYTES_PER_PIXEL * width * height);
        // read pixels to the array
        var gl = renderer.gl;
        gl.readPixels(frame.x * resolution, frame.y * resolution, width, height, gl.RGBA, gl.UNSIGNED_BYTE, webglPixels);
        // add the pixels to the canvas
        var canvasData = canvasBuffer.context.getImageData(0, 0, width, height);
        Extract1.arrayPostDivide(webglPixels, canvasData.data);
        canvasBuffer.context.putImageData(canvasData, 0, 0);
        // pulling pixels
        if (flipY) {
            var target_1 = new _utils.CanvasRenderTarget(canvasBuffer.width, canvasBuffer.height, 1);
            target_1.context.scale(1, -1);
            // we can't render to itself because we should be empty before render.
            target_1.context.drawImage(canvasBuffer.canvas, 0, -height);
            canvasBuffer.destroy();
            canvasBuffer = target_1;
        }
        if (generated) renderTexture.destroy(true);
        // send the canvas back..
        return canvasBuffer.canvas;
    };
    /**
     * Will return a one-dimensional array containing the pixel data of the entire texture in RGBA
     * order, with integer values between 0 and 255 (included).
     *
     * @param {PIXI.DisplayObject|PIXI.RenderTexture} target - A displayObject or renderTexture
     *  to convert. If left empty will use the main renderer
     * @return {Uint8Array} One-dimensional array containing the pixel data of the entire texture
     */ Extract1.prototype.pixels = function(target) {
        var renderer = this.renderer;
        var resolution;
        var frame;
        var renderTexture;
        var generated = false;
        if (target) {
            if (target instanceof _core.RenderTexture) renderTexture = target;
            else {
                renderTexture = this.renderer.generateTexture(target);
                generated = true;
            }
        }
        if (renderTexture) {
            resolution = renderTexture.baseTexture.resolution;
            frame = renderTexture.frame;
            // bind the buffer
            renderer.renderTexture.bind(renderTexture);
        } else {
            resolution = renderer.resolution;
            frame = TEMP_RECT;
            frame.width = renderer.width;
            frame.height = renderer.height;
            renderer.renderTexture.bind(null);
        }
        var width = frame.width * resolution;
        var height = frame.height * resolution;
        var webglPixels = new Uint8Array(BYTES_PER_PIXEL * width * height);
        // read pixels to the array
        var gl = renderer.gl;
        gl.readPixels(frame.x * resolution, frame.y * resolution, width, height, gl.RGBA, gl.UNSIGNED_BYTE, webglPixels);
        if (generated) renderTexture.destroy(true);
        Extract1.arrayPostDivide(webglPixels, webglPixels);
        return webglPixels;
    };
    /**
     * Destroys the extract
     *
     */ Extract1.prototype.destroy = function() {
        this.renderer = null;
    };
    /**
     * Takes premultiplied pixel data and produces regular pixel data
     *
     * @private
     * @param {number[] | Uint8Array | Uint8ClampedArray} pixels - array of pixel data
     * @param {number[] | Uint8Array | Uint8ClampedArray} out - output array
     */ Extract1.arrayPostDivide = function(pixels, out) {
        for(var i = 0; i < pixels.length; i += 4){
            var alpha = out[i + 3] = pixels[i + 3];
            if (alpha !== 0) {
                out[i] = Math.round(Math.min(pixels[i] * 255 / alpha, 255));
                out[i + 1] = Math.round(Math.min(pixels[i + 1] * 255 / alpha, 255));
                out[i + 2] = Math.round(Math.min(pixels[i + 2] * 255 / alpha, 255));
            } else {
                out[i] = pixels[i];
                out[i + 1] = pixels[i + 1];
                out[i + 2] = pixels[i + 2];
            }
        }
    };
    return Extract1;
}();

},{"@pixi/utils":"joR65","@pixi/math":"1qR3C","@pixi/core":"d0INm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1PTMa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AppLoaderPlugin", ()=>AppLoaderPlugin
);
parcelHelpers.export(exports, "Loader", ()=>Loader
);
parcelHelpers.export(exports, "LoaderResource", ()=>LoaderResource
);
parcelHelpers.export(exports, "TextureLoader", ()=>TextureLoader
);
/*!
 * @pixi/loaders - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/loaders is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
/* jshint -W097 */ /**
 * @memberof PIXI
 */ var SignalBinding = function() {
    /**
     * SignalBinding constructor.
     * @constructs SignalBinding
     * @param {Function} fn - Event handler to be called.
     * @param {Boolean} [once=false] - Should this listener be removed after dispatch
     * @param {object} [thisArg] - The context of the callback function.
     * @api private
     */ // eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types
    function SignalBinding1(fn, once, thisArg) {
        if (once === void 0) once = false;
        this._fn = fn;
        this._once = once;
        this._thisArg = thisArg;
        this._next = this._prev = this._owner = null;
    }
    SignalBinding1.prototype.detach = function() {
        if (this._owner === null) return false;
        this._owner.detach(this);
        return true;
    };
    return SignalBinding1;
}();
/**
 * @private
 */ function _addSignalBinding(self, node) {
    if (!self._head) {
        self._head = node;
        self._tail = node;
    } else {
        self._tail._next = node;
        node._prev = self._tail;
        self._tail = node;
    }
    node._owner = self;
    return node;
}
/**
 * @memberof PIXI
 */ var Signal = function() {
    /**
     * MiniSignal constructor.
     * @example
     * let mySignal = new Signal();
     * let binding = mySignal.add(onSignal);
     * mySignal.dispatch('foo', 'bar');
     * mySignal.detach(binding);
     */ function Signal1() {
        this._head = this._tail = undefined;
    }
    /**
     * Return an array of attached SignalBinding.
     *
     * @param {Boolean} [exists=false] - We only need to know if there are handlers.
     * @returns {PIXI.SignalBinding[]|Boolean} Array of attached SignalBinding or Boolean if called with exists = true
     * @api public
     */ Signal1.prototype.handlers = function(exists) {
        if (exists === void 0) exists = false;
        var node = this._head;
        if (exists) return !!node;
        var ee = [];
        while(node){
            ee.push(node);
            node = node._next;
        }
        return ee;
    };
    /**
     * Return true if node is a SignalBinding attached to this MiniSignal
     *
     * @param {PIXI.SignalBinding} node - Node to check.
     * @returns {Boolean} True if node is attache to mini-signal
     */ Signal1.prototype.has = function(node) {
        if (!(node instanceof SignalBinding)) throw new Error('MiniSignal#has(): First arg must be a SignalBinding object.');
        return node._owner === this;
    };
    /**
     * Dispaches a signal to all registered listeners.
     *
     * @returns {Boolean} Indication if we've emitted an event.
     */ Signal1.prototype.dispatch = function() {
        var arguments$1 = arguments;
        var args = [];
        for(var _i = 0; _i < arguments.length; _i++)args[_i] = arguments$1[_i];
        var node = this._head;
        if (!node) return false;
        while(node){
            if (node._once) this.detach(node);
            node._fn.apply(node._thisArg, args);
            node = node._next;
        }
        return true;
    };
    /**
     * Register a new listener.
     *
     * @param {Function} fn - Callback function.
     * @param {object} [thisArg] - The context of the callback function.
     * @returns {PIXI.SignalBinding} The SignalBinding node that was added.
     */ Signal1.prototype.add = function(fn, thisArg) {
        if (thisArg === void 0) thisArg = null;
        if (typeof fn !== 'function') throw new Error('MiniSignal#add(): First arg must be a Function.');
        return _addSignalBinding(this, new SignalBinding(fn, false, thisArg));
    };
    /**
     * Register a new listener that will be executed only once.
     *
     * @param {Function} fn - Callback function.
     * @param {object} [thisArg] - The context of the callback function.
     * @returns {PIXI.SignalBinding} The SignalBinding node that was added.
     */ Signal1.prototype.once = function(fn, thisArg) {
        if (thisArg === void 0) thisArg = null;
        if (typeof fn !== 'function') throw new Error('MiniSignal#once(): First arg must be a Function.');
        return _addSignalBinding(this, new SignalBinding(fn, true, thisArg));
    };
    /**
     * Remove binding object.
     *
     * @param {PIXI.SignalBinding} node - The binding node that will be removed.
     * @returns {Signal} The instance on which this method was called.
     * @api public */ Signal1.prototype.detach = function(node) {
        if (!(node instanceof SignalBinding)) throw new Error('MiniSignal#detach(): First arg must be a SignalBinding object.');
        if (node._owner !== this) return this;
         // todo: or error?
        if (node._prev) node._prev._next = node._next;
        if (node._next) node._next._prev = node._prev;
        if (node === this._head) {
            this._head = node._next;
            if (node._next === null) this._tail = null;
        } else if (node === this._tail) {
            this._tail = node._prev;
            this._tail._next = null;
        }
        node._owner = null;
        return this;
    };
    /**
     * Detach all listeners.
     *
     * @returns {Signal} The instance on which this method was called.
     */ Signal1.prototype.detachAll = function() {
        var node = this._head;
        if (!node) return this;
        this._head = this._tail = null;
        while(node){
            node._owner = null;
            node = node._next;
        }
        return this;
    };
    return Signal1;
}();
/**
 * function from npm package `parseUri`, converted to TS to avoid leftpad incident
 * @param {string} str
 * @param [opts] - options
 * @param {boolean} [opts.strictMode] - type of parser
 */ function parseUri(str, opts) {
    opts = opts || {
    };
    var o = {
        // eslint-disable-next-line max-len
        key: [
            'source',
            'protocol',
            'authority',
            'userInfo',
            'user',
            'password',
            'host',
            'port',
            'relative',
            'path',
            'directory',
            'file',
            'query',
            'anchor'
        ],
        q: {
            name: 'queryKey',
            parser: /(?:^|&)([^&=]*)=?([^&]*)/g
        },
        parser: {
            // eslint-disable-next-line max-len
            strict: /^(?:([^:\/?#]+):)?(?:\/\/((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\/?#]*)(?::(\d*))?))?((((?:[^?#\/]*\/)*)([^?#]*))(?:\?([^#]*))?(?:#(.*))?)/,
            // eslint-disable-next-line max-len
            loose: /^(?:(?![^:@]+:[^:@\/]*@)([^:\/?#.]+):)?(?:\/\/)?((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\/?#]*)(?::(\d*))?)(((\/(?:[^?#](?![^?#\/]*\.[^?#\/.]+(?:[?#]|$)))*\/?)?([^?#\/]*))(?:\?([^#]*))?(?:#(.*))?)/
        }
    };
    var m = o.parser[opts.strictMode ? 'strict' : 'loose'].exec(str);
    var uri = {
    };
    var i = 14;
    while(i--)uri[o.key[i]] = m[i] || '';
    uri[o.q.name] = {
    };
    uri[o.key[12]].replace(o.q.parser, function(_t0, t1, t2) {
        if (t1) uri[o.q.name][t1] = t2;
    });
    return uri;
}
// tests if CORS is supported in XHR, if not we need to use XDR
var useXdr = !!(self.XDomainRequest && !('withCredentials' in new XMLHttpRequest()));
var tempAnchor = null;
// some status constants
var STATUS_NONE = 0;
var STATUS_OK = 200;
var STATUS_EMPTY = 204;
var STATUS_IE_BUG_EMPTY = 1223;
var STATUS_TYPE_OK = 2;
// noop
function _noop() {
}
/**
 * Quick helper to set a value on one of the extension maps. Ensures there is no
 * dot at the start of the extension.
 *
 * @ignore
 * @param map - The map to set on.
 * @param extname - The extension (or key) to set.
 * @param val - The value to set.
 */ function setExtMap(map, extname, val) {
    if (extname && extname.indexOf('.') === 0) extname = extname.substring(1);
    if (!extname) return;
    map[extname] = val;
}
/**
 * Quick helper to get string xhr type.
 *
 * @ignore
 * @param xhr - The request to check.
 * @return The type.
 */ function reqType(xhr) {
    return xhr.toString().replace('object ', '');
}
/**
 * Manages the state and loading of a resource and all child resources.
 *
 * Can be extended in `GlobalMixins.LoaderResource`.
 *
 * @memberof PIXI
 */ var LoaderResource = function() {
    /**
     * @param {string} name - The name of the resource to load.
     * @param {string|string[]} url - The url for this resource, for audio/video loads you can pass
     *      an array of sources.
     * @param {object} [options] - The options for the load.
     * @param {string|boolean} [options.crossOrigin] - Is this request cross-origin? Default is to
     *      determine automatically.
     * @param {number} [options.timeout=0] - A timeout in milliseconds for the load. If the load takes
     *      longer than this time it is cancelled and the load is considered a failure. If this value is
     *      set to `0` then there is no explicit timeout.
     * @param {PIXI.LoaderResource.LOAD_TYPE} [options.loadType=LOAD_TYPE.XHR] - How should this resource
     *      be loaded?
     * @param {PIXI.LoaderResource.XHR_RESPONSE_TYPE} [options.xhrType=XHR_RESPONSE_TYPE.DEFAULT] - How
     *      should the data being loaded be interpreted when using XHR?
     * @param {PIXI.LoaderResource.IMetadata} [options.metadata] - Extra configuration for middleware
     *      and the Resource object.
     */ function LoaderResource1(name, url, options) {
        /**
         * The `dequeue` method that will be used a storage place for the async queue dequeue method
         * used privately by the loader.
         *
         * @private
         * @member {function}
         */ this._dequeue = _noop;
        /**
         * Used a storage place for the on load binding used privately by the loader.
         *
         * @private
         * @member {function}
         */ this._onLoadBinding = null;
        /**
         * The timer for element loads to check if they timeout.
         *
         * @private
         */ this._elementTimer = 0;
        /**
         * The `complete` function bound to this resource's context.
         *
         * @private
         * @type {function}
         */ this._boundComplete = null;
        /**
         * The `_onError` function bound to this resource's context.
         *
         * @private
         * @type {function}
         */ this._boundOnError = null;
        /**
         * The `_onProgress` function bound to this resource's context.
         *
         * @private
         * @type {function}
         */ this._boundOnProgress = null;
        /**
         * The `_onTimeout` function bound to this resource's context.
         *
         * @private
         * @type {function}
         */ this._boundOnTimeout = null;
        this._boundXhrOnError = null;
        this._boundXhrOnTimeout = null;
        this._boundXhrOnAbort = null;
        this._boundXhrOnLoad = null;
        if (typeof name !== 'string' || typeof url !== 'string') throw new Error('Both name and url are required for constructing a resource.');
        options = options || {
        };
        this._flags = 0;
        // set data url flag, needs to be set early for some _determineX checks to work.
        this._setFlag(LoaderResource1.STATUS_FLAGS.DATA_URL, url.indexOf('data:') === 0);
        this.name = name;
        this.url = url;
        this.extension = this._getExtension();
        this.data = null;
        this.crossOrigin = options.crossOrigin === true ? 'anonymous' : options.crossOrigin;
        this.timeout = options.timeout || 0;
        this.loadType = options.loadType || this._determineLoadType();
        // The type used to load the resource via XHR. If unset, determined automatically.
        this.xhrType = options.xhrType;
        // Extra info for middleware, and controlling specifics about how the resource loads.
        // Note that if you pass in a `loadElement`, the Resource class takes ownership of it.
        // Meaning it will modify it as it sees fit.
        this.metadata = options.metadata || {
        };
        // The error that occurred while loading (if any).
        this.error = null;
        // The XHR object that was used to load this resource. This is only set
        // when `loadType` is `LoaderResource.LOAD_TYPE.XHR`.
        this.xhr = null;
        // The child resources this resource owns.
        this.children = [];
        // The resource type.
        this.type = LoaderResource1.TYPE.UNKNOWN;
        // The progress chunk owned by this resource.
        this.progressChunk = 0;
        // The `dequeue` method that will be used a storage place for the async queue dequeue method
        // used privately by the loader.
        this._dequeue = _noop;
        // Used a storage place for the on load binding used privately by the loader.
        this._onLoadBinding = null;
        // The timer for element loads to check if they timeout.
        this._elementTimer = 0;
        this._boundComplete = this.complete.bind(this);
        this._boundOnError = this._onError.bind(this);
        this._boundOnProgress = this._onProgress.bind(this);
        this._boundOnTimeout = this._onTimeout.bind(this);
        // xhr callbacks
        this._boundXhrOnError = this._xhrOnError.bind(this);
        this._boundXhrOnTimeout = this._xhrOnTimeout.bind(this);
        this._boundXhrOnAbort = this._xhrOnAbort.bind(this);
        this._boundXhrOnLoad = this._xhrOnLoad.bind(this);
        // Dispatched when the resource beings to load.
        this.onStart = new Signal();
        // Dispatched each time progress of this resource load updates.
        // Not all resources types and loader systems can support this event
        // so sometimes it may not be available. If the resource
        // is being loaded on a modern browser, using XHR, and the remote server
        // properly sets Content-Length headers, then this will be available.
        this.onProgress = new Signal();
        // Dispatched once this resource has loaded, if there was an error it will
        // be in the `error` property.
        this.onComplete = new Signal();
        // Dispatched after this resource has had all the *after* middleware run on it.
        this.onAfterMiddleware = new Signal();
    }
    /**
     * Sets the load type to be used for a specific extension.
     *
     * @static
     * @param {string} extname - The extension to set the type for, e.g. "png" or "fnt"
     * @param {PIXI.LoaderResource.LOAD_TYPE} loadType - The load type to set it to.
     */ LoaderResource1.setExtensionLoadType = function(extname, loadType) {
        setExtMap(LoaderResource1._loadTypeMap, extname, loadType);
    };
    /**
     * Sets the load type to be used for a specific extension.
     *
     * @static
     * @param {string} extname - The extension to set the type for, e.g. "png" or "fnt"
     * @param {PIXI.LoaderResource.XHR_RESPONSE_TYPE} xhrType - The xhr type to set it to.
     */ LoaderResource1.setExtensionXhrType = function(extname, xhrType) {
        setExtMap(LoaderResource1._xhrTypeMap, extname, xhrType);
    };
    Object.defineProperty(LoaderResource1.prototype, "isDataUrl", {
        /**
         * When the resource starts to load.
         *
         * @memberof PIXI.LoaderResource
         * @callback OnStartSignal
         * @param {Resource} resource - The resource that the event happened on.
         */ /**
         * When the resource reports loading progress.
         *
         * @memberof PIXI.LoaderResource
         * @callback OnProgressSignal
         * @param {Resource} resource - The resource that the event happened on.
         * @param {number} percentage - The progress of the load in the range [0, 1].
         */ /**
         * When the resource finishes loading.
         *
         * @memberof PIXI.LoaderResource
         * @callback OnCompleteSignal
         * @param {Resource} resource - The resource that the event happened on.
         */ /**
         * @memberof PIXI.LoaderResource
         * @typedef {object} IMetadata
         * @property {HTMLImageElement|HTMLAudioElement|HTMLVideoElement} [loadElement=null] - The
         *      element to use for loading, instead of creating one.
         * @property {boolean} [skipSource=false] - Skips adding source(s) to the load element. This
         *      is useful if you want to pass in a `loadElement` that you already added load sources to.
         * @property {string|string[]} [mimeType] - The mime type to use for the source element
         *      of a video/audio elment. If the urls are an array, you can pass this as an array as well
         *      where each index is the mime type to use for the corresponding url index.
         */ /**
         * Stores whether or not this url is a data url.
         *
         * @readonly
         * @member {boolean}
         */ get: function() {
            return this._hasFlag(LoaderResource1.STATUS_FLAGS.DATA_URL);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(LoaderResource1.prototype, "isComplete", {
        /**
         * Describes if this resource has finished loading. Is true when the resource has completely
         * loaded.
         *
         * @readonly
         * @member {boolean}
         */ get: function() {
            return this._hasFlag(LoaderResource1.STATUS_FLAGS.COMPLETE);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(LoaderResource1.prototype, "isLoading", {
        /**
         * Describes if this resource is currently loading. Is true when the resource starts loading,
         * and is false again when complete.
         *
         * @readonly
         * @member {boolean}
         */ get: function() {
            return this._hasFlag(LoaderResource1.STATUS_FLAGS.LOADING);
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Marks the resource as complete.
     *
     */ LoaderResource1.prototype.complete = function() {
        this._clearEvents();
        this._finish();
    };
    /**
     * Aborts the loading of this resource, with an optional message.
     *
     * @param {string} message - The message to use for the error
     */ LoaderResource1.prototype.abort = function(message) {
        // abort can be called multiple times, ignore subsequent calls.
        if (this.error) return;
        // store error
        this.error = new Error(message);
        // clear events before calling aborts
        this._clearEvents();
        // abort the actual loading
        if (this.xhr) this.xhr.abort();
        else if (this.xdr) this.xdr.abort();
        else if (this.data) {
            // single source
            if (this.data.src) this.data.src = LoaderResource1.EMPTY_GIF;
            else while(this.data.firstChild)this.data.removeChild(this.data.firstChild);
        }
        // done now.
        this._finish();
    };
    /**
     * Kicks off loading of this resource. This method is asynchronous.
     *
     * @param {PIXI.LoaderResource.OnCompleteSignal} [cb] - Optional callback to call once the resource is loaded.
     */ LoaderResource1.prototype.load = function(cb) {
        var _this = this;
        if (this.isLoading) return;
        if (this.isComplete) {
            if (cb) setTimeout(function() {
                return cb(_this);
            }, 1);
            return;
        } else if (cb) this.onComplete.once(cb);
        this._setFlag(LoaderResource1.STATUS_FLAGS.LOADING, true);
        this.onStart.dispatch(this);
        // if unset, determine the value
        if (this.crossOrigin === false || typeof this.crossOrigin !== 'string') this.crossOrigin = this._determineCrossOrigin(this.url);
        switch(this.loadType){
            case LoaderResource1.LOAD_TYPE.IMAGE:
                this.type = LoaderResource1.TYPE.IMAGE;
                this._loadElement('image');
                break;
            case LoaderResource1.LOAD_TYPE.AUDIO:
                this.type = LoaderResource1.TYPE.AUDIO;
                this._loadSourceElement('audio');
                break;
            case LoaderResource1.LOAD_TYPE.VIDEO:
                this.type = LoaderResource1.TYPE.VIDEO;
                this._loadSourceElement('video');
                break;
            case LoaderResource1.LOAD_TYPE.XHR:
            /* falls through */ default:
                if (useXdr && this.crossOrigin) this._loadXdr();
                else this._loadXhr();
                break;
        }
    };
    /**
     * Checks if the flag is set.
     *
     * @param flag - The flag to check.
     * @return True if the flag is set.
     */ LoaderResource1.prototype._hasFlag = function(flag) {
        return (this._flags & flag) !== 0;
    };
    /**
     * (Un)Sets the flag.
     *
     * @param flag - The flag to (un)set.
     * @param value - Whether to set or (un)set the flag.
     */ LoaderResource1.prototype._setFlag = function(flag, value) {
        this._flags = value ? this._flags | flag : this._flags & ~flag;
    };
    /**
     * Clears all the events from the underlying loading source.
     */ LoaderResource1.prototype._clearEvents = function() {
        clearTimeout(this._elementTimer);
        if (this.data && this.data.removeEventListener) {
            this.data.removeEventListener('error', this._boundOnError, false);
            this.data.removeEventListener('load', this._boundComplete, false);
            this.data.removeEventListener('progress', this._boundOnProgress, false);
            this.data.removeEventListener('canplaythrough', this._boundComplete, false);
        }
        if (this.xhr) {
            if (this.xhr.removeEventListener) {
                this.xhr.removeEventListener('error', this._boundXhrOnError, false);
                this.xhr.removeEventListener('timeout', this._boundXhrOnTimeout, false);
                this.xhr.removeEventListener('abort', this._boundXhrOnAbort, false);
                this.xhr.removeEventListener('progress', this._boundOnProgress, false);
                this.xhr.removeEventListener('load', this._boundXhrOnLoad, false);
            } else {
                this.xhr.onerror = null;
                this.xhr.ontimeout = null;
                this.xhr.onprogress = null;
                this.xhr.onload = null;
            }
        }
    };
    /**
     * Finalizes the load.
     */ LoaderResource1.prototype._finish = function() {
        if (this.isComplete) throw new Error('Complete called again for an already completed resource.');
        this._setFlag(LoaderResource1.STATUS_FLAGS.COMPLETE, true);
        this._setFlag(LoaderResource1.STATUS_FLAGS.LOADING, false);
        this.onComplete.dispatch(this);
    };
    /**
     * Loads this resources using an element that has a single source,
     * like an HTMLImageElement.
     * @private
     * @param type - The type of element to use.
     */ LoaderResource1.prototype._loadElement = function(type) {
        if (this.metadata.loadElement) this.data = this.metadata.loadElement;
        else if (type === 'image' && typeof self.Image !== 'undefined') this.data = new Image();
        else this.data = document.createElement(type);
        if (this.crossOrigin) this.data.crossOrigin = this.crossOrigin;
        if (!this.metadata.skipSource) this.data.src = this.url;
        this.data.addEventListener('error', this._boundOnError, false);
        this.data.addEventListener('load', this._boundComplete, false);
        this.data.addEventListener('progress', this._boundOnProgress, false);
        if (this.timeout) this._elementTimer = setTimeout(this._boundOnTimeout, this.timeout);
    };
    /**
     * Loads this resources using an element that has multiple sources,
     * like an HTMLAudioElement or HTMLVideoElement.
     * @param type - The type of element to use.
     */ LoaderResource1.prototype._loadSourceElement = function(type) {
        if (this.metadata.loadElement) this.data = this.metadata.loadElement;
        else if (type === 'audio' && typeof self.Audio !== 'undefined') this.data = new Audio();
        else this.data = document.createElement(type);
        if (this.data === null) {
            this.abort("Unsupported element: " + type);
            return;
        }
        if (this.crossOrigin) this.data.crossOrigin = this.crossOrigin;
        if (!this.metadata.skipSource) {
            // support for CocoonJS Canvas+ runtime, lacks document.createElement('source')
            if (navigator.isCocoonJS) this.data.src = Array.isArray(this.url) ? this.url[0] : this.url;
            else if (Array.isArray(this.url)) {
                var mimeTypes = this.metadata.mimeType;
                for(var i = 0; i < this.url.length; ++i)this.data.appendChild(this._createSource(type, this.url[i], Array.isArray(mimeTypes) ? mimeTypes[i] : mimeTypes));
            } else {
                var mimeTypes = this.metadata.mimeType;
                this.data.appendChild(this._createSource(type, this.url, Array.isArray(mimeTypes) ? mimeTypes[0] : mimeTypes));
            }
        }
        this.data.addEventListener('error', this._boundOnError, false);
        this.data.addEventListener('load', this._boundComplete, false);
        this.data.addEventListener('progress', this._boundOnProgress, false);
        this.data.addEventListener('canplaythrough', this._boundComplete, false);
        this.data.load();
        if (this.timeout) this._elementTimer = setTimeout(this._boundOnTimeout, this.timeout);
    };
    /**
     * Loads this resources using an XMLHttpRequest.
     */ LoaderResource1.prototype._loadXhr = function() {
        // if unset, determine the value
        if (typeof this.xhrType !== 'string') this.xhrType = this._determineXhrType();
        var xhr = this.xhr = new XMLHttpRequest();
        // set the request type and url
        xhr.open('GET', this.url, true);
        xhr.timeout = this.timeout;
        // load json as text and parse it ourselves. We do this because some browsers
        // *cough* safari *cough* can't deal with it.
        if (this.xhrType === LoaderResource1.XHR_RESPONSE_TYPE.JSON || this.xhrType === LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT) xhr.responseType = LoaderResource1.XHR_RESPONSE_TYPE.TEXT;
        else xhr.responseType = this.xhrType;
        xhr.addEventListener('error', this._boundXhrOnError, false);
        xhr.addEventListener('timeout', this._boundXhrOnTimeout, false);
        xhr.addEventListener('abort', this._boundXhrOnAbort, false);
        xhr.addEventListener('progress', this._boundOnProgress, false);
        xhr.addEventListener('load', this._boundXhrOnLoad, false);
        xhr.send();
    };
    /**
     * Loads this resources using an XDomainRequest. This is here because we need to support IE9 (gross).
     */ LoaderResource1.prototype._loadXdr = function() {
        // if unset, determine the value
        if (typeof this.xhrType !== 'string') this.xhrType = this._determineXhrType();
        var xdr = this.xhr = new self.XDomainRequest(); // eslint-disable-line no-undef
        // XDomainRequest has a few quirks. Occasionally it will abort requests
        // A way to avoid this is to make sure ALL callbacks are set even if not used
        // More info here: http://stackoverflow.com/questions/15786966/xdomainrequest-aborts-post-on-ie-9
        xdr.timeout = this.timeout || 5000; // XDR needs a timeout value or it breaks in IE9
        xdr.onerror = this._boundXhrOnError;
        xdr.ontimeout = this._boundXhrOnTimeout;
        xdr.onprogress = this._boundOnProgress;
        xdr.onload = this._boundXhrOnLoad;
        xdr.open('GET', this.url, true);
        // Note: The xdr.send() call is wrapped in a timeout to prevent an
        // issue with the interface where some requests are lost if multiple
        // XDomainRequests are being sent at the same time.
        // Some info here: https://github.com/photonstorm/phaser/issues/1248
        setTimeout(function() {
            return xdr.send();
        }, 1);
    };
    /**
     * Creates a source used in loading via an element.
     * @param type - The element type (video or audio).
     * @param url - The source URL to load from.
     * @param [mime] - The mime type of the video
     * @return The source element.
     */ LoaderResource1.prototype._createSource = function(type, url, mime) {
        if (!mime) mime = type + "/" + this._getExtension(url);
        var source = document.createElement('source');
        source.src = url;
        source.type = mime;
        return source;
    };
    /**
     * Called if a load errors out.
     *
     * @param event - The error event from the element that emits it.
     */ LoaderResource1.prototype._onError = function(event) {
        this.abort("Failed to load element using: " + event.target.nodeName);
    };
    /**
     * Called if a load progress event fires for an element or xhr/xdr.
     * @param event - Progress event.
     */ LoaderResource1.prototype._onProgress = function(event) {
        if (event && event.lengthComputable) this.onProgress.dispatch(this, event.loaded / event.total);
    };
    /**
     * Called if a timeout event fires for an element.
     */ LoaderResource1.prototype._onTimeout = function() {
        this.abort("Load timed out.");
    };
    /**
     * Called if an error event fires for xhr/xdr.
     */ LoaderResource1.prototype._xhrOnError = function() {
        var xhr = this.xhr;
        this.abort(reqType(xhr) + " Request failed. Status: " + xhr.status + ", text: \"" + xhr.statusText + "\"");
    };
    /**
     * Called if an error event fires for xhr/xdr.
     */ LoaderResource1.prototype._xhrOnTimeout = function() {
        var xhr = this.xhr;
        this.abort(reqType(xhr) + " Request timed out.");
    };
    /**
     * Called if an abort event fires for xhr/xdr.
     */ LoaderResource1.prototype._xhrOnAbort = function() {
        var xhr = this.xhr;
        this.abort(reqType(xhr) + " Request was aborted by the user.");
    };
    /**
     * Called when data successfully loads from an xhr/xdr request.
     */ LoaderResource1.prototype._xhrOnLoad = function() {
        var xhr = this.xhr;
        var text = '';
        var status = typeof xhr.status === 'undefined' ? STATUS_OK : xhr.status; // XDR has no `.status`, assume 200.
        // responseText is accessible only if responseType is '' or 'text' and on older browsers
        if (xhr.responseType === '' || xhr.responseType === 'text' || typeof xhr.responseType === 'undefined') text = xhr.responseText;
        // status can be 0 when using the `file://` protocol so we also check if a response is set.
        // If it has a response, we assume 200; otherwise a 0 status code with no contents is an aborted request.
        if (status === STATUS_NONE && (text.length > 0 || xhr.responseType === LoaderResource1.XHR_RESPONSE_TYPE.BUFFER)) status = STATUS_OK;
        else if (status === STATUS_IE_BUG_EMPTY) status = STATUS_EMPTY;
        var statusType = status / 100 | 0;
        if (statusType === STATUS_TYPE_OK) {
            // if text, just return it
            if (this.xhrType === LoaderResource1.XHR_RESPONSE_TYPE.TEXT) {
                this.data = text;
                this.type = LoaderResource1.TYPE.TEXT;
            } else if (this.xhrType === LoaderResource1.XHR_RESPONSE_TYPE.JSON) try {
                this.data = JSON.parse(text);
                this.type = LoaderResource1.TYPE.JSON;
            } catch (e) {
                this.abort("Error trying to parse loaded json: " + e);
                return;
            }
            else if (this.xhrType === LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT) try {
                if (self.DOMParser) {
                    var domparser = new DOMParser();
                    this.data = domparser.parseFromString(text, 'text/xml');
                } else {
                    var div = document.createElement('div');
                    div.innerHTML = text;
                    this.data = div;
                }
                this.type = LoaderResource1.TYPE.XML;
            } catch (e$1) {
                this.abort("Error trying to parse loaded xml: " + e$1);
                return;
            }
            else this.data = xhr.response || text;
        } else {
            this.abort("[" + xhr.status + "] " + xhr.statusText + ": " + xhr.responseURL);
            return;
        }
        this.complete();
    };
    /**
     * Sets the `crossOrigin` property for this resource based on if the url
     * for this resource is cross-origin. If crossOrigin was manually set, this
     * function does nothing.
     * @private
     * @param url - The url to test.
     * @param [loc=self.location] - The location object to test against.
     * @return The crossOrigin value to use (or empty string for none).
     */ // eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types
    LoaderResource1.prototype._determineCrossOrigin = function(url, loc) {
        // data: and javascript: urls are considered same-origin
        if (url.indexOf('data:') === 0) return '';
        // A sandboxed iframe without the 'allow-same-origin' attribute will have a special
        // origin designed not to match self.location.origin, and will always require
        // crossOrigin requests regardless of whether the location matches.
        if (self.origin !== self.location.origin) return 'anonymous';
        // default is self.location
        loc = loc || self.location;
        if (!tempAnchor) tempAnchor = document.createElement('a');
        // let the browser determine the full href for the url of this resource and then
        // parse with the node url lib, we can't use the properties of the anchor element
        // because they don't work in IE9 :(
        tempAnchor.href = url;
        var parsedUrl = parseUri(tempAnchor.href, {
            strictMode: true
        });
        var samePort = !parsedUrl.port && loc.port === '' || parsedUrl.port === loc.port;
        var protocol = parsedUrl.protocol ? parsedUrl.protocol + ":" : '';
        // if cross origin
        if (parsedUrl.host !== loc.hostname || !samePort || protocol !== loc.protocol) return 'anonymous';
        return '';
    };
    /**
     * Determines the responseType of an XHR request based on the extension of the
     * resource being loaded.
     *
     * @private
     * @return {PIXI.LoaderResource.XHR_RESPONSE_TYPE} The responseType to use.
     */ LoaderResource1.prototype._determineXhrType = function() {
        return LoaderResource1._xhrTypeMap[this.extension] || LoaderResource1.XHR_RESPONSE_TYPE.TEXT;
    };
    /**
     * Determines the loadType of a resource based on the extension of the
     * resource being loaded.
     *
     * @private
     * @return {PIXI.LoaderResource.LOAD_TYPE} The loadType to use.
     */ LoaderResource1.prototype._determineLoadType = function() {
        return LoaderResource1._loadTypeMap[this.extension] || LoaderResource1.LOAD_TYPE.XHR;
    };
    /**
     * Extracts the extension (sans '.') of the file being loaded by the resource.
     *
     * @param [url] - url to parse, `this.url` by default.
     * @return The extension.
     */ LoaderResource1.prototype._getExtension = function(url) {
        if (url === void 0) url = this.url;
        var ext = '';
        if (this.isDataUrl) {
            var slashIndex = url.indexOf('/');
            ext = url.substring(slashIndex + 1, url.indexOf(';', slashIndex));
        } else {
            var queryStart = url.indexOf('?');
            var hashStart = url.indexOf('#');
            var index = Math.min(queryStart > -1 ? queryStart : url.length, hashStart > -1 ? hashStart : url.length);
            url = url.substring(0, index);
            ext = url.substring(url.lastIndexOf('.') + 1);
        }
        return ext.toLowerCase();
    };
    /**
     * Determines the mime type of an XHR request based on the responseType of
     * resource being loaded.
     *
     * @param type - The type to get a mime type for.
     * @private
     * @return The mime type to use.
     */ LoaderResource1.prototype._getMimeFromXhrType = function(type) {
        switch(type){
            case LoaderResource1.XHR_RESPONSE_TYPE.BUFFER:
                return 'application/octet-binary';
            case LoaderResource1.XHR_RESPONSE_TYPE.BLOB:
                return 'application/blob';
            case LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT:
                return 'application/xml';
            case LoaderResource1.XHR_RESPONSE_TYPE.JSON:
                return 'application/json';
            case LoaderResource1.XHR_RESPONSE_TYPE.DEFAULT:
            case LoaderResource1.XHR_RESPONSE_TYPE.TEXT:
            /* falls through */ default:
                return 'text/plain';
        }
    };
    return LoaderResource1;
}();
// eslint-disable-next-line @typescript-eslint/no-namespace
(function(LoaderResource1) {
    /**
     * The types of resources a resource could represent.
     *
     * @static
     * @readonly
     * @enum {number}
     * @memberof PIXI.LoaderResource
     */ var STATUS_FLAGS;
    (function(STATUS_FLAGS1) {
        /** None */ STATUS_FLAGS1[STATUS_FLAGS1["NONE"] = 0] = "NONE";
        /** Data URL */ STATUS_FLAGS1[STATUS_FLAGS1["DATA_URL"] = 1] = "DATA_URL";
        /** Complete */ STATUS_FLAGS1[STATUS_FLAGS1["COMPLETE"] = 2] = "COMPLETE";
        /** Loading */ STATUS_FLAGS1[STATUS_FLAGS1["LOADING"] = 4] = "LOADING";
    })(STATUS_FLAGS = LoaderResource1.STATUS_FLAGS || (LoaderResource1.STATUS_FLAGS = {
    }));
    /**
     * The types of resources a resource could represent.
     *
     * @static
     * @readonly
     * @enum {number}
     * @memberof PIXI.LoaderResource
     */ var TYPE;
    (function(TYPE1) {
        /** Unknown */ TYPE1[TYPE1["UNKNOWN"] = 0] = "UNKNOWN";
        /** JSON */ TYPE1[TYPE1["JSON"] = 1] = "JSON";
        /** XML */ TYPE1[TYPE1["XML"] = 2] = "XML";
        /** Image */ TYPE1[TYPE1["IMAGE"] = 3] = "IMAGE";
        /** Audio */ TYPE1[TYPE1["AUDIO"] = 4] = "AUDIO";
        /** Video */ TYPE1[TYPE1["VIDEO"] = 5] = "VIDEO";
        /** Plain text */ TYPE1[TYPE1["TEXT"] = 6] = "TEXT";
    })(TYPE = LoaderResource1.TYPE || (LoaderResource1.TYPE = {
    }));
    /**
     * The types of loading a resource can use.
     *
     * @static
     * @readonly
     * @enum {number}
     * @memberof PIXI.LoaderResource
     */ var LOAD_TYPE;
    (function(LOAD_TYPE1) {
        /** Uses XMLHttpRequest to load the resource. */ LOAD_TYPE1[LOAD_TYPE1["XHR"] = 1] = "XHR";
        /** Uses an `Image` object to load the resource. */ LOAD_TYPE1[LOAD_TYPE1["IMAGE"] = 2] = "IMAGE";
        /** Uses an `Audio` object to load the resource. */ LOAD_TYPE1[LOAD_TYPE1["AUDIO"] = 3] = "AUDIO";
        /** Uses a `Video` object to load the resource. */ LOAD_TYPE1[LOAD_TYPE1["VIDEO"] = 4] = "VIDEO";
    })(LOAD_TYPE = LoaderResource1.LOAD_TYPE || (LoaderResource1.LOAD_TYPE = {
    }));
    /**
     * The XHR ready states, used internally.
     *
     * @static
     * @readonly
     * @enum {string}
     * @memberof PIXI.LoaderResource
     */ var XHR_RESPONSE_TYPE;
    (function(XHR_RESPONSE_TYPE1) {
        /** string */ XHR_RESPONSE_TYPE1["DEFAULT"] = "text";
        /** ArrayBuffer */ XHR_RESPONSE_TYPE1["BUFFER"] = "arraybuffer";
        /** Blob */ XHR_RESPONSE_TYPE1["BLOB"] = "blob";
        /** Document */ XHR_RESPONSE_TYPE1["DOCUMENT"] = "document";
        /** Object */ XHR_RESPONSE_TYPE1["JSON"] = "json";
        /** String */ XHR_RESPONSE_TYPE1["TEXT"] = "text";
    })(XHR_RESPONSE_TYPE = LoaderResource1.XHR_RESPONSE_TYPE || (LoaderResource1.XHR_RESPONSE_TYPE = {
    }));
    LoaderResource1._loadTypeMap = {
        // images
        gif: LoaderResource1.LOAD_TYPE.IMAGE,
        png: LoaderResource1.LOAD_TYPE.IMAGE,
        bmp: LoaderResource1.LOAD_TYPE.IMAGE,
        jpg: LoaderResource1.LOAD_TYPE.IMAGE,
        jpeg: LoaderResource1.LOAD_TYPE.IMAGE,
        tif: LoaderResource1.LOAD_TYPE.IMAGE,
        tiff: LoaderResource1.LOAD_TYPE.IMAGE,
        webp: LoaderResource1.LOAD_TYPE.IMAGE,
        tga: LoaderResource1.LOAD_TYPE.IMAGE,
        svg: LoaderResource1.LOAD_TYPE.IMAGE,
        'svg+xml': LoaderResource1.LOAD_TYPE.IMAGE,
        // audio
        mp3: LoaderResource1.LOAD_TYPE.AUDIO,
        ogg: LoaderResource1.LOAD_TYPE.AUDIO,
        wav: LoaderResource1.LOAD_TYPE.AUDIO,
        // videos
        mp4: LoaderResource1.LOAD_TYPE.VIDEO,
        webm: LoaderResource1.LOAD_TYPE.VIDEO
    };
    LoaderResource1._xhrTypeMap = {
        // xml
        xhtml: LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT,
        html: LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT,
        htm: LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT,
        xml: LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT,
        tmx: LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT,
        svg: LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT,
        // This was added to handle Tiled Tileset XML, but .tsx is also a TypeScript React Component.
        // Since it is way less likely for people to be loading TypeScript files instead of Tiled files,
        // this should probably be fine.
        tsx: LoaderResource1.XHR_RESPONSE_TYPE.DOCUMENT,
        // images
        gif: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        png: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        bmp: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        jpg: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        jpeg: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        tif: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        tiff: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        webp: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        tga: LoaderResource1.XHR_RESPONSE_TYPE.BLOB,
        // json
        json: LoaderResource1.XHR_RESPONSE_TYPE.JSON,
        // text
        text: LoaderResource1.XHR_RESPONSE_TYPE.TEXT,
        txt: LoaderResource1.XHR_RESPONSE_TYPE.TEXT,
        // fonts
        ttf: LoaderResource1.XHR_RESPONSE_TYPE.BUFFER,
        otf: LoaderResource1.XHR_RESPONSE_TYPE.BUFFER
    };
    // We can't set the `src` attribute to empty string, so on abort we set it to this 1px transparent gif
    LoaderResource1.EMPTY_GIF = 'data:image/gif;base64,R0lGODlhAQABAIAAAP///wAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==';
})(LoaderResource || (LoaderResource = {
}));
/**
 * Smaller version of the async library constructs.
 * @ignore
 */ function _noop$1() {
}
/**
 * Ensures a function is only called once.
 * @ignore
 * @param {function} fn - The function to wrap.
 * @return {function} The wrapping function.
 */ function onlyOnce(fn) {
    return function onceWrapper() {
        var arguments$1 = arguments;
        var args = [];
        for(var _i = 0; _i < arguments.length; _i++)args[_i] = arguments$1[_i];
        if (fn === null) throw new Error('Callback was already called.');
        var callFn = fn;
        fn = null;
        callFn.apply(this, args);
    };
}
/**
 * @private
 * @memberof PIXI
 */ var AsyncQueueItem = function() {
    /**
     * @private
     */ function AsyncQueueItem1(data, callback) {
        this.data = data;
        this.callback = callback;
    }
    return AsyncQueueItem1;
}();
/**
 * @private
 * @memberof PIXI
 */ var AsyncQueue = function() {
    /**
     * @private
     */ function AsyncQueue1(worker, concurrency) {
        var _this = this;
        if (concurrency === void 0) concurrency = 1;
        this.workers = 0;
        this.saturated = _noop$1;
        this.unsaturated = _noop$1;
        this.empty = _noop$1;
        this.drain = _noop$1;
        this.error = _noop$1;
        this.started = false;
        this.paused = false;
        this._tasks = [];
        this._insert = function(data, insertAtFront, callback) {
            if (callback && typeof callback !== 'function') throw new Error('task callback must be a function');
            _this.started = true;
            // eslint-disable-next-line no-eq-null,eqeqeq
            if (data == null && _this.idle()) {
                // call drain immediately if there are no tasks
                setTimeout(function() {
                    return _this.drain();
                }, 1);
                return;
            }
            var item = new AsyncQueueItem(data, typeof callback === 'function' ? callback : _noop$1);
            if (insertAtFront) _this._tasks.unshift(item);
            else _this._tasks.push(item);
            setTimeout(_this.process, 1);
        };
        this.process = function() {
            while(!_this.paused && _this.workers < _this.concurrency && _this._tasks.length){
                var task = _this._tasks.shift();
                if (_this._tasks.length === 0) _this.empty();
                _this.workers += 1;
                if (_this.workers === _this.concurrency) _this.saturated();
                _this._worker(task.data, onlyOnce(_this._next(task)));
            }
        };
        this._worker = worker;
        if (concurrency === 0) throw new Error('Concurrency must not be zero');
        this.concurrency = concurrency;
        this.buffer = concurrency / 4;
    }
    /**
     * @private
     */ AsyncQueue1.prototype._next = function(task) {
        var _this = this;
        return function() {
            var arguments$1 = arguments;
            var args = [];
            for(var _i = 0; _i < arguments.length; _i++)args[_i] = arguments$1[_i];
            _this.workers -= 1;
            task.callback.apply(task, args);
            // eslint-disable-next-line no-eq-null,eqeqeq
            if (args[0] != null) _this.error(args[0], task.data);
            if (_this.workers <= _this.concurrency - _this.buffer) _this.unsaturated();
            if (_this.idle()) _this.drain();
            _this.process();
        };
    };
    // That was in object
    // eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types
    AsyncQueue1.prototype.push = function(data, callback) {
        this._insert(data, false, callback);
    };
    AsyncQueue1.prototype.kill = function() {
        this.workers = 0;
        this.drain = _noop$1;
        this.started = false;
        this._tasks = [];
    };
    // eslint-disable-next-line @typescript-eslint/explicit-module-boundary-types
    AsyncQueue1.prototype.unshift = function(data, callback) {
        this._insert(data, true, callback);
    };
    AsyncQueue1.prototype.length = function() {
        return this._tasks.length;
    };
    AsyncQueue1.prototype.running = function() {
        return this.workers;
    };
    AsyncQueue1.prototype.idle = function() {
        return this._tasks.length + this.workers === 0;
    };
    AsyncQueue1.prototype.pause = function() {
        if (this.paused === true) return;
        this.paused = true;
    };
    AsyncQueue1.prototype.resume = function() {
        if (this.paused === false) return;
        this.paused = false;
        // Need to call this.process once per concurrent
        // worker to preserve full concurrency after pause
        for(var w = 1; w <= this.concurrency; w++)this.process();
    };
    /**
     * Iterates an array in series.
     *
     * @param {Array.<*>} array - Array to iterate.
     * @param {function} iterator - Function to call for each element.
     * @param {function} callback - Function to call when done, or on error.
     * @param {boolean} [deferNext=false] - Break synchronous each loop by calling next with a setTimeout of 1.
     */ AsyncQueue1.eachSeries = function(array, iterator, callback, deferNext) {
        var i = 0;
        var len = array.length;
        function next(err) {
            if (err || i === len) {
                if (callback) callback(err);
                return;
            }
            if (deferNext) setTimeout(function() {
                iterator(array[i++], next);
            }, 1);
            else iterator(array[i++], next);
        }
        next();
    };
    /**
     * Async queue implementation,
     *
     * @param {function} worker - The worker function to call for each task.
     * @param {number} concurrency - How many workers to run in parrallel.
     * @return {*} The async queue object.
     */ AsyncQueue1.queue = function(worker, concurrency) {
        return new AsyncQueue1(worker, concurrency);
    };
    return AsyncQueue1;
}();
// some constants
var MAX_PROGRESS = 100;
var rgxExtractUrlHash = /(#[\w-]+)?$/;
/**
 * The new loader, forked from Resource Loader by Chad Engler: https://github.com/englercj/resource-loader
 *
 * ```js
 * const loader = PIXI.Loader.shared; // PixiJS exposes a premade instance for you to use.
 * //or
 * const loader = new PIXI.Loader(); // you can also create your own if you want
 *
 * const sprites = {};
 *
 * // Chainable `add` to enqueue a resource
 * loader.add('bunny', 'data/bunny.png')
 *       .add('spaceship', 'assets/spritesheet.json');
 * loader.add('scoreFont', 'assets/score.fnt');
 *
 * // Chainable `pre` to add a middleware that runs for each resource, *before* loading that resource.
 * // This is useful to implement custom caching modules (using filesystem, indexeddb, memory, etc).
 * loader.pre(cachingMiddleware);
 *
 * // Chainable `use` to add a middleware that runs for each resource, *after* loading that resource.
 * // This is useful to implement custom parsing modules (like spritesheet parsers, spine parser, etc).
 * loader.use(parsingMiddleware);
 *
 * // The `load` method loads the queue of resources, and calls the passed in callback called once all
 * // resources have loaded.
 * loader.load((loader, resources) => {
 *     // resources is an object where the key is the name of the resource loaded and the value is the resource object.
 *     // They have a couple default properties:
 *     // - `url`: The URL that the resource was loaded from
 *     // - `error`: The error that happened when trying to load (if any)
 *     // - `data`: The raw data that was loaded
 *     // also may contain other properties based on the middleware that runs.
 *     sprites.bunny = new PIXI.TilingSprite(resources.bunny.texture);
 *     sprites.spaceship = new PIXI.TilingSprite(resources.spaceship.texture);
 *     sprites.scoreFont = new PIXI.TilingSprite(resources.scoreFont.texture);
 * });
 *
 * // throughout the process multiple signals can be dispatched.
 * loader.onProgress.add(() => {}); // called once per loaded/errored file
 * loader.onError.add(() => {}); // called once per errored file
 * loader.onLoad.add(() => {}); // called once per loaded file
 * loader.onComplete.add(() => {}); // called once when the queued resources all load.
 * ```
 *
 * @class Loader
 * @memberof PIXI
 */ var Loader = function() {
    /**
     * @param baseUrl - The base url for all resources loaded by this loader.
     * @param concurrency - The number of resources to load concurrently.
     */ function Loader1(baseUrl, concurrency) {
        var _this = this;
        if (baseUrl === void 0) baseUrl = '';
        if (concurrency === void 0) concurrency = 10;
        /**
         * The middleware to run before loading each resource.
         */ this._beforeMiddleware = [];
        /**
         * The middleware to run after loading each resource.
         */ this._afterMiddleware = [];
        /**
         * The tracks the resources we are currently completing parsing for.
         */ this._resourcesParsing = [];
        /**
         * The `_loadResource` function bound with this object context.
         *
         * @private
         * @member {function}
         * @param {PIXI.LoaderResource} r - The resource to load
         * @param {Function} d - The dequeue function
         * @return {undefined}
         */ this._boundLoadResource = function(r, d) {
            return _this._loadResource(r, d);
        };
        /**
         * All the resources for this loader keyed by name.
         *
         * @member {object<string, PIXI.LoaderResource>}
         */ this.resources = {
        };
        this.baseUrl = baseUrl;
        this.progress = 0;
        this.loading = false;
        this.defaultQueryString = '';
        this._beforeMiddleware = [];
        this._afterMiddleware = [];
        this._resourcesParsing = [];
        this._boundLoadResource = function(r, d) {
            return _this._loadResource(r, d);
        };
        this._queue = AsyncQueue.queue(this._boundLoadResource, concurrency);
        this._queue.pause();
        this.resources = {
        };
        this.onProgress = new Signal();
        this.onError = new Signal();
        this.onLoad = new Signal();
        this.onStart = new Signal();
        this.onComplete = new Signal();
        for(var i = 0; i < Loader1._plugins.length; ++i){
            var plugin = Loader1._plugins[i];
            var pre = plugin.pre, use = plugin.use;
            if (pre) this.pre(pre);
            if (use) this.use(use);
        }
        this._protected = false;
    }
    /**
     * Same as add, params have strict order
     * @private
     * @param name - The name of the resource to load.
     * @param url - The url for this resource, relative to the baseUrl of this loader.
     * @param options - The options for the load.
     * @param callback - Function to call when this specific resource completes loading.
     * @return {this} Returns itself.
     */ Loader1.prototype._add = function(name, url, options, callback) {
        // if loading already you can only add resources that have a parent.
        if (this.loading && (!options || !options.parentResource)) throw new Error('Cannot add resources while the loader is running.');
        // check if resource already exists.
        if (this.resources[name]) throw new Error("Resource named \"" + name + "\" already exists.");
        // add base url if this isn't an absolute url
        url = this._prepareUrl(url);
        // create the store the resource
        this.resources[name] = new LoaderResource(name, url, options);
        if (typeof callback === 'function') this.resources[name].onAfterMiddleware.once(callback);
        // if actively loading, make sure to adjust progress chunks for that parent and its children
        if (this.loading) {
            var parent = options.parentResource;
            var incompleteChildren = [];
            for(var i = 0; i < parent.children.length; ++i)if (!parent.children[i].isComplete) incompleteChildren.push(parent.children[i]);
            var fullChunk = parent.progressChunk * (incompleteChildren.length + 1); // +1 for parent
            var eachChunk = fullChunk / (incompleteChildren.length + 2); // +2 for parent & new child
            parent.children.push(this.resources[name]);
            parent.progressChunk = eachChunk;
            for(var i = 0; i < incompleteChildren.length; ++i)incompleteChildren[i].progressChunk = eachChunk;
            this.resources[name].progressChunk = eachChunk;
        }
        // add the resource to the queue
        this._queue.push(this.resources[name]);
        return this;
    };
    /* eslint-enable require-jsdoc,valid-jsdoc */ /**
     * Sets up a middleware function that will run *before* the
     * resource is loaded.
     *
     * @param fn - The middleware function to register.
     * @return Returns itself.
     */ Loader1.prototype.pre = function(fn) {
        this._beforeMiddleware.push(fn);
        return this;
    };
    /**
     * Sets up a middleware function that will run *after* the
     * resource is loaded.
     *
     * @param fn - The middleware function to register.
     * @return Returns itself.
     */ Loader1.prototype.use = function(fn) {
        this._afterMiddleware.push(fn);
        return this;
    };
    /**
     * Resets the queue of the loader to prepare for a new load.
     *
     * @return Returns itself.
     */ Loader1.prototype.reset = function() {
        this.progress = 0;
        this.loading = false;
        this._queue.kill();
        this._queue.pause();
        // abort all resource loads
        for(var k in this.resources){
            var res = this.resources[k];
            if (res._onLoadBinding) res._onLoadBinding.detach();
            if (res.isLoading) res.abort('loader reset');
        }
        this.resources = {
        };
        return this;
    };
    /**
     * Starts loading the queued resources.
     * @param [cb] - Optional callback that will be bound to the `complete` event.
     * @return Returns itself.
     */ Loader1.prototype.load = function(cb) {
        // register complete callback if they pass one
        if (typeof cb === 'function') this.onComplete.once(cb);
        // if the queue has already started we are done here
        if (this.loading) return this;
        if (this._queue.idle()) {
            this._onStart();
            this._onComplete();
        } else {
            // distribute progress chunks
            var numTasks = this._queue._tasks.length;
            var chunk = MAX_PROGRESS / numTasks;
            for(var i = 0; i < this._queue._tasks.length; ++i)this._queue._tasks[i].data.progressChunk = chunk;
            // notify we are starting
            this._onStart();
            // start loading
            this._queue.resume();
        }
        return this;
    };
    Object.defineProperty(Loader1.prototype, "concurrency", {
        /**
         * The number of resources to load concurrently.
         *
         * @member {number}
         * @default 10
         */ get: function() {
            return this._queue.concurrency;
        },
        // eslint-disable-next-line require-jsdoc
        set: function(concurrency) {
            this._queue.concurrency = concurrency;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Prepares a url for usage based on the configuration of this object
     * @param url - The url to prepare.
     * @return The prepared url.
     */ Loader1.prototype._prepareUrl = function(url) {
        var parsedUrl = parseUri(url, {
            strictMode: true
        });
        var result;
        // absolute url, just use it as is.
        if (parsedUrl.protocol || !parsedUrl.path || url.indexOf('//') === 0) result = url;
        else if (this.baseUrl.length && this.baseUrl.lastIndexOf('/') !== this.baseUrl.length - 1 && url.charAt(0) !== '/') result = this.baseUrl + "/" + url;
        else result = this.baseUrl + url;
        // if we need to add a default querystring, there is a bit more work
        if (this.defaultQueryString) {
            var hash = rgxExtractUrlHash.exec(result)[0];
            result = result.substr(0, result.length - hash.length);
            if (result.indexOf('?') !== -1) result += "&" + this.defaultQueryString;
            else result += "?" + this.defaultQueryString;
            result += hash;
        }
        return result;
    };
    /**
     * Loads a single resource.
     *
     * @private
     * @param {PIXI.LoaderResource} resource - The resource to load.
     * @param {function} dequeue - The function to call when we need to dequeue this item.
     */ Loader1.prototype._loadResource = function(resource, dequeue) {
        var _this = this;
        resource._dequeue = dequeue;
        // run before middleware
        AsyncQueue.eachSeries(this._beforeMiddleware, function(fn, next) {
            fn.call(_this, resource, function() {
                // if the before middleware marks the resource as complete,
                // break and don't process any more before middleware
                next(resource.isComplete ? {
                } : null);
            });
        }, function() {
            if (resource.isComplete) _this._onLoad(resource);
            else {
                resource._onLoadBinding = resource.onComplete.once(_this._onLoad, _this);
                resource.load();
            }
        }, true);
    };
    /**
     * Called once loading has started.
     */ Loader1.prototype._onStart = function() {
        this.progress = 0;
        this.loading = true;
        this.onStart.dispatch(this);
    };
    /**
     * Called once each resource has loaded.
     */ Loader1.prototype._onComplete = function() {
        this.progress = MAX_PROGRESS;
        this.loading = false;
        this.onComplete.dispatch(this, this.resources);
    };
    /**
     * Called each time a resources is loaded.
     * @param resource - The resource that was loaded
     */ Loader1.prototype._onLoad = function(resource) {
        var _this = this;
        resource._onLoadBinding = null;
        // remove this resource from the async queue, and add it to our list of resources that are being parsed
        this._resourcesParsing.push(resource);
        resource._dequeue();
        // run all the after middleware for this resource
        AsyncQueue.eachSeries(this._afterMiddleware, function(fn, next) {
            fn.call(_this, resource, next);
        }, function() {
            resource.onAfterMiddleware.dispatch(resource);
            _this.progress = Math.min(MAX_PROGRESS, _this.progress + resource.progressChunk);
            _this.onProgress.dispatch(_this, resource);
            if (resource.error) _this.onError.dispatch(resource.error, _this, resource);
            else _this.onLoad.dispatch(_this, resource);
            _this._resourcesParsing.splice(_this._resourcesParsing.indexOf(resource), 1);
            // do completion check
            if (_this._queue.idle() && _this._resourcesParsing.length === 0) _this._onComplete();
        }, true);
    };
    /**
     * Destroy the loader, removes references.
     */ Loader1.prototype.destroy = function() {
        if (!this._protected) this.reset();
    };
    Object.defineProperty(Loader1, "shared", {
        /**
         * A premade instance of the loader that can be used to load resources.
         */ get: function() {
            var shared = Loader1._shared;
            if (!shared) {
                shared = new Loader1();
                shared._protected = true;
                Loader1._shared = shared;
            }
            return shared;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Adds a Loader plugin for the global shared loader and all
     * new Loader instances created.
     *
     * @param plugin - The plugin to add
     * @return Reference to PIXI.Loader for chaining
     */ Loader1.registerPlugin = function(plugin) {
        Loader1._plugins.push(plugin);
        if (plugin.add) plugin.add();
        return Loader1;
    };
    Loader1._plugins = [];
    return Loader1;
}();
Loader.prototype.add = function add(name, url, options, callback) {
    // special case of an array of objects or urls
    if (Array.isArray(name)) {
        for(var i = 0; i < name.length; ++i)this.add(name[i]);
        return this;
    }
    // if an object is passed instead of params
    if (typeof name === 'object') {
        options = name;
        callback = url || options.callback || options.onComplete;
        url = options.url;
        name = options.name || options.key || options.url;
    }
    // case where no name is passed shift all args over by one.
    if (typeof url !== 'string') {
        callback = options;
        options = url;
        url = name;
    }
    // now that we shifted make sure we have a proper url.
    if (typeof url !== 'string') throw new Error('No url passed to add resource to loader.');
    // options are optional so people might pass a function and no options
    if (typeof options === 'function') {
        callback = options;
        options = null;
    }
    return this._add(name, url, options, callback);
};
/**
 * Application plugin for supporting loader option. Installing the LoaderPlugin
 * is not necessary if using **pixi.js** or **pixi.js-legacy**.
 * @example
 * import {AppLoaderPlugin} from '@pixi/loaders';
 * import {Application} from '@pixi/app';
 * Application.registerPlugin(AppLoaderPlugin);
 * @class
 * @memberof PIXI
 */ var AppLoaderPlugin = function() {
    function AppLoaderPlugin1() {
    }
    /**
     * Called on application constructor
     * @param {object} options
     * @private
     */ AppLoaderPlugin1.init = function(options) {
        options = Object.assign({
            sharedLoader: false
        }, options);
        /**
         * Loader instance to help with asset loading.
         * @memberof PIXI.Application#
         * @type {PIXI.Loader}
         * @readonly
         */ this.loader = options.sharedLoader ? Loader.shared : new Loader();
    };
    /**
     * Called when application destroyed
     *
     * @private
     */ AppLoaderPlugin1.destroy = function() {
        if (this.loader) {
            this.loader.destroy();
            this.loader = null;
        }
    };
    return AppLoaderPlugin1;
}();
/**
 * Loader plugin for handling Texture resources.
 *
 * @memberof PIXI
 */ var TextureLoader = function() {
    function TextureLoader1() {
    }
    /**
     * Handle SVG elements a text, render with SVGResource.
     */ TextureLoader1.add = function() {
        LoaderResource.setExtensionLoadType('svg', LoaderResource.LOAD_TYPE.XHR);
        LoaderResource.setExtensionXhrType('svg', LoaderResource.XHR_RESPONSE_TYPE.TEXT);
    };
    /**
     * Called after a resource is loaded.
     * @see PIXI.Loader.loaderMiddleware
     * @param resource
     * @param {function} next
     */ TextureLoader1.use = function(resource, next) {
        // create a new texture if the data is an Image object
        if (resource.data && (resource.type === LoaderResource.TYPE.IMAGE || resource.extension === 'svg')) {
            var data = resource.data, url = resource.url, name = resource.name, metadata = resource.metadata;
            _core.Texture.fromLoader(data, url, name, metadata).then(function(texture) {
                resource.texture = texture;
                next();
            })// TODO: handle errors in Texture.fromLoader
            // so we can pass them to the Loader
            .catch(next);
        } else next();
    };
    return TextureLoader1;
}();
var _keyStr = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=';
/**
 * Encodes binary into base64.
 *
 * @function encodeBinary
 * @param {string} input - The input data to encode.
 * @returns {string} The encoded base64 string
 */ function encodeBinary(input) {
    var output = '';
    var inx = 0;
    while(inx < input.length){
        // Fill byte buffer array
        var bytebuffer = [
            0,
            0,
            0
        ];
        var encodedCharIndexes = [
            0,
            0,
            0,
            0
        ];
        for(var jnx = 0; jnx < bytebuffer.length; ++jnx)if (inx < input.length) // throw away high-order byte, as documented at:
        // https://developer.mozilla.org/En/Using_XMLHttpRequest#Handling_binary_data
        bytebuffer[jnx] = input.charCodeAt(inx++) & 255;
        else bytebuffer[jnx] = 0;
        // Get each encoded character, 6 bits at a time
        // index 1: first 6 bits
        encodedCharIndexes[0] = bytebuffer[0] >> 2;
        // index 2: second 6 bits (2 least significant bits from input byte 1 + 4 most significant bits from byte 2)
        encodedCharIndexes[1] = (bytebuffer[0] & 3) << 4 | bytebuffer[1] >> 4;
        // index 3: third 6 bits (4 least significant bits from input byte 2 + 2 most significant bits from byte 3)
        encodedCharIndexes[2] = (bytebuffer[1] & 15) << 2 | bytebuffer[2] >> 6;
        // index 3: forth 6 bits (6 least significant bits from input byte 3)
        encodedCharIndexes[3] = bytebuffer[2] & 63;
        // Determine whether padding happened, and adjust accordingly
        var paddingBytes = inx - (input.length - 1);
        switch(paddingBytes){
            case 2:
                // Set last 2 characters to padding char
                encodedCharIndexes[3] = 64;
                encodedCharIndexes[2] = 64;
                break;
            case 1:
                // Set last character to padding char
                encodedCharIndexes[3] = 64;
                break;
        }
        // Now we will grab each appropriate character out of our keystring
        // based on our index array and append it to the output string
        for(var jnx = 0; jnx < encodedCharIndexes.length; ++jnx)output += _keyStr.charAt(encodedCharIndexes[jnx]);
    }
    return output;
}
var Url = self.URL || self.webkitURL;
/**
 * A middleware for transforming XHR loaded Blobs into more useful objects
 *
 * @ignore
 * @function parsing
 * @example
 * import { Loader, middleware } from 'resource-loader';
 * const loader = new Loader();
 * loader.use(middleware.parsing);
 * @param resource - Current Resource
 * @param next - Callback when complete
 */ function parsing(resource, next) {
    if (!resource.data) {
        next();
        return;
    }
    // if this was an XHR load of a blob
    if (resource.xhr && resource.xhrType === LoaderResource.XHR_RESPONSE_TYPE.BLOB) {
        // if there is no blob support we probably got a binary string back
        if (!self.Blob || typeof resource.data === 'string') {
            var type = resource.xhr.getResponseHeader('content-type');
            // this is an image, convert the binary string into a data url
            if (type && type.indexOf('image') === 0) {
                resource.data = new Image();
                resource.data.src = "data:" + type + ";base64," + encodeBinary(resource.xhr.responseText);
                resource.type = LoaderResource.TYPE.IMAGE;
                // wait until the image loads and then callback
                resource.data.onload = function() {
                    resource.data.onload = null;
                    next();
                };
                // next will be called on load
                return;
            }
        } else if (resource.data.type.indexOf('image') === 0) {
            var src_1 = Url.createObjectURL(resource.data);
            resource.blob = resource.data;
            resource.data = new Image();
            resource.data.src = src_1;
            resource.type = LoaderResource.TYPE.IMAGE;
            // cleanup the no longer used blob after the image loads
            // TODO: Is this correct? Will the image be invalid after revoking?
            resource.data.onload = function() {
                Url.revokeObjectURL(src_1);
                resource.data.onload = null;
                next();
            };
            // next will be called on load.
            return;
        }
    }
    next();
}
// parse any blob into more usable objects (e.g. Image)
Loader.registerPlugin({
    use: parsing
});
// parse any Image objects into textures
Loader.registerPlugin(TextureLoader);

},{"@pixi/core":"d0INm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9HMtg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BlobResource", ()=>BlobResource1
);
parcelHelpers.export(exports, "CompressedTextureLoader", ()=>CompressedTextureLoader
);
parcelHelpers.export(exports, "CompressedTextureResource", ()=>CompressedTextureResource1
);
parcelHelpers.export(exports, "DDSLoader", ()=>DDSLoader
);
parcelHelpers.export(exports, "FORMATS_TO_COMPONENTS", ()=>FORMATS_TO_COMPONENTS
);
parcelHelpers.export(exports, "INTERNAL_FORMATS", ()=>INTERNAL_FORMATS
);
parcelHelpers.export(exports, "INTERNAL_FORMAT_TO_BYTES_PER_PIXEL", ()=>INTERNAL_FORMAT_TO_BYTES_PER_PIXEL
);
parcelHelpers.export(exports, "KTXLoader", ()=>KTXLoader
);
parcelHelpers.export(exports, "TYPES_TO_BYTES_PER_COMPONENT", ()=>TYPES_TO_BYTES_PER_COMPONENT
);
parcelHelpers.export(exports, "TYPES_TO_BYTES_PER_PIXEL", ()=>TYPES_TO_BYTES_PER_PIXEL
);
/*!
 * @pixi/compressed-textures - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/compressed-textures is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
var _loaders = require("@pixi/loaders");
var _utils = require("@pixi/utils");
var _constants = require("@pixi/constants");
var _a;
/**
 * WebGL internal formats, including compressed texture formats provided by extensions
 *
 * @memberof PIXI
 * @static
 * @name INTERNAL_FORMATS
 * @enum {number}
 * @property {number} COMPRESSED_RGB_S3TC_DXT1_EXT=0x83F0
 * @property {number} COMPRESSED_RGBA_S3TC_DXT1_EXT=0x83F1
 * @property {number} COMPRESSED_RGBA_S3TC_DXT3_EXT=0x83F2
 * @property {number} COMPRESSED_RGBA_S3TC_DXT5_EXT=0x83F3
 * @property {number} COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT=35917
 * @property {number} COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT=35918
 * @property {number} COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT=35919
 * @property {number} COMPRESSED_SRGB_S3TC_DXT1_EXT=35916
 * @property {number} COMPRESSED_R11_EAC=0x9270
 * @property {number} COMPRESSED_SIGNED_R11_EAC=0x9271
 * @property {number} COMPRESSED_RG11_EAC=0x9272
 * @property {number} COMPRESSED_SIGNED_RG11_EAC=0x9273
 * @property {number} COMPRESSED_RGB8_ETC2=0x9274
 * @property {number} COMPRESSED_RGBA8_ETC2_EAC=0x9278
 * @property {number} COMPRESSED_SRGB8_ETC2=0x9275
 * @property {number} COMPRESSED_SRGB8_ALPHA8_ETC2_EAC=0x9279
 * @property {number} COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2=0x9276
 * @property {number} COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2=0x9277
 * @property {number} COMPRESSED_RGB_PVRTC_4BPPV1_IMG=0x8C00
 * @property {number} COMPRESSED_RGBA_PVRTC_4BPPV1_IMG=0x8C02
 * @property {number} COMPRESSED_RGB_PVRTC_2BPPV1_IMG=0x8C01
 * @property {number} COMPRESSED_RGBA_PVRTC_2BPPV1_IMG=0x8C03
 * @property {number} COMPRESSED_RGB_ETC1_WEBGL=0x8D64
 * @property {number} COMPRESSED_RGB_ATC_WEBGL=0x8C92
 * @property {number} COMPRESSED_RGBA_ATC_EXPLICIT_ALPHA_WEBGL=0x8C92
 * @property {number} COMPRESSED_RGBA_ATC_INTERPOLATED_ALPHA_WEBGL=0x87EE
 */ var INTERNAL_FORMATS;
(function(INTERNAL_FORMATS1) {
    // WEBGL_compressed_texture_s3tc
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGB_S3TC_DXT1_EXT"] = 33776] = "COMPRESSED_RGB_S3TC_DXT1_EXT";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGBA_S3TC_DXT1_EXT"] = 33777] = "COMPRESSED_RGBA_S3TC_DXT1_EXT";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGBA_S3TC_DXT3_EXT"] = 33778] = "COMPRESSED_RGBA_S3TC_DXT3_EXT";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGBA_S3TC_DXT5_EXT"] = 33779] = "COMPRESSED_RGBA_S3TC_DXT5_EXT";
    // WEBGL_compressed_texture_s3tc_srgb
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT"] = 35917] = "COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT"] = 35918] = "COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT"] = 35919] = "COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SRGB_S3TC_DXT1_EXT"] = 35916] = "COMPRESSED_SRGB_S3TC_DXT1_EXT";
    // WEBGL_compressed_texture_etc
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_R11_EAC"] = 37488] = "COMPRESSED_R11_EAC";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SIGNED_R11_EAC"] = 37489] = "COMPRESSED_SIGNED_R11_EAC";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RG11_EAC"] = 37490] = "COMPRESSED_RG11_EAC";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SIGNED_RG11_EAC"] = 37491] = "COMPRESSED_SIGNED_RG11_EAC";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGB8_ETC2"] = 37492] = "COMPRESSED_RGB8_ETC2";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGBA8_ETC2_EAC"] = 37496] = "COMPRESSED_RGBA8_ETC2_EAC";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SRGB8_ETC2"] = 37493] = "COMPRESSED_SRGB8_ETC2";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SRGB8_ALPHA8_ETC2_EAC"] = 37497] = "COMPRESSED_SRGB8_ALPHA8_ETC2_EAC";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2"] = 37494] = "COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2"] = 37495] = "COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2";
    // WEBGL_compressed_texture_pvrtc
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGB_PVRTC_4BPPV1_IMG"] = 35840] = "COMPRESSED_RGB_PVRTC_4BPPV1_IMG";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGBA_PVRTC_4BPPV1_IMG"] = 35842] = "COMPRESSED_RGBA_PVRTC_4BPPV1_IMG";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGB_PVRTC_2BPPV1_IMG"] = 35841] = "COMPRESSED_RGB_PVRTC_2BPPV1_IMG";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGBA_PVRTC_2BPPV1_IMG"] = 35843] = "COMPRESSED_RGBA_PVRTC_2BPPV1_IMG";
    // WEBGL_compressed_texture_etc1
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGB_ETC1_WEBGL"] = 36196] = "COMPRESSED_RGB_ETC1_WEBGL";
    // WEBGL_compressed_texture_atc
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGB_ATC_WEBGL"] = 35986] = "COMPRESSED_RGB_ATC_WEBGL";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGBA_ATC_EXPLICIT_ALPHA_WEBGL"] = 35986] = "COMPRESSED_RGBA_ATC_EXPLICIT_ALPHA_WEBGL";
    INTERNAL_FORMATS1[INTERNAL_FORMATS1["COMPRESSED_RGBA_ATC_INTERPOLATED_ALPHA_WEBGL"] = 34798] = "COMPRESSED_RGBA_ATC_INTERPOLATED_ALPHA_WEBGL";
})(INTERNAL_FORMATS || (INTERNAL_FORMATS = {
}));
/**
 * Maps the compressed texture formats in {@link PIXI.INTERNAL_FORMATS} to the number of bytes taken by
 * each texel.
 *
 * @memberof PIXI
 * @static
 * @ignore
 */ var INTERNAL_FORMAT_TO_BYTES_PER_PIXEL = (_a = {
}, // WEBGL_compressed_texture_s3tc
_a[INTERNAL_FORMATS.COMPRESSED_RGB_S3TC_DXT1_EXT] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT1_EXT] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT3_EXT] = 1, _a[INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT5_EXT] = 1, // WEBGL_compressed_texture_s3tc
_a[INTERNAL_FORMATS.COMPRESSED_SRGB_S3TC_DXT1_EXT] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT] = 1, _a[INTERNAL_FORMATS.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT] = 1, // WEBGL_compressed_texture_etc
_a[INTERNAL_FORMATS.COMPRESSED_R11_EAC] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_SIGNED_R11_EAC] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_RG11_EAC] = 1, _a[INTERNAL_FORMATS.COMPRESSED_SIGNED_RG11_EAC] = 1, _a[INTERNAL_FORMATS.COMPRESSED_RGB8_ETC2] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_RGBA8_ETC2_EAC] = 1, _a[INTERNAL_FORMATS.COMPRESSED_SRGB8_ETC2] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_SRGB8_ALPHA8_ETC2_EAC] = 1, _a[INTERNAL_FORMATS.COMPRESSED_RGB8_PUNCHTHROUGH_ALPHA1_ETC2] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_SRGB8_PUNCHTHROUGH_ALPHA1_ETC2] = 0.5, // WEBGL_compressed_texture_pvrtc
_a[INTERNAL_FORMATS.COMPRESSED_RGB_PVRTC_4BPPV1_IMG] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_RGB_PVRTC_2BPPV1_IMG] = 0.25, _a[INTERNAL_FORMATS.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG] = 0.25, // WEBGL_compressed_texture_etc1
_a[INTERNAL_FORMATS.COMPRESSED_RGB_ETC1_WEBGL] = 0.5, // @see https://www.khronos.org/registry/OpenGL/extensions/AMD/AMD_compressed_ATC_texture.txt
// WEBGL_compressed_texture_atc
_a[INTERNAL_FORMATS.COMPRESSED_RGB_ATC_WEBGL] = 0.5, _a[INTERNAL_FORMATS.COMPRESSED_RGBA_ATC_EXPLICIT_ALPHA_WEBGL] = 1, _a[INTERNAL_FORMATS.COMPRESSED_RGBA_ATC_INTERPOLATED_ALPHA_WEBGL] = 1, _a);
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
function __awaiter(thisArg, _arguments, P, generator) {
    return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        }
        function rejected(value) {
            try {
                step(generator["throw"](value));
            } catch (e) {
                reject(e);
            }
        }
        function step(result) {
            result.done ? resolve(result.value) : new P(function(resolve1) {
                resolve1(result.value);
            }).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}
function __generator(thisArg, body) {
    var _ = {
        label: 0,
        sent: function() {
            if (t[0] & 1) throw t[1];
            return t[1];
        },
        trys: [],
        ops: []
    }, f, y, t, g;
    function verb(n) {
        return function(v) {
            return step([
                n,
                v
            ]);
        };
    }
    function step(op) {
        if (f) {
            throw new TypeError("Generator is already executing.");
        }
        while(_){
            try {
                if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) {
                    return t;
                }
                if (y = 0, t) {
                    op = [
                        op[0] & 2,
                        t.value
                    ];
                }
                switch(op[0]){
                    case 0:
                    case 1:
                        t = op;
                        break;
                    case 4:
                        _.label++;
                        return {
                            value: op[1],
                            done: false
                        };
                    case 5:
                        _.label++;
                        y = op[1];
                        op = [
                            0
                        ];
                        continue;
                    case 7:
                        op = _.ops.pop();
                        _.trys.pop();
                        continue;
                    default:
                        if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                            _ = 0;
                            continue;
                        }
                        if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                            _.label = op[1];
                            break;
                        }
                        if (op[0] === 6 && _.label < t[1]) {
                            _.label = t[1];
                            t = op;
                            break;
                        }
                        if (t && _.label < t[2]) {
                            _.label = t[2];
                            _.ops.push(op);
                            break;
                        }
                        if (t[2]) {
                            _.ops.pop();
                        }
                        _.trys.pop();
                        continue;
                }
                op = body.call(thisArg, _);
            } catch (e) {
                op = [
                    6,
                    e
                ];
                y = 0;
            } finally{
                f = t = 0;
            }
        }
        if (op[0] & 5) {
            throw op[1];
        }
        return {
            value: op[0] ? op[1] : void 0,
            done: true
        };
    }
    return g = {
        next: verb(0),
        "throw": verb(1),
        "return": verb(2)
    }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
    }), g;
}
/**
 * Resource that fetches texture data over the network and stores it in a buffer.
 *
 * @class
 * @extends PIXI.Resource
 * @memberof PIXI
 */ var BlobResource1 = function(_super) {
    __extends(BlobResource2, _super);
    /**
     * @param {string} url - the URL of the texture file
     * @param {boolean}[autoLoad] - whether to fetch the data immediately;
     *  you can fetch it later via {@link BlobResource#load}
     */ function BlobResource2(source, options) {
        if (options === void 0) options = {
            width: 1,
            height: 1,
            autoLoad: true
        };
        var _this = this;
        var origin;
        var data;
        if (typeof source === 'string') {
            origin = source;
            data = new Uint8Array();
        } else {
            origin = null;
            data = source;
        }
        _this = _super.call(this, data, options) || this;
        /**
         * The URL of the texture file
         * @member {string}
         */ _this.origin = origin;
        /**
         * The viewable buffer on the data
         * @member {ViewableBuffer}
         */ // HINT: BlobResource allows "null" sources, assuming the child class provides an alternative
        _this.buffer = data ? new _core.ViewableBuffer(data) : null;
        // Allow autoLoad = "undefined" still load the resource by default
        if (_this.origin && options.autoLoad !== false) _this.load();
        if (data && data.length) {
            _this.loaded = true;
            _this.onBlobLoaded(_this.buffer.rawBinaryData);
        }
        return _this;
    }
    BlobResource2.prototype.onBlobLoaded = function(_data) {
    // TODO: Override this method
    };
    /**
     * Loads the blob
     */ BlobResource2.prototype.load = function() {
        return __awaiter(this, void 0, Promise, function() {
            var response, blob, arrayBuffer;
            return __generator(this, function(_a1) {
                switch(_a1.label){
                    case 0:
                        return [
                            4 /*yield*/ ,
                            fetch(this.origin)
                        ];
                    case 1:
                        response = _a1.sent();
                        return [
                            4 /*yield*/ ,
                            response.blob()
                        ];
                    case 2:
                        blob = _a1.sent();
                        return [
                            4 /*yield*/ ,
                            blob.arrayBuffer()
                        ];
                    case 3:
                        arrayBuffer = _a1.sent();
                        this.data = new Uint32Array(arrayBuffer);
                        this.buffer = new _core.ViewableBuffer(arrayBuffer);
                        this.loaded = true;
                        this.onBlobLoaded(arrayBuffer);
                        this.update();
                        return [
                            2 /*return*/ ,
                            this
                        ];
                }
            });
        });
    };
    return BlobResource2;
}(_core.BufferResource);
/**
 * Resource for compressed texture formats, as follows: S3TC/DXTn (& their sRGB formats), ATC, ASTC, ETC 1/2, PVRTC.
 *
 * Compressed textures improve performance when rendering is texture-bound. The texture data stays compressed in
 * graphics memory, increasing memory locality and speeding up texture fetches. These formats can also be used to store
 * more detail in the same amount of memory.
 *
 * For most developers, container file formats are a better abstraction instead of directly handling raw texture
 * data. PixiJS provides native support for the following texture file formats (via {@link PIXI.Loader}):
 *
 * * **.dds** - the DirectDraw Surface file format stores DXTn (DXT-1,3,5) data. See {@link PIXI.DDSLoader}
 * * **.ktx** - the Khronos Texture Container file format supports storing all the supported WebGL compression formats.
 *  See {@link PIXI.KTXLoader}.
 * * **.basis** - the BASIS supercompressed file format stores texture data in an internal format that is transcoded
 *  to the compression format supported on the device at _runtime_. It also supports transcoding into a uncompressed
 *  format as a fallback; you must install the `@pixi/basis-loader`, `@pixi/basis-transcoder` packages separately to
 *  use these files. See {@link PIXI.BasisLoader}.
 *
 * The loaders for the aforementioned formats use `CompressedTextureResource` internally. It is strongly suggested that
 * they be used instead.
 *
 * ## Working directly with CompressedTextureResource
 *
 * Since `CompressedTextureResource` inherits `BlobResource`, you can provide it a URL pointing to a file containing
 * the raw texture data (with no file headers!):
 *
 * ```js
 * // The resource backing the texture data for your textures.
 * // NOTE: You can also provide a ArrayBufferView instead of a URL. This is used when loading data from a container file
 * //   format such as KTX, DDS, or BASIS.
 * const compressedResource = new PIXI.CompressedTextureResource("bunny.dxt5", {
 *   format: PIXI.INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT5_EXT,
 *   width: 256,
 *   height: 256
 * });
 *
 * // You can create a base-texture to the cache, so that future `Texture`s can be created using the `Texture.from` API.
 * const baseTexture = new PIXI.BaseTexture(compressedResource, { pmaMode: PIXI.ALPHA_MODES.NPM });
 *
 * // Create a Texture to add to the TextureCache
 * const texture = new PIXI.Texture(baseTexture);
 *
 * // Add baseTexture & texture to the global texture cache
 * PIXI.BaseTexture.addToCache(baseTexture, "bunny.dxt5");
 * PIXI.Texture.addToCache(texture, "bunny.dxt5");
 * ```
 *
 * @memberof PIXI
 */ var CompressedTextureResource1 = function(_super) {
    __extends(CompressedTextureResource2, _super);
    /**
     * @param source - the buffer/URL holding the compressed texture data
     * @param options
     * @param {PIXI.INTERNAL_FORMATS} options.format - the compression format
     * @param {number} options.width - the image width in pixels.
     * @param {number} options.height - the image height in pixels.
     * @param {number} [options.level=1] - the mipmap levels stored in the compressed texture, including level 0.
     * @param {number} [options.levelBuffers] - the buffers for each mipmap level. `CompressedTextureResource` can allows you
     *      to pass `null` for `source`, for cases where each level is stored in non-contiguous memory.
     */ function CompressedTextureResource2(source, options) {
        var _this = _super.call(this, source, options) || this;
        _this.format = options.format;
        _this.levels = options.levels || 1;
        _this._width = options.width;
        _this._height = options.height;
        _this._extension = CompressedTextureResource2._formatToExtension(_this.format);
        if (options.levelBuffers || _this.buffer) // ViewableBuffer doesn't support byteOffset :-( so allow source to be Uint8Array
        _this._levelBuffers = options.levelBuffers || CompressedTextureResource2._createLevelBuffers(source instanceof Uint8Array ? source : _this.buffer.uint8View, _this.format, _this.levels, 4, 4, _this.width, _this.height);
        return _this;
    }
    /**
     * @override
     * @param renderer - A reference to the current renderer
     * @param _texture - the texture
     * @param _glTexture - texture instance for this webgl context
     */ CompressedTextureResource2.prototype.upload = function(renderer, _texture, _glTexture) {
        var gl = renderer.gl;
        var extension = renderer.context.extensions[this._extension];
        if (!extension) throw new Error(this._extension + " textures are not supported on the current machine");
        if (!this._levelBuffers) // Do not try to upload data before BlobResource loads, unless the levelBuffers were provided directly!
        return false;
        for(var i = 0, j = this.levels; i < j; i++){
            var _a1 = this._levelBuffers[i], levelID = _a1.levelID, levelWidth = _a1.levelWidth, levelHeight = _a1.levelHeight, levelBuffer = _a1.levelBuffer;
            gl.compressedTexImage2D(gl.TEXTURE_2D, levelID, this.format, levelWidth, levelHeight, 0, levelBuffer);
        }
        return true;
    };
    /** @protected */ CompressedTextureResource2.prototype.onBlobLoaded = function() {
        this._levelBuffers = CompressedTextureResource2._createLevelBuffers(this.buffer.uint8View, this.format, this.levels, 4, 4, this.width, this.height);
    };
    /**
     * Returns the key (to ContextSystem#extensions) for the WebGL extension supporting the compression format
     *
     * @private
     * @param format - the compression format to get the extension for.
     */ CompressedTextureResource2._formatToExtension = function(format) {
        if (format >= 33776 && format <= 33779) return 's3tc';
        else if (format >= 37488 && format <= 37497) return 'etc';
        else if (format >= 35840 && format <= 35843) return 'pvrtc';
        else if (format >= 36196) return 'etc1';
        else if (format >= 35986 && format <= 34798) return 'atc';
        throw new Error('Invalid (compressed) texture format given!');
    };
    /**
     * Pre-creates buffer views for each mipmap level
     *
     * @private
     * @param buffer -
     * @param format - compression formats
     * @param levels - mipmap levels
     * @param blockWidth -
     * @param blockHeight -
     * @param imageWidth - width of the image in pixels
     * @param imageHeight - height of the image in pixels
     */ CompressedTextureResource2._createLevelBuffers = function(buffer, format, levels, blockWidth, blockHeight, imageWidth, imageHeight) {
        // The byte-size of the first level buffer
        var buffers = new Array(levels);
        var offset = buffer.byteOffset;
        var levelWidth = imageWidth;
        var levelHeight = imageHeight;
        var alignedLevelWidth = levelWidth + blockWidth - 1 & ~(blockWidth - 1);
        var alignedLevelHeight = levelHeight + blockHeight - 1 & ~(blockHeight - 1);
        var levelSize = alignedLevelWidth * alignedLevelHeight * INTERNAL_FORMAT_TO_BYTES_PER_PIXEL[format];
        for(var i = 0; i < levels; i++){
            buffers[i] = {
                levelID: i,
                levelWidth: levels > 1 ? levelWidth : alignedLevelWidth,
                levelHeight: levels > 1 ? levelHeight : alignedLevelHeight,
                levelBuffer: new Uint8Array(buffer.buffer, offset, levelSize)
            };
            offset += levelSize;
            // Calculate levelBuffer dimensions for next iteration
            levelWidth = levelWidth >> 1 || 1;
            levelHeight = levelHeight >> 1 || 1;
            alignedLevelWidth = levelWidth + blockWidth - 1 & ~(blockWidth - 1);
            alignedLevelHeight = levelHeight + blockHeight - 1 & ~(blockHeight - 1);
            levelSize = alignedLevelWidth * alignedLevelHeight * INTERNAL_FORMAT_TO_BYTES_PER_PIXEL[format];
        }
        return buffers;
    };
    return CompressedTextureResource2;
}(BlobResource1);
/* eslint-enable camelcase */ /**
 * Loader plugin for handling compressed textures for all platforms.
 *
 * @class
 * @memberof PIXI
 * @implements PIXI.ILoaderPlugin
 */ var CompressedTextureLoader = function() {
    function CompressedTextureLoader1() {
    }
    /**
     * Called after a compressed-textures manifest is loaded.
     *
     * This will then load the correct compression format for the device. Your manifest should adhere
     * to the following schema:
     *
     * ```js
     * import { INTERNAL_FORMATS } from '@pixi/constants';
     *
     * type CompressedTextureManifest = {
     *  textures: Array<{ src: string, format?: keyof INTERNAL_FORMATS}>,
     *  cacheID: string;
     * };
     * ```
     *
     * This is an example of a .json manifest file
     *
     * ```json
     * {
     *   "cacheID":"asset",
     *   "textures":[
     *     { "src":"asset.fallback.png" },
     *     { "format":"COMPRESSED_RGBA_S3TC_DXT5_EXT", "src":"asset.s3tc.ktx" },
     *     { "format":"COMPRESSED_RGBA8_ETC2_EAC", "src":"asset.etc.ktx" },
     *     { "format":"RGBA_PVRTC_4BPPV1_IMG", "src":"asset.pvrtc.ktx" }
     *   ]
     * }
     * ```
     */ CompressedTextureLoader1.use = function(resource, next) {
        var data = resource.data;
        var loader = this;
        if (resource.type === _loaders.LoaderResource.TYPE.JSON && data && data.cacheID && data.textures) {
            var textures = data.textures;
            var textureURL = void 0;
            var fallbackURL = void 0;
            // Search for an extension that holds one the formats
            for(var i = 0, j = textures.length; i < j; i++){
                var texture = textures[i];
                var url_1 = texture.src;
                var format = texture.format;
                if (!format) fallbackURL = url_1;
                if (CompressedTextureLoader1.textureFormats[format]) {
                    textureURL = url_1;
                    break;
                }
            }
            textureURL = textureURL || fallbackURL;
            // Make sure we have a URL
            if (!textureURL) {
                next(new Error("Cannot load compressed-textures in " + resource.url + ", make sure you provide a fallback"));
                return;
            }
            if (textureURL === resource.url) {
                // Prevent infinite loops
                next(new Error('URL of compressed texture cannot be the same as the manifest\'s URL'));
                return;
            }
            var loadOptions = {
                crossOrigin: resource.crossOrigin,
                metadata: resource.metadata.imageMetadata,
                parentResource: resource
            };
            var resourcePath = _utils.url.resolve(resource.url.replace(loader.baseUrl, ''), textureURL);
            var resourceName = data.cacheID;
            // The appropriate loader should register the texture
            loader.add(resourceName, resourcePath, loadOptions, function(res) {
                if (res.error) {
                    next(res.error);
                    return;
                }
                var _a2 = res.texture, texture = _a2 === void 0 ? null : _a2, _b = res.textures, textures1 = _b === void 0 ? {
                } : _b;
                // Make sure texture/textures is assigned to parent resource
                Object.assign(resource, {
                    texture: texture,
                    textures: textures1
                });
                // Pass along any error
                next();
            });
        } else next();
    };
    /**
     * Detects the available compressed texture extensions on the device.
     * @ignore
     */ CompressedTextureLoader1.add = function() {
        // Auto-detect WebGL compressed-texture extensions
        var canvas = document.createElement('canvas');
        var gl = canvas.getContext('webgl');
        if (!gl) {
            console.warn('WebGL not available for compressed textures. Silently failing.');
            return;
        }
        var extensions = {
            s3tc: gl.getExtension('WEBGL_compressed_texture_s3tc'),
            s3tc_sRGB: gl.getExtension('WEBGL_compressed_texture_s3tc_srgb'),
            etc: gl.getExtension('WEBGL_compressed_texture_etc'),
            etc1: gl.getExtension('WEBGL_compressed_texture_etc1'),
            pvrtc: gl.getExtension('WEBGL_compressed_texture_pvrtc') || gl.getExtension('WEBKIT_WEBGL_compressed_texture_pvrtc'),
            atc: gl.getExtension('WEBGL_compressed_texture_atc'),
            astc: gl.getExtension('WEBGL_compressed_texture_astc')
        };
        CompressedTextureLoader1.textureExtensions = extensions;
        CompressedTextureLoader1.textureFormats = {
        };
        // Assign all available compressed-texture formats
        for(var extensionName in extensions){
            var extension = extensions[extensionName];
            if (!extension) continue;
            Object.assign(CompressedTextureLoader1.textureFormats, Object.getPrototypeOf(extension));
        }
    };
    return CompressedTextureLoader1;
}();
/**
 * Creates base-textures and textures for each compressed-texture resource and adds them into the global
 * texture cache. The first texture has two IDs - `${url}`, `${url}-1`; while the rest have an ID of the
 * form `${url}-i`.
 *
 * @param url - the original address of the resources
 * @param resources - the resources backing texture data
 * @ignore
 */ function registerCompressedTextures(url, resources, metadata) {
    var result = {
        textures: {
        },
        texture: null
    };
    if (!resources) return result;
    var textures = resources.map(function(resource) {
        return new _core.Texture(new _core.BaseTexture(resource, Object.assign({
            mipmap: _constants.MIPMAP_MODES.OFF,
            alphaMode: _constants.ALPHA_MODES.NO_PREMULTIPLIED_ALPHA
        }, metadata)));
    });
    textures.forEach(function(texture, i) {
        var baseTexture = texture.baseTexture;
        var cacheID = url + "-" + (i + 1);
        _core.BaseTexture.addToCache(baseTexture, cacheID);
        _core.Texture.addToCache(texture, cacheID);
        if (i === 0) {
            _core.BaseTexture.addToCache(baseTexture, url);
            _core.Texture.addToCache(texture, url);
            result.texture = texture;
        }
        result.textures[cacheID] = texture;
    });
    return result;
}
var _a$1, _b;
// Set DDS files to be loaded as an ArrayBuffer
_loaders.LoaderResource.setExtensionXhrType('dds', _loaders.LoaderResource.XHR_RESPONSE_TYPE.BUFFER);
var DDS_MAGIC_SIZE = 4;
var DDS_HEADER_SIZE = 124;
var DDS_HEADER_PF_SIZE = 32;
var DDS_HEADER_DX10_SIZE = 20;
// DDS file format magic word
var DDS_MAGIC = 542327876;
/**
 * DWORD offsets of the DDS file header fields (relative to file start).
 *
 * @ignore
 */ var DDS_FIELDS = {
    SIZE: 1,
    FLAGS: 2,
    HEIGHT: 3,
    WIDTH: 4,
    MIPMAP_COUNT: 7,
    PIXEL_FORMAT: 19
};
/**
 * DWORD offsets of the DDS PIXEL_FORMAT fields.
 *
 * @ignore
 */ var DDS_PF_FIELDS = {
    SIZE: 0,
    FLAGS: 1,
    FOURCC: 2,
    RGB_BITCOUNT: 3,
    R_BIT_MASK: 4,
    G_BIT_MASK: 5,
    B_BIT_MASK: 6,
    A_BIT_MASK: 7
};
/**
 * DWORD offsets of the DDS_HEADER_DX10 fields.
 *
 * @ignore
 */ var DDS_DX10_FIELDS = {
    DXGI_FORMAT: 0,
    RESOURCE_DIMENSION: 1,
    MISC_FLAG: 2,
    ARRAY_SIZE: 3,
    MISC_FLAGS2: 4
};
/**
 * @see https://docs.microsoft.com/en-us/windows/win32/api/dxgiformat/ne-dxgiformat-dxgi_format
 * @ignore
 */ // This is way over-blown for us! Lend us a hand, and remove the ones that aren't used (but set the remaining
// ones to their correct value)
var DXGI_FORMAT;
(function(DXGI_FORMAT1) {
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_UNKNOWN"] = 0] = "DXGI_FORMAT_UNKNOWN";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32B32A32_TYPELESS"] = 1] = "DXGI_FORMAT_R32G32B32A32_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32B32A32_FLOAT"] = 2] = "DXGI_FORMAT_R32G32B32A32_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32B32A32_UINT"] = 3] = "DXGI_FORMAT_R32G32B32A32_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32B32A32_SINT"] = 4] = "DXGI_FORMAT_R32G32B32A32_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32B32_TYPELESS"] = 5] = "DXGI_FORMAT_R32G32B32_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32B32_FLOAT"] = 6] = "DXGI_FORMAT_R32G32B32_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32B32_UINT"] = 7] = "DXGI_FORMAT_R32G32B32_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32B32_SINT"] = 8] = "DXGI_FORMAT_R32G32B32_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16B16A16_TYPELESS"] = 9] = "DXGI_FORMAT_R16G16B16A16_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16B16A16_FLOAT"] = 10] = "DXGI_FORMAT_R16G16B16A16_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16B16A16_UNORM"] = 11] = "DXGI_FORMAT_R16G16B16A16_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16B16A16_UINT"] = 12] = "DXGI_FORMAT_R16G16B16A16_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16B16A16_SNORM"] = 13] = "DXGI_FORMAT_R16G16B16A16_SNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16B16A16_SINT"] = 14] = "DXGI_FORMAT_R16G16B16A16_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32_TYPELESS"] = 15] = "DXGI_FORMAT_R32G32_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32_FLOAT"] = 16] = "DXGI_FORMAT_R32G32_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32_UINT"] = 17] = "DXGI_FORMAT_R32G32_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G32_SINT"] = 18] = "DXGI_FORMAT_R32G32_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32G8X24_TYPELESS"] = 19] = "DXGI_FORMAT_R32G8X24_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_D32_FLOAT_S8X24_UINT"] = 20] = "DXGI_FORMAT_D32_FLOAT_S8X24_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32_FLOAT_X8X24_TYPELESS"] = 21] = "DXGI_FORMAT_R32_FLOAT_X8X24_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_X32_TYPELESS_G8X24_UINT"] = 22] = "DXGI_FORMAT_X32_TYPELESS_G8X24_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R10G10B10A2_TYPELESS"] = 23] = "DXGI_FORMAT_R10G10B10A2_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R10G10B10A2_UNORM"] = 24] = "DXGI_FORMAT_R10G10B10A2_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R10G10B10A2_UINT"] = 25] = "DXGI_FORMAT_R10G10B10A2_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R11G11B10_FLOAT"] = 26] = "DXGI_FORMAT_R11G11B10_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8B8A8_TYPELESS"] = 27] = "DXGI_FORMAT_R8G8B8A8_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8B8A8_UNORM"] = 28] = "DXGI_FORMAT_R8G8B8A8_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8B8A8_UNORM_SRGB"] = 29] = "DXGI_FORMAT_R8G8B8A8_UNORM_SRGB";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8B8A8_UINT"] = 30] = "DXGI_FORMAT_R8G8B8A8_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8B8A8_SNORM"] = 31] = "DXGI_FORMAT_R8G8B8A8_SNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8B8A8_SINT"] = 32] = "DXGI_FORMAT_R8G8B8A8_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16_TYPELESS"] = 33] = "DXGI_FORMAT_R16G16_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16_FLOAT"] = 34] = "DXGI_FORMAT_R16G16_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16_UNORM"] = 35] = "DXGI_FORMAT_R16G16_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16_UINT"] = 36] = "DXGI_FORMAT_R16G16_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16_SNORM"] = 37] = "DXGI_FORMAT_R16G16_SNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16G16_SINT"] = 38] = "DXGI_FORMAT_R16G16_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32_TYPELESS"] = 39] = "DXGI_FORMAT_R32_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_D32_FLOAT"] = 40] = "DXGI_FORMAT_D32_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32_FLOAT"] = 41] = "DXGI_FORMAT_R32_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32_UINT"] = 42] = "DXGI_FORMAT_R32_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R32_SINT"] = 43] = "DXGI_FORMAT_R32_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R24G8_TYPELESS"] = 44] = "DXGI_FORMAT_R24G8_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_D24_UNORM_S8_UINT"] = 45] = "DXGI_FORMAT_D24_UNORM_S8_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R24_UNORM_X8_TYPELESS"] = 46] = "DXGI_FORMAT_R24_UNORM_X8_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_X24_TYPELESS_G8_UINT"] = 47] = "DXGI_FORMAT_X24_TYPELESS_G8_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8_TYPELESS"] = 48] = "DXGI_FORMAT_R8G8_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8_UNORM"] = 49] = "DXGI_FORMAT_R8G8_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8_UINT"] = 50] = "DXGI_FORMAT_R8G8_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8_SNORM"] = 51] = "DXGI_FORMAT_R8G8_SNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8_SINT"] = 52] = "DXGI_FORMAT_R8G8_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16_TYPELESS"] = 53] = "DXGI_FORMAT_R16_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16_FLOAT"] = 54] = "DXGI_FORMAT_R16_FLOAT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_D16_UNORM"] = 55] = "DXGI_FORMAT_D16_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16_UNORM"] = 56] = "DXGI_FORMAT_R16_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16_UINT"] = 57] = "DXGI_FORMAT_R16_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16_SNORM"] = 58] = "DXGI_FORMAT_R16_SNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R16_SINT"] = 59] = "DXGI_FORMAT_R16_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8_TYPELESS"] = 60] = "DXGI_FORMAT_R8_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8_UNORM"] = 61] = "DXGI_FORMAT_R8_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8_UINT"] = 62] = "DXGI_FORMAT_R8_UINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8_SNORM"] = 63] = "DXGI_FORMAT_R8_SNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8_SINT"] = 64] = "DXGI_FORMAT_R8_SINT";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_A8_UNORM"] = 65] = "DXGI_FORMAT_A8_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R1_UNORM"] = 66] = "DXGI_FORMAT_R1_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R9G9B9E5_SHAREDEXP"] = 67] = "DXGI_FORMAT_R9G9B9E5_SHAREDEXP";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R8G8_B8G8_UNORM"] = 68] = "DXGI_FORMAT_R8G8_B8G8_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_G8R8_G8B8_UNORM"] = 69] = "DXGI_FORMAT_G8R8_G8B8_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC1_TYPELESS"] = 70] = "DXGI_FORMAT_BC1_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC1_UNORM"] = 71] = "DXGI_FORMAT_BC1_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC1_UNORM_SRGB"] = 72] = "DXGI_FORMAT_BC1_UNORM_SRGB";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC2_TYPELESS"] = 73] = "DXGI_FORMAT_BC2_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC2_UNORM"] = 74] = "DXGI_FORMAT_BC2_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC2_UNORM_SRGB"] = 75] = "DXGI_FORMAT_BC2_UNORM_SRGB";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC3_TYPELESS"] = 76] = "DXGI_FORMAT_BC3_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC3_UNORM"] = 77] = "DXGI_FORMAT_BC3_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC3_UNORM_SRGB"] = 78] = "DXGI_FORMAT_BC3_UNORM_SRGB";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC4_TYPELESS"] = 79] = "DXGI_FORMAT_BC4_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC4_UNORM"] = 80] = "DXGI_FORMAT_BC4_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC4_SNORM"] = 81] = "DXGI_FORMAT_BC4_SNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC5_TYPELESS"] = 82] = "DXGI_FORMAT_BC5_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC5_UNORM"] = 83] = "DXGI_FORMAT_BC5_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC5_SNORM"] = 84] = "DXGI_FORMAT_BC5_SNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B5G6R5_UNORM"] = 85] = "DXGI_FORMAT_B5G6R5_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B5G5R5A1_UNORM"] = 86] = "DXGI_FORMAT_B5G5R5A1_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B8G8R8A8_UNORM"] = 87] = "DXGI_FORMAT_B8G8R8A8_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B8G8R8X8_UNORM"] = 88] = "DXGI_FORMAT_B8G8R8X8_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_R10G10B10_XR_BIAS_A2_UNORM"] = 89] = "DXGI_FORMAT_R10G10B10_XR_BIAS_A2_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B8G8R8A8_TYPELESS"] = 90] = "DXGI_FORMAT_B8G8R8A8_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B8G8R8A8_UNORM_SRGB"] = 91] = "DXGI_FORMAT_B8G8R8A8_UNORM_SRGB";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B8G8R8X8_TYPELESS"] = 92] = "DXGI_FORMAT_B8G8R8X8_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B8G8R8X8_UNORM_SRGB"] = 93] = "DXGI_FORMAT_B8G8R8X8_UNORM_SRGB";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC6H_TYPELESS"] = 94] = "DXGI_FORMAT_BC6H_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC6H_UF16"] = 95] = "DXGI_FORMAT_BC6H_UF16";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC6H_SF16"] = 96] = "DXGI_FORMAT_BC6H_SF16";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC7_TYPELESS"] = 97] = "DXGI_FORMAT_BC7_TYPELESS";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC7_UNORM"] = 98] = "DXGI_FORMAT_BC7_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_BC7_UNORM_SRGB"] = 99] = "DXGI_FORMAT_BC7_UNORM_SRGB";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_AYUV"] = 100] = "DXGI_FORMAT_AYUV";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_Y410"] = 101] = "DXGI_FORMAT_Y410";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_Y416"] = 102] = "DXGI_FORMAT_Y416";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_NV12"] = 103] = "DXGI_FORMAT_NV12";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_P010"] = 104] = "DXGI_FORMAT_P010";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_P016"] = 105] = "DXGI_FORMAT_P016";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_420_OPAQUE"] = 106] = "DXGI_FORMAT_420_OPAQUE";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_YUY2"] = 107] = "DXGI_FORMAT_YUY2";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_Y210"] = 108] = "DXGI_FORMAT_Y210";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_Y216"] = 109] = "DXGI_FORMAT_Y216";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_NV11"] = 110] = "DXGI_FORMAT_NV11";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_AI44"] = 111] = "DXGI_FORMAT_AI44";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_IA44"] = 112] = "DXGI_FORMAT_IA44";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_P8"] = 113] = "DXGI_FORMAT_P8";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_A8P8"] = 114] = "DXGI_FORMAT_A8P8";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_B4G4R4A4_UNORM"] = 115] = "DXGI_FORMAT_B4G4R4A4_UNORM";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_P208"] = 116] = "DXGI_FORMAT_P208";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_V208"] = 117] = "DXGI_FORMAT_V208";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_V408"] = 118] = "DXGI_FORMAT_V408";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_SAMPLER_FEEDBACK_MIN_MIP_OPAQUE"] = 119] = "DXGI_FORMAT_SAMPLER_FEEDBACK_MIN_MIP_OPAQUE";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_SAMPLER_FEEDBACK_MIP_REGION_USED_OPAQUE"] = 120] = "DXGI_FORMAT_SAMPLER_FEEDBACK_MIP_REGION_USED_OPAQUE";
    DXGI_FORMAT1[DXGI_FORMAT1["DXGI_FORMAT_FORCE_UINT"] = 121] = "DXGI_FORMAT_FORCE_UINT";
})(DXGI_FORMAT || (DXGI_FORMAT = {
}));
/**
 * Possible values of the field {@link DDS_DX10_FIELDS.RESOURCE_DIMENSION}
 *
 * @ignore
 */ var D3D10_RESOURCE_DIMENSION;
(function(D3D10_RESOURCE_DIMENSION1) {
    D3D10_RESOURCE_DIMENSION1[D3D10_RESOURCE_DIMENSION1["DDS_DIMENSION_TEXTURE1D"] = 2] = "DDS_DIMENSION_TEXTURE1D";
    D3D10_RESOURCE_DIMENSION1[D3D10_RESOURCE_DIMENSION1["DDS_DIMENSION_TEXTURE2D"] = 3] = "DDS_DIMENSION_TEXTURE2D";
    D3D10_RESOURCE_DIMENSION1[D3D10_RESOURCE_DIMENSION1["DDS_DIMENSION_TEXTURE3D"] = 6] = "DDS_DIMENSION_TEXTURE3D";
})(D3D10_RESOURCE_DIMENSION || (D3D10_RESOURCE_DIMENSION = {
}));
var PF_FLAGS = 1;
// PIXEL_FORMAT flags
var DDPF_ALPHA = 2;
var DDPF_FOURCC = 4;
var DDPF_RGB = 64;
var DDPF_YUV = 512;
var DDPF_LUMINANCE = 131072;
// Four character codes for DXTn formats
var FOURCC_DXT1 = 827611204;
var FOURCC_DXT3 = 861165636;
var FOURCC_DXT5 = 894720068;
var FOURCC_DX10 = 808540228;
// Cubemap texture flag (for DDS_DX10_FIELDS.MISC_FLAG)
var DDS_RESOURCE_MISC_TEXTURECUBE = 4;
/**
 * Maps `FOURCC_*` formats to internal formats (see {@link PIXI.INTERNAL_FORMATS}).
 *
 * @ignore
 */ var FOURCC_TO_FORMAT = (_a$1 = {
}, _a$1[FOURCC_DXT1] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT1_EXT, _a$1[FOURCC_DXT3] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT3_EXT, _a$1[FOURCC_DXT5] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT5_EXT, _a$1);
/**
 * Maps {@link DXGI_FORMAT} to types/internal-formats (see {@link PIXI.TYPES}, {@link PIXI.INTERNAL_FORMATS})
 *
 * @ignore
 */ var DXGI_TO_FORMAT = (_b = {
}, // WEBGL_compressed_texture_s3tc
_b[DXGI_FORMAT.DXGI_FORMAT_BC1_TYPELESS] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT1_EXT, _b[DXGI_FORMAT.DXGI_FORMAT_BC1_UNORM] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT1_EXT, _b[DXGI_FORMAT.DXGI_FORMAT_BC2_TYPELESS] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT3_EXT, _b[DXGI_FORMAT.DXGI_FORMAT_BC2_UNORM] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT3_EXT, _b[DXGI_FORMAT.DXGI_FORMAT_BC3_TYPELESS] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT5_EXT, _b[DXGI_FORMAT.DXGI_FORMAT_BC3_UNORM] = INTERNAL_FORMATS.COMPRESSED_RGBA_S3TC_DXT5_EXT, // WEBGL_compressed_texture_s3tc_srgb
_b[DXGI_FORMAT.DXGI_FORMAT_BC1_UNORM_SRGB] = INTERNAL_FORMATS.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT, _b[DXGI_FORMAT.DXGI_FORMAT_BC2_UNORM_SRGB] = INTERNAL_FORMATS.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT, _b[DXGI_FORMAT.DXGI_FORMAT_BC3_UNORM_SRGB] = INTERNAL_FORMATS.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT, _b);
/**
 * @class
 * @memberof PIXI
 * @implements PIXI.ILoaderPlugin
 * @see https://docs.microsoft.com/en-us/windows/win32/direct3ddds/dx-graphics-dds-pguide
 */ var DDSLoader = function() {
    function DDSLoader1() {
    }
    /**
     * Registers a DDS compressed texture
     * @see PIXI.Loader.loaderMiddleware
     * @param resource - loader resource that is checked to see if it is a DDS file
     * @param next - callback Function to call when done
     */ DDSLoader1.use = function(resource, next) {
        if (resource.extension === 'dds' && resource.data) try {
            Object.assign(resource, registerCompressedTextures(resource.name || resource.url, DDSLoader1.parse(resource.data), resource.metadata));
        } catch (err) {
            next(err);
            return;
        }
        next();
    };
    /** Parses the DDS file header, generates base-textures, and puts them into the texture cache. */ DDSLoader1.parse = function(arrayBuffer) {
        var data = new Uint32Array(arrayBuffer);
        var magicWord = data[0];
        if (magicWord !== DDS_MAGIC) throw new Error('Invalid DDS file magic word');
        var header = new Uint32Array(arrayBuffer, 0, DDS_HEADER_SIZE / Uint32Array.BYTES_PER_ELEMENT);
        // DDS header fields
        var height = header[DDS_FIELDS.HEIGHT];
        var width = header[DDS_FIELDS.WIDTH];
        var mipmapCount = header[DDS_FIELDS.MIPMAP_COUNT];
        // PIXEL_FORMAT fields
        var pixelFormat = new Uint32Array(arrayBuffer, DDS_FIELDS.PIXEL_FORMAT * Uint32Array.BYTES_PER_ELEMENT, DDS_HEADER_PF_SIZE / Uint32Array.BYTES_PER_ELEMENT);
        var formatFlags = pixelFormat[PF_FLAGS];
        // File contains compressed texture(s)
        if (formatFlags & DDPF_FOURCC) {
            var fourCC = pixelFormat[DDS_PF_FIELDS.FOURCC];
            // File contains one DXTn compressed texture
            if (fourCC !== FOURCC_DX10) {
                var internalFormat_1 = FOURCC_TO_FORMAT[fourCC];
                var dataOffset_1 = DDS_MAGIC_SIZE + DDS_HEADER_SIZE;
                var texData = new Uint8Array(arrayBuffer, dataOffset_1);
                var resource = new CompressedTextureResource1(texData, {
                    format: internalFormat_1,
                    width: width,
                    height: height,
                    levels: mipmapCount // CompressedTextureResource will separate the levelBuffers for us!
                });
                return [
                    resource
                ];
            }
            // FOURCC_DX10 indicates there is a 20-byte DDS_HEADER_DX10 after DDS_HEADER
            var dx10Offset = DDS_MAGIC_SIZE + DDS_HEADER_SIZE;
            var dx10Header = new Uint32Array(data.buffer, dx10Offset, DDS_HEADER_DX10_SIZE / Uint32Array.BYTES_PER_ELEMENT);
            var dxgiFormat = dx10Header[DDS_DX10_FIELDS.DXGI_FORMAT];
            var resourceDimension = dx10Header[DDS_DX10_FIELDS.RESOURCE_DIMENSION];
            var miscFlag = dx10Header[DDS_DX10_FIELDS.MISC_FLAG];
            var arraySize = dx10Header[DDS_DX10_FIELDS.ARRAY_SIZE];
            // Map dxgiFormat to PIXI.INTERNAL_FORMATS
            var internalFormat_2 = DXGI_TO_FORMAT[dxgiFormat];
            if (internalFormat_2 === undefined) throw new Error("DDSLoader cannot parse texture data with DXGI format " + dxgiFormat);
            if (miscFlag === DDS_RESOURCE_MISC_TEXTURECUBE) // FIXME: Anybody excited about cubemap compressed textures?
            throw new Error('DDSLoader does not support cubemap textures');
            if (resourceDimension === D3D10_RESOURCE_DIMENSION.DDS_DIMENSION_TEXTURE3D) // FIXME: Anybody excited about 3D compressed textures?
            throw new Error('DDSLoader does not supported 3D texture data');
            // Uint8Array buffers of image data, including all mipmap levels in each image
            var imageBuffers = new Array();
            var dataOffset = DDS_MAGIC_SIZE + DDS_HEADER_SIZE + DDS_HEADER_DX10_SIZE;
            if (arraySize === 1) // No need bothering with the imageSize calculation!
            imageBuffers.push(new Uint8Array(arrayBuffer, dataOffset));
            else {
                // Calculate imageSize for each texture, and then locate each image's texture data
                var pixelSize = INTERNAL_FORMAT_TO_BYTES_PER_PIXEL[internalFormat_2];
                var imageSize = 0;
                var levelWidth = width;
                var levelHeight = height;
                for(var i = 0; i < mipmapCount; i++){
                    var alignedLevelWidth = Math.max(1, levelWidth + 3 & -4);
                    var alignedLevelHeight = Math.max(1, levelHeight + 3 & -4);
                    var levelSize = alignedLevelWidth * alignedLevelHeight * pixelSize;
                    imageSize += levelSize;
                    levelWidth = levelWidth >>> 1;
                    levelHeight = levelHeight >>> 1;
                }
                var imageOffset = dataOffset;
                // NOTE: Cubemaps have 6-images per texture (but they aren't supported so ^_^)
                for(var i = 0; i < arraySize; i++){
                    imageBuffers.push(new Uint8Array(arrayBuffer, imageOffset, imageSize));
                    imageOffset += imageSize;
                }
            }
            // Uint8Array -> CompressedTextureResource, and we're done!
            return imageBuffers.map(function(buffer) {
                return new CompressedTextureResource1(buffer, {
                    format: internalFormat_2,
                    width: width,
                    height: height,
                    levels: mipmapCount
                });
            });
        }
        if (formatFlags & DDPF_RGB) // FIXME: We might want to allow uncompressed *.dds files?
        throw new Error('DDSLoader does not support uncompressed texture data.');
        if (formatFlags & DDPF_YUV) // FIXME: Does anybody need this feature?
        throw new Error('DDSLoader does not supported YUV uncompressed texture data.');
        if (formatFlags & DDPF_LUMINANCE) // FIXME: Microsoft says older DDS filers use this feature! Probably not worth the effort!
        throw new Error('DDSLoader does not support single-channel (lumninance) texture data!');
        if (formatFlags & DDPF_ALPHA) // FIXME: I'm tired! See above =)
        throw new Error('DDSLoader does not support single-channel (alpha) texture data!');
        throw new Error('DDSLoader failed to load a texture file due to an unknown reason!');
    };
    return DDSLoader1;
}();
var _a$2, _b$1, _c;
// Set KTX files to be loaded as an ArrayBuffer
_loaders.LoaderResource.setExtensionXhrType('ktx', _loaders.LoaderResource.XHR_RESPONSE_TYPE.BUFFER);
/**
 * The 12-byte KTX file identifier
 *
 * @see https://www.khronos.org/opengles/sdk/tools/KTX/file_format_spec/#2.1
 * @ignore
 */ var FILE_IDENTIFIER = [
    171,
    75,
    84,
    88,
    32,
    49,
    49,
    187,
    13,
    10,
    26,
    10
];
/**
 * The value stored in the "endianness" field.
 *
 * @see https://www.khronos.org/opengles/sdk/tools/KTX/file_format_spec/#2.2
 * @ignore
 */ var ENDIANNESS = 67305985;
/**
 * Byte offsets of the KTX file header fields
 *
 * @ignore
 */ var KTX_FIELDS = {
    FILE_IDENTIFIER: 0,
    ENDIANNESS: 12,
    GL_TYPE: 16,
    GL_TYPE_SIZE: 20,
    GL_FORMAT: 24,
    GL_INTERNAL_FORMAT: 28,
    GL_BASE_INTERNAL_FORMAT: 32,
    PIXEL_WIDTH: 36,
    PIXEL_HEIGHT: 40,
    PIXEL_DEPTH: 44,
    NUMBER_OF_ARRAY_ELEMENTS: 48,
    NUMBER_OF_FACES: 52,
    NUMBER_OF_MIPMAP_LEVELS: 56,
    BYTES_OF_KEY_VALUE_DATA: 60
};
/**
 * Byte size of the file header fields in {@code KTX_FIELDS}
 *
 * @ignore
 */ var FILE_HEADER_SIZE = 64;
/**
 * Maps {@link PIXI.TYPES} to the bytes taken per component, excluding those ones that are bit-fields.
 *
 * @ignore
 */ var TYPES_TO_BYTES_PER_COMPONENT = (_a$2 = {
}, _a$2[_constants.TYPES.UNSIGNED_BYTE] = 1, _a$2[_constants.TYPES.UNSIGNED_SHORT] = 2, _a$2[_constants.TYPES.FLOAT] = 4, _a$2[_constants.TYPES.HALF_FLOAT] = 8, _a$2);
/**
 * Number of components in each {@link PIXI.FORMATS}
 *
 * @ignore
 */ var FORMATS_TO_COMPONENTS = (_b$1 = {
}, _b$1[_constants.FORMATS.RGBA] = 4, _b$1[_constants.FORMATS.RGB] = 3, _b$1[_constants.FORMATS.LUMINANCE] = 1, _b$1[_constants.FORMATS.LUMINANCE_ALPHA] = 2, _b$1[_constants.FORMATS.ALPHA] = 1, _b$1);
/**
 * Number of bytes per pixel in bit-field types in {@link PIXI.TYPES}
 *
 * @ignore
 */ var TYPES_TO_BYTES_PER_PIXEL = (_c = {
}, _c[_constants.TYPES.UNSIGNED_SHORT_4_4_4_4] = 2, _c[_constants.TYPES.UNSIGNED_SHORT_5_5_5_1] = 2, _c[_constants.TYPES.UNSIGNED_SHORT_5_6_5] = 2, _c);
/**
 * Loader plugin for handling KTX texture container files.
 *
 * This KTX loader does not currently support the following features:
 * * cube textures
 * * 3D textures
 * * vendor-specific key/value data parsing
 * * endianness conversion for big-endian machines
 * * embedded *.basis files
 *
 * It does supports the following features:
 * * multiple textures per file
 * * mipmapping
 *
 * @class
 * @memberof PIXI
 * @implements PIXI.ILoaderPlugin
 */ var KTXLoader = function() {
    function KTXLoader1() {
    }
    /**
     * Called after a KTX file is loaded.
     *
     * This will parse the KTX file header and add a {@code BaseTexture} to the texture
     * cache.
     *
     * @see PIXI.Loader.loaderMiddleware
     * @param resource - loader resource that is checked to see if it is a KTX file
     * @param next - callback Function to call when done
     */ KTXLoader1.use = function(resource, next) {
        if (resource.extension === 'ktx' && resource.data) try {
            var url = resource.name || resource.url;
            Object.assign(resource, registerCompressedTextures(url, KTXLoader1.parse(url, resource.data), resource.metadata));
        } catch (err) {
            next(err);
            return;
        }
        next();
    };
    /** Parses the KTX file header, generates base-textures, and puts them into the texture cache. */ KTXLoader1.parse = function(url, arrayBuffer) {
        var dataView = new DataView(arrayBuffer);
        if (!KTXLoader1.validate(url, dataView)) return null;
        var littleEndian = dataView.getUint32(KTX_FIELDS.ENDIANNESS, true) === ENDIANNESS;
        var glType = dataView.getUint32(KTX_FIELDS.GL_TYPE, littleEndian);
        // const glTypeSize = dataView.getUint32(KTX_FIELDS.GL_TYPE_SIZE, littleEndian);
        var glFormat = dataView.getUint32(KTX_FIELDS.GL_FORMAT, littleEndian);
        var glInternalFormat = dataView.getUint32(KTX_FIELDS.GL_INTERNAL_FORMAT, littleEndian);
        var pixelWidth = dataView.getUint32(KTX_FIELDS.PIXEL_WIDTH, littleEndian);
        var pixelHeight = dataView.getUint32(KTX_FIELDS.PIXEL_HEIGHT, littleEndian) || 1; // "pixelHeight = 0" -> "1"
        var pixelDepth = dataView.getUint32(KTX_FIELDS.PIXEL_DEPTH, littleEndian) || 1; // ^^
        var numberOfArrayElements = dataView.getUint32(KTX_FIELDS.NUMBER_OF_ARRAY_ELEMENTS, littleEndian) || 1; // ^^
        var numberOfFaces = dataView.getUint32(KTX_FIELDS.NUMBER_OF_FACES, littleEndian);
        var numberOfMipmapLevels = dataView.getUint32(KTX_FIELDS.NUMBER_OF_MIPMAP_LEVELS, littleEndian);
        var bytesOfKeyValueData = dataView.getUint32(KTX_FIELDS.BYTES_OF_KEY_VALUE_DATA, littleEndian);
        // Whether the platform architecture is little endian. If littleEndian !== platformLittleEndian, then the
        // file contents must be endian-converted!
        // TODO: Endianness conversion
        // const platformLittleEndian = new Uint8Array((new Uint32Array([ENDIANNESS])).buffer)[0] === 0x01;
        if (pixelHeight === 0 || pixelDepth !== 1) throw new Error('Only 2D textures are supported');
        if (numberOfFaces !== 1) throw new Error('CubeTextures are not supported by KTXLoader yet!');
        if (numberOfArrayElements !== 1) // TODO: Support splitting array-textures into multiple BaseTextures
        throw new Error('WebGL does not support array textures');
        // TODO: 8x4 blocks for 2bpp pvrtc
        var blockWidth = 4;
        var blockHeight = 4;
        var alignedWidth = pixelWidth + 3 & -4;
        var alignedHeight = pixelHeight + 3 & -4;
        var imageBuffers = new Array(numberOfArrayElements);
        var imagePixels = pixelWidth * pixelHeight;
        if (glType === 0) // Align to 16 pixels (4x4 blocks)
        imagePixels = alignedWidth * alignedHeight;
        var imagePixelByteSize;
        if (glType !== 0) {
            // Uncompressed texture format
            if (TYPES_TO_BYTES_PER_COMPONENT[glType]) imagePixelByteSize = TYPES_TO_BYTES_PER_COMPONENT[glType] * FORMATS_TO_COMPONENTS[glFormat];
            else imagePixelByteSize = TYPES_TO_BYTES_PER_PIXEL[glType];
        } else imagePixelByteSize = INTERNAL_FORMAT_TO_BYTES_PER_PIXEL[glInternalFormat];
        if (imagePixelByteSize === undefined) throw new Error('Unable to resolve the pixel format stored in the *.ktx file!');
        var imageByteSize = imagePixels * imagePixelByteSize;
        var mipByteSize = imageByteSize;
        var mipWidth = pixelWidth;
        var mipHeight = pixelHeight;
        var alignedMipWidth = alignedWidth;
        var alignedMipHeight = alignedHeight;
        var imageOffset = FILE_HEADER_SIZE + bytesOfKeyValueData;
        for(var mipmapLevel = 0; mipmapLevel < numberOfMipmapLevels; mipmapLevel++){
            var imageSize = dataView.getUint32(imageOffset, littleEndian);
            var elementOffset = imageOffset + 4;
            for(var arrayElement = 0; arrayElement < numberOfArrayElements; arrayElement++){
                // TODO: Maybe support 3D textures? :-)
                // for (let zSlice = 0; zSlice < pixelDepth; zSlice)
                var mips = imageBuffers[arrayElement];
                if (!mips) mips = imageBuffers[arrayElement] = new Array(numberOfMipmapLevels);
                mips[mipmapLevel] = {
                    levelID: mipmapLevel,
                    levelWidth: numberOfMipmapLevels > 1 ? mipWidth : alignedMipWidth,
                    levelHeight: numberOfMipmapLevels > 1 ? mipHeight : alignedMipHeight,
                    levelBuffer: new Uint8Array(arrayBuffer, elementOffset, mipByteSize)
                };
                elementOffset += mipByteSize;
            }
            // HINT: Aligns to 4-byte boundary after jumping imageSize (in lieu of mipPadding)
            imageOffset += imageSize + 4; // (+4 to jump the imageSize field itself)
            imageOffset = imageOffset % 4 !== 0 ? imageOffset + 4 - imageOffset % 4 : imageOffset;
            // Calculate mipWidth, mipHeight for _next_ iteration
            mipWidth = mipWidth >> 1 || 1;
            mipHeight = mipHeight >> 1 || 1;
            alignedMipWidth = mipWidth + blockWidth - 1 & ~(blockWidth - 1);
            alignedMipHeight = mipHeight + blockHeight - 1 & ~(blockHeight - 1);
            // Each mipmap level is 4-times smaller?
            mipByteSize = alignedMipWidth * alignedMipHeight * imagePixelByteSize;
        }
        // We use the levelBuffers feature of CompressedTextureResource b/c texture data is image-major, not level-major.
        if (glType !== 0) throw new Error('TODO: Uncompressed');
        return imageBuffers.map(function(levelBuffers) {
            return new CompressedTextureResource1(null, {
                format: glInternalFormat,
                width: pixelWidth,
                height: pixelHeight,
                levels: numberOfMipmapLevels,
                levelBuffers: levelBuffers
            });
        });
    };
    /** Checks whether the arrayBuffer contains a valid *.ktx file. */ KTXLoader1.validate = function(url, dataView) {
        // NOTE: Do not optimize this into 3 32-bit integer comparison because the endianness
        // of the data is not specified.
        for(var i = 0; i < FILE_IDENTIFIER.length; i++)if (dataView.getUint8(i) !== FILE_IDENTIFIER[i]) {
            console.error(url + " is not a valid *.ktx file!");
            return false;
        }
        return true;
    };
    return KTXLoader1;
}();

},{"@pixi/core":"d0INm","@pixi/loaders":"1PTMa","@pixi/utils":"joR65","@pixi/constants":"lqjFh","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j2a6m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ParticleContainer", ()=>ParticleContainer1
);
parcelHelpers.export(exports, "ParticleRenderer", ()=>ParticleRenderer1
);
/*!
 * @pixi/particle-container - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/particle-container is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _constants = require("@pixi/constants");
var _display = require("@pixi/display");
var _utils = require("@pixi/utils");
var _core = require("@pixi/core");
var _math = require("@pixi/math");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * The ParticleContainer class is a really fast version of the Container built solely for speed,
 * so use when you need a lot of sprites or particles.
 *
 * The tradeoff of the ParticleContainer is that most advanced functionality will not work.
 * ParticleContainer implements the basic object transform (position, scale, rotation)
 * and some advanced functionality like tint (as of v4.5.6).
 *
 * Other more advanced functionality like masking, children, filters, etc will not work on sprites in this batch.
 *
 * It's extremely easy to use:
 * ```js
 * let container = new ParticleContainer();
 *
 * for (let i = 0; i < 100; ++i)
 * {
 *     let sprite = PIXI.Sprite.from("myImage.png");
 *     container.addChild(sprite);
 * }
 * ```
 *
 * And here you have a hundred sprites that will be rendered at the speed of light.
 *
 * @class
 * @extends PIXI.Container
 * @memberof PIXI
 */ var ParticleContainer1 = function(_super) {
    __extends(ParticleContainer2, _super);
    /**
     * @param {number} [maxSize=1500] - The maximum number of particles that can be rendered by the container.
     *  Affects size of allocated buffers.
     * @param {object} [properties] - The properties of children that should be uploaded to the gpu and applied.
     * @param {boolean} [properties.vertices=false] - When true, vertices be uploaded and applied.
     *                  if sprite's ` scale/anchor/trim/frame/orig` is dynamic, please set `true`.
     * @param {boolean} [properties.position=true] - When true, position be uploaded and applied.
     * @param {boolean} [properties.rotation=false] - When true, rotation be uploaded and applied.
     * @param {boolean} [properties.uvs=false] - When true, uvs be uploaded and applied.
     * @param {boolean} [properties.tint=false] - When true, alpha and tint be uploaded and applied.
     * @param {number} [batchSize=16384] - Number of particles per batch. If less than maxSize, it uses maxSize instead.
     * @param {boolean} [autoResize=false] - If true, container allocates more batches in case
     *  there are more than `maxSize` particles.
     */ function ParticleContainer2(maxSize, properties, batchSize, autoResize) {
        if (maxSize === void 0) maxSize = 1500;
        if (batchSize === void 0) batchSize = 16384;
        if (autoResize === void 0) autoResize = false;
        var _this = _super.call(this) || this;
        // Making sure the batch size is valid
        // 65535 is max vertex index in the index buffer (see ParticleRenderer)
        // so max number of particles is 65536 / 4 = 16384
        var maxBatchSize = 16384;
        if (batchSize > maxBatchSize) batchSize = maxBatchSize;
        /**
         * Set properties to be dynamic (true) / static (false)
         *
         * @member {boolean[]}
         * @private
         */ _this._properties = [
            false,
            true,
            false,
            false,
            false
        ];
        /**
         * @member {number}
         * @private
         */ _this._maxSize = maxSize;
        /**
         * @member {number}
         * @private
         */ _this._batchSize = batchSize;
        /**
         * @member {Array<PIXI.Buffer>}
         * @private
         */ _this._buffers = null;
        /**
         * for every batch stores _updateID corresponding to the last change in that batch
         * @member {number[]}
         * @private
         */ _this._bufferUpdateIDs = [];
        /**
         * when child inserted, removed or changes position this number goes up
         * @member {number[]}
         * @private
         */ _this._updateID = 0;
        /**
         * @member {boolean}
         *
         */ _this.interactiveChildren = false;
        /**
         * The blend mode to be applied to the sprite. Apply a value of `PIXI.BLEND_MODES.NORMAL`
         * to reset the blend mode.
         *
         * @member {number}
         * @default PIXI.BLEND_MODES.NORMAL
         * @see PIXI.BLEND_MODES
         */ _this.blendMode = _constants.BLEND_MODES.NORMAL;
        /**
         * If true, container allocates more batches in case there are more than `maxSize` particles.
         * @member {boolean}
         * @default false
         */ _this.autoResize = autoResize;
        /**
         * If true PixiJS will Math.floor() x/y values when rendering, stopping pixel interpolation.
         * Advantages can include sharper image quality (like text) and faster rendering on canvas.
         * The main disadvantage is movement of objects may appear less smooth.
         * Default to true here as performance is usually the priority for particles.
         *
         * @member {boolean}
         * @default true
         */ _this.roundPixels = true;
        /**
         * The texture used to render the children.
         *
         * @readonly
         * @member {PIXI.BaseTexture}
         */ _this.baseTexture = null;
        _this.setProperties(properties);
        /**
         * The tint applied to the container.
         * This is a hex value. A value of 0xFFFFFF will remove any tint effect.
         *
         * @private
         * @member {number}
         * @default 0xFFFFFF
         */ _this._tint = 0;
        _this.tintRgb = new Float32Array(4);
        _this.tint = 16777215;
        return _this;
    }
    /**
     * Sets the private properties array to dynamic / static based on the passed properties object
     *
     * @param {object} properties - The properties to be uploaded
     */ ParticleContainer2.prototype.setProperties = function(properties) {
        if (properties) {
            this._properties[0] = 'vertices' in properties || 'scale' in properties ? !!properties.vertices || !!properties.scale : this._properties[0];
            this._properties[1] = 'position' in properties ? !!properties.position : this._properties[1];
            this._properties[2] = 'rotation' in properties ? !!properties.rotation : this._properties[2];
            this._properties[3] = 'uvs' in properties ? !!properties.uvs : this._properties[3];
            this._properties[4] = 'tint' in properties || 'alpha' in properties ? !!properties.tint || !!properties.alpha : this._properties[4];
        }
    };
    /**
     * Updates the object transform for rendering
     *
     * @private
     */ ParticleContainer2.prototype.updateTransform = function() {
        // TODO don't need to!
        this.displayObjectUpdateTransform();
    };
    Object.defineProperty(ParticleContainer2.prototype, "tint", {
        /**
         * The tint applied to the container. This is a hex value.
         * A value of 0xFFFFFF will remove any tint effect.
         ** IMPORTANT: This is a WebGL only feature and will be ignored by the canvas renderer.
         * @member {number}
         * @default 0xFFFFFF
         */ get: function() {
            return this._tint;
        },
        set: function(value) {
            this._tint = value;
            _utils.hex2rgb(value, this.tintRgb);
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Renders the container using the WebGL renderer
     *
     * @private
     * @param {PIXI.Renderer} renderer - The webgl renderer
     */ ParticleContainer2.prototype.render = function(renderer) {
        var _this = this;
        if (!this.visible || this.worldAlpha <= 0 || !this.children.length || !this.renderable) return;
        if (!this.baseTexture) {
            this.baseTexture = this.children[0]._texture.baseTexture;
            if (!this.baseTexture.valid) this.baseTexture.once('update', function() {
                return _this.onChildrenChange(0);
            });
        }
        renderer.batch.setObjectRenderer(renderer.plugins.particle);
        renderer.plugins.particle.render(this);
    };
    /**
     * Set the flag that static data should be updated to true
     *
     * @private
     * @param {number} smallestChildIndex - The smallest child index
     */ ParticleContainer2.prototype.onChildrenChange = function(smallestChildIndex) {
        var bufferIndex = Math.floor(smallestChildIndex / this._batchSize);
        while(this._bufferUpdateIDs.length < bufferIndex)this._bufferUpdateIDs.push(0);
        this._bufferUpdateIDs[bufferIndex] = ++this._updateID;
    };
    ParticleContainer2.prototype.dispose = function() {
        if (this._buffers) {
            for(var i = 0; i < this._buffers.length; ++i)this._buffers[i].destroy();
            this._buffers = null;
        }
    };
    /**
     * Destroys the container
     *
     * @param {object|boolean} [options] - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.children=false] - if set to true, all the children will have their
     *  destroy method called as well. 'options' will be passed on to those calls.
     * @param {boolean} [options.texture=false] - Only used for child Sprites if options.children is set to true
     *  Should it destroy the texture of the child sprite
     * @param {boolean} [options.baseTexture=false] - Only used for child Sprites if options.children is set to true
     *  Should it destroy the base texture of the child sprite
     */ ParticleContainer2.prototype.destroy = function(options) {
        _super.prototype.destroy.call(this, options);
        this.dispose();
        this._properties = null;
        this._buffers = null;
        this._bufferUpdateIDs = null;
    };
    return ParticleContainer2;
}(_display.Container);
/*
 * @author Mat Groves
 *
 * Big thanks to the very clever Matt DesLauriers <mattdesl> https://github.com/mattdesl/
 * for creating the original PixiJS version!
 * Also a thanks to https://github.com/bchevalier for tweaking the tint and alpha so that
 * they now share 4 bytes on the vertex buffer
 *
 * Heavily inspired by LibGDX's ParticleBuffer:
 * https://github.com/libgdx/libgdx/blob/master/gdx/src/com/badlogic/gdx/graphics/g2d/ParticleBuffer.java
 */ /**
 * The particle buffer manages the static and dynamic buffers for a particle container.
 *
 * @class
 * @private
 * @memberof PIXI
 */ var ParticleBuffer = function() {
    /**
     * @private
     * @param {object} properties - The properties to upload.
     * @param {boolean[]} dynamicPropertyFlags - Flags for which properties are dynamic.
     * @param {number} size - The size of the batch.
     */ function ParticleBuffer1(properties, dynamicPropertyFlags, size) {
        this.geometry = new _core.Geometry();
        this.indexBuffer = null;
        /**
         * The number of particles the buffer can hold
         *
         * @private
         * @member {number}
         */ this.size = size;
        /**
         * A list of the properties that are dynamic.
         *
         * @private
         * @member {object[]}
         */ this.dynamicProperties = [];
        /**
         * A list of the properties that are static.
         *
         * @private
         * @member {object[]}
         */ this.staticProperties = [];
        for(var i = 0; i < properties.length; ++i){
            var property = properties[i];
            // Make copy of properties object so that when we edit the offset it doesn't
            // change all other instances of the object literal
            property = {
                attributeName: property.attributeName,
                size: property.size,
                uploadFunction: property.uploadFunction,
                type: property.type || _constants.TYPES.FLOAT,
                offset: property.offset
            };
            if (dynamicPropertyFlags[i]) this.dynamicProperties.push(property);
            else this.staticProperties.push(property);
        }
        this.staticStride = 0;
        this.staticBuffer = null;
        this.staticData = null;
        this.staticDataUint32 = null;
        this.dynamicStride = 0;
        this.dynamicBuffer = null;
        this.dynamicData = null;
        this.dynamicDataUint32 = null;
        this._updateID = 0;
        this.initBuffers();
    }
    /**
     * Sets up the renderer context and necessary buffers.
     *
     * @private
     */ ParticleBuffer1.prototype.initBuffers = function() {
        var geometry = this.geometry;
        var dynamicOffset = 0;
        /**
         * Holds the indices of the geometry (quads) to draw
         *
         * @member {Uint16Array}
         * @private
         */ this.indexBuffer = new _core.Buffer(_utils.createIndicesForQuads(this.size), true, true);
        geometry.addIndex(this.indexBuffer);
        this.dynamicStride = 0;
        for(var i = 0; i < this.dynamicProperties.length; ++i){
            var property = this.dynamicProperties[i];
            property.offset = dynamicOffset;
            dynamicOffset += property.size;
            this.dynamicStride += property.size;
        }
        var dynBuffer = new ArrayBuffer(this.size * this.dynamicStride * 16);
        this.dynamicData = new Float32Array(dynBuffer);
        this.dynamicDataUint32 = new Uint32Array(dynBuffer);
        this.dynamicBuffer = new _core.Buffer(this.dynamicData, false, false);
        // static //
        var staticOffset = 0;
        this.staticStride = 0;
        for(var i = 0; i < this.staticProperties.length; ++i){
            var property = this.staticProperties[i];
            property.offset = staticOffset;
            staticOffset += property.size;
            this.staticStride += property.size;
        }
        var statBuffer = new ArrayBuffer(this.size * this.staticStride * 16);
        this.staticData = new Float32Array(statBuffer);
        this.staticDataUint32 = new Uint32Array(statBuffer);
        this.staticBuffer = new _core.Buffer(this.staticData, true, false);
        for(var i = 0; i < this.dynamicProperties.length; ++i){
            var property = this.dynamicProperties[i];
            geometry.addAttribute(property.attributeName, this.dynamicBuffer, 0, property.type === _constants.TYPES.UNSIGNED_BYTE, property.type, this.dynamicStride * 4, property.offset * 4);
        }
        for(var i = 0; i < this.staticProperties.length; ++i){
            var property = this.staticProperties[i];
            geometry.addAttribute(property.attributeName, this.staticBuffer, 0, property.type === _constants.TYPES.UNSIGNED_BYTE, property.type, this.staticStride * 4, property.offset * 4);
        }
    };
    /**
     * Uploads the dynamic properties.
     *
     * @private
     * @param {PIXI.DisplayObject[]} children - The children to upload.
     * @param {number} startIndex - The index to start at.
     * @param {number} amount - The number to upload.
     */ ParticleBuffer1.prototype.uploadDynamic = function(children, startIndex, amount) {
        for(var i = 0; i < this.dynamicProperties.length; i++){
            var property = this.dynamicProperties[i];
            property.uploadFunction(children, startIndex, amount, property.type === _constants.TYPES.UNSIGNED_BYTE ? this.dynamicDataUint32 : this.dynamicData, this.dynamicStride, property.offset);
        }
        this.dynamicBuffer._updateID++;
    };
    /**
     * Uploads the static properties.
     *
     * @private
     * @param {PIXI.DisplayObject[]} children - The children to upload.
     * @param {number} startIndex - The index to start at.
     * @param {number} amount - The number to upload.
     */ ParticleBuffer1.prototype.uploadStatic = function(children, startIndex, amount) {
        for(var i = 0; i < this.staticProperties.length; i++){
            var property = this.staticProperties[i];
            property.uploadFunction(children, startIndex, amount, property.type === _constants.TYPES.UNSIGNED_BYTE ? this.staticDataUint32 : this.staticData, this.staticStride, property.offset);
        }
        this.staticBuffer._updateID++;
    };
    /**
     * Destroys the ParticleBuffer.
     *
     * @private
     */ ParticleBuffer1.prototype.destroy = function() {
        this.indexBuffer = null;
        this.dynamicProperties = null;
        this.dynamicBuffer = null;
        this.dynamicData = null;
        this.dynamicDataUint32 = null;
        this.staticProperties = null;
        this.staticBuffer = null;
        this.staticData = null;
        this.staticDataUint32 = null;
        // all buffers are destroyed inside geometry
        this.geometry.destroy();
    };
    return ParticleBuffer1;
}();
var fragment = "varying vec2 vTextureCoord;\nvarying vec4 vColor;\n\nuniform sampler2D uSampler;\n\nvoid main(void){\n    vec4 color = texture2D(uSampler, vTextureCoord) * vColor;\n    gl_FragColor = color;\n}";
var vertex = "attribute vec2 aVertexPosition;\nattribute vec2 aTextureCoord;\nattribute vec4 aColor;\n\nattribute vec2 aPositionCoord;\nattribute float aRotation;\n\nuniform mat3 translationMatrix;\nuniform vec4 uColor;\n\nvarying vec2 vTextureCoord;\nvarying vec4 vColor;\n\nvoid main(void){\n    float x = (aVertexPosition.x) * cos(aRotation) - (aVertexPosition.y) * sin(aRotation);\n    float y = (aVertexPosition.x) * sin(aRotation) + (aVertexPosition.y) * cos(aRotation);\n\n    vec2 v = vec2(x, y);\n    v = v + aPositionCoord;\n\n    gl_Position = vec4((translationMatrix * vec3(v, 1.0)).xy, 0.0, 1.0);\n\n    vTextureCoord = aTextureCoord;\n    vColor = aColor * uColor;\n}\n";
/*
 * @author Mat Groves
 *
 * Big thanks to the very clever Matt DesLauriers <mattdesl> https://github.com/mattdesl/
 * for creating the original PixiJS version!
 * Also a thanks to https://github.com/bchevalier for tweaking the tint and alpha so that they now
 * share 4 bytes on the vertex buffer
 *
 * Heavily inspired by LibGDX's ParticleRenderer:
 * https://github.com/libgdx/libgdx/blob/master/gdx/src/com/badlogic/gdx/graphics/g2d/ParticleRenderer.java
 */ /**
 * Renderer for Particles that is designer for speed over feature set.
 *
 * @class
 * @memberof PIXI
 */ var ParticleRenderer1 = function(_super) {
    __extends(ParticleRenderer2, _super);
    /**
     * @param {PIXI.Renderer} renderer - The renderer this sprite batch works for.
     */ function ParticleRenderer2(renderer) {
        var _this = _super.call(this, renderer) || this;
        // 65535 is max vertex index in the index buffer (see ParticleRenderer)
        // so max number of particles is 65536 / 4 = 16384
        // and max number of element in the index buffer is 16384 * 6 = 98304
        // Creating a full index buffer, overhead is 98304 * 2 = 196Ko
        // let numIndices = 98304;
        /**
         * The default shader that is used if a sprite doesn't have a more specific one.
         *
         * @member {PIXI.Shader}
         */ _this.shader = null;
        _this.properties = null;
        _this.tempMatrix = new _math.Matrix();
        _this.properties = [
            // verticesData
            {
                attributeName: 'aVertexPosition',
                size: 2,
                uploadFunction: _this.uploadVertices,
                offset: 0
            },
            // positionData
            {
                attributeName: 'aPositionCoord',
                size: 2,
                uploadFunction: _this.uploadPosition,
                offset: 0
            },
            // rotationData
            {
                attributeName: 'aRotation',
                size: 1,
                uploadFunction: _this.uploadRotation,
                offset: 0
            },
            // uvsData
            {
                attributeName: 'aTextureCoord',
                size: 2,
                uploadFunction: _this.uploadUvs,
                offset: 0
            },
            // tintData
            {
                attributeName: 'aColor',
                size: 1,
                type: _constants.TYPES.UNSIGNED_BYTE,
                uploadFunction: _this.uploadTint,
                offset: 0
            }
        ];
        _this.shader = _core.Shader.from(vertex, fragment, {
        });
        /**
         * The WebGL state in which this renderer will work.
         *
         * @member {PIXI.State}
         * @readonly
         */ _this.state = _core.State.for2d();
        return _this;
    }
    /**
     * Renders the particle container object.
     *
     * @param {PIXI.ParticleContainer} container - The container to render using this ParticleRenderer
     */ ParticleRenderer2.prototype.render = function(container) {
        var children = container.children;
        var maxSize = container._maxSize;
        var batchSize = container._batchSize;
        var renderer = this.renderer;
        var totalChildren = children.length;
        if (totalChildren === 0) return;
        else if (totalChildren > maxSize && !container.autoResize) totalChildren = maxSize;
        var buffers = container._buffers;
        if (!buffers) buffers = container._buffers = this.generateBuffers(container);
        var baseTexture = children[0]._texture.baseTexture;
        // if the uvs have not updated then no point rendering just yet!
        this.state.blendMode = _utils.correctBlendMode(container.blendMode, baseTexture.alphaMode);
        renderer.state.set(this.state);
        var gl = renderer.gl;
        var m = container.worldTransform.copyTo(this.tempMatrix);
        m.prepend(renderer.globalUniforms.uniforms.projectionMatrix);
        this.shader.uniforms.translationMatrix = m.toArray(true);
        this.shader.uniforms.uColor = _utils.premultiplyRgba(container.tintRgb, container.worldAlpha, this.shader.uniforms.uColor, baseTexture.alphaMode);
        this.shader.uniforms.uSampler = baseTexture;
        this.renderer.shader.bind(this.shader);
        var updateStatic = false;
        // now lets upload and render the buffers..
        for(var i = 0, j = 0; i < totalChildren; i += batchSize, j += 1){
            var amount = totalChildren - i;
            if (amount > batchSize) amount = batchSize;
            if (j >= buffers.length) buffers.push(this._generateOneMoreBuffer(container));
            var buffer = buffers[j];
            // we always upload the dynamic
            buffer.uploadDynamic(children, i, amount);
            var bid = container._bufferUpdateIDs[j] || 0;
            updateStatic = updateStatic || buffer._updateID < bid;
            // we only upload the static content when we have to!
            if (updateStatic) {
                buffer._updateID = container._updateID;
                buffer.uploadStatic(children, i, amount);
            }
            // bind the buffer
            renderer.geometry.bind(buffer.geometry);
            gl.drawElements(gl.TRIANGLES, amount * 6, gl.UNSIGNED_SHORT, 0);
        }
    };
    /**
     * Creates one particle buffer for each child in the container we want to render and updates internal properties
     *
     * @param {PIXI.ParticleContainer} container - The container to render using this ParticleRenderer
     * @return {PIXI.ParticleBuffer[]} The buffers
     * @private
     */ ParticleRenderer2.prototype.generateBuffers = function(container) {
        var buffers = [];
        var size = container._maxSize;
        var batchSize = container._batchSize;
        var dynamicPropertyFlags = container._properties;
        for(var i = 0; i < size; i += batchSize)buffers.push(new ParticleBuffer(this.properties, dynamicPropertyFlags, batchSize));
        return buffers;
    };
    /**
     * Creates one more particle buffer, because container has autoResize feature
     *
     * @param {PIXI.ParticleContainer} container - The container to render using this ParticleRenderer
     * @return {PIXI.ParticleBuffer} generated buffer
     * @private
     */ ParticleRenderer2.prototype._generateOneMoreBuffer = function(container) {
        var batchSize = container._batchSize;
        var dynamicPropertyFlags = container._properties;
        return new ParticleBuffer(this.properties, dynamicPropertyFlags, batchSize);
    };
    /**
     * Uploads the vertices.
     *
     * @param {PIXI.DisplayObject[]} children - the array of display objects to render
     * @param {number} startIndex - the index to start from in the children array
     * @param {number} amount - the amount of children that will have their vertices uploaded
     * @param {number[]} array - The vertices to upload.
     * @param {number} stride - Stride to use for iteration.
     * @param {number} offset - Offset to start at.
     */ ParticleRenderer2.prototype.uploadVertices = function(children, startIndex, amount, array, stride, offset) {
        var w0 = 0;
        var w1 = 0;
        var h0 = 0;
        var h1 = 0;
        for(var i = 0; i < amount; ++i){
            var sprite = children[startIndex + i];
            var texture = sprite._texture;
            var sx = sprite.scale.x;
            var sy = sprite.scale.y;
            var trim = texture.trim;
            var orig = texture.orig;
            if (trim) {
                // if the sprite is trimmed and is not a tilingsprite then we need to add the
                // extra space before transforming the sprite coords..
                w1 = trim.x - sprite.anchor.x * orig.width;
                w0 = w1 + trim.width;
                h1 = trim.y - sprite.anchor.y * orig.height;
                h0 = h1 + trim.height;
            } else {
                w0 = orig.width * (1 - sprite.anchor.x);
                w1 = orig.width * -sprite.anchor.x;
                h0 = orig.height * (1 - sprite.anchor.y);
                h1 = orig.height * -sprite.anchor.y;
            }
            array[offset] = w1 * sx;
            array[offset + 1] = h1 * sy;
            array[offset + stride] = w0 * sx;
            array[offset + stride + 1] = h1 * sy;
            array[offset + stride * 2] = w0 * sx;
            array[offset + stride * 2 + 1] = h0 * sy;
            array[offset + stride * 3] = w1 * sx;
            array[offset + stride * 3 + 1] = h0 * sy;
            offset += stride * 4;
        }
    };
    /**
     * Uploads the position.
     *
     * @param {PIXI.DisplayObject[]} children - the array of display objects to render
     * @param {number} startIndex - the index to start from in the children array
     * @param {number} amount - the amount of children that will have their positions uploaded
     * @param {number[]} array - The vertices to upload.
     * @param {number} stride - Stride to use for iteration.
     * @param {number} offset - Offset to start at.
     */ ParticleRenderer2.prototype.uploadPosition = function(children, startIndex, amount, array, stride, offset) {
        for(var i = 0; i < amount; i++){
            var spritePosition = children[startIndex + i].position;
            array[offset] = spritePosition.x;
            array[offset + 1] = spritePosition.y;
            array[offset + stride] = spritePosition.x;
            array[offset + stride + 1] = spritePosition.y;
            array[offset + stride * 2] = spritePosition.x;
            array[offset + stride * 2 + 1] = spritePosition.y;
            array[offset + stride * 3] = spritePosition.x;
            array[offset + stride * 3 + 1] = spritePosition.y;
            offset += stride * 4;
        }
    };
    /**
     * Uploads the rotation.
     *
     * @param {PIXI.DisplayObject[]} children - the array of display objects to render
     * @param {number} startIndex - the index to start from in the children array
     * @param {number} amount - the amount of children that will have their rotation uploaded
     * @param {number[]} array - The vertices to upload.
     * @param {number} stride - Stride to use for iteration.
     * @param {number} offset - Offset to start at.
     */ ParticleRenderer2.prototype.uploadRotation = function(children, startIndex, amount, array, stride, offset) {
        for(var i = 0; i < amount; i++){
            var spriteRotation = children[startIndex + i].rotation;
            array[offset] = spriteRotation;
            array[offset + stride] = spriteRotation;
            array[offset + stride * 2] = spriteRotation;
            array[offset + stride * 3] = spriteRotation;
            offset += stride * 4;
        }
    };
    /**
     * Uploads the Uvs
     *
     * @param {PIXI.DisplayObject[]} children - the array of display objects to render
     * @param {number} startIndex - the index to start from in the children array
     * @param {number} amount - the amount of children that will have their rotation uploaded
     * @param {number[]} array - The vertices to upload.
     * @param {number} stride - Stride to use for iteration.
     * @param {number} offset - Offset to start at.
     */ ParticleRenderer2.prototype.uploadUvs = function(children, startIndex, amount, array, stride, offset) {
        for(var i = 0; i < amount; ++i){
            var textureUvs = children[startIndex + i]._texture._uvs;
            if (textureUvs) {
                array[offset] = textureUvs.x0;
                array[offset + 1] = textureUvs.y0;
                array[offset + stride] = textureUvs.x1;
                array[offset + stride + 1] = textureUvs.y1;
                array[offset + stride * 2] = textureUvs.x2;
                array[offset + stride * 2 + 1] = textureUvs.y2;
                array[offset + stride * 3] = textureUvs.x3;
                array[offset + stride * 3 + 1] = textureUvs.y3;
                offset += stride * 4;
            } else {
                // TODO you know this can be easier!
                array[offset] = 0;
                array[offset + 1] = 0;
                array[offset + stride] = 0;
                array[offset + stride + 1] = 0;
                array[offset + stride * 2] = 0;
                array[offset + stride * 2 + 1] = 0;
                array[offset + stride * 3] = 0;
                array[offset + stride * 3 + 1] = 0;
                offset += stride * 4;
            }
        }
    };
    /**
     * Uploads the tint.
     *
     * @param {PIXI.DisplayObject[]} children - the array of display objects to render
     * @param {number} startIndex - the index to start from in the children array
     * @param {number} amount - the amount of children that will have their rotation uploaded
     * @param {number[]} array - The vertices to upload.
     * @param {number} stride - Stride to use for iteration.
     * @param {number} offset - Offset to start at.
     */ ParticleRenderer2.prototype.uploadTint = function(children, startIndex, amount, array, stride, offset) {
        for(var i = 0; i < amount; ++i){
            var sprite = children[startIndex + i];
            var premultiplied = sprite._texture.baseTexture.alphaMode > 0;
            var alpha = sprite.alpha;
            // we dont call extra function if alpha is 1.0, that's faster
            var argb = alpha < 1 && premultiplied ? _utils.premultiplyTint(sprite._tintRGB, alpha) : sprite._tintRGB + (alpha * 255 << 24);
            array[offset] = argb;
            array[offset + stride] = argb;
            array[offset + stride * 2] = argb;
            array[offset + stride * 3] = argb;
            offset += stride * 4;
        }
    };
    /**
     * Destroys the ParticleRenderer.
     */ ParticleRenderer2.prototype.destroy = function() {
        _super.prototype.destroy.call(this);
        if (this.shader) {
            this.shader.destroy();
            this.shader = null;
        }
        this.tempMatrix = null;
    };
    return ParticleRenderer2;
}(_core.ObjectRenderer);

},{"@pixi/constants":"lqjFh","@pixi/display":"hQqz5","@pixi/utils":"joR65","@pixi/core":"d0INm","@pixi/math":"1qR3C","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gZ0OT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BasePrepare", ()=>BasePrepare
);
parcelHelpers.export(exports, "CountLimiter", ()=>CountLimiter
);
parcelHelpers.export(exports, "Prepare", ()=>Prepare1
);
parcelHelpers.export(exports, "TimeLimiter", ()=>TimeLimiter
);
/*!
 * @pixi/prepare - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/prepare is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _settings = require("@pixi/settings");
var _core = require("@pixi/core");
var _graphics = require("@pixi/graphics");
var _ticker = require("@pixi/ticker");
var _display = require("@pixi/display");
var _text = require("@pixi/text");
/**
 * Default number of uploads per frame using prepare plugin.
 *
 * @static
 * @memberof PIXI.settings
 * @name UPLOADS_PER_FRAME
 * @type {number}
 * @default 4
 */ _settings.settings.UPLOADS_PER_FRAME = 4;
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * CountLimiter limits the number of items handled by a {@link PIXI.BasePrepare} to a specified
 * number of items per frame.
 *
 * @class
 * @memberof PIXI
 */ var CountLimiter = function() {
    /**
     * @param {number} maxItemsPerFrame - The maximum number of items that can be prepared each frame.
     */ function CountLimiter1(maxItemsPerFrame) {
        /**
         * The maximum number of items that can be prepared each frame.
         * @type {number}
         * @private
         */ this.maxItemsPerFrame = maxItemsPerFrame;
        /**
         * The number of items that can be prepared in the current frame.
         * @type {number}
         * @private
         */ this.itemsLeft = 0;
    }
    /**
     * Resets any counting properties to start fresh on a new frame.
     */ CountLimiter1.prototype.beginFrame = function() {
        this.itemsLeft = this.maxItemsPerFrame;
    };
    /**
     * Checks to see if another item can be uploaded. This should only be called once per item.
     * @return {boolean} If the item is allowed to be uploaded.
     */ CountLimiter1.prototype.allowedToUpload = function() {
        return (this.itemsLeft--) > 0;
    };
    return CountLimiter1;
}();
/**
 * Built-in hook to find multiple textures from objects like AnimatedSprites.
 *
 * @private
 * @param {PIXI.DisplayObject} item - Display object to check
 * @param {Array<*>} queue - Collection of items to upload
 * @return {boolean} if a PIXI.Texture object was found.
 */ function findMultipleBaseTextures(item, queue) {
    var result = false;
    // Objects with multiple textures
    if (item && item._textures && item._textures.length) {
        for(var i = 0; i < item._textures.length; i++)if (item._textures[i] instanceof _core.Texture) {
            var baseTexture = item._textures[i].baseTexture;
            if (queue.indexOf(baseTexture) === -1) {
                queue.push(baseTexture);
                result = true;
            }
        }
    }
    return result;
}
/**
 * Built-in hook to find BaseTextures from Texture.
 *
 * @private
 * @param {PIXI.Texture} item - Display object to check
 * @param {Array<*>} queue - Collection of items to upload
 * @return {boolean} if a PIXI.Texture object was found.
 */ function findBaseTexture(item, queue) {
    if (item.baseTexture instanceof _core.BaseTexture) {
        var texture = item.baseTexture;
        if (queue.indexOf(texture) === -1) queue.push(texture);
        return true;
    }
    return false;
}
/**
 * Built-in hook to find textures from objects.
 *
 * @private
 * @param {PIXI.DisplayObject} item - Display object to check
 * @param {Array<*>} queue - Collection of items to upload
 * @return {boolean} if a PIXI.Texture object was found.
 */ function findTexture(item, queue) {
    if (item._texture && item._texture instanceof _core.Texture) {
        var texture = item._texture.baseTexture;
        if (queue.indexOf(texture) === -1) queue.push(texture);
        return true;
    }
    return false;
}
/**
 * Built-in hook to draw PIXI.Text to its texture.
 *
 * @private
 * @param {PIXI.AbstractRenderer|PIXI.BasePrepare} helper - Not used by this upload handler
 * @param {PIXI.DisplayObject} item - Item to check
 * @return {boolean} If item was uploaded.
 */ function drawText(_helper, item) {
    if (item instanceof _text.Text) {
        // updating text will return early if it is not dirty
        item.updateText(true);
        return true;
    }
    return false;
}
/**
 * Built-in hook to calculate a text style for a PIXI.Text object.
 *
 * @private
 * @param {PIXI.AbstractRenderer|PIXI.BasePrepare} helper - Not used by this upload handler
 * @param {PIXI.DisplayObject} item - Item to check
 * @return {boolean} If item was uploaded.
 */ function calculateTextStyle(_helper, item) {
    if (item instanceof _text.TextStyle) {
        var font = item.toFontString();
        _text.TextMetrics.measureFont(font);
        return true;
    }
    return false;
}
/**
 * Built-in hook to find Text objects.
 *
 * @private
 * @param {PIXI.DisplayObject} item - Display object to check
 * @param {Array<*>} queue - Collection of items to upload
 * @return {boolean} if a PIXI.Text object was found.
 */ function findText(item, queue) {
    if (item instanceof _text.Text) {
        // push the text style to prepare it - this can be really expensive
        if (queue.indexOf(item.style) === -1) queue.push(item.style);
        // also push the text object so that we can render it (to canvas/texture) if needed
        if (queue.indexOf(item) === -1) queue.push(item);
        // also push the Text's texture for upload to GPU
        var texture = item._texture.baseTexture;
        if (queue.indexOf(texture) === -1) queue.push(texture);
        return true;
    }
    return false;
}
/**
 * Built-in hook to find TextStyle objects.
 *
 * @private
 * @param {PIXI.TextStyle} item - Display object to check
 * @param {Array<*>} queue - Collection of items to upload
 * @return {boolean} if a PIXI.TextStyle object was found.
 */ function findTextStyle(item, queue) {
    if (item instanceof _text.TextStyle) {
        if (queue.indexOf(item) === -1) queue.push(item);
        return true;
    }
    return false;
}
/**
 * The prepare manager provides functionality to upload content to the GPU.
 *
 * BasePrepare handles basic queuing functionality and is extended by
 * {@link PIXI.Prepare} and {@link PIXI.CanvasPrepare}
 * to provide preparation capabilities specific to their respective renderers.
 *
 * @example
 * // Create a sprite
 * const sprite = PIXI.Sprite.from('something.png');
 *
 * // Load object into GPU
 * app.renderer.plugins.prepare.upload(sprite, () => {
 *
 *     //Texture(s) has been uploaded to GPU
 *     app.stage.addChild(sprite);
 *
 * })
 *
 * @abstract
 * @class
 * @memberof PIXI
 */ var BasePrepare = function() {
    /**
     * @param {PIXI.AbstractRenderer} renderer - A reference to the current renderer
     */ function BasePrepare1(renderer) {
        var _this = this;
        /**
         * The limiter to be used to control how quickly items are prepared.
         * @type {PIXI.CountLimiter|PIXI.TimeLimiter}
         */ this.limiter = new CountLimiter(_settings.settings.UPLOADS_PER_FRAME);
        /**
         * Reference to the renderer.
         * @type {PIXI.AbstractRenderer}
         * @protected
         */ this.renderer = renderer;
        /**
         * The only real difference between CanvasPrepare and Prepare is what they pass
         * to upload hooks. That different parameter is stored here.
         * @type {object}
         * @protected
         */ this.uploadHookHelper = null;
        /**
         * Collection of items to uploads at once.
         * @type {Array<*>}
         * @private
         */ this.queue = [];
        /**
         * Collection of additional hooks for finding assets.
         * @type {Array<Function>}
         * @private
         */ this.addHooks = [];
        /**
         * Collection of additional hooks for processing assets.
         * @type {Array<Function>}
         * @private
         */ this.uploadHooks = [];
        /**
         * Callback to call after completed.
         * @type {Array<Function>}
         * @private
         */ this.completes = [];
        /**
         * If prepare is ticking (running).
         * @type {boolean}
         * @private
         */ this.ticking = false;
        /**
         * 'bound' call for prepareItems().
         * @type {Function}
         * @private
         */ this.delayedTick = function() {
            // unlikely, but in case we were destroyed between tick() and delayedTick()
            if (!_this.queue) return;
            _this.prepareItems();
        };
        // hooks to find the correct texture
        this.registerFindHook(findText);
        this.registerFindHook(findTextStyle);
        this.registerFindHook(findMultipleBaseTextures);
        this.registerFindHook(findBaseTexture);
        this.registerFindHook(findTexture);
        // upload hooks
        this.registerUploadHook(drawText);
        this.registerUploadHook(calculateTextStyle);
    }
    /**
     * Upload all the textures and graphics to the GPU.
     *
     * @param {Function|PIXI.DisplayObject|PIXI.Container|PIXI.BaseTexture|PIXI.Texture|PIXI.Graphics|PIXI.Text} item -
     *        Either the container or display object to search for items to upload, the items to upload themselves,
     *        or the callback function, if items have been added using `prepare.add`.
     * @param {Function} [done] - Optional callback when all queued uploads have completed
     */ BasePrepare1.prototype.upload = function(item, done) {
        if (typeof item === 'function') {
            done = item;
            item = null;
        }
        // If a display object, search for items
        // that we could upload
        if (item) this.add(item);
        // Get the items for upload from the display
        if (this.queue.length) {
            if (done) this.completes.push(done);
            if (!this.ticking) {
                this.ticking = true;
                _ticker.Ticker.system.addOnce(this.tick, this, _ticker.UPDATE_PRIORITY.UTILITY);
            }
        } else if (done) done();
    };
    /**
     * Handle tick update
     *
     * @private
     */ BasePrepare1.prototype.tick = function() {
        setTimeout(this.delayedTick, 0);
    };
    /**
     * Actually prepare items. This is handled outside of the tick because it will take a while
     * and we do NOT want to block the current animation frame from rendering.
     *
     * @private
     */ BasePrepare1.prototype.prepareItems = function() {
        this.limiter.beginFrame();
        // Upload the graphics
        while(this.queue.length && this.limiter.allowedToUpload()){
            var item = this.queue[0];
            var uploaded = false;
            if (item && !item._destroyed) {
                for(var i = 0, len = this.uploadHooks.length; i < len; i++)if (this.uploadHooks[i](this.uploadHookHelper, item)) {
                    this.queue.shift();
                    uploaded = true;
                    break;
                }
            }
            if (!uploaded) this.queue.shift();
        }
        // We're finished
        if (!this.queue.length) {
            this.ticking = false;
            var completes = this.completes.slice(0);
            this.completes.length = 0;
            for(var i = 0, len = completes.length; i < len; i++)completes[i]();
        } else // if we are not finished, on the next rAF do this again
        _ticker.Ticker.system.addOnce(this.tick, this, _ticker.UPDATE_PRIORITY.UTILITY);
    };
    /**
     * Adds hooks for finding items.
     *
     * @param {Function} addHook - Function call that takes two parameters: `item:*, queue:Array`
     *          function must return `true` if it was able to add item to the queue.
     * @return {this} Instance of plugin for chaining.
     */ BasePrepare1.prototype.registerFindHook = function(addHook) {
        if (addHook) this.addHooks.push(addHook);
        return this;
    };
    /**
     * Adds hooks for uploading items.
     *
     * @param {Function} uploadHook - Function call that takes two parameters: `prepare:CanvasPrepare, item:*` and
     *          function must return `true` if it was able to handle upload of item.
     * @return {this} Instance of plugin for chaining.
     */ BasePrepare1.prototype.registerUploadHook = function(uploadHook) {
        if (uploadHook) this.uploadHooks.push(uploadHook);
        return this;
    };
    /**
     * Manually add an item to the uploading queue.
     *
     * @param {PIXI.DisplayObject|PIXI.Container|PIXI.BaseTexture|PIXI.Texture|PIXI.Graphics|PIXI.Text|*} item - Object to
     *        add to the queue
     * @return {this} Instance of plugin for chaining.
     */ BasePrepare1.prototype.add = function(item) {
        // Add additional hooks for finding elements on special
        // types of objects that
        for(var i = 0, len = this.addHooks.length; i < len; i++){
            if (this.addHooks[i](item, this.queue)) break;
        }
        // Get children recursively
        if (item instanceof _display.Container) for(var i = item.children.length - 1; i >= 0; i--)this.add(item.children[i]);
        return this;
    };
    /**
     * Destroys the plugin, don't use after this.
     *
     */ BasePrepare1.prototype.destroy = function() {
        if (this.ticking) _ticker.Ticker.system.remove(this.tick, this);
        this.ticking = false;
        this.addHooks = null;
        this.uploadHooks = null;
        this.renderer = null;
        this.completes = null;
        this.queue = null;
        this.limiter = null;
        this.uploadHookHelper = null;
    };
    return BasePrepare1;
}();
/**
 * Built-in hook to upload PIXI.Texture objects to the GPU.
 *
 * @private
 * @param {PIXI.Renderer} renderer - instance of the webgl renderer
 * @param {PIXI.BaseTexture} item - Item to check
 * @return {boolean} If item was uploaded.
 */ function uploadBaseTextures(renderer, item) {
    if (item instanceof _core.BaseTexture) {
        // if the texture already has a GL texture, then the texture has been prepared or rendered
        // before now. If the texture changed, then the changer should be calling texture.update() which
        // reuploads the texture without need for preparing it again
        if (!item._glTextures[renderer.CONTEXT_UID]) renderer.texture.bind(item);
        return true;
    }
    return false;
}
/**
 * Built-in hook to upload PIXI.Graphics to the GPU.
 *
 * @private
 * @param {PIXI.Renderer} renderer - instance of the webgl renderer
 * @param {PIXI.DisplayObject} item - Item to check
 * @return {boolean} If item was uploaded.
 */ function uploadGraphics(renderer, item) {
    if (!(item instanceof _graphics.Graphics)) return false;
    var geometry = item.geometry;
    // update dirty graphics to get batches
    item.finishPoly();
    geometry.updateBatches();
    var batches = geometry.batches;
    // upload all textures found in styles
    for(var i = 0; i < batches.length; i++){
        var texture = batches[i].style.texture;
        if (texture) uploadBaseTextures(renderer, texture.baseTexture);
    }
    // if its not batchable - update vao for particular shader
    if (!geometry.batchable) renderer.geometry.bind(geometry, item._resolveDirectShader(renderer));
    return true;
}
/**
 * Built-in hook to find graphics.
 *
 * @private
 * @param {PIXI.DisplayObject} item - Display object to check
 * @param {Array<*>} queue - Collection of items to upload
 * @return {boolean} if a PIXI.Graphics object was found.
 */ function findGraphics(item, queue) {
    if (item instanceof _graphics.Graphics) {
        queue.push(item);
        return true;
    }
    return false;
}
/**
 * The prepare plugin provides renderer-specific plugins for pre-rendering DisplayObjects. These plugins are useful for
 * asynchronously preparing and uploading to the GPU assets, textures, graphics waiting to be displayed.
 *
 * Do not instantiate this plugin directly. It is available from the `renderer.plugins` property.
 * See {@link PIXI.CanvasRenderer#plugins} or {@link PIXI.Renderer#plugins}.
 * @example
 * // Create a new application
 * const app = new PIXI.Application();
 * document.body.appendChild(app.view);
 *
 * // Don't start rendering right away
 * app.stop();
 *
 * // create a display object
 * const rect = new PIXI.Graphics()
 *     .beginFill(0x00ff00)
 *     .drawRect(40, 40, 200, 200);
 *
 * // Add to the stage
 * app.stage.addChild(rect);
 *
 * // Don't start rendering until the graphic is uploaded to the GPU
 * app.renderer.plugins.prepare.upload(app.stage, () => {
 *     app.start();
 * });
 *
 * @class
 * @extends PIXI.BasePrepare
 * @memberof PIXI
 */ var Prepare1 = function(_super) {
    __extends(Prepare2, _super);
    /**
     * @param {PIXI.Renderer} renderer - A reference to the current renderer
     */ function Prepare2(renderer) {
        var _this = _super.call(this, renderer) || this;
        _this.uploadHookHelper = _this.renderer;
        // Add textures and graphics to upload
        _this.registerFindHook(findGraphics);
        _this.registerUploadHook(uploadBaseTextures);
        _this.registerUploadHook(uploadGraphics);
        return _this;
    }
    return Prepare2;
}(BasePrepare);
/**
 * TimeLimiter limits the number of items handled by a {@link PIXI.BasePrepare} to a specified
 * number of milliseconds per frame.
 *
 * @class
 * @memberof PIXI
 */ var TimeLimiter = function() {
    /**
     * @param {number} maxMilliseconds - The maximum milliseconds that can be spent preparing items each frame.
     */ function TimeLimiter1(maxMilliseconds) {
        /**
         * The maximum milliseconds that can be spent preparing items each frame.
         * @type {number}
         * @private
         */ this.maxMilliseconds = maxMilliseconds;
        /**
         * The start time of the current frame.
         * @type {number}
         * @private
         */ this.frameStart = 0;
    }
    /**
     * Resets any counting properties to start fresh on a new frame.
     */ TimeLimiter1.prototype.beginFrame = function() {
        this.frameStart = Date.now();
    };
    /**
     * Checks to see if another item can be uploaded. This should only be called once per item.
     * @return {boolean} If the item is allowed to be uploaded.
     */ TimeLimiter1.prototype.allowedToUpload = function() {
        return Date.now() - this.frameStart < this.maxMilliseconds;
    };
    return TimeLimiter1;
}();

},{"@pixi/settings":"habh9","@pixi/core":"d0INm","@pixi/graphics":"eq7Pq","@pixi/ticker":"5j6Uq","@pixi/display":"hQqz5","@pixi/text":"fmwBo","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eq7Pq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "FillStyle", ()=>FillStyle
);
parcelHelpers.export(exports, "GRAPHICS_CURVES", ()=>GRAPHICS_CURVES
);
parcelHelpers.export(exports, "Graphics", ()=>Graphics1
);
parcelHelpers.export(exports, "GraphicsData", ()=>GraphicsData
);
parcelHelpers.export(exports, "GraphicsGeometry", ()=>GraphicsGeometry1
);
parcelHelpers.export(exports, "LINE_CAP", ()=>LINE_CAP
);
parcelHelpers.export(exports, "LINE_JOIN", ()=>LINE_JOIN
);
parcelHelpers.export(exports, "LineStyle", ()=>LineStyle1
);
parcelHelpers.export(exports, "graphicsUtils", ()=>graphicsUtils
);
/*!
 * @pixi/graphics - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/graphics is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
var _math = require("@pixi/math");
var _utils = require("@pixi/utils");
var _constants = require("@pixi/constants");
var _display = require("@pixi/display");
/**
 * Supported line joints in `PIXI.LineStyle` for graphics.
 *
 * @see PIXI.Graphics#lineStyle
 * @see https://graphicdesign.stackexchange.com/questions/59018/what-is-a-bevel-join-of-two-lines-exactly-illustrator
 *
 * @name LINE_JOIN
 * @memberof PIXI
 * @static
 * @enum {string}
 * @property {string} MITER - 'miter': make a sharp corner where outer part of lines meet
 * @property {string} BEVEL - 'bevel': add a square butt at each end of line segment and fill the triangle at turn
 * @property {string} ROUND - 'round': add an arc at the joint
 */ var LINE_JOIN;
(function(LINE_JOIN1) {
    LINE_JOIN1["MITER"] = "miter";
    LINE_JOIN1["BEVEL"] = "bevel";
    LINE_JOIN1["ROUND"] = "round";
})(LINE_JOIN || (LINE_JOIN = {
}));
/**
 * Support line caps in `PIXI.LineStyle` for graphics.
 *
 * @see PIXI.Graphics#lineStyle
 *
 * @name LINE_CAP
 * @memberof PIXI
 * @static
 * @enum {string}
 * @property {string} BUTT - 'butt': don't add any cap at line ends (leaves orthogonal edges)
 * @property {string} ROUND - 'round': add semicircle at ends
 * @property {string} SQUARE - 'square': add square at end (like `BUTT` except more length at end)
 */ var LINE_CAP;
(function(LINE_CAP1) {
    LINE_CAP1["BUTT"] = "butt";
    LINE_CAP1["ROUND"] = "round";
    LINE_CAP1["SQUARE"] = "square";
})(LINE_CAP || (LINE_CAP = {
}));
/**
 * Graphics curves resolution settings. If `adaptive` flag is set to `true`,
 * the resolution is calculated based on the curve's length to ensure better visual quality.
 * Adaptive draw works with `bezierCurveTo` and `quadraticCurveTo`.
 *
 * @static
 * @constant
 * @memberof PIXI
 * @name GRAPHICS_CURVES
 * @type {object}
 * @property {boolean} adaptive=true - flag indicating if the resolution should be adaptive
 * @property {number} maxLength=10 - maximal length of a single segment of the curve (if adaptive = false, ignored)
 * @property {number} minSegments=8 - minimal number of segments in the curve (if adaptive = false, ignored)
 * @property {number} maxSegments=2048 - maximal number of segments in the curve (if adaptive = false, ignored)
 */ var GRAPHICS_CURVES = {
    adaptive: true,
    maxLength: 10,
    minSegments: 8,
    maxSegments: 2048,
    epsilon: 0.0001,
    _segmentsCount: function(length, defaultSegments) {
        if (defaultSegments === void 0) defaultSegments = 20;
        if (!this.adaptive || !length || isNaN(length)) return defaultSegments;
        var result = Math.ceil(length / this.maxLength);
        if (result < this.minSegments) result = this.minSegments;
        else if (result > this.maxSegments) result = this.maxSegments;
        return result;
    }
};
/**
 * Fill style object for Graphics.
 *
 * @class
 * @memberof PIXI
 */ var FillStyle = function() {
    function FillStyle1() {
        /**
         * The hex color value used when coloring the Graphics object.
         *
         * @default 0xFFFFFF
         */ this.color = 16777215;
        /** The alpha value used when filling the Graphics object. */ this.alpha = 1;
        /**
         * The texture to be used for the fill.
         *
         * @member {PIXI.Texture}
         * @default 0
         */ this.texture = _core.Texture.WHITE;
        /**
         * The transform applied to the texture.
         *
         * @member {PIXI.Matrix}
         * @default null
         */ this.matrix = null;
        /** If the current fill is visible. */ this.visible = false;
        this.reset();
    }
    /**
     * Clones the object
     *
     * @return {PIXI.FillStyle}
     */ FillStyle1.prototype.clone = function() {
        var obj = new FillStyle1();
        obj.color = this.color;
        obj.alpha = this.alpha;
        obj.texture = this.texture;
        obj.matrix = this.matrix;
        obj.visible = this.visible;
        return obj;
    };
    /**
     * Reset
     */ FillStyle1.prototype.reset = function() {
        this.color = 16777215;
        this.alpha = 1;
        this.texture = _core.Texture.WHITE;
        this.matrix = null;
        this.visible = false;
    };
    /**
     * Destroy and don't use after this
     */ FillStyle1.prototype.destroy = function() {
        this.texture = null;
        this.matrix = null;
    };
    return FillStyle1;
}();
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * Builds a polygon to draw
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {PIXI.WebGLGraphicsData} graphicsData - The graphics object containing all the necessary properties
 * @param {object} webGLData - an object containing all the WebGL-specific information to create this shape
 * @param {object} webGLDataNativeLines - an object containing all the WebGL-specific information to create nativeLines
 */ var buildPoly = {
    build: function(graphicsData) {
        graphicsData.points = graphicsData.shape.points.slice();
    },
    triangulate: function(graphicsData, graphicsGeometry) {
        var points = graphicsData.points;
        var holes = graphicsData.holes;
        var verts = graphicsGeometry.points;
        var indices = graphicsGeometry.indices;
        if (points.length >= 6) {
            var holeArray = [];
            // Process holes..
            for(var i = 0; i < holes.length; i++){
                var hole = holes[i];
                holeArray.push(points.length / 2);
                points = points.concat(hole.points);
            }
            // sort color
            var triangles = _utils.earcut(points, holeArray, 2);
            if (!triangles) return;
            var vertPos = verts.length / 2;
            for(var i = 0; i < triangles.length; i += 3){
                indices.push(triangles[i] + vertPos);
                indices.push(triangles[i + 1] + vertPos);
                indices.push(triangles[i + 2] + vertPos);
            }
            for(var i = 0; i < points.length; i++)verts.push(points[i]);
        }
    }
};
// for type only
/**
 * Builds a circle to draw
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {PIXI.WebGLGraphicsData} graphicsData - The graphics object to draw
 * @param {object} webGLData - an object containing all the WebGL-specific information to create this shape
 * @param {object} webGLDataNativeLines - an object containing all the WebGL-specific information to create nativeLines
 */ var buildCircle = {
    build: function(graphicsData) {
        // need to convert points to a nice regular data
        var circleData = graphicsData.shape;
        var points = graphicsData.points;
        var x = circleData.x;
        var y = circleData.y;
        var width;
        var height;
        points.length = 0;
        // TODO - bit hacky??
        if (graphicsData.type === _math.SHAPES.CIRC) {
            width = circleData.radius;
            height = circleData.radius;
        } else {
            var ellipseData = graphicsData.shape;
            width = ellipseData.width;
            height = ellipseData.height;
        }
        if (width === 0 || height === 0) return;
        var totalSegs = Math.floor(30 * Math.sqrt(circleData.radius)) || Math.floor(15 * Math.sqrt(width + height));
        totalSegs /= 2.3;
        var seg = Math.PI * 2 / totalSegs;
        for(var i = 0; i < totalSegs - 0.5; i++)points.push(x + Math.sin(-seg * i) * width, y + Math.cos(-seg * i) * height);
        points.push(points[0], points[1]);
    },
    triangulate: function(graphicsData, graphicsGeometry) {
        var points = graphicsData.points;
        var verts = graphicsGeometry.points;
        var indices = graphicsGeometry.indices;
        var vertPos = verts.length / 2;
        var center = vertPos;
        var circle = graphicsData.shape;
        var matrix = graphicsData.matrix;
        var x = circle.x;
        var y = circle.y;
        // Push center (special point)
        verts.push(graphicsData.matrix ? matrix.a * x + matrix.c * y + matrix.tx : x, graphicsData.matrix ? matrix.b * x + matrix.d * y + matrix.ty : y);
        for(var i = 0; i < points.length; i += 2){
            verts.push(points[i], points[i + 1]);
            // add some uvs
            indices.push(vertPos++, center, vertPos);
        }
    }
};
/**
 * Builds a rectangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {PIXI.WebGLGraphicsData} graphicsData - The graphics object containing all the necessary properties
 * @param {object} webGLData - an object containing all the WebGL-specific information to create this shape
 * @param {object} webGLDataNativeLines - an object containing all the WebGL-specific information to create nativeLines
 */ var buildRectangle = {
    build: function(graphicsData) {
        // --- //
        // need to convert points to a nice regular data
        //
        var rectData = graphicsData.shape;
        var x = rectData.x;
        var y = rectData.y;
        var width = rectData.width;
        var height = rectData.height;
        var points = graphicsData.points;
        points.length = 0;
        points.push(x, y, x + width, y, x + width, y + height, x, y + height);
    },
    triangulate: function(graphicsData, graphicsGeometry) {
        var points = graphicsData.points;
        var verts = graphicsGeometry.points;
        var vertPos = verts.length / 2;
        verts.push(points[0], points[1], points[2], points[3], points[6], points[7], points[4], points[5]);
        graphicsGeometry.indices.push(vertPos, vertPos + 1, vertPos + 2, vertPos + 1, vertPos + 2, vertPos + 3);
    }
};
/**
 * Calculate a single point for a quadratic bezier curve.
 * Utility function used by quadraticBezierCurve.
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {number} n1 - first number
 * @param {number} n2 - second number
 * @param {number} perc - percentage
 * @return {number} the result
 *
 */ function getPt(n1, n2, perc) {
    var diff = n2 - n1;
    return n1 + diff * perc;
}
/**
 * Calculate the points for a quadratic bezier curve. (helper function..)
 * Based on: https://stackoverflow.com/questions/785097/how-do-i-implement-a-bezier-curve-in-c
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {number} fromX - Origin point x
 * @param {number} fromY - Origin point x
 * @param {number} cpX - Control point x
 * @param {number} cpY - Control point y
 * @param {number} toX - Destination point x
 * @param {number} toY - Destination point y
 * @param {number[]} [out=[]] - The output array to add points into. If not passed, a new array is created.
 * @return {number[]} an array of points
 */ function quadraticBezierCurve(fromX, fromY, cpX, cpY, toX, toY, out) {
    if (out === void 0) out = [];
    var n = 20;
    var points = out;
    var xa = 0;
    var ya = 0;
    var xb = 0;
    var yb = 0;
    var x = 0;
    var y = 0;
    for(var i = 0, j = 0; i <= n; ++i){
        j = i / n;
        // The Green Line
        xa = getPt(fromX, cpX, j);
        ya = getPt(fromY, cpY, j);
        xb = getPt(cpX, toX, j);
        yb = getPt(cpY, toY, j);
        // The Black Dot
        x = getPt(xa, xb, j);
        y = getPt(ya, yb, j);
        // Handle case when first curve points overlaps and earcut fails to triangulate
        if (i === 0 && points[points.length - 2] === x && points[points.length - 1] === y) continue;
        points.push(x, y);
    }
    return points;
}
/**
 * Builds a rounded rectangle to draw
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {PIXI.WebGLGraphicsData} graphicsData - The graphics object containing all the necessary properties
 * @param {object} webGLData - an object containing all the WebGL-specific information to create this shape
 * @param {object} webGLDataNativeLines - an object containing all the WebGL-specific information to create nativeLines
 */ var buildRoundedRectangle = {
    build: function(graphicsData) {
        var rrectData = graphicsData.shape;
        var points = graphicsData.points;
        var x = rrectData.x;
        var y = rrectData.y;
        var width = rrectData.width;
        var height = rrectData.height;
        // Don't allow negative radius or greater than half the smallest width
        var radius = Math.max(0, Math.min(rrectData.radius, Math.min(width, height) / 2));
        points.length = 0;
        // No radius, do a simple rectangle
        if (!radius) points.push(x, y, x + width, y, x + width, y + height, x, y + height);
        else {
            quadraticBezierCurve(x, y + radius, x, y, x + radius, y, points);
            quadraticBezierCurve(x + width - radius, y, x + width, y, x + width, y + radius, points);
            quadraticBezierCurve(x + width, y + height - radius, x + width, y + height, x + width - radius, y + height, points);
            quadraticBezierCurve(x + radius, y + height, x, y + height, x, y + height - radius, points);
        }
    },
    triangulate: function(graphicsData, graphicsGeometry) {
        var points = graphicsData.points;
        var verts = graphicsGeometry.points;
        var indices = graphicsGeometry.indices;
        var vecPos = verts.length / 2;
        var triangles = _utils.earcut(points, null, 2);
        for(var i = 0, j = triangles.length; i < j; i += 3){
            indices.push(triangles[i] + vecPos);
            //     indices.push(triangles[i] + vecPos);
            indices.push(triangles[i + 1] + vecPos);
            //   indices.push(triangles[i + 2] + vecPos);
            indices.push(triangles[i + 2] + vecPos);
        }
        for(var i = 0, j = points.length; i < j; i++)verts.push(points[i], points[++i]);
    }
};
/**
 * Buffers vertices to draw a square cap.
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {number} x - X-coord of end point
 * @param {number} y - Y-coord of end point
 * @param {number} nx - X-coord of line normal pointing inside
 * @param {number} ny - Y-coord of line normal pointing inside
 * @param {Array<number>} verts - vertex buffer
 * @returns {}
 */ function square(x, y, nx, ny, innerWeight, outerWeight, clockwise, /* rotation for square (true at left end, false at right end) */ verts) {
    var ix = x - nx * innerWeight;
    var iy = y - ny * innerWeight;
    var ox = x + nx * outerWeight;
    var oy = y + ny * outerWeight;
    /* Rotate nx,ny for extension vector */ var exx;
    var eyy;
    if (clockwise) {
        exx = ny;
        eyy = -nx;
    } else {
        exx = -ny;
        eyy = nx;
    }
    /* [i|0]x,y extended at cap */ var eix = ix + exx;
    var eiy = iy + eyy;
    var eox = ox + exx;
    var eoy = oy + eyy;
    /* Square itself must be inserted clockwise*/ verts.push(eix, eiy);
    verts.push(eox, eoy);
    return 2;
}
/**
 * Buffers vertices to draw an arc at the line joint or cap.
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {number} cx - X-coord of center
 * @param {number} cy - Y-coord of center
 * @param {number} sx - X-coord of arc start
 * @param {number} sy - Y-coord of arc start
 * @param {number} ex - X-coord of arc end
 * @param {number} ey - Y-coord of arc end
 * @param {Array<number>} verts - buffer of vertices
 * @param {boolean} clockwise - orientation of vertices
 * @returns {number} - no. of vertices pushed
 */ function round(cx, cy, sx, sy, ex, ey, verts, clockwise) {
    var cx2p0x = sx - cx;
    var cy2p0y = sy - cy;
    var angle0 = Math.atan2(cx2p0x, cy2p0y);
    var angle1 = Math.atan2(ex - cx, ey - cy);
    if (clockwise && angle0 < angle1) angle0 += Math.PI * 2;
    else if (!clockwise && angle0 > angle1) angle1 += Math.PI * 2;
    var startAngle = angle0;
    var angleDiff = angle1 - angle0;
    var absAngleDiff = Math.abs(angleDiff);
    /* if (absAngleDiff >= PI_LBOUND && absAngleDiff <= PI_UBOUND)
    {
        const r1x = cx - nxtPx;
        const r1y = cy - nxtPy;

        if (r1x === 0)
        {
            if (r1y > 0)
            {
                angleDiff = -angleDiff;
            }
        }
        else if (r1x >= -GRAPHICS_CURVES.epsilon)
        {
            angleDiff = -angleDiff;
        }
    }*/ var radius = Math.sqrt(cx2p0x * cx2p0x + cy2p0y * cy2p0y);
    var segCount = (15 * absAngleDiff * Math.sqrt(radius) / Math.PI >> 0) + 1;
    var angleInc = angleDiff / segCount;
    startAngle += angleInc;
    if (clockwise) {
        verts.push(cx, cy);
        verts.push(sx, sy);
        for(var i = 1, angle = startAngle; i < segCount; i++, angle += angleInc){
            verts.push(cx, cy);
            verts.push(cx + Math.sin(angle) * radius, cy + Math.cos(angle) * radius);
        }
        verts.push(cx, cy);
        verts.push(ex, ey);
    } else {
        verts.push(sx, sy);
        verts.push(cx, cy);
        for(var i = 1, angle = startAngle; i < segCount; i++, angle += angleInc){
            verts.push(cx + Math.sin(angle) * radius, cy + Math.cos(angle) * radius);
            verts.push(cx, cy);
        }
        verts.push(ex, ey);
        verts.push(cx, cy);
    }
    return segCount * 2;
}
/**
 * Builds a line to draw using the polygon method.
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {PIXI.GraphicsData} graphicsData - The graphics object containing all the necessary properties
 * @param {PIXI.GraphicsGeometry} graphicsGeometry - Geometry where to append output
 */ function buildNonNativeLine(graphicsData, graphicsGeometry) {
    var shape = graphicsData.shape;
    var points = graphicsData.points || shape.points.slice();
    var eps = graphicsGeometry.closePointEps;
    if (points.length === 0) return;
    // if the line width is an odd number add 0.5 to align to a whole pixel
    // commenting this out fixes #711 and #1620
    // if (graphicsData.lineWidth%2)
    // {
    //     for (i = 0; i < points.length; i++)
    //     {
    //         points[i] += 0.5;
    //     }
    // }
    var style = graphicsData.lineStyle;
    // get first and last point.. figure out the middle!
    var firstPoint = new _math.Point(points[0], points[1]);
    var lastPoint = new _math.Point(points[points.length - 2], points[points.length - 1]);
    var closedShape = shape.type !== _math.SHAPES.POLY || shape.closeStroke;
    var closedPath = Math.abs(firstPoint.x - lastPoint.x) < eps && Math.abs(firstPoint.y - lastPoint.y) < eps;
    // if the first point is the last point - gonna have issues :)
    if (closedShape) {
        // need to clone as we are going to slightly modify the shape..
        points = points.slice();
        if (closedPath) {
            points.pop();
            points.pop();
            lastPoint.set(points[points.length - 2], points[points.length - 1]);
        }
        var midPointX = (firstPoint.x + lastPoint.x) * 0.5;
        var midPointY = (lastPoint.y + firstPoint.y) * 0.5;
        points.unshift(midPointX, midPointY);
        points.push(midPointX, midPointY);
    }
    var verts = graphicsGeometry.points;
    var length = points.length / 2;
    var indexCount = points.length;
    var indexStart = verts.length / 2;
    // Max. inner and outer width
    var width = style.width / 2;
    var widthSquared = width * width;
    var miterLimitSquared = style.miterLimit * style.miterLimit;
    /* Line segments of interest where (x1,y1) forms the corner. */ var x0 = points[0];
    var y0 = points[1];
    var x1 = points[2];
    var y1 = points[3];
    var x2 = 0;
    var y2 = 0;
    /* perp[?](x|y) = the line normal with magnitude lineWidth. */ var perpx = -(y0 - y1);
    var perpy = x0 - x1;
    var perp1x = 0;
    var perp1y = 0;
    var dist = Math.sqrt(perpx * perpx + perpy * perpy);
    perpx /= dist;
    perpy /= dist;
    perpx *= width;
    perpy *= width;
    var ratio = style.alignment; // 0.5;
    var innerWeight = (1 - ratio) * 2;
    var outerWeight = ratio * 2;
    if (!closedShape) {
        if (style.cap === LINE_CAP.ROUND) indexCount += round(x0 - perpx * (innerWeight - outerWeight) * 0.5, y0 - perpy * (innerWeight - outerWeight) * 0.5, x0 - perpx * innerWeight, y0 - perpy * innerWeight, x0 + perpx * outerWeight, y0 + perpy * outerWeight, verts, true) + 2;
        else if (style.cap === LINE_CAP.SQUARE) indexCount += square(x0, y0, perpx, perpy, innerWeight, outerWeight, true, verts);
    }
    // Push first point (below & above vertices)
    verts.push(x0 - perpx * innerWeight, y0 - perpy * innerWeight);
    verts.push(x0 + perpx * outerWeight, y0 + perpy * outerWeight);
    for(var i = 1; i < length - 1; ++i){
        x0 = points[(i - 1) * 2];
        y0 = points[(i - 1) * 2 + 1];
        x1 = points[i * 2];
        y1 = points[i * 2 + 1];
        x2 = points[(i + 1) * 2];
        y2 = points[(i + 1) * 2 + 1];
        perpx = -(y0 - y1);
        perpy = x0 - x1;
        dist = Math.sqrt(perpx * perpx + perpy * perpy);
        perpx /= dist;
        perpy /= dist;
        perpx *= width;
        perpy *= width;
        perp1x = -(y1 - y2);
        perp1y = x1 - x2;
        dist = Math.sqrt(perp1x * perp1x + perp1y * perp1y);
        perp1x /= dist;
        perp1y /= dist;
        perp1x *= width;
        perp1y *= width;
        /* d[x|y](0|1) = the component displacement between points p(0,1|1,2) */ var dx0 = x1 - x0;
        var dy0 = y0 - y1;
        var dx1 = x1 - x2;
        var dy1 = y2 - y1;
        /* +ve if internal angle counterclockwise, -ve if internal angle clockwise. */ var cross = dy0 * dx1 - dy1 * dx0;
        var clockwise = cross < 0;
        /* Going nearly straight? */ if (Math.abs(cross) < 0.1) {
            verts.push(x1 - perpx * innerWeight, y1 - perpy * innerWeight);
            verts.push(x1 + perpx * outerWeight, y1 + perpy * outerWeight);
            continue;
        }
        /* p[x|y] is the miter point. pdist is the distance between miter point and p1. */ var c1 = (-perpx + x0) * (-perpy + y1) - (-perpx + x1) * (-perpy + y0);
        var c2 = (-perp1x + x2) * (-perp1y + y1) - (-perp1x + x1) * (-perp1y + y2);
        var px = (dx0 * c2 - dx1 * c1) / cross;
        var py = (dy1 * c1 - dy0 * c2) / cross;
        var pdist = (px - x1) * (px - x1) + (py - y1) * (py - y1);
        /* Inner miter point */ var imx = x1 + (px - x1) * innerWeight;
        var imy = y1 + (py - y1) * innerWeight;
        /* Outer miter point */ var omx = x1 - (px - x1) * outerWeight;
        var omy = y1 - (py - y1) * outerWeight;
        /* Is the inside miter point too far away, creating a spike? */ var smallerInsideSegmentSq = Math.min(dx0 * dx0 + dy0 * dy0, dx1 * dx1 + dy1 * dy1);
        var insideWeight = clockwise ? innerWeight : outerWeight;
        var smallerInsideDiagonalSq = smallerInsideSegmentSq + insideWeight * insideWeight * widthSquared;
        var insideMiterOk = pdist <= smallerInsideDiagonalSq;
        if (insideMiterOk) {
            if (style.join === LINE_JOIN.BEVEL || pdist / widthSquared > miterLimitSquared) {
                if (clockwise) /* rotating at inner angle */ {
                    verts.push(imx, imy); // inner miter point
                    verts.push(x1 + perpx * outerWeight, y1 + perpy * outerWeight); // first segment's outer vertex
                    verts.push(imx, imy); // inner miter point
                    verts.push(x1 + perp1x * outerWeight, y1 + perp1y * outerWeight); // second segment's outer vertex
                } else /* rotating at outer angle */ {
                    verts.push(x1 - perpx * innerWeight, y1 - perpy * innerWeight); // first segment's inner vertex
                    verts.push(omx, omy); // outer miter point
                    verts.push(x1 - perp1x * innerWeight, y1 - perp1y * innerWeight); // second segment's outer vertex
                    verts.push(omx, omy); // outer miter point
                }
                indexCount += 2;
            } else if (style.join === LINE_JOIN.ROUND) {
                if (clockwise) /* arc is outside */ {
                    verts.push(imx, imy);
                    verts.push(x1 + perpx * outerWeight, y1 + perpy * outerWeight);
                    indexCount += round(x1, y1, x1 + perpx * outerWeight, y1 + perpy * outerWeight, x1 + perp1x * outerWeight, y1 + perp1y * outerWeight, verts, true) + 4;
                    verts.push(imx, imy);
                    verts.push(x1 + perp1x * outerWeight, y1 + perp1y * outerWeight);
                } else /* arc is inside */ {
                    verts.push(x1 - perpx * innerWeight, y1 - perpy * innerWeight);
                    verts.push(omx, omy);
                    indexCount += round(x1, y1, x1 - perpx * innerWeight, y1 - perpy * innerWeight, x1 - perp1x * innerWeight, y1 - perp1y * innerWeight, verts, false) + 4;
                    verts.push(x1 - perp1x * innerWeight, y1 - perp1y * innerWeight);
                    verts.push(omx, omy);
                }
            } else {
                verts.push(imx, imy);
                verts.push(omx, omy);
            }
        } else {
            verts.push(x1 - perpx * innerWeight, y1 - perpy * innerWeight); // first segment's inner vertex
            verts.push(x1 + perpx * outerWeight, y1 + perpy * outerWeight); // first segment's outer vertex
            if (style.join === LINE_JOIN.BEVEL || pdist / widthSquared > miterLimitSquared) ;
            else if (style.join === LINE_JOIN.ROUND) {
                if (clockwise) indexCount += round(x1, y1, x1 + perpx * outerWeight, y1 + perpy * outerWeight, x1 + perp1x * outerWeight, y1 + perp1y * outerWeight, verts, true) + 2;
                else indexCount += round(x1, y1, x1 - perpx * innerWeight, y1 - perpy * innerWeight, x1 - perp1x * innerWeight, y1 - perp1y * innerWeight, verts, false) + 2;
            } else {
                if (clockwise) {
                    verts.push(omx, omy); // inner miter point
                    verts.push(omx, omy); // inner miter point
                } else {
                    verts.push(imx, imy); // outer miter point
                    verts.push(imx, imy); // outer miter point
                }
                indexCount += 2;
            }
            verts.push(x1 - perp1x * innerWeight, y1 - perp1y * innerWeight); // second segment's inner vertex
            verts.push(x1 + perp1x * outerWeight, y1 + perp1y * outerWeight); // second segment's outer vertex
            indexCount += 2;
        }
    }
    x0 = points[(length - 2) * 2];
    y0 = points[(length - 2) * 2 + 1];
    x1 = points[(length - 1) * 2];
    y1 = points[(length - 1) * 2 + 1];
    perpx = -(y0 - y1);
    perpy = x0 - x1;
    dist = Math.sqrt(perpx * perpx + perpy * perpy);
    perpx /= dist;
    perpy /= dist;
    perpx *= width;
    perpy *= width;
    verts.push(x1 - perpx * innerWeight, y1 - perpy * innerWeight);
    verts.push(x1 + perpx * outerWeight, y1 + perpy * outerWeight);
    if (!closedShape) {
        if (style.cap === LINE_CAP.ROUND) indexCount += round(x1 - perpx * (innerWeight - outerWeight) * 0.5, y1 - perpy * (innerWeight - outerWeight) * 0.5, x1 - perpx * innerWeight, y1 - perpy * innerWeight, x1 + perpx * outerWeight, y1 + perpy * outerWeight, verts, false) + 2;
        else if (style.cap === LINE_CAP.SQUARE) indexCount += square(x1, y1, perpx, perpy, innerWeight, outerWeight, false, verts);
    }
    var indices = graphicsGeometry.indices;
    var eps2 = GRAPHICS_CURVES.epsilon * GRAPHICS_CURVES.epsilon;
    // indices.push(indexStart);
    for(var i = indexStart; i < indexCount + indexStart - 2; ++i){
        x0 = verts[i * 2];
        y0 = verts[i * 2 + 1];
        x1 = verts[(i + 1) * 2];
        y1 = verts[(i + 1) * 2 + 1];
        x2 = verts[(i + 2) * 2];
        y2 = verts[(i + 2) * 2 + 1];
        /* Skip zero area triangles */ if (Math.abs(x0 * (y1 - y2) + x1 * (y2 - y0) + x2 * (y0 - y1)) < eps2) continue;
        indices.push(i, i + 1, i + 2);
    }
}
/**
 * Builds a line to draw using the gl.drawArrays(gl.LINES) method
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {PIXI.GraphicsData} graphicsData - The graphics object containing all the necessary properties
 * @param {PIXI.GraphicsGeometry} graphicsGeometry - Geometry where to append output
 */ function buildNativeLine(graphicsData, graphicsGeometry) {
    var i = 0;
    var shape = graphicsData.shape;
    var points = graphicsData.points || shape.points;
    var closedShape = shape.type !== _math.SHAPES.POLY || shape.closeStroke;
    if (points.length === 0) return;
    var verts = graphicsGeometry.points;
    var indices = graphicsGeometry.indices;
    var length = points.length / 2;
    var startIndex = verts.length / 2;
    var currentIndex = startIndex;
    verts.push(points[0], points[1]);
    for(i = 1; i < length; i++){
        verts.push(points[i * 2], points[i * 2 + 1]);
        indices.push(currentIndex, currentIndex + 1);
        currentIndex++;
    }
    if (closedShape) indices.push(currentIndex, startIndex);
}
/**
 * Builds a line to draw
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {PIXI.GraphicsData} graphicsData - The graphics object containing all the necessary properties
 * @param {PIXI.GraphicsGeometry} graphicsGeometry - Geometry where to append output
 */ function buildLine(graphicsData, graphicsGeometry) {
    if (graphicsData.lineStyle.native) buildNativeLine(graphicsData, graphicsGeometry);
    else buildNonNativeLine(graphicsData, graphicsGeometry);
}
/**
 * Utilities for arc curves
 * @class
 * @private
 */ var ArcUtils = function() {
    function ArcUtils1() {
    }
    /**
     * The arcTo() method creates an arc/curve between two tangents on the canvas.
     *
     * "borrowed" from https://code.google.com/p/fxcanvas/ - thanks google!
     *
     * @private
     * @param {number} x1 - The x-coordinate of the beginning of the arc
     * @param {number} y1 - The y-coordinate of the beginning of the arc
     * @param {number} x2 - The x-coordinate of the end of the arc
     * @param {number} y2 - The y-coordinate of the end of the arc
     * @param {number} radius - The radius of the arc
     * @return {object} If the arc length is valid, return center of circle, radius and other info otherwise `null`.
     */ ArcUtils1.curveTo = function(x1, y1, x2, y2, radius, points) {
        var fromX = points[points.length - 2];
        var fromY = points[points.length - 1];
        var a1 = fromY - y1;
        var b1 = fromX - x1;
        var a2 = y2 - y1;
        var b2 = x2 - x1;
        var mm = Math.abs(a1 * b2 - b1 * a2);
        if (mm < 0.00000001 || radius === 0) {
            if (points[points.length - 2] !== x1 || points[points.length - 1] !== y1) points.push(x1, y1);
            return null;
        }
        var dd = a1 * a1 + b1 * b1;
        var cc = a2 * a2 + b2 * b2;
        var tt = a1 * a2 + b1 * b2;
        var k1 = radius * Math.sqrt(dd) / mm;
        var k2 = radius * Math.sqrt(cc) / mm;
        var j1 = k1 * tt / dd;
        var j2 = k2 * tt / cc;
        var cx = k1 * b2 + k2 * b1;
        var cy = k1 * a2 + k2 * a1;
        var px = b1 * (k2 + j1);
        var py = a1 * (k2 + j1);
        var qx = b2 * (k1 + j2);
        var qy = a2 * (k1 + j2);
        var startAngle = Math.atan2(py - cy, px - cx);
        var endAngle = Math.atan2(qy - cy, qx - cx);
        return {
            cx: cx + x1,
            cy: cy + y1,
            radius: radius,
            startAngle: startAngle,
            endAngle: endAngle,
            anticlockwise: b1 * a2 > b2 * a1
        };
    };
    /* eslint-disable max-len */ /**
     * The arc method creates an arc/curve (used to create circles, or parts of circles).
     *
     * @private
     * @param {number} startX - Start x location of arc
     * @param {number} startY - Start y location of arc
     * @param {number} cx - The x-coordinate of the center of the circle
     * @param {number} cy - The y-coordinate of the center of the circle
     * @param {number} radius - The radius of the circle
     * @param {number} startAngle - The starting angle, in radians (0 is at the 3 o'clock position
     *  of the arc's circle)
     * @param {number} endAngle - The ending angle, in radians
     * @param {boolean} anticlockwise - Specifies whether the drawing should be
     *  counter-clockwise or clockwise. False is default, and indicates clockwise, while true
     *  indicates counter-clockwise.
     * @param {number[]} points - Collection of points to add to
     */ ArcUtils1.arc = function(_startX, _startY, cx, cy, radius, startAngle, endAngle, _anticlockwise, points) {
        var sweep = endAngle - startAngle;
        var n = GRAPHICS_CURVES._segmentsCount(Math.abs(sweep) * radius, Math.ceil(Math.abs(sweep) / _math.PI_2) * 40);
        var theta = sweep / (n * 2);
        var theta2 = theta * 2;
        var cTheta = Math.cos(theta);
        var sTheta = Math.sin(theta);
        var segMinus = n - 1;
        var remainder = segMinus % 1 / segMinus;
        for(var i = 0; i <= segMinus; ++i){
            var real = i + remainder * i;
            var angle = theta + startAngle + theta2 * real;
            var c = Math.cos(angle);
            var s = -Math.sin(angle);
            points.push((cTheta * c + sTheta * s) * radius + cx, (cTheta * -s + sTheta * c) * radius + cy);
        }
    };
    return ArcUtils1;
}();
/**
 * Utilities for bezier curves
 * @class
 * @private
 */ var BezierUtils = function() {
    function BezierUtils1() {
    }
    /**
     * Calculate length of bezier curve.
     * Analytical solution is impossible, since it involves an integral that does not integrate in general.
     * Therefore numerical solution is used.
     *
     * @private
     * @param {number} fromX - Starting point x
     * @param {number} fromY - Starting point y
     * @param {number} cpX - Control point x
     * @param {number} cpY - Control point y
     * @param {number} cpX2 - Second Control point x
     * @param {number} cpY2 - Second Control point y
     * @param {number} toX - Destination point x
     * @param {number} toY - Destination point y
     * @return {number} Length of bezier curve
     */ BezierUtils1.curveLength = function(fromX, fromY, cpX, cpY, cpX2, cpY2, toX, toY) {
        var n = 10;
        var result = 0;
        var t = 0;
        var t2 = 0;
        var t3 = 0;
        var nt = 0;
        var nt2 = 0;
        var nt3 = 0;
        var x = 0;
        var y = 0;
        var dx = 0;
        var dy = 0;
        var prevX = fromX;
        var prevY = fromY;
        for(var i = 1; i <= n; ++i){
            t = i / n;
            t2 = t * t;
            t3 = t2 * t;
            nt = 1 - t;
            nt2 = nt * nt;
            nt3 = nt2 * nt;
            x = nt3 * fromX + 3 * nt2 * t * cpX + 3 * nt * t2 * cpX2 + t3 * toX;
            y = nt3 * fromY + 3 * nt2 * t * cpY + 3 * nt * t2 * cpY2 + t3 * toY;
            dx = prevX - x;
            dy = prevY - y;
            prevX = x;
            prevY = y;
            result += Math.sqrt(dx * dx + dy * dy);
        }
        return result;
    };
    /**
     * Calculate the points for a bezier curve and then draws it.
     *
     * Ignored from docs since it is not directly exposed.
     *
     * @ignore
     * @param {number} cpX - Control point x
     * @param {number} cpY - Control point y
     * @param {number} cpX2 - Second Control point x
     * @param {number} cpY2 - Second Control point y
     * @param {number} toX - Destination point x
     * @param {number} toY - Destination point y
     * @param {number[]} points - Path array to push points into
     */ BezierUtils1.curveTo = function(cpX, cpY, cpX2, cpY2, toX, toY, points) {
        var fromX = points[points.length - 2];
        var fromY = points[points.length - 1];
        points.length -= 2;
        var n = GRAPHICS_CURVES._segmentsCount(BezierUtils1.curveLength(fromX, fromY, cpX, cpY, cpX2, cpY2, toX, toY));
        var dt = 0;
        var dt2 = 0;
        var dt3 = 0;
        var t2 = 0;
        var t3 = 0;
        points.push(fromX, fromY);
        for(var i = 1, j = 0; i <= n; ++i){
            j = i / n;
            dt = 1 - j;
            dt2 = dt * dt;
            dt3 = dt2 * dt;
            t2 = j * j;
            t3 = t2 * j;
            points.push(dt3 * fromX + 3 * dt2 * j * cpX + 3 * dt * t2 * cpX2 + t3 * toX, dt3 * fromY + 3 * dt2 * j * cpY + 3 * dt * t2 * cpY2 + t3 * toY);
        }
    };
    return BezierUtils1;
}();
/**
 * Utilities for quadratic curves
 * @class
 * @private
 */ var QuadraticUtils = function() {
    function QuadraticUtils1() {
    }
    /**
     * Calculate length of quadratic curve
     * @see {@link http://www.malczak.linuxpl.com/blog/quadratic-bezier-curve-length/}
     * for the detailed explanation of math behind this.
     *
     * @private
     * @param {number} fromX - x-coordinate of curve start point
     * @param {number} fromY - y-coordinate of curve start point
     * @param {number} cpX - x-coordinate of curve control point
     * @param {number} cpY - y-coordinate of curve control point
     * @param {number} toX - x-coordinate of curve end point
     * @param {number} toY - y-coordinate of curve end point
     * @return {number} Length of quadratic curve
     */ QuadraticUtils1.curveLength = function(fromX, fromY, cpX, cpY, toX, toY) {
        var ax = fromX - 2 * cpX + toX;
        var ay = fromY - 2 * cpY + toY;
        var bx = 2 * cpX - 2 * fromX;
        var by = 2 * cpY - 2 * fromY;
        var a = 4 * (ax * ax + ay * ay);
        var b = 4 * (ax * bx + ay * by);
        var c = bx * bx + by * by;
        var s = 2 * Math.sqrt(a + b + c);
        var a2 = Math.sqrt(a);
        var a32 = 2 * a * a2;
        var c2 = 2 * Math.sqrt(c);
        var ba = b / a2;
        return (a32 * s + a2 * b * (s - c2) + (4 * c * a - b * b) * Math.log((2 * a2 + ba + s) / (ba + c2))) / (4 * a32);
    };
    /**
     * Calculate the points for a quadratic bezier curve and then draws it.
     * Based on: https://stackoverflow.com/questions/785097/how-do-i-implement-a-bezier-curve-in-c
     *
     * @private
     * @param {number} cpX - Control point x
     * @param {number} cpY - Control point y
     * @param {number} toX - Destination point x
     * @param {number} toY - Destination point y
     * @param {number[]} points - Points to add segments to.
     */ QuadraticUtils1.curveTo = function(cpX, cpY, toX, toY, points) {
        var fromX = points[points.length - 2];
        var fromY = points[points.length - 1];
        var n = GRAPHICS_CURVES._segmentsCount(QuadraticUtils1.curveLength(fromX, fromY, cpX, cpY, toX, toY));
        var xa = 0;
        var ya = 0;
        for(var i = 1; i <= n; ++i){
            var j = i / n;
            xa = fromX + (cpX - fromX) * j;
            ya = fromY + (cpY - fromY) * j;
            points.push(xa + (cpX + (toX - cpX) * j - xa) * j, ya + (cpY + (toY - cpY) * j - ya) * j);
        }
    };
    return QuadraticUtils1;
}();
/**
 * A structure to hold interim batch objects for Graphics.
 * @class
 * @memberof PIXI.graphicsUtils
 */ var BatchPart = function() {
    function BatchPart1() {
        this.reset();
    }
    /**
     * Begin batch part
     *
     * @param {PIXI.FillStyle | PIXI.LineStyle} style
     * @param {number} startIndex
     * @param {number} attribStart
     */ BatchPart1.prototype.begin = function(style, startIndex, attribStart) {
        this.reset();
        this.style = style;
        this.start = startIndex;
        this.attribStart = attribStart;
    };
    /**
     * End batch part
     *
     * @param {number} endIndex
     * @param {number} endAttrib
     */ BatchPart1.prototype.end = function(endIndex, endAttrib) {
        this.attribSize = endAttrib - this.attribStart;
        this.size = endIndex - this.start;
    };
    BatchPart1.prototype.reset = function() {
        this.style = null;
        this.size = 0;
        this.start = 0;
        this.attribStart = 0;
        this.attribSize = 0;
    };
    return BatchPart1;
}();
/**
 * Generalized convenience utilities for Graphics.
 *
 * @namespace graphicsUtils
 * @memberof PIXI
 */ var _a;
/**
 * Map of fill commands for each shape type.
 *
 * @memberof PIXI.graphicsUtils
 * @member {Object} FILL_COMMANDS
 */ var FILL_COMMANDS = (_a = {
}, _a[_math.SHAPES.POLY] = buildPoly, _a[_math.SHAPES.CIRC] = buildCircle, _a[_math.SHAPES.ELIP] = buildCircle, _a[_math.SHAPES.RECT] = buildRectangle, _a[_math.SHAPES.RREC] = buildRoundedRectangle, _a);
/**
 * Batch pool, stores unused batches for preventing allocations.
 *
 * @memberof PIXI.graphicsUtils
 * @member {Array<PIXI.graphicsUtils.BatchPart>} BATCH_POOL
 */ var BATCH_POOL = [];
/**
 * Draw call pool, stores unused draw calls for preventing allocations.
 *
 * @memberof PIXI.graphicsUtils
 * @member {Array<PIXI.BatchDrawCall>} DRAW_CALL_POOL
 */ var DRAW_CALL_POOL = [];
/**
 * Determine if polygon is clockwise or counterclockwise.
 * @see {@link https://stackoverflow.com/questions/1165647}
 *
 * Ignored from docs since it is not directly exposed.
 *
 * @ignore
 * @private
 * @param {Polygon} polygon
 * @return {boolean}
 */ function isPolygonClockwise(polygon) {
    var points = polygon.points;
    var sum = 0;
    for(var i = 0; i < points.length - 2; i += 2)sum += (points[i + 2] - points[i]) * (points[i + 3] + points[i + 1]);
    return sum > 0;
}
/**
 * A class to contain data useful for Graphics objects
 *
 * @class
 * @memberof PIXI
 */ var GraphicsData = function() {
    /**
     *
     * @param {PIXI.Circle|PIXI.Ellipse|PIXI.Polygon|PIXI.Rectangle|PIXI.RoundedRectangle} shape - The shape object to draw.
     * @param {PIXI.FillStyle} [fillStyle] - the width of the line to draw
     * @param {PIXI.LineStyle} [lineStyle] - the color of the line to draw
     * @param {PIXI.Matrix} [matrix] - Transform matrix
     */ function GraphicsData1(shape, fillStyle, lineStyle, matrix) {
        if (fillStyle === void 0) fillStyle = null;
        if (lineStyle === void 0) lineStyle = null;
        if (matrix === void 0) matrix = null;
        /** The collection of points. */ this.points = [];
        /**
         * The collection of holes.
         *
         * @member {PIXI.GraphicsData[]}
         */ this.holes = [];
        /**
         * The shape object to draw.
         * @member {PIXI.Circle|PIXI.Ellipse|PIXI.Polygon|PIXI.Rectangle|PIXI.RoundedRectangle}
         */ this.shape = shape;
        /**
         * The style of the line.
         * @member {PIXI.LineStyle}
         */ this.lineStyle = lineStyle;
        /**
         * The style of the fill.
         * @member {PIXI.FillStyle}
         */ this.fillStyle = fillStyle;
        /**
         * The transform matrix.
         * @member {PIXI.Matrix}
         */ this.matrix = matrix;
        /**
         * The type of the shape, see the Const.Shapes file for all the existing types,
         * @member {number}
         */ this.type = shape.type;
    }
    /**
     * Creates a new GraphicsData object with the same values as this one.
     *
     * @return {PIXI.GraphicsData} Cloned GraphicsData object
     */ GraphicsData1.prototype.clone = function() {
        return new GraphicsData1(this.shape, this.fillStyle, this.lineStyle, this.matrix);
    };
    /**
     * Destroys the Graphics data.
     *
     */ GraphicsData1.prototype.destroy = function() {
        this.shape = null;
        this.holes.length = 0;
        this.holes = null;
        this.points.length = 0;
        this.points = null;
        this.lineStyle = null;
        this.fillStyle = null;
    };
    return GraphicsData1;
}();
var tmpPoint = new _math.Point();
var tmpBounds = new _display.Bounds();
/**
 * The Graphics class contains methods used to draw primitive shapes such as lines, circles and
 * rectangles to the display, and to color and fill them.
 *
 * GraphicsGeometry is designed to not be continually updating the geometry since it's expensive
 * to re-tesselate using **earcut**. Consider using {@link PIXI.Mesh} for this use-case, it's much faster.
 *
 * @class
 * @extends PIXI.BatchGeometry
 * @memberof PIXI
 */ var GraphicsGeometry1 = function(_super) {
    __extends(GraphicsGeometry2, _super);
    // eslint-disable-next-line @typescript-eslint/no-useless-constructor
    function GraphicsGeometry2() {
        var _this = _super.call(this) || this;
        /**
         * Minimal distance between points that are considered different.
         * Affects line tesselation.
         */ _this.closePointEps = 0.0001;
        /** Padding to add to the bounds. */ _this.boundsPadding = 0;
        _this.uvsFloat32 = null;
        _this.indicesUint16 = null;
        _this.batchable = false;
        /** An array of points to draw, 2 numbers per point */ _this.points = [];
        /** The collection of colors */ _this.colors = [];
        /** The UVs collection */ _this.uvs = [];
        /** The indices of the vertices */ _this.indices = [];
        /** Reference to the texture IDs. */ _this.textureIds = [];
        /**
         * The collection of drawn shapes.
         *
         * @member {PIXI.GraphicsData[]}
         */ _this.graphicsData = [];
        /**
         * List of current draw calls drived from the batches.
         *
         * @member {PIXI.BatchDrawCall[]}
         */ _this.drawCalls = [];
        /** Batches need to regenerated if the geometry is updated. */ _this.batchDirty = -1;
        /**
         * Intermediate abstract format sent to batch system.
         * Can be converted to drawCalls or to batchable objects.
         *
         * @member {PIXI.graphicsUtils.BatchPart[]}
         */ _this.batches = [];
        /** Used to detect if the graphics object has changed. */ _this.dirty = 0;
        /** Used to check if the cache is dirty. */ _this.cacheDirty = -1;
        /** Used to detect if we cleared the graphicsData. */ _this.clearDirty = 0;
        /** Index of the last batched shape in the stack of calls. */ _this.shapeIndex = 0;
        /**
         * Cached bounds.
         *
         * @member {PIXI.Bounds}
         */ _this._bounds = new _display.Bounds();
        /** The bounds dirty flag. */ _this.boundsDirty = -1;
        return _this;
    }
    Object.defineProperty(GraphicsGeometry2.prototype, "bounds", {
        /**
         * Get the current bounds of the graphic geometry.
         *
         * @member {PIXI.Bounds}
         * @readonly
         */ get: function() {
            if (this.boundsDirty !== this.dirty) {
                this.boundsDirty = this.dirty;
                this.calculateBounds();
            }
            return this._bounds;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Call if you changed graphicsData manually.
     * Empties all batch buffers.
     */ GraphicsGeometry2.prototype.invalidate = function() {
        this.boundsDirty = -1;
        this.dirty++;
        this.batchDirty++;
        this.shapeIndex = 0;
        this.points.length = 0;
        this.colors.length = 0;
        this.uvs.length = 0;
        this.indices.length = 0;
        this.textureIds.length = 0;
        for(var i = 0; i < this.drawCalls.length; i++){
            this.drawCalls[i].texArray.clear();
            DRAW_CALL_POOL.push(this.drawCalls[i]);
        }
        this.drawCalls.length = 0;
        for(var i = 0; i < this.batches.length; i++){
            var batchPart = this.batches[i];
            batchPart.reset();
            BATCH_POOL.push(batchPart);
        }
        this.batches.length = 0;
    };
    /**
     * Clears the graphics that were drawn to this Graphics object, and resets fill and line style settings.
     *
     * @return {PIXI.GraphicsGeometry} This GraphicsGeometry object. Good for chaining method calls
     */ GraphicsGeometry2.prototype.clear = function() {
        if (this.graphicsData.length > 0) {
            this.invalidate();
            this.clearDirty++;
            this.graphicsData.length = 0;
        }
        return this;
    };
    /**
     * Draws the given shape to this Graphics object. Can be any of Circle, Rectangle, Ellipse, Line or Polygon.
     *
     * @param {PIXI.Circle|PIXI.Ellipse|PIXI.Polygon|PIXI.Rectangle|PIXI.RoundedRectangle} shape - The shape object to draw.
     * @param {PIXI.FillStyle} fillStyle - Defines style of the fill.
     * @param {PIXI.LineStyle} lineStyle - Defines style of the lines.
     * @param {PIXI.Matrix} matrix - Transform applied to the points of the shape.
     * @return {PIXI.GraphicsGeometry} Returns geometry for chaining.
     */ GraphicsGeometry2.prototype.drawShape = function(shape, fillStyle, lineStyle, matrix) {
        if (fillStyle === void 0) fillStyle = null;
        if (lineStyle === void 0) lineStyle = null;
        if (matrix === void 0) matrix = null;
        var data = new GraphicsData(shape, fillStyle, lineStyle, matrix);
        this.graphicsData.push(data);
        this.dirty++;
        return this;
    };
    /**
     * Draws the given shape to this Graphics object. Can be any of Circle, Rectangle, Ellipse, Line or Polygon.
     *
     * @param {PIXI.Circle|PIXI.Ellipse|PIXI.Polygon|PIXI.Rectangle|PIXI.RoundedRectangle} shape - The shape object to draw.
     * @param {PIXI.Matrix} matrix - Transform applied to the points of the shape.
     * @return {PIXI.GraphicsGeometry} Returns geometry for chaining.
     */ GraphicsGeometry2.prototype.drawHole = function(shape, matrix) {
        if (matrix === void 0) matrix = null;
        if (!this.graphicsData.length) return null;
        var data = new GraphicsData(shape, null, null, matrix);
        var lastShape = this.graphicsData[this.graphicsData.length - 1];
        data.lineStyle = lastShape.lineStyle;
        lastShape.holes.push(data);
        this.dirty++;
        return this;
    };
    /**
     * Destroys the GraphicsGeometry object.
     *
     */ GraphicsGeometry2.prototype.destroy = function() {
        _super.prototype.destroy.call(this);
        // destroy each of the GraphicsData objects
        for(var i = 0; i < this.graphicsData.length; ++i)this.graphicsData[i].destroy();
        this.points.length = 0;
        this.points = null;
        this.colors.length = 0;
        this.colors = null;
        this.uvs.length = 0;
        this.uvs = null;
        this.indices.length = 0;
        this.indices = null;
        this.indexBuffer.destroy();
        this.indexBuffer = null;
        this.graphicsData.length = 0;
        this.graphicsData = null;
        this.drawCalls.length = 0;
        this.drawCalls = null;
        this.batches.length = 0;
        this.batches = null;
        this._bounds = null;
    };
    /**
     * Check to see if a point is contained within this geometry.
     *
     * @param {PIXI.IPointData} point - Point to check if it's contained.
     * @return {Boolean} `true` if the point is contained within geometry.
     */ GraphicsGeometry2.prototype.containsPoint = function(point) {
        var graphicsData = this.graphicsData;
        for(var i = 0; i < graphicsData.length; ++i){
            var data = graphicsData[i];
            if (!data.fillStyle.visible) continue;
            // only deal with fills..
            if (data.shape) {
                if (data.matrix) data.matrix.applyInverse(point, tmpPoint);
                else tmpPoint.copyFrom(point);
                if (data.shape.contains(tmpPoint.x, tmpPoint.y)) {
                    var hitHole = false;
                    if (data.holes) for(var i_1 = 0; i_1 < data.holes.length; i_1++){
                        var hole = data.holes[i_1];
                        if (hole.shape.contains(tmpPoint.x, tmpPoint.y)) {
                            hitHole = true;
                            break;
                        }
                    }
                    if (!hitHole) return true;
                }
            }
        }
        return false;
    };
    /**
     * Generates intermediate batch data. Either gets converted to drawCalls
     * or used to convert to batch objects directly by the Graphics object.
     *
     * @param {boolean} [allow32Indices] - Allow using 32-bit indices for preventing artifacts when more that 65535 vertices
     */ GraphicsGeometry2.prototype.updateBatches = function(allow32Indices) {
        if (!this.graphicsData.length) {
            this.batchable = true;
            return;
        }
        if (!this.validateBatching()) return;
        this.cacheDirty = this.dirty;
        var uvs = this.uvs;
        var graphicsData = this.graphicsData;
        var batchPart = null;
        var currentStyle = null;
        if (this.batches.length > 0) {
            batchPart = this.batches[this.batches.length - 1];
            currentStyle = batchPart.style;
        }
        for(var i = this.shapeIndex; i < graphicsData.length; i++){
            this.shapeIndex++;
            var data = graphicsData[i];
            var fillStyle = data.fillStyle;
            var lineStyle = data.lineStyle;
            var command = FILL_COMMANDS[data.type];
            // build out the shapes points..
            command.build(data);
            if (data.matrix) this.transformPoints(data.points, data.matrix);
            for(var j = 0; j < 2; j++){
                var style = j === 0 ? fillStyle : lineStyle;
                if (!style.visible) continue;
                var nextTexture = style.texture.baseTexture;
                var index_1 = this.indices.length;
                var attribIndex = this.points.length / 2;
                nextTexture.wrapMode = _constants.WRAP_MODES.REPEAT;
                if (j === 0) this.processFill(data);
                else this.processLine(data);
                var size = this.points.length / 2 - attribIndex;
                if (size === 0) continue;
                // close batch if style is different
                if (batchPart && !this._compareStyles(currentStyle, style)) {
                    batchPart.end(index_1, attribIndex);
                    batchPart = null;
                }
                // spawn new batch if its first batch or previous was closed
                if (!batchPart) {
                    batchPart = BATCH_POOL.pop() || new BatchPart();
                    batchPart.begin(style, index_1, attribIndex);
                    this.batches.push(batchPart);
                    currentStyle = style;
                }
                this.addUvs(this.points, uvs, style.texture, attribIndex, size, style.matrix);
            }
        }
        var index = this.indices.length;
        var attrib = this.points.length / 2;
        if (batchPart) batchPart.end(index, attrib);
        if (this.batches.length === 0) {
            // there are no visible styles in GraphicsData
            // its possible that someone wants Graphics just for the bounds
            this.batchable = true;
            return;
        }
        // prevent allocation when length is same as buffer
        if (this.indicesUint16 && this.indices.length === this.indicesUint16.length) this.indicesUint16.set(this.indices);
        else {
            var need32 = attrib > 65535 && allow32Indices;
            this.indicesUint16 = need32 ? new Uint32Array(this.indices) : new Uint16Array(this.indices);
        }
        // TODO make this a const..
        this.batchable = this.isBatchable();
        if (this.batchable) this.packBatches();
        else this.buildDrawCalls();
    };
    /**
     * Affinity check
     *
     * @param {PIXI.FillStyle | PIXI.LineStyle} styleA
     * @param {PIXI.FillStyle | PIXI.LineStyle} styleB
     */ GraphicsGeometry2.prototype._compareStyles = function(styleA, styleB) {
        if (!styleA || !styleB) return false;
        if (styleA.texture.baseTexture !== styleB.texture.baseTexture) return false;
        if (styleA.color + styleA.alpha !== styleB.color + styleB.alpha) return false;
        if (!!styleA.native !== !!styleB.native) return false;
        return true;
    };
    /**
     * Test geometry for batching process.
     *
     * @protected
     */ GraphicsGeometry2.prototype.validateBatching = function() {
        if (this.dirty === this.cacheDirty || !this.graphicsData.length) return false;
        for(var i = 0, l = this.graphicsData.length; i < l; i++){
            var data = this.graphicsData[i];
            var fill = data.fillStyle;
            var line = data.lineStyle;
            if (fill && !fill.texture.baseTexture.valid) return false;
            if (line && !line.texture.baseTexture.valid) return false;
        }
        return true;
    };
    /**
     * Offset the indices so that it works with the batcher.
     *
     * @protected
     */ GraphicsGeometry2.prototype.packBatches = function() {
        this.batchDirty++;
        this.uvsFloat32 = new Float32Array(this.uvs);
        var batches = this.batches;
        for(var i = 0, l = batches.length; i < l; i++){
            var batch = batches[i];
            for(var j = 0; j < batch.size; j++){
                var index = batch.start + j;
                this.indicesUint16[index] = this.indicesUint16[index] - batch.attribStart;
            }
        }
    };
    /**
     * Checks to see if this graphics geometry can be batched.
     * Currently it needs to be small enough and not contain any native lines.
     *
     * @protected
     */ GraphicsGeometry2.prototype.isBatchable = function() {
        // prevent heavy mesh batching
        if (this.points.length > 131070) return false;
        var batches = this.batches;
        for(var i = 0; i < batches.length; i++){
            if (batches[i].style.native) return false;
        }
        return this.points.length < GraphicsGeometry2.BATCHABLE_SIZE * 2;
    };
    /**
     * Converts intermediate batches data to drawCalls.
     *
     * @protected
     */ GraphicsGeometry2.prototype.buildDrawCalls = function() {
        var TICK = ++_core.BaseTexture._globalBatch;
        for(var i = 0; i < this.drawCalls.length; i++){
            this.drawCalls[i].texArray.clear();
            DRAW_CALL_POOL.push(this.drawCalls[i]);
        }
        this.drawCalls.length = 0;
        var colors = this.colors;
        var textureIds = this.textureIds;
        var currentGroup = DRAW_CALL_POOL.pop();
        if (!currentGroup) {
            currentGroup = new _core.BatchDrawCall();
            currentGroup.texArray = new _core.BatchTextureArray();
        }
        currentGroup.texArray.count = 0;
        currentGroup.start = 0;
        currentGroup.size = 0;
        currentGroup.type = _constants.DRAW_MODES.TRIANGLES;
        var textureCount = 0;
        var currentTexture = null;
        var textureId = 0;
        var native = false;
        var drawMode = _constants.DRAW_MODES.TRIANGLES;
        var index = 0;
        this.drawCalls.push(currentGroup);
        // TODO - this can be simplified
        for(var i = 0; i < this.batches.length; i++){
            var data = this.batches[i];
            // TODO add some full on MAX_TEXTURE CODE..
            var MAX_TEXTURES = 8;
            // Forced cast for checking `native` without errors
            var style = data.style;
            var nextTexture = style.texture.baseTexture;
            if (native !== !!style.native) {
                native = !!style.native;
                drawMode = native ? _constants.DRAW_MODES.LINES : _constants.DRAW_MODES.TRIANGLES;
                // force the batch to break!
                currentTexture = null;
                textureCount = MAX_TEXTURES;
                TICK++;
            }
            if (currentTexture !== nextTexture) {
                currentTexture = nextTexture;
                if (nextTexture._batchEnabled !== TICK) {
                    if (textureCount === MAX_TEXTURES) {
                        TICK++;
                        textureCount = 0;
                        if (currentGroup.size > 0) {
                            currentGroup = DRAW_CALL_POOL.pop();
                            if (!currentGroup) {
                                currentGroup = new _core.BatchDrawCall();
                                currentGroup.texArray = new _core.BatchTextureArray();
                            }
                            this.drawCalls.push(currentGroup);
                        }
                        currentGroup.start = index;
                        currentGroup.size = 0;
                        currentGroup.texArray.count = 0;
                        currentGroup.type = drawMode;
                    }
                    // TODO add this to the render part..
                    // Hack! Because texture has protected `touched`
                    nextTexture.touched = 1; // touch;
                    nextTexture._batchEnabled = TICK;
                    nextTexture._batchLocation = textureCount;
                    nextTexture.wrapMode = _constants.WRAP_MODES.REPEAT;
                    currentGroup.texArray.elements[currentGroup.texArray.count++] = nextTexture;
                    textureCount++;
                }
            }
            currentGroup.size += data.size;
            index += data.size;
            textureId = nextTexture._batchLocation;
            this.addColors(colors, style.color, style.alpha, data.attribSize, data.attribStart);
            this.addTextureIds(textureIds, textureId, data.attribSize, data.attribStart);
        }
        _core.BaseTexture._globalBatch = TICK;
        // upload..
        // merge for now!
        this.packAttributes();
    };
    /**
     * Packs attributes to single buffer.
     *
     * @protected
     */ GraphicsGeometry2.prototype.packAttributes = function() {
        var verts = this.points;
        var uvs = this.uvs;
        var colors = this.colors;
        var textureIds = this.textureIds;
        // verts are 2 positions.. so we * by 3 as there are 6 properties.. then 4 cos its bytes
        var glPoints = new ArrayBuffer(verts.length * 12);
        var f32 = new Float32Array(glPoints);
        var u32 = new Uint32Array(glPoints);
        var p = 0;
        for(var i = 0; i < verts.length / 2; i++){
            f32[p++] = verts[i * 2];
            f32[p++] = verts[i * 2 + 1];
            f32[p++] = uvs[i * 2];
            f32[p++] = uvs[i * 2 + 1];
            u32[p++] = colors[i];
            f32[p++] = textureIds[i];
        }
        this._buffer.update(glPoints);
        this._indexBuffer.update(this.indicesUint16);
    };
    /**
     * Process fill part of Graphics.
     *
     * @param {PIXI.GraphicsData} data
     * @protected
     */ GraphicsGeometry2.prototype.processFill = function(data) {
        if (data.holes.length) {
            this.processHoles(data.holes);
            buildPoly.triangulate(data, this);
        } else {
            var command = FILL_COMMANDS[data.type];
            command.triangulate(data, this);
        }
    };
    /**
     * Process line part of Graphics.
     *
     * @param {PIXI.GraphicsData} data
     * @protected
     */ GraphicsGeometry2.prototype.processLine = function(data) {
        buildLine(data, this);
        for(var i = 0; i < data.holes.length; i++)buildLine(data.holes[i], this);
    };
    /**
     * Process the holes data.
     *
     * @param {PIXI.GraphicsData[]} holes - Holes to render
     * @protected
     */ GraphicsGeometry2.prototype.processHoles = function(holes) {
        for(var i = 0; i < holes.length; i++){
            var hole = holes[i];
            var command = FILL_COMMANDS[hole.type];
            command.build(hole);
            if (hole.matrix) this.transformPoints(hole.points, hole.matrix);
        }
    };
    /**
     * Update the local bounds of the object. Expensive to use performance-wise.
     *
     * @protected
     */ GraphicsGeometry2.prototype.calculateBounds = function() {
        var bounds = this._bounds;
        var sequenceBounds = tmpBounds;
        var curMatrix = _math.Matrix.IDENTITY;
        this._bounds.clear();
        sequenceBounds.clear();
        for(var i = 0; i < this.graphicsData.length; i++){
            var data = this.graphicsData[i];
            var shape = data.shape;
            var type = data.type;
            var lineStyle = data.lineStyle;
            var nextMatrix = data.matrix || _math.Matrix.IDENTITY;
            var lineWidth = 0;
            if (lineStyle && lineStyle.visible) {
                var alignment = lineStyle.alignment;
                lineWidth = lineStyle.width;
                if (type === _math.SHAPES.POLY) {
                    if (isPolygonClockwise(shape)) lineWidth = lineWidth * (1 - alignment);
                    else lineWidth = lineWidth * alignment;
                } else lineWidth = lineWidth * Math.max(0, alignment);
            }
            if (curMatrix !== nextMatrix) {
                if (!sequenceBounds.isEmpty()) {
                    bounds.addBoundsMatrix(sequenceBounds, curMatrix);
                    sequenceBounds.clear();
                }
                curMatrix = nextMatrix;
            }
            if (type === _math.SHAPES.RECT || type === _math.SHAPES.RREC) {
                var rect = shape;
                sequenceBounds.addFramePad(rect.x, rect.y, rect.x + rect.width, rect.y + rect.height, lineWidth, lineWidth);
            } else if (type === _math.SHAPES.CIRC) {
                var circle = shape;
                sequenceBounds.addFramePad(circle.x, circle.y, circle.x, circle.y, circle.radius + lineWidth, circle.radius + lineWidth);
            } else if (type === _math.SHAPES.ELIP) {
                var ellipse = shape;
                sequenceBounds.addFramePad(ellipse.x, ellipse.y, ellipse.x, ellipse.y, ellipse.width + lineWidth, ellipse.height + lineWidth);
            } else {
                var poly = shape;
                // adding directly to the bounds
                bounds.addVerticesMatrix(curMatrix, poly.points, 0, poly.points.length, lineWidth, lineWidth);
            }
        }
        if (!sequenceBounds.isEmpty()) bounds.addBoundsMatrix(sequenceBounds, curMatrix);
        bounds.pad(this.boundsPadding, this.boundsPadding);
    };
    /**
     * Transform points using matrix.
     *
     * @protected
     * @param {number[]} points - Points to transform
     * @param {PIXI.Matrix} matrix - Transform matrix
     */ GraphicsGeometry2.prototype.transformPoints = function(points, matrix) {
        for(var i = 0; i < points.length / 2; i++){
            var x = points[i * 2];
            var y = points[i * 2 + 1];
            points[i * 2] = matrix.a * x + matrix.c * y + matrix.tx;
            points[i * 2 + 1] = matrix.b * x + matrix.d * y + matrix.ty;
        }
    };
    /**
     * Add colors.
     *
     * @protected
     * @param {number[]} colors - List of colors to add to
     * @param {number} color - Color to add
     * @param {number} alpha - Alpha to use
     * @param {number} size - Number of colors to add
     * @param {number} offset
     */ GraphicsGeometry2.prototype.addColors = function(colors, color, alpha, size, offset) {
        if (offset === void 0) offset = 0;
        // TODO use the premultiply bits Ivan added
        var rgb = (color >> 16) + (color & 65280) + ((color & 255) << 16);
        var rgba = _utils.premultiplyTint(rgb, alpha);
        colors.length = Math.max(colors.length, offset + size);
        for(var i = 0; i < size; i++)colors[offset + i] = rgba;
    };
    /**
     * Add texture id that the shader/fragment wants to use.
     *
     * @protected
     * @param {number[]} textureIds
     * @param {number} id
     * @param {number} size
     * @param {number} offset
     */ GraphicsGeometry2.prototype.addTextureIds = function(textureIds, id, size, offset) {
        if (offset === void 0) offset = 0;
        textureIds.length = Math.max(textureIds.length, offset + size);
        for(var i = 0; i < size; i++)textureIds[offset + i] = id;
    };
    /**
     * Generates the UVs for a shape.
     *
     * @protected
     * @param {number[]} verts - Vertices
     * @param {number[]} uvs - UVs
     * @param {PIXI.Texture} texture - Reference to Texture
     * @param {number} start - Index buffer start index.
     * @param {number} size - The size/length for index buffer.
     * @param {PIXI.Matrix} [matrix] - Optional transform for all points.
     */ GraphicsGeometry2.prototype.addUvs = function(verts, uvs, texture, start, size, matrix) {
        if (matrix === void 0) matrix = null;
        var index = 0;
        var uvsStart = uvs.length;
        var frame = texture.frame;
        while(index < size){
            var x = verts[(start + index) * 2];
            var y = verts[(start + index) * 2 + 1];
            if (matrix) {
                var nx = matrix.a * x + matrix.c * y + matrix.tx;
                y = matrix.b * x + matrix.d * y + matrix.ty;
                x = nx;
            }
            index++;
            uvs.push(x / frame.width, y / frame.height);
        }
        var baseTexture = texture.baseTexture;
        if (frame.width < baseTexture.width || frame.height < baseTexture.height) this.adjustUvs(uvs, texture, uvsStart, size);
    };
    /**
     * Modify uvs array according to position of texture region
     * Does not work with rotated or trimmed textures
     *
     * @param {number[]} uvs - array
     * @param {PIXI.Texture} texture - region
     * @param {number} start - starting index for uvs
     * @param {number} size - how many points to adjust
     */ GraphicsGeometry2.prototype.adjustUvs = function(uvs, texture, start, size) {
        var baseTexture = texture.baseTexture;
        var eps = 0.000001;
        var finish = start + size * 2;
        var frame = texture.frame;
        var scaleX = frame.width / baseTexture.width;
        var scaleY = frame.height / baseTexture.height;
        var offsetX = frame.x / frame.width;
        var offsetY = frame.y / frame.height;
        var minX = Math.floor(uvs[start] + eps);
        var minY = Math.floor(uvs[start + 1] + eps);
        for(var i = start + 2; i < finish; i += 2){
            minX = Math.min(minX, Math.floor(uvs[i] + eps));
            minY = Math.min(minY, Math.floor(uvs[i + 1] + eps));
        }
        offsetX -= minX;
        offsetY -= minY;
        for(var i = start; i < finish; i += 2){
            uvs[i] = (uvs[i] + offsetX) * scaleX;
            uvs[i + 1] = (uvs[i + 1] + offsetY) * scaleY;
        }
    };
    /**
     * The maximum number of points to consider an object "batchable",
     * able to be batched by the renderer's batch system.
\    */ GraphicsGeometry2.BATCHABLE_SIZE = 100;
    return GraphicsGeometry2;
}(_core.BatchGeometry);
/**
 * Represents the line style for Graphics.
 * @memberof PIXI
 * @class
 * @extends PIXI.FillStyle
 */ var LineStyle1 = function(_super) {
    __extends(LineStyle2, _super);
    function LineStyle2() {
        var _this = _super !== null && _super.apply(this, arguments) || this;
        /** The width (thickness) of any lines drawn. */ _this.width = 0;
        /** The alignment of any lines drawn (0.5 = middle, 1 = outer, 0 = inner). WebGL only. */ _this.alignment = 0.5;
        /** If true the lines will be draw using LINES instead of TRIANGLE_STRIP */ _this.native = false;
        /**
         * Line cap style.
         *
         * @member {PIXI.LINE_CAP}
         * @default PIXI.LINE_CAP.BUTT
         */ _this.cap = LINE_CAP.BUTT;
        /**
         * Line join style.
         *
         * @member {PIXI.LINE_JOIN}
         * @default PIXI.LINE_JOIN.MITER
         */ _this.join = LINE_JOIN.MITER;
        /** Miter limit. */ _this.miterLimit = 10;
        return _this;
    }
    /**
     * Clones the object
     *
     * @return {PIXI.LineStyle}
     */ LineStyle2.prototype.clone = function() {
        var obj = new LineStyle2();
        obj.color = this.color;
        obj.alpha = this.alpha;
        obj.texture = this.texture;
        obj.matrix = this.matrix;
        obj.visible = this.visible;
        obj.width = this.width;
        obj.alignment = this.alignment;
        obj.native = this.native;
        obj.cap = this.cap;
        obj.join = this.join;
        obj.miterLimit = this.miterLimit;
        return obj;
    };
    /**
     * Reset the line style to default.
     */ LineStyle2.prototype.reset = function() {
        _super.prototype.reset.call(this);
        // Override default line style color
        this.color = 0;
        this.alignment = 0.5;
        this.width = 0;
        this.native = false;
    };
    return LineStyle2;
}(FillStyle);
var temp = new Float32Array(3);
// a default shaders map used by graphics..
var DEFAULT_SHADERS = {
};
/**
 * The Graphics class is primarily used to render primitive shapes such as lines, circles and
 * rectangles to the display, and to color and fill them.  However, you can also use a Graphics
 * object to build a list of primitives to use as a mask, or as a complex hitArea.
 *
 * Please note that due to legacy naming conventions, the behavior of some functions in this class
 * can be confusing.  Each call to `drawRect()`, `drawPolygon()`, etc. actually stores that primitive
 * in the Geometry class's GraphicsGeometry object for later use in rendering or hit testing - the
 * functions do not directly draw anything to the screen.  Similarly, the `clear()` function doesn't
 * change the screen, it simply resets the list of primitives, which can be useful if you want to
 * rebuild the contents of an existing Graphics object.
 *
 * Once a GraphicsGeometry list is built, you can re-use it in other Geometry objects as
 * an optimization, by passing it into a new Geometry object's constructor.  Because of this
 * ability, it's important to call `destroy()` on Geometry objects once you are done with them, to
 * properly dereference each GraphicsGeometry and prevent memory leaks.
 *
 * @class
 * @extends PIXI.Container
 * @memberof PIXI
 */ var Graphics1 = function(_super) {
    __extends(Graphics2, _super);
    /**
     * @param {PIXI.GraphicsGeometry} [geometry=null] - Geometry to use, if omitted
     *        will create a new GraphicsGeometry instance.
     */ function Graphics2(geometry) {
        if (geometry === void 0) geometry = null;
        var _this = _super.call(this) || this;
        /**
         * Represents the vertex and fragment shaders that processes the geometry and runs on the GPU.
         * Can be shared between multiple Graphics objects.
         *
         * @member {PIXI.Shader}
         */ _this.shader = null;
        /** Renderer plugin for batching */ _this.pluginName = 'batch';
        /**
         * Current path
         *
         * @member {PIXI.Polygon}
         * @readonly
         */ _this.currentPath = null;
        /**
         * A collections of batches! These can be drawn by the renderer batch system.
         *
         * @member {PIXI.IGraphicsBatchElement[]}
         */ _this.batches = [];
        /** Update dirty for limiting calculating tints for batches. */ _this.batchTint = -1;
        /** Update dirty for limiting calculating batches.*/ _this.batchDirty = -1;
        /** Copy of the object vertex data. */ _this.vertexData = null;
        /**
         * Current fill style
         *
         * @member {PIXI.FillStyle}
         */ _this._fillStyle = new FillStyle();
        /**
         * Current line style
         *
         * @member {PIXI.LineStyle}
         */ _this._lineStyle = new LineStyle1();
        /**
         * Current shape transform matrix.
         *
         * @member {PIXI.Matrix}
         */ _this._matrix = null;
        /**  Current hole mode is enabled. */ _this._holeMode = false;
        /**
         * Represents the WebGL state the Graphics required to render, excludes shader and geometry. E.g.,
         * blend mode, culling, depth testing, direction of rendering triangles, backface, etc.
         *
         * @member {PIXI.State}
         */ _this.state = _core.State.for2d();
        _this._geometry = geometry || new GraphicsGeometry1();
        _this._geometry.refCount++;
        /**
         * When cacheAsBitmap is set to true the graphics object will be rendered as if it was a sprite.
         * This is useful if your graphics element does not change often, as it will speed up the rendering
         * of the object in exchange for taking up texture memory. It is also useful if you need the graphics
         * object to be anti-aliased, because it will be rendered using canvas. This is not recommended if
         * you are constantly redrawing the graphics element.
         *
         * @name cacheAsBitmap
         * @member {boolean}
         * @memberof PIXI.Graphics#
         * @default false
         */ _this._transformID = -1;
        // Set default
        _this.tint = 16777215;
        _this.blendMode = _constants.BLEND_MODES.NORMAL;
        return _this;
    }
    Object.defineProperty(Graphics2.prototype, "geometry", {
        /**
         * Includes vertex positions, face indices, normals, colors, UVs, and
         * custom attributes within buffers, reducing the cost of passing all
         * this data to the GPU. Can be shared between multiple Mesh or Graphics objects.
         *
         * @member {PIXI.GraphicsGeometry}
         * @readonly
         */ get: function() {
            return this._geometry;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Creates a new Graphics object with the same values as this one.
     * Note that only the geometry of the object is cloned, not its transform (position,scale,etc)
     *
     * @return {PIXI.Graphics} A clone of the graphics object
     */ Graphics2.prototype.clone = function() {
        this.finishPoly();
        return new Graphics2(this._geometry);
    };
    Object.defineProperty(Graphics2.prototype, "blendMode", {
        get: function() {
            return this.state.blendMode;
        },
        /**
         * The blend mode to be applied to the graphic shape. Apply a value of
         * `PIXI.BLEND_MODES.NORMAL` to reset the blend mode.  Note that, since each
         * primitive in the GraphicsGeometry list is rendered sequentially, modes
         * such as `PIXI.BLEND_MODES.ADD` and `PIXI.BLEND_MODES.MULTIPLY` will
         * be applied per-primitive.
         *
         * @member {number}
         * @default PIXI.BLEND_MODES.NORMAL;
         * @see PIXI.BLEND_MODES
         */ set: function(value) {
            this.state.blendMode = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Graphics2.prototype, "tint", {
        /**
         * The tint applied to each graphic shape. This is a hex value. A value of
         * 0xFFFFFF will remove any tint effect.
         *
         * @member {number}
         * @default 0xFFFFFF
         */ get: function() {
            return this._tint;
        },
        set: function(value) {
            this._tint = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Graphics2.prototype, "fill", {
        /**
         * The current fill style.
         *
         * @member {PIXI.FillStyle}
         * @readonly
         */ get: function() {
            return this._fillStyle;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Graphics2.prototype, "line", {
        /**
         * The current line style.
         *
         * @member {PIXI.LineStyle}
         * @readonly
         */ get: function() {
            return this._lineStyle;
        },
        enumerable: false,
        configurable: true
    });
    Graphics2.prototype.lineStyle = function(options, color, alpha, alignment, native) {
        if (options === void 0) options = null;
        if (color === void 0) color = 0;
        if (alpha === void 0) alpha = 1;
        if (alignment === void 0) alignment = 0.5;
        if (native === void 0) native = false;
        // Support non-object params: (width, color, alpha, alignment, native)
        if (typeof options === 'number') options = {
            width: options,
            color: color,
            alpha: alpha,
            alignment: alignment,
            native: native
        };
        return this.lineTextureStyle(options);
    };
    /**
     * Like line style but support texture for line fill.
     *
     * @param {object} [options] - Collection of options for setting line style.
     * @param {number} [options.width=0] - width of the line to draw, will update the objects stored style
     * @param {PIXI.Texture} [options.texture=PIXI.Texture.WHITE] - Texture to use
     * @param {number} [options.color=0x0] - color of the line to draw, will update the objects stored style.
     *  Default 0xFFFFFF if texture present.
     * @param {number} [options.alpha=1] - alpha of the line to draw, will update the objects stored style
     * @param {PIXI.Matrix} [options.matrix=null] - Texture matrix to transform texture
     * @param {number} [options.alignment=0.5] - alignment of the line to draw, (0 = inner, 0.5 = middle, 1 = outer).
     *        WebGL only.
     * @param {boolean} [options.native=false] - If true the lines will be draw using LINES instead of TRIANGLE_STRIP
     * @param {PIXI.LINE_CAP}[options.cap=PIXI.LINE_CAP.BUTT] - line cap style
     * @param {PIXI.LINE_JOIN}[options.join=PIXI.LINE_JOIN.MITER] - line join style
     * @param {number}[options.miterLimit=10] - miter limit ratio
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.lineTextureStyle = function(options) {
        // Apply defaults
        options = Object.assign({
            width: 0,
            texture: _core.Texture.WHITE,
            color: options && options.texture ? 16777215 : 0,
            alpha: 1,
            matrix: null,
            alignment: 0.5,
            native: false,
            cap: LINE_CAP.BUTT,
            join: LINE_JOIN.MITER,
            miterLimit: 10
        }, options);
        if (this.currentPath) this.startPoly();
        var visible = options.width > 0 && options.alpha > 0;
        if (!visible) this._lineStyle.reset();
        else {
            if (options.matrix) {
                options.matrix = options.matrix.clone();
                options.matrix.invert();
            }
            Object.assign(this._lineStyle, {
                visible: visible
            }, options);
        }
        return this;
    };
    /**
     * Start a polygon object internally
     * @protected
     */ Graphics2.prototype.startPoly = function() {
        if (this.currentPath) {
            var points = this.currentPath.points;
            var len = this.currentPath.points.length;
            if (len > 2) {
                this.drawShape(this.currentPath);
                this.currentPath = new _math.Polygon();
                this.currentPath.closeStroke = false;
                this.currentPath.points.push(points[len - 2], points[len - 1]);
            }
        } else {
            this.currentPath = new _math.Polygon();
            this.currentPath.closeStroke = false;
        }
    };
    /**
     * Finish the polygon object.
     * @protected
     */ Graphics2.prototype.finishPoly = function() {
        if (this.currentPath) {
            if (this.currentPath.points.length > 2) {
                this.drawShape(this.currentPath);
                this.currentPath = null;
            } else this.currentPath.points.length = 0;
        }
    };
    /**
     * Moves the current drawing position to x, y.
     *
     * @param {number} x - the X coordinate to move to
     * @param {number} y - the Y coordinate to move to
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.moveTo = function(x, y) {
        this.startPoly();
        this.currentPath.points[0] = x;
        this.currentPath.points[1] = y;
        return this;
    };
    /**
     * Draws a line using the current line style from the current drawing position to (x, y);
     * The current drawing position is then set to (x, y).
     *
     * @param {number} x - the X coordinate to draw to
     * @param {number} y - the Y coordinate to draw to
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.lineTo = function(x, y) {
        if (!this.currentPath) this.moveTo(0, 0);
        // remove duplicates..
        var points = this.currentPath.points;
        var fromX = points[points.length - 2];
        var fromY = points[points.length - 1];
        if (fromX !== x || fromY !== y) points.push(x, y);
        return this;
    };
    /**
     * Initialize the curve
     *
     * @param {number} [x=0]
     * @param {number} [y=0]
     */ Graphics2.prototype._initCurve = function(x, y) {
        if (x === void 0) x = 0;
        if (y === void 0) y = 0;
        if (this.currentPath) {
            if (this.currentPath.points.length === 0) this.currentPath.points = [
                x,
                y
            ];
        } else this.moveTo(x, y);
    };
    /**
     * Calculate the points for a quadratic bezier curve and then draws it.
     * Based on: https://stackoverflow.com/questions/785097/how-do-i-implement-a-bezier-curve-in-c
     *
     * @param {number} cpX - Control point x
     * @param {number} cpY - Control point y
     * @param {number} toX - Destination point x
     * @param {number} toY - Destination point y
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.quadraticCurveTo = function(cpX, cpY, toX, toY) {
        this._initCurve();
        var points = this.currentPath.points;
        if (points.length === 0) this.moveTo(0, 0);
        QuadraticUtils.curveTo(cpX, cpY, toX, toY, points);
        return this;
    };
    /**
     * Calculate the points for a bezier curve and then draws it.
     *
     * @param {number} cpX - Control point x
     * @param {number} cpY - Control point y
     * @param {number} cpX2 - Second Control point x
     * @param {number} cpY2 - Second Control point y
     * @param {number} toX - Destination point x
     * @param {number} toY - Destination point y
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.bezierCurveTo = function(cpX, cpY, cpX2, cpY2, toX, toY) {
        this._initCurve();
        BezierUtils.curveTo(cpX, cpY, cpX2, cpY2, toX, toY, this.currentPath.points);
        return this;
    };
    /**
     * The arcTo() method creates an arc/curve between two tangents on the canvas.
     *
     * "borrowed" from https://code.google.com/p/fxcanvas/ - thanks google!
     *
     * @param {number} x1 - The x-coordinate of the first tangent point of the arc
     * @param {number} y1 - The y-coordinate of the first tangent point of the arc
     * @param {number} x2 - The x-coordinate of the end of the arc
     * @param {number} y2 - The y-coordinate of the end of the arc
     * @param {number} radius - The radius of the arc
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.arcTo = function(x1, y1, x2, y2, radius) {
        this._initCurve(x1, y1);
        var points = this.currentPath.points;
        var result = ArcUtils.curveTo(x1, y1, x2, y2, radius, points);
        if (result) {
            var cx = result.cx, cy = result.cy, radius_1 = result.radius, startAngle = result.startAngle, endAngle = result.endAngle, anticlockwise = result.anticlockwise;
            this.arc(cx, cy, radius_1, startAngle, endAngle, anticlockwise);
        }
        return this;
    };
    /**
     * The arc method creates an arc/curve (used to create circles, or parts of circles).
     *
     * @param {number} cx - The x-coordinate of the center of the circle
     * @param {number} cy - The y-coordinate of the center of the circle
     * @param {number} radius - The radius of the circle
     * @param {number} startAngle - The starting angle, in radians (0 is at the 3 o'clock position
     *  of the arc's circle)
     * @param {number} endAngle - The ending angle, in radians
     * @param {boolean} [anticlockwise=false] - Specifies whether the drawing should be
     *  counter-clockwise or clockwise. False is default, and indicates clockwise, while true
     *  indicates counter-clockwise.
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.arc = function(cx, cy, radius, startAngle, endAngle, anticlockwise) {
        if (anticlockwise === void 0) anticlockwise = false;
        if (startAngle === endAngle) return this;
        if (!anticlockwise && endAngle <= startAngle) endAngle += _math.PI_2;
        else if (anticlockwise && startAngle <= endAngle) startAngle += _math.PI_2;
        var sweep = endAngle - startAngle;
        if (sweep === 0) return this;
        var startX = cx + Math.cos(startAngle) * radius;
        var startY = cy + Math.sin(startAngle) * radius;
        var eps = this._geometry.closePointEps;
        // If the currentPath exists, take its points. Otherwise call `moveTo` to start a path.
        var points = this.currentPath ? this.currentPath.points : null;
        if (points) {
            // TODO: make a better fix.
            // We check how far our start is from the last existing point
            var xDiff = Math.abs(points[points.length - 2] - startX);
            var yDiff = Math.abs(points[points.length - 1] - startY);
            if (xDiff < eps && yDiff < eps) ;
            else points.push(startX, startY);
        } else {
            this.moveTo(startX, startY);
            points = this.currentPath.points;
        }
        ArcUtils.arc(startX, startY, cx, cy, radius, startAngle, endAngle, anticlockwise, points);
        return this;
    };
    /**
     * Specifies a simple one-color fill that subsequent calls to other Graphics methods
     * (such as lineTo() or drawCircle()) use when drawing.
     *
     * @param {number} [color=0] - the color of the fill
     * @param {number} [alpha=1] - the alpha of the fill
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.beginFill = function(color, alpha) {
        if (color === void 0) color = 0;
        if (alpha === void 0) alpha = 1;
        return this.beginTextureFill({
            texture: _core.Texture.WHITE,
            color: color,
            alpha: alpha
        });
    };
    /**
     * Begin the texture fill
     *
     * @param {object} [options] - Object object.
     * @param {PIXI.Texture} [options.texture=PIXI.Texture.WHITE] - Texture to fill
     * @param {number} [options.color=0xffffff] - Background to fill behind texture
     * @param {number} [options.alpha=1] - Alpha of fill
     * @param {PIXI.Matrix} [options.matrix=null] - Transform matrix
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.beginTextureFill = function(options) {
        // Apply defaults
        options = Object.assign({
            texture: _core.Texture.WHITE,
            color: 16777215,
            alpha: 1,
            matrix: null
        }, options);
        if (this.currentPath) this.startPoly();
        var visible = options.alpha > 0;
        if (!visible) this._fillStyle.reset();
        else {
            if (options.matrix) {
                options.matrix = options.matrix.clone();
                options.matrix.invert();
            }
            Object.assign(this._fillStyle, {
                visible: visible
            }, options);
        }
        return this;
    };
    /**
     * Applies a fill to the lines and shapes that were added since the last call to the beginFill() method.
     *
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.endFill = function() {
        this.finishPoly();
        this._fillStyle.reset();
        return this;
    };
    /**
     * Draws a rectangle shape.
     *
     * @param {number} x - The X coord of the top-left of the rectangle
     * @param {number} y - The Y coord of the top-left of the rectangle
     * @param {number} width - The width of the rectangle
     * @param {number} height - The height of the rectangle
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.drawRect = function(x, y, width, height) {
        return this.drawShape(new _math.Rectangle(x, y, width, height));
    };
    /**
     * Draw a rectangle shape with rounded/beveled corners.
     *
     * @param {number} x - The X coord of the top-left of the rectangle
     * @param {number} y - The Y coord of the top-left of the rectangle
     * @param {number} width - The width of the rectangle
     * @param {number} height - The height of the rectangle
     * @param {number} radius - Radius of the rectangle corners
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.drawRoundedRect = function(x, y, width, height, radius) {
        return this.drawShape(new _math.RoundedRectangle(x, y, width, height, radius));
    };
    /**
     * Draws a circle.
     *
     * @param {number} x - The X coordinate of the center of the circle
     * @param {number} y - The Y coordinate of the center of the circle
     * @param {number} radius - The radius of the circle
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.drawCircle = function(x, y, radius) {
        return this.drawShape(new _math.Circle(x, y, radius));
    };
    /**
     * Draws an ellipse.
     *
     * @param {number} x - The X coordinate of the center of the ellipse
     * @param {number} y - The Y coordinate of the center of the ellipse
     * @param {number} width - The half width of the ellipse
     * @param {number} height - The half height of the ellipse
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.drawEllipse = function(x, y, width, height) {
        return this.drawShape(new _math.Ellipse(x, y, width, height));
    };
    /**
     * Draws a polygon using the given path.
     *
     * @param {number[]|PIXI.Point[]|PIXI.Polygon} path - The path data used to construct the polygon.
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.drawPolygon = function() {
        var arguments$1 = arguments;
        var path = [];
        for(var _i = 0; _i < arguments.length; _i++)path[_i] = arguments$1[_i];
        var points;
        var closeStroke = true; // !!this._fillStyle;
        var poly = path[0];
        // check if data has points..
        if (poly.points) {
            closeStroke = poly.closeStroke;
            points = poly.points;
        } else if (Array.isArray(path[0])) points = path[0];
        else points = path;
        var shape = new _math.Polygon(points);
        shape.closeStroke = closeStroke;
        this.drawShape(shape);
        return this;
    };
    /**
     * Draw any shape.
     *
     * @param {PIXI.Circle|PIXI.Ellipse|PIXI.Polygon|PIXI.Rectangle|PIXI.RoundedRectangle} shape - Shape to draw
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.drawShape = function(shape) {
        if (!this._holeMode) this._geometry.drawShape(shape, this._fillStyle.clone(), this._lineStyle.clone(), this._matrix);
        else this._geometry.drawHole(shape, this._matrix);
        return this;
    };
    /**
     * Clears the graphics that were drawn to this Graphics object, and resets fill and line style settings.
     *
     * @return {PIXI.Graphics} This Graphics object. Good for chaining method calls
     */ Graphics2.prototype.clear = function() {
        this._geometry.clear();
        this._lineStyle.reset();
        this._fillStyle.reset();
        this._boundsID++;
        this._matrix = null;
        this._holeMode = false;
        this.currentPath = null;
        return this;
    };
    /**
     * True if graphics consists of one rectangle, and thus, can be drawn like a Sprite and
     * masked with gl.scissor.
     *
     * @returns {boolean} True if only 1 rect.
     */ Graphics2.prototype.isFastRect = function() {
        var data = this._geometry.graphicsData;
        return data.length === 1 && data[0].shape.type === _math.SHAPES.RECT && !data[0].holes.length && !(data[0].lineStyle.visible && data[0].lineStyle.width);
    };
    /**
     * Renders the object using the WebGL renderer
     *
     * @param {PIXI.Renderer} renderer - The renderer
     */ Graphics2.prototype._render = function(renderer) {
        this.finishPoly();
        var geometry = this._geometry;
        var hasuint32 = renderer.context.supports.uint32Indices;
        // batch part..
        // batch it!
        geometry.updateBatches(hasuint32);
        if (geometry.batchable) {
            if (this.batchDirty !== geometry.batchDirty) this._populateBatches();
            this._renderBatched(renderer);
        } else {
            // no batching...
            renderer.batch.flush();
            this._renderDirect(renderer);
        }
    };
    /** Populating batches for rendering. */ Graphics2.prototype._populateBatches = function() {
        var geometry = this._geometry;
        var blendMode = this.blendMode;
        var len = geometry.batches.length;
        this.batchTint = -1;
        this._transformID = -1;
        this.batchDirty = geometry.batchDirty;
        this.batches.length = len;
        this.vertexData = new Float32Array(geometry.points);
        for(var i = 0; i < len; i++){
            var gI = geometry.batches[i];
            var color = gI.style.color;
            var vertexData = new Float32Array(this.vertexData.buffer, gI.attribStart * 8, gI.attribSize * 2);
            var uvs = new Float32Array(geometry.uvsFloat32.buffer, gI.attribStart * 8, gI.attribSize * 2);
            var indices = new Uint16Array(geometry.indicesUint16.buffer, gI.start * 2, gI.size);
            var batch = {
                vertexData: vertexData,
                blendMode: blendMode,
                indices: indices,
                uvs: uvs,
                _batchRGB: _utils.hex2rgb(color),
                _tintRGB: color,
                _texture: gI.style.texture,
                alpha: gI.style.alpha,
                worldAlpha: 1
            };
            this.batches[i] = batch;
        }
    };
    /**
     * Renders the batches using the BathedRenderer plugin
     *
     * @param {PIXI.Renderer} renderer - The renderer
     */ Graphics2.prototype._renderBatched = function(renderer) {
        if (!this.batches.length) return;
        renderer.batch.setObjectRenderer(renderer.plugins[this.pluginName]);
        this.calculateVertices();
        this.calculateTints();
        for(var i = 0, l = this.batches.length; i < l; i++){
            var batch = this.batches[i];
            batch.worldAlpha = this.worldAlpha * batch.alpha;
            renderer.plugins[this.pluginName].render(batch);
        }
    };
    /**
     * Renders the graphics direct
     *
     * @param {PIXI.Renderer} renderer - The renderer
     */ Graphics2.prototype._renderDirect = function(renderer) {
        var shader = this._resolveDirectShader(renderer);
        var geometry = this._geometry;
        var tint = this.tint;
        var worldAlpha = this.worldAlpha;
        var uniforms = shader.uniforms;
        var drawCalls = geometry.drawCalls;
        // lets set the transfomr
        uniforms.translationMatrix = this.transform.worldTransform;
        // and then lets set the tint..
        uniforms.tint[0] = (tint >> 16 & 255) / 255 * worldAlpha;
        uniforms.tint[1] = (tint >> 8 & 255) / 255 * worldAlpha;
        uniforms.tint[2] = (tint & 255) / 255 * worldAlpha;
        uniforms.tint[3] = worldAlpha;
        // the first draw call, we can set the uniforms of the shader directly here.
        // this means that we can tack advantage of the sync function of pixi!
        // bind and sync uniforms..
        // there is a way to optimise this..
        renderer.shader.bind(shader);
        renderer.geometry.bind(geometry, shader);
        // set state..
        renderer.state.set(this.state);
        // then render the rest of them...
        for(var i = 0, l = drawCalls.length; i < l; i++)this._renderDrawCallDirect(renderer, geometry.drawCalls[i]);
    };
    /**
     * Renders specific DrawCall
     *
     * @param {PIXI.Renderer} renderer
     * @param {PIXI.BatchDrawCall} drawCall
     */ Graphics2.prototype._renderDrawCallDirect = function(renderer, drawCall) {
        var texArray = drawCall.texArray, type = drawCall.type, size = drawCall.size, start = drawCall.start;
        var groupTextureCount = texArray.count;
        for(var j = 0; j < groupTextureCount; j++)renderer.texture.bind(texArray.elements[j], j);
        renderer.geometry.draw(type, size, start);
    };
    /**
     * Resolves shader for direct rendering
     *
     * @param {PIXI.Renderer} renderer - The renderer
     */ Graphics2.prototype._resolveDirectShader = function(renderer) {
        var shader = this.shader;
        var pluginName = this.pluginName;
        if (!shader) {
            // if there is no shader here, we can use the default shader.
            // and that only gets created if we actually need it..
            // but may be more than one plugins for graphics
            if (!DEFAULT_SHADERS[pluginName]) {
                var MAX_TEXTURES = renderer.plugins.batch.MAX_TEXTURES;
                var sampleValues = new Int32Array(MAX_TEXTURES);
                for(var i = 0; i < MAX_TEXTURES; i++)sampleValues[i] = i;
                var uniforms = {
                    tint: new Float32Array([
                        1,
                        1,
                        1,
                        1
                    ]),
                    translationMatrix: new _math.Matrix(),
                    default: _core.UniformGroup.from({
                        uSamplers: sampleValues
                    }, true)
                };
                var program = renderer.plugins[pluginName]._shader.program;
                DEFAULT_SHADERS[pluginName] = new _core.Shader(program, uniforms);
            }
            shader = DEFAULT_SHADERS[pluginName];
        }
        return shader;
    };
    /** Retrieves the bounds of the graphic shape as a rectangle object. */ Graphics2.prototype._calculateBounds = function() {
        this.finishPoly();
        var geometry = this._geometry;
        // skipping when graphics is empty, like a container
        if (!geometry.graphicsData.length) return;
        var _a1 = geometry.bounds, minX = _a1.minX, minY = _a1.minY, maxX = _a1.maxX, maxY = _a1.maxY;
        this._bounds.addFrame(this.transform, minX, minY, maxX, maxY);
    };
    /**
     * Tests if a point is inside this graphics object
     *
     * @param {PIXI.IPointData} point - the point to test
     * @return {boolean} the result of the test
     */ Graphics2.prototype.containsPoint = function(point) {
        this.worldTransform.applyInverse(point, Graphics2._TEMP_POINT);
        return this._geometry.containsPoint(Graphics2._TEMP_POINT);
    };
    /** Recalculate the tint by applying tint to batches using Graphics tint. */ Graphics2.prototype.calculateTints = function() {
        if (this.batchTint !== this.tint) {
            this.batchTint = this.tint;
            var tintRGB = _utils.hex2rgb(this.tint, temp);
            for(var i = 0; i < this.batches.length; i++){
                var batch = this.batches[i];
                var batchTint = batch._batchRGB;
                var r = tintRGB[0] * batchTint[0] * 255;
                var g = tintRGB[1] * batchTint[1] * 255;
                var b = tintRGB[2] * batchTint[2] * 255;
                // TODO Ivan, can this be done in one go?
                var color = (r << 16) + (g << 8) + (b | 0);
                batch._tintRGB = (color >> 16) + (color & 65280) + ((color & 255) << 16);
            }
        }
    };
    /**
     * If there's a transform update or a change to the shape of the
     * geometry, recalculate the vertices.
     */ Graphics2.prototype.calculateVertices = function() {
        var wtID = this.transform._worldID;
        if (this._transformID === wtID) return;
        this._transformID = wtID;
        var wt = this.transform.worldTransform;
        var a = wt.a;
        var b = wt.b;
        var c = wt.c;
        var d = wt.d;
        var tx = wt.tx;
        var ty = wt.ty;
        var data = this._geometry.points; // batch.vertexDataOriginal;
        var vertexData = this.vertexData;
        var count = 0;
        for(var i = 0; i < data.length; i += 2){
            var x = data[i];
            var y = data[i + 1];
            vertexData[count++] = a * x + c * y + tx;
            vertexData[count++] = d * y + b * x + ty;
        }
    };
    /**
     * Closes the current path.
     *
     * @return {PIXI.Graphics} Returns itself.
     */ Graphics2.prototype.closePath = function() {
        var currentPath = this.currentPath;
        if (currentPath) {
            // we don't need to add extra point in the end because buildLine will take care of that
            currentPath.closeStroke = true;
            // ensure that the polygon is completed, and is available for hit detection
            // (even if the graphics is not rendered yet)
            this.finishPoly();
        }
        return this;
    };
    /**
     * Apply a matrix to the positional data.
     *
     * @param {PIXI.Matrix} matrix - Matrix to use for transform current shape.
     * @return {PIXI.Graphics} Returns itself.
     */ Graphics2.prototype.setMatrix = function(matrix) {
        this._matrix = matrix;
        return this;
    };
    /**
     * Begin adding holes to the last draw shape
     * IMPORTANT: holes must be fully inside a shape to work
     * Also weirdness ensues if holes overlap!
     * Ellipses, Circles, Rectangles and Rounded Rectangles cannot be holes or host for holes in CanvasRenderer,
     * please use `moveTo` `lineTo`, `quadraticCurveTo` if you rely on pixi-legacy bundle.
     * @return {PIXI.Graphics} Returns itself.
     */ Graphics2.prototype.beginHole = function() {
        this.finishPoly();
        this._holeMode = true;
        return this;
    };
    /**
     * End adding holes to the last draw shape
     * @return {PIXI.Graphics} Returns itself.
     */ Graphics2.prototype.endHole = function() {
        this.finishPoly();
        this._holeMode = false;
        return this;
    };
    /**
     * Destroys the Graphics object.
     *
     * @param {object|boolean} [options] - Options parameter. A boolean will act as if all
     *  options have been set to that value
     * @param {boolean} [options.children=false] - if set to true, all the children will have
     *  their destroy method called as well. 'options' will be passed on to those calls.
     * @param {boolean} [options.texture=false] - Only used for child Sprites if options.children is set to true
     *  Should it destroy the texture of the child sprite
     * @param {boolean} [options.baseTexture=false] - Only used for child Sprites if options.children is set to true
     *  Should it destroy the base texture of the child sprite
     */ Graphics2.prototype.destroy = function(options) {
        this._geometry.refCount--;
        if (this._geometry.refCount === 0) this._geometry.dispose();
        this._matrix = null;
        this.currentPath = null;
        this._lineStyle.destroy();
        this._lineStyle = null;
        this._fillStyle.destroy();
        this._fillStyle = null;
        this._geometry = null;
        this.shader = null;
        this.vertexData = null;
        this.batches.length = 0;
        this.batches = null;
        _super.prototype.destroy.call(this, options);
    };
    /**
     * Temporary point to use for containsPoint
     *
     * @static
     * @private
     * @member {PIXI.Point}
     */ Graphics2._TEMP_POINT = new _math.Point();
    return Graphics2;
}(_display.Container);
var graphicsUtils = {
    buildPoly: buildPoly,
    buildCircle: buildCircle,
    buildRectangle: buildRectangle,
    buildRoundedRectangle: buildRoundedRectangle,
    buildLine: buildLine,
    ArcUtils: ArcUtils,
    BezierUtils: BezierUtils,
    QuadraticUtils: QuadraticUtils,
    BatchPart: BatchPart,
    FILL_COMMANDS: FILL_COMMANDS,
    BATCH_POOL: BATCH_POOL,
    DRAW_CALL_POOL: DRAW_CALL_POOL
};

},{"@pixi/core":"d0INm","@pixi/math":"1qR3C","@pixi/utils":"joR65","@pixi/constants":"lqjFh","@pixi/display":"hQqz5","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fmwBo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "TEXT_GRADIENT", ()=>TEXT_GRADIENT
);
parcelHelpers.export(exports, "Text", ()=>Text1
);
parcelHelpers.export(exports, "TextMetrics", ()=>TextMetrics1
);
parcelHelpers.export(exports, "TextStyle", ()=>TextStyle
);
/*!
 * @pixi/text - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/text is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _sprite = require("@pixi/sprite");
var _core = require("@pixi/core");
var _settings = require("@pixi/settings");
var _math = require("@pixi/math");
var _utils = require("@pixi/utils");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * Constants that define the type of gradient on text.
 *
 * @static
 * @constant
 * @name TEXT_GRADIENT
 * @memberof PIXI
 * @type {object}
 * @property {number} LINEAR_VERTICAL Vertical gradient
 * @property {number} LINEAR_HORIZONTAL Linear gradient
 */ var TEXT_GRADIENT;
(function(TEXT_GRADIENT1) {
    TEXT_GRADIENT1[TEXT_GRADIENT1["LINEAR_VERTICAL"] = 0] = "LINEAR_VERTICAL";
    TEXT_GRADIENT1[TEXT_GRADIENT1["LINEAR_HORIZONTAL"] = 1] = "LINEAR_HORIZONTAL";
})(TEXT_GRADIENT || (TEXT_GRADIENT = {
}));
// disabling eslint for now, going to rewrite this in v5
var defaultStyle = {
    align: 'left',
    breakWords: false,
    dropShadow: false,
    dropShadowAlpha: 1,
    dropShadowAngle: Math.PI / 6,
    dropShadowBlur: 0,
    dropShadowColor: 'black',
    dropShadowDistance: 5,
    fill: 'black',
    fillGradientType: TEXT_GRADIENT.LINEAR_VERTICAL,
    fillGradientStops: [],
    fontFamily: 'Arial',
    fontSize: 26,
    fontStyle: 'normal',
    fontVariant: 'normal',
    fontWeight: 'normal',
    letterSpacing: 0,
    lineHeight: 0,
    lineJoin: 'miter',
    miterLimit: 10,
    padding: 0,
    stroke: 'black',
    strokeThickness: 0,
    textBaseline: 'alphabetic',
    trim: false,
    whiteSpace: 'pre',
    wordWrap: false,
    wordWrapWidth: 100,
    leading: 0
};
var genericFontFamilies = [
    'serif',
    'sans-serif',
    'monospace',
    'cursive',
    'fantasy',
    'system-ui'
];
/**
 * A TextStyle Object contains information to decorate a Text objects.
 *
 * An instance can be shared between multiple Text objects; then changing the style will update all text objects using it.
 *
 * A tool can be used to generate a text style [here](https://pixijs.io/pixi-text-style).
 *
 * @class
 * @memberof PIXI
 */ var TextStyle = function() {
    /**
     * @param {object} [style] - The style parameters
     * @param {string} [style.align='left'] - Alignment for multiline text ('left', 'center' or 'right'),
     *  does not affect single line text
     * @param {boolean} [style.breakWords=false] - Indicates if lines can be wrapped within words, it
     *  needs wordWrap to be set to true
     * @param {boolean} [style.dropShadow=false] - Set a drop shadow for the text
     * @param {number} [style.dropShadowAlpha=1] - Set alpha for the drop shadow
     * @param {number} [style.dropShadowAngle=Math.PI/6] - Set a angle of the drop shadow
     * @param {number} [style.dropShadowBlur=0] - Set a shadow blur radius
     * @param {string|number} [style.dropShadowColor='black'] - A fill style to be used on the dropshadow e.g 'red', '#00FF00'
     * @param {number} [style.dropShadowDistance=5] - Set a distance of the drop shadow
     * @param {string|string[]|number|number[]|CanvasGradient|CanvasPattern} [style.fill='black'] - A canvas
     *  fillstyle that will be used on the text e.g 'red', '#00FF00'. Can be an array to create a gradient
     *  eg ['#000000','#FFFFFF']
     * {@link https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/fillStyle|MDN}
     * @param {number} [style.fillGradientType=PIXI.TEXT_GRADIENT.LINEAR_VERTICAL] - If fill is an array of colours
     *  to create a gradient, this can change the type/direction of the gradient. See {@link PIXI.TEXT_GRADIENT}
     * @param {number[]} [style.fillGradientStops] - If fill is an array of colours to create a gradient, this array can set
     * the stop points (numbers between 0 and 1) for the color, overriding the default behaviour of evenly spacing them.
     * @param {string|string[]} [style.fontFamily='Arial'] - The font family
     * @param {number|string} [style.fontSize=26] - The font size (as a number it converts to px, but as a string,
     *  equivalents are '26px','20pt','160%' or '1.6em')
     * @param {string} [style.fontStyle='normal'] - The font style ('normal', 'italic' or 'oblique')
     * @param {string} [style.fontVariant='normal'] - The font variant ('normal' or 'small-caps')
     * @param {string} [style.fontWeight='normal'] - The font weight ('normal', 'bold', 'bolder', 'lighter' and '100',
     *  '200', '300', '400', '500', '600', '700', '800' or '900')
     * @param {number} [style.leading=0] - The space between lines
     * @param {number} [style.letterSpacing=0] - The amount of spacing between letters, default is 0
     * @param {number} [style.lineHeight] - The line height, a number that represents the vertical space that a letter uses
     * @param {string} [style.lineJoin='miter'] - The lineJoin property sets the type of corner created, it can resolve
     *      spiked text issues. Possible values "miter" (creates a sharp corner), "round" (creates a round corner) or "bevel"
     *      (creates a squared corner).
     * @param {number} [style.miterLimit=10] - The miter limit to use when using the 'miter' lineJoin mode. This can reduce
     *      or increase the spikiness of rendered text.
     * @param {number} [style.padding=0] - Occasionally some fonts are cropped. Adding some padding will prevent this from
     *     happening by adding padding to all sides of the text.
     * @param {string|number} [style.stroke='black'] - A canvas fillstyle that will be used on the text stroke
     *  e.g 'blue', '#FCFF00'
     * @param {number} [style.strokeThickness=0] - A number that represents the thickness of the stroke.
     *  Default is 0 (no stroke)
     * @param {boolean} [style.trim=false] - Trim transparent borders
     * @param {string} [style.textBaseline='alphabetic'] - The baseline of the text that is rendered.
     * @param {string} [style.whiteSpace='pre'] - Determines whether newlines & spaces are collapsed or preserved "normal"
     *      (collapse, collapse), "pre" (preserve, preserve) | "pre-line" (preserve, collapse). It needs wordWrap to be set to true
     * @param {boolean} [style.wordWrap=false] - Indicates if word wrap should be used
     * @param {number} [style.wordWrapWidth=100] - The width at which text will wrap, it needs wordWrap to be set to true
     */ function TextStyle1(style) {
        this.styleID = 0;
        this.reset();
        deepCopyProperties(this, style, style);
    }
    /**
     * Creates a new TextStyle object with the same values as this one.
     * Note that the only the properties of the object are cloned.
     *
     * @return {PIXI.TextStyle} New cloned TextStyle object
     */ TextStyle1.prototype.clone = function() {
        var clonedProperties = {
        };
        deepCopyProperties(clonedProperties, this, defaultStyle);
        return new TextStyle1(clonedProperties);
    };
    /**
     * Resets all properties to the defaults specified in TextStyle.prototype._default
     */ TextStyle1.prototype.reset = function() {
        deepCopyProperties(this, defaultStyle, defaultStyle);
    };
    Object.defineProperty(TextStyle1.prototype, "align", {
        /**
         * Alignment for multiline text ('left', 'center' or 'right'), does not affect single line text
         *
         * @member {string}
         */ get: function() {
            return this._align;
        },
        set: function(align) {
            if (this._align !== align) {
                this._align = align;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "breakWords", {
        /**
         * Indicates if lines can be wrapped within words, it needs wordWrap to be set to true
         *
         * @member {boolean}
         */ get: function() {
            return this._breakWords;
        },
        set: function(breakWords) {
            if (this._breakWords !== breakWords) {
                this._breakWords = breakWords;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "dropShadow", {
        /**
         * Set a drop shadow for the text
         *
         * @member {boolean}
         */ get: function() {
            return this._dropShadow;
        },
        set: function(dropShadow) {
            if (this._dropShadow !== dropShadow) {
                this._dropShadow = dropShadow;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "dropShadowAlpha", {
        /**
         * Set alpha for the drop shadow
         *
         * @member {number}
         */ get: function() {
            return this._dropShadowAlpha;
        },
        set: function(dropShadowAlpha) {
            if (this._dropShadowAlpha !== dropShadowAlpha) {
                this._dropShadowAlpha = dropShadowAlpha;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "dropShadowAngle", {
        /**
         * Set a angle of the drop shadow
         *
         * @member {number}
         */ get: function() {
            return this._dropShadowAngle;
        },
        set: function(dropShadowAngle) {
            if (this._dropShadowAngle !== dropShadowAngle) {
                this._dropShadowAngle = dropShadowAngle;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "dropShadowBlur", {
        /**
         * Set a shadow blur radius
         *
         * @member {number}
         */ get: function() {
            return this._dropShadowBlur;
        },
        set: function(dropShadowBlur) {
            if (this._dropShadowBlur !== dropShadowBlur) {
                this._dropShadowBlur = dropShadowBlur;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "dropShadowColor", {
        /**
         * A fill style to be used on the dropshadow e.g 'red', '#00FF00'
         *
         * @member {string|number}
         */ get: function() {
            return this._dropShadowColor;
        },
        set: function(dropShadowColor) {
            var outputColor = getColor(dropShadowColor);
            if (this._dropShadowColor !== outputColor) {
                this._dropShadowColor = outputColor;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "dropShadowDistance", {
        /**
         * Set a distance of the drop shadow
         *
         * @member {number}
         */ get: function() {
            return this._dropShadowDistance;
        },
        set: function(dropShadowDistance) {
            if (this._dropShadowDistance !== dropShadowDistance) {
                this._dropShadowDistance = dropShadowDistance;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "fill", {
        /**
         * A canvas fillstyle that will be used on the text e.g 'red', '#00FF00'.
         * Can be an array to create a gradient eg ['#000000','#FFFFFF']
         * {@link https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D/fillStyle|MDN}
         *
         * @member {string|string[]|number|number[]|CanvasGradient|CanvasPattern}
         */ get: function() {
            return this._fill;
        },
        set: function(fill) {
            // TODO: Can't have different types for getter and setter. The getter shouldn't have the number type as
            //       the setter converts to string. See this thread for more details:
            //       https://github.com/microsoft/TypeScript/issues/2521
            // TODO: Not sure if getColor works properly with CanvasGradient and/or CanvasPattern, can't pass in
            //       without casting here.
            var outputColor = getColor(fill);
            if (this._fill !== outputColor) {
                this._fill = outputColor;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "fillGradientType", {
        /**
         * If fill is an array of colours to create a gradient, this can change the type/direction of the gradient.
         * See {@link PIXI.TEXT_GRADIENT}
         *
         * @member {number}
         */ get: function() {
            return this._fillGradientType;
        },
        set: function(fillGradientType) {
            if (this._fillGradientType !== fillGradientType) {
                this._fillGradientType = fillGradientType;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "fillGradientStops", {
        /**
         * If fill is an array of colours to create a gradient, this array can set the stop points
         * (numbers between 0 and 1) for the color, overriding the default behaviour of evenly spacing them.
         *
         * @member {number[]}
         */ get: function() {
            return this._fillGradientStops;
        },
        set: function(fillGradientStops) {
            if (!areArraysEqual(this._fillGradientStops, fillGradientStops)) {
                this._fillGradientStops = fillGradientStops;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "fontFamily", {
        /**
         * The font family
         *
         * @member {string|string[]}
         */ get: function() {
            return this._fontFamily;
        },
        set: function(fontFamily) {
            if (this.fontFamily !== fontFamily) {
                this._fontFamily = fontFamily;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "fontSize", {
        /**
         * The font size
         * (as a number it converts to px, but as a string, equivalents are '26px','20pt','160%' or '1.6em')
         *
         * @member {number|string}
         */ get: function() {
            return this._fontSize;
        },
        set: function(fontSize) {
            if (this._fontSize !== fontSize) {
                this._fontSize = fontSize;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "fontStyle", {
        /**
         * The font style
         * ('normal', 'italic' or 'oblique')
         *
         * @member {string}
         */ get: function() {
            return this._fontStyle;
        },
        set: function(fontStyle) {
            if (this._fontStyle !== fontStyle) {
                this._fontStyle = fontStyle;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "fontVariant", {
        /**
         * The font variant
         * ('normal' or 'small-caps')
         *
         * @member {string}
         */ get: function() {
            return this._fontVariant;
        },
        set: function(fontVariant) {
            if (this._fontVariant !== fontVariant) {
                this._fontVariant = fontVariant;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "fontWeight", {
        /**
         * The font weight
         * ('normal', 'bold', 'bolder', 'lighter' and '100', '200', '300', '400', '500', '600', '700', 800' or '900')
         *
         * @member {string}
         */ get: function() {
            return this._fontWeight;
        },
        set: function(fontWeight) {
            if (this._fontWeight !== fontWeight) {
                this._fontWeight = fontWeight;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "letterSpacing", {
        /**
         * The amount of spacing between letters, default is 0
         *
         * @member {number}
         */ get: function() {
            return this._letterSpacing;
        },
        set: function(letterSpacing) {
            if (this._letterSpacing !== letterSpacing) {
                this._letterSpacing = letterSpacing;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "lineHeight", {
        /**
         * The line height, a number that represents the vertical space that a letter uses
         *
         * @member {number}
         */ get: function() {
            return this._lineHeight;
        },
        set: function(lineHeight) {
            if (this._lineHeight !== lineHeight) {
                this._lineHeight = lineHeight;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "leading", {
        /**
         * The space between lines
         *
         * @member {number}
         */ get: function() {
            return this._leading;
        },
        set: function(leading) {
            if (this._leading !== leading) {
                this._leading = leading;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "lineJoin", {
        /**
         * The lineJoin property sets the type of corner created, it can resolve spiked text issues.
         * Default is 'miter' (creates a sharp corner).
         *
         * @member {string}
         */ get: function() {
            return this._lineJoin;
        },
        set: function(lineJoin) {
            if (this._lineJoin !== lineJoin) {
                this._lineJoin = lineJoin;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "miterLimit", {
        /**
         * The miter limit to use when using the 'miter' lineJoin mode
         * This can reduce or increase the spikiness of rendered text.
         *
         * @member {number}
         */ get: function() {
            return this._miterLimit;
        },
        set: function(miterLimit) {
            if (this._miterLimit !== miterLimit) {
                this._miterLimit = miterLimit;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "padding", {
        /**
         * Occasionally some fonts are cropped. Adding some padding will prevent this from happening
         * by adding padding to all sides of the text.
         *
         * @member {number}
         */ get: function() {
            return this._padding;
        },
        set: function(padding) {
            if (this._padding !== padding) {
                this._padding = padding;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "stroke", {
        /**
         * A canvas fillstyle that will be used on the text stroke
         * e.g 'blue', '#FCFF00'
         *
         * @member {string|number}
         */ get: function() {
            return this._stroke;
        },
        set: function(stroke) {
            // TODO: Can't have different types for getter and setter. The getter shouldn't have the number type as
            //       the setter converts to string. See this thread for more details:
            //       https://github.com/microsoft/TypeScript/issues/2521
            var outputColor = getColor(stroke);
            if (this._stroke !== outputColor) {
                this._stroke = outputColor;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "strokeThickness", {
        /**
         * A number that represents the thickness of the stroke.
         * Default is 0 (no stroke)
         *
         * @member {number}
         */ get: function() {
            return this._strokeThickness;
        },
        set: function(strokeThickness) {
            if (this._strokeThickness !== strokeThickness) {
                this._strokeThickness = strokeThickness;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "textBaseline", {
        /**
         * The baseline of the text that is rendered.
         *
         * @member {string}
         */ get: function() {
            return this._textBaseline;
        },
        set: function(textBaseline) {
            if (this._textBaseline !== textBaseline) {
                this._textBaseline = textBaseline;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "trim", {
        /**
         * Trim transparent borders
         *
         * @member {boolean}
         */ get: function() {
            return this._trim;
        },
        set: function(trim) {
            if (this._trim !== trim) {
                this._trim = trim;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "whiteSpace", {
        /**
         * How newlines and spaces should be handled.
         * Default is 'pre' (preserve, preserve).
         *
         *  value       | New lines     |   Spaces
         *  ---         | ---           |   ---
         * 'normal'     | Collapse      |   Collapse
         * 'pre'        | Preserve      |   Preserve
         * 'pre-line'   | Preserve      |   Collapse
         *
         * @member {string}
         */ get: function() {
            return this._whiteSpace;
        },
        set: function(whiteSpace) {
            if (this._whiteSpace !== whiteSpace) {
                this._whiteSpace = whiteSpace;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "wordWrap", {
        /**
         * Indicates if word wrap should be used
         *
         * @member {boolean}
         */ get: function() {
            return this._wordWrap;
        },
        set: function(wordWrap) {
            if (this._wordWrap !== wordWrap) {
                this._wordWrap = wordWrap;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TextStyle1.prototype, "wordWrapWidth", {
        /**
         * The width at which text will wrap, it needs wordWrap to be set to true
         *
         * @member {number}
         */ get: function() {
            return this._wordWrapWidth;
        },
        set: function(wordWrapWidth) {
            if (this._wordWrapWidth !== wordWrapWidth) {
                this._wordWrapWidth = wordWrapWidth;
                this.styleID++;
            }
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Generates a font style string to use for `TextMetrics.measureFont()`.
     *
     * @return {string} Font style string, for passing to `TextMetrics.measureFont()`
     */ TextStyle1.prototype.toFontString = function() {
        // build canvas api font setting from individual components. Convert a numeric this.fontSize to px
        var fontSizeString = typeof this.fontSize === 'number' ? this.fontSize + "px" : this.fontSize;
        // Clean-up fontFamily property by quoting each font name
        // this will support font names with spaces
        var fontFamilies = this.fontFamily;
        if (!Array.isArray(this.fontFamily)) fontFamilies = this.fontFamily.split(',');
        for(var i = fontFamilies.length - 1; i >= 0; i--){
            // Trim any extra white-space
            var fontFamily = fontFamilies[i].trim();
            // Check if font already contains strings
            if (!/([\"\'])[^\'\"]+\1/.test(fontFamily) && genericFontFamilies.indexOf(fontFamily) < 0) fontFamily = "\"" + fontFamily + "\"";
            fontFamilies[i] = fontFamily;
        }
        return this.fontStyle + " " + this.fontVariant + " " + this.fontWeight + " " + fontSizeString + " " + fontFamilies.join(',');
    };
    return TextStyle1;
}();
/**
 * Utility function to convert hexadecimal colors to strings, and simply return the color if it's a string.
 * @private
 * @param {string|number} color
 * @return {string} The color as a string.
 */ function getSingleColor(color) {
    if (typeof color === 'number') return _utils.hex2string(color);
    else if (typeof color === 'string') {
        if (color.indexOf('0x') === 0) color = color.replace('0x', '#');
    }
    return color;
}
function getColor(color) {
    if (!Array.isArray(color)) return getSingleColor(color);
    else {
        for(var i = 0; i < color.length; ++i)color[i] = getSingleColor(color[i]);
        return color;
    }
}
/**
 * Utility function to convert hexadecimal colors to strings, and simply return the color if it's a string.
 * This version can also convert array of colors
 * @private
 * @param {Array} array1 - First array to compare
 * @param {Array} array2 - Second array to compare
 * @return {boolean} Do the arrays contain the same values in the same order
 */ function areArraysEqual(array1, array2) {
    if (!Array.isArray(array1) || !Array.isArray(array2)) return false;
    if (array1.length !== array2.length) return false;
    for(var i = 0; i < array1.length; ++i){
        if (array1[i] !== array2[i]) return false;
    }
    return true;
}
/**
 * Utility function to ensure that object properties are copied by value, and not by reference
 * @private
 * @param {Object} target - Target object to copy properties into
 * @param {Object} source - Source object for the properties to copy
 * @param {string} propertyObj - Object containing properties names we want to loop over
 */ function deepCopyProperties(target, source, propertyObj) {
    for(var prop in propertyObj)if (Array.isArray(source[prop])) target[prop] = source[prop].slice();
    else target[prop] = source[prop];
}
/**
 * The TextMetrics object represents the measurement of a block of text with a specified style.
 *
 * ```js
 * let style = new PIXI.TextStyle({fontFamily : 'Arial', fontSize: 24, fill : 0xff1010, align : 'center'})
 * let textMetrics = PIXI.TextMetrics.measureText('Your text', style)
 * ```
 *
 * @class
 * @memberof PIXI
 */ var TextMetrics1 = function() {
    /**
     * @param {string} text - the text that was measured
     * @param {PIXI.TextStyle} style - the style that was measured
     * @param {number} width - the measured width of the text
     * @param {number} height - the measured height of the text
     * @param {string[]} lines - an array of the lines of text broken by new lines and wrapping if specified in style
     * @param {number[]} lineWidths - an array of the line widths for each line matched to `lines`
     * @param {number} lineHeight - the measured line height for this style
     * @param {number} maxLineWidth - the maximum line width for all measured lines
     * @param {Object} fontProperties - the font properties object from TextMetrics.measureFont
     */ function TextMetrics2(text, style, width, height, lines, lineWidths, lineHeight, maxLineWidth, fontProperties) {
        /**
         * The text that was measured
         *
         * @member {string}
         */ this.text = text;
        /**
         * The style that was measured
         *
         * @member {PIXI.TextStyle}
         */ this.style = style;
        /**
         * The measured width of the text
         *
         * @member {number}
         */ this.width = width;
        /**
         * The measured height of the text
         *
         * @member {number}
         */ this.height = height;
        /**
         * An array of lines of the text broken by new lines and wrapping is specified in style
         *
         * @member {string[]}
         */ this.lines = lines;
        /**
         * An array of the line widths for each line matched to `lines`
         *
         * @member {number[]}
         */ this.lineWidths = lineWidths;
        /**
         * The measured line height for this style
         *
         * @member {number}
         */ this.lineHeight = lineHeight;
        /**
         * The maximum line width for all measured lines
         *
         * @member {number}
         */ this.maxLineWidth = maxLineWidth;
        /**
         * The font properties object from TextMetrics.measureFont
         *
         * @member {PIXI.IFontMetrics}
         */ this.fontProperties = fontProperties;
    }
    /**
     * Measures the supplied string of text and returns a Rectangle.
     *
     * @param {string} text - the text to measure.
     * @param {PIXI.TextStyle} style - the text style to use for measuring
     * @param {boolean} [wordWrap] - optional override for if word-wrap should be applied to the text.
     * @param {HTMLCanvasElement} [canvas] - optional specification of the canvas to use for measuring.
     * @return {PIXI.TextMetrics} measured width and height of the text.
     */ TextMetrics2.measureText = function(text, style, wordWrap, canvas) {
        if (canvas === void 0) canvas = TextMetrics2._canvas;
        wordWrap = wordWrap === undefined || wordWrap === null ? style.wordWrap : wordWrap;
        var font = style.toFontString();
        var fontProperties = TextMetrics2.measureFont(font);
        // fallback in case UA disallow canvas data extraction
        // (toDataURI, getImageData functions)
        if (fontProperties.fontSize === 0) {
            fontProperties.fontSize = style.fontSize;
            fontProperties.ascent = style.fontSize;
        }
        var context = canvas.getContext('2d');
        context.font = font;
        var outputText = wordWrap ? TextMetrics2.wordWrap(text, style, canvas) : text;
        var lines = outputText.split(/(?:\r\n|\r|\n)/);
        var lineWidths = new Array(lines.length);
        var maxLineWidth = 0;
        for(var i = 0; i < lines.length; i++){
            var lineWidth = context.measureText(lines[i]).width + (lines[i].length - 1) * style.letterSpacing;
            lineWidths[i] = lineWidth;
            maxLineWidth = Math.max(maxLineWidth, lineWidth);
        }
        var width = maxLineWidth + style.strokeThickness;
        if (style.dropShadow) width += style.dropShadowDistance;
        var lineHeight = style.lineHeight || fontProperties.fontSize + style.strokeThickness;
        var height = Math.max(lineHeight, fontProperties.fontSize + style.strokeThickness) + (lines.length - 1) * (lineHeight + style.leading);
        if (style.dropShadow) height += style.dropShadowDistance;
        return new TextMetrics2(text, style, width, height, lines, lineWidths, lineHeight + style.leading, maxLineWidth, fontProperties);
    };
    /**
     * Applies newlines to a string to have it optimally fit into the horizontal
     * bounds set by the Text object's wordWrapWidth property.
     *
     * @private
     * @param {string} text - String to apply word wrapping to
     * @param {PIXI.TextStyle} style - the style to use when wrapping
     * @param {HTMLCanvasElement} [canvas] - optional specification of the canvas to use for measuring.
     * @return {string} New string with new lines applied where required
     */ TextMetrics2.wordWrap = function(text, style, canvas) {
        if (canvas === void 0) canvas = TextMetrics2._canvas;
        var context = canvas.getContext('2d');
        var width = 0;
        var line = '';
        var lines = '';
        var cache = Object.create(null);
        var letterSpacing = style.letterSpacing, whiteSpace = style.whiteSpace;
        // How to handle whitespaces
        var collapseSpaces = TextMetrics2.collapseSpaces(whiteSpace);
        var collapseNewlines = TextMetrics2.collapseNewlines(whiteSpace);
        // whether or not spaces may be added to the beginning of lines
        var canPrependSpaces = !collapseSpaces;
        // There is letterSpacing after every char except the last one
        // t_h_i_s_' '_i_s_' '_a_n_' '_e_x_a_m_p_l_e_' '_!
        // so for convenience the above needs to be compared to width + 1 extra letterSpace
        // t_h_i_s_' '_i_s_' '_a_n_' '_e_x_a_m_p_l_e_' '_!_
        // ________________________________________________
        // And then the final space is simply no appended to each line
        var wordWrapWidth = style.wordWrapWidth + letterSpacing;
        // break text into words, spaces and newline chars
        var tokens = TextMetrics2.tokenize(text);
        for(var i = 0; i < tokens.length; i++){
            // get the word, space or newlineChar
            var token = tokens[i];
            // if word is a new line
            if (TextMetrics2.isNewline(token)) {
                // keep the new line
                if (!collapseNewlines) {
                    lines += TextMetrics2.addLine(line);
                    canPrependSpaces = !collapseSpaces;
                    line = '';
                    width = 0;
                    continue;
                }
                // if we should collapse new lines
                // we simply convert it into a space
                token = ' ';
            }
            // if we should collapse repeated whitespaces
            if (collapseSpaces) {
                // check both this and the last tokens for spaces
                var currIsBreakingSpace = TextMetrics2.isBreakingSpace(token);
                var lastIsBreakingSpace = TextMetrics2.isBreakingSpace(line[line.length - 1]);
                if (currIsBreakingSpace && lastIsBreakingSpace) continue;
            }
            // get word width from cache if possible
            var tokenWidth = TextMetrics2.getFromCache(token, letterSpacing, cache, context);
            // word is longer than desired bounds
            if (tokenWidth > wordWrapWidth) {
                // if we are not already at the beginning of a line
                if (line !== '') {
                    // start newlines for overflow words
                    lines += TextMetrics2.addLine(line);
                    line = '';
                    width = 0;
                }
                // break large word over multiple lines
                if (TextMetrics2.canBreakWords(token, style.breakWords)) {
                    // break word into characters
                    var characters = TextMetrics2.wordWrapSplit(token);
                    // loop the characters
                    for(var j = 0; j < characters.length; j++){
                        var char = characters[j];
                        var k = 1;
                        // we are not at the end of the token
                        while(characters[j + k]){
                            var nextChar = characters[j + k];
                            var lastChar = char[char.length - 1];
                            // should not split chars
                            if (!TextMetrics2.canBreakChars(lastChar, nextChar, token, j, style.breakWords)) // combine chars & move forward one
                            char += nextChar;
                            else break;
                            k++;
                        }
                        j += char.length - 1;
                        var characterWidth = TextMetrics2.getFromCache(char, letterSpacing, cache, context);
                        if (characterWidth + width > wordWrapWidth) {
                            lines += TextMetrics2.addLine(line);
                            canPrependSpaces = false;
                            line = '';
                            width = 0;
                        }
                        line += char;
                        width += characterWidth;
                    }
                } else {
                    // if there are words in this line already
                    // finish that line and start a new one
                    if (line.length > 0) {
                        lines += TextMetrics2.addLine(line);
                        line = '';
                        width = 0;
                    }
                    var isLastToken = i === tokens.length - 1;
                    // give it its own line if it's not the end
                    lines += TextMetrics2.addLine(token, !isLastToken);
                    canPrependSpaces = false;
                    line = '';
                    width = 0;
                }
            } else {
                // word won't fit because of existing words
                // start a new line
                if (tokenWidth + width > wordWrapWidth) {
                    // if its a space we don't want it
                    canPrependSpaces = false;
                    // add a new line
                    lines += TextMetrics2.addLine(line);
                    // start a new line
                    line = '';
                    width = 0;
                }
                // don't add spaces to the beginning of lines
                if (line.length > 0 || !TextMetrics2.isBreakingSpace(token) || canPrependSpaces) {
                    // add the word to the current line
                    line += token;
                    // update width counter
                    width += tokenWidth;
                }
            }
        }
        lines += TextMetrics2.addLine(line, false);
        return lines;
    };
    /**
     * Convienience function for logging each line added during the wordWrap
     * method
     *
     * @private
     * @param  {string}   line        - The line of text to add
     * @param  {boolean}  newLine     - Add new line character to end
     * @return {string}  A formatted line
     */ TextMetrics2.addLine = function(line, newLine) {
        if (newLine === void 0) newLine = true;
        line = TextMetrics2.trimRight(line);
        line = newLine ? line + "\n" : line;
        return line;
    };
    /**
     * Gets & sets the widths of calculated characters in a cache object
     *
     * @private
     * @param  {string}                    key            - The key
     * @param  {number}                    letterSpacing  - The letter spacing
     * @param  {object}                    cache          - The cache
     * @param  {CanvasRenderingContext2D}  context        - The canvas context
     * @return {number}                    The from cache.
     */ TextMetrics2.getFromCache = function(key, letterSpacing, cache, context) {
        var width = cache[key];
        if (typeof width !== 'number') {
            var spacing = key.length * letterSpacing;
            width = context.measureText(key).width + spacing;
            cache[key] = width;
        }
        return width;
    };
    /**
     * Determines whether we should collapse breaking spaces
     *
     * @private
     * @param  {string}   whiteSpace - The TextStyle property whiteSpace
     * @return {boolean}  should collapse
     */ TextMetrics2.collapseSpaces = function(whiteSpace) {
        return whiteSpace === 'normal' || whiteSpace === 'pre-line';
    };
    /**
     * Determines whether we should collapse newLine chars
     *
     * @private
     * @param  {string}   whiteSpace - The white space
     * @return {boolean}  should collapse
     */ TextMetrics2.collapseNewlines = function(whiteSpace) {
        return whiteSpace === 'normal';
    };
    /**
     * trims breaking whitespaces from string
     *
     * @private
     * @param  {string}  text - The text
     * @return {string}  trimmed string
     */ TextMetrics2.trimRight = function(text) {
        if (typeof text !== 'string') return '';
        for(var i = text.length - 1; i >= 0; i--){
            var char = text[i];
            if (!TextMetrics2.isBreakingSpace(char)) break;
            text = text.slice(0, -1);
        }
        return text;
    };
    /**
     * Determines if char is a newline.
     *
     * @private
     * @param  {string}  char - The character
     * @return {boolean}  True if newline, False otherwise.
     */ TextMetrics2.isNewline = function(char) {
        if (typeof char !== 'string') return false;
        return TextMetrics2._newlines.indexOf(char.charCodeAt(0)) >= 0;
    };
    /**
     * Determines if char is a breaking whitespace.
     *
     * It allows one to determine whether char should be a breaking whitespace
     * For example certain characters in CJK langs or numbers.
     * It must return a boolean.
     *
     * @param  {string}  char     - The character
     * @param  {string}  [nextChar] - The next character
     * @return {boolean}  True if whitespace, False otherwise.
     */ TextMetrics2.isBreakingSpace = function(char, _nextChar) {
        if (typeof char !== 'string') return false;
        return TextMetrics2._breakingSpaces.indexOf(char.charCodeAt(0)) >= 0;
    };
    /**
     * Splits a string into words, breaking-spaces and newLine characters
     *
     * @private
     * @param  {string}  text - The text
     * @return {string[]}  A tokenized array
     */ TextMetrics2.tokenize = function(text) {
        var tokens = [];
        var token = '';
        if (typeof text !== 'string') return tokens;
        for(var i = 0; i < text.length; i++){
            var char = text[i];
            var nextChar = text[i + 1];
            if (TextMetrics2.isBreakingSpace(char, nextChar) || TextMetrics2.isNewline(char)) {
                if (token !== '') {
                    tokens.push(token);
                    token = '';
                }
                tokens.push(char);
                continue;
            }
            token += char;
        }
        if (token !== '') tokens.push(token);
        return tokens;
    };
    /**
     * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
     *
     * It allows one to customise which words should break
     * Examples are if the token is CJK or numbers.
     * It must return a boolean.
     *
     * @param  {string}  token       - The token
     * @param  {boolean}  breakWords - The style attr break words
     * @return {boolean} whether to break word or not
     */ TextMetrics2.canBreakWords = function(_token, breakWords) {
        return breakWords;
    };
    /**
     * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
     *
     * It allows one to determine whether a pair of characters
     * should be broken by newlines
     * For example certain characters in CJK langs or numbers.
     * It must return a boolean.
     *
     * @param  {string}  char        - The character
     * @param  {string}  nextChar    - The next character
     * @param  {string}  token       - The token/word the characters are from
     * @param  {number}  index       - The index in the token of the char
     * @param  {boolean}  breakWords - The style attr break words
     * @return {boolean} whether to break word or not
     */ TextMetrics2.canBreakChars = function(_char, _nextChar, _token, _index, _breakWords) {
        return true;
    };
    /**
     * Overridable helper method used internally by TextMetrics, exposed to allow customizing the class's behavior.
     *
     * It is called when a token (usually a word) has to be split into separate pieces
     * in order to determine the point to break a word.
     * It must return an array of characters.
     *
     * @example
     * // Correctly splits emojis, eg "🤪🤪" will result in two element array, each with one emoji.
     * TextMetrics.wordWrapSplit = (token) => [...token];
     *
     * @param  {string}  token - The token to split
     * @return {string[]} The characters of the token
     */ TextMetrics2.wordWrapSplit = function(token) {
        return token.split('');
    };
    /**
     * Calculates the ascent, descent and fontSize of a given font-style
     *
     * @static
     * @param {string} font - String representing the style of the font
     * @return {PIXI.IFontMetrics} Font properties object
     */ TextMetrics2.measureFont = function(font) {
        // as this method is used for preparing assets, don't recalculate things if we don't need to
        if (TextMetrics2._fonts[font]) return TextMetrics2._fonts[font];
        var properties = {
            ascent: 0,
            descent: 0,
            fontSize: 0
        };
        var canvas = TextMetrics2._canvas;
        var context = TextMetrics2._context;
        context.font = font;
        var metricsString = TextMetrics2.METRICS_STRING + TextMetrics2.BASELINE_SYMBOL;
        var width = Math.ceil(context.measureText(metricsString).width);
        var baseline = Math.ceil(context.measureText(TextMetrics2.BASELINE_SYMBOL).width);
        var height = Math.ceil(TextMetrics2.HEIGHT_MULTIPLIER * baseline);
        baseline = baseline * TextMetrics2.BASELINE_MULTIPLIER | 0;
        canvas.width = width;
        canvas.height = height;
        context.fillStyle = '#f00';
        context.fillRect(0, 0, width, height);
        context.font = font;
        context.textBaseline = 'alphabetic';
        context.fillStyle = '#000';
        context.fillText(metricsString, 0, baseline);
        var imagedata = context.getImageData(0, 0, width, height).data;
        var pixels = imagedata.length;
        var line = width * 4;
        var i = 0;
        var idx = 0;
        var stop = false;
        // ascent. scan from top to bottom until we find a non red pixel
        for(i = 0; i < baseline; ++i){
            for(var j = 0; j < line; j += 4)if (imagedata[idx + j] !== 255) {
                stop = true;
                break;
            }
            if (!stop) idx += line;
            else break;
        }
        properties.ascent = baseline - i;
        idx = pixels - line;
        stop = false;
        // descent. scan from bottom to top until we find a non red pixel
        for(i = height; i > baseline; --i){
            for(var j = 0; j < line; j += 4)if (imagedata[idx + j] !== 255) {
                stop = true;
                break;
            }
            if (!stop) idx -= line;
            else break;
        }
        properties.descent = i - baseline;
        properties.fontSize = properties.ascent + properties.descent;
        TextMetrics2._fonts[font] = properties;
        return properties;
    };
    /**
     * Clear font metrics in metrics cache.
     *
     * @static
     * @param {string} [font] - font name. If font name not set then clear cache for all fonts.
     */ TextMetrics2.clearMetrics = function(font) {
        if (font === void 0) font = '';
        if (font) delete TextMetrics2._fonts[font];
        else TextMetrics2._fonts = {
        };
    };
    return TextMetrics2;
}();
/**
 * Internal return object for {@link PIXI.TextMetrics.measureFont `TextMetrics.measureFont`}.
 *
 * @typedef {object} FontMetrics
 * @property {number} ascent - The ascent distance
 * @property {number} descent - The descent distance
 * @property {number} fontSize - Font size from ascent to descent
 * @memberof PIXI.TextMetrics
 * @private
 */ var canvas = function() {
    try {
        // OffscreenCanvas2D measureText can be up to 40% faster.
        var c = new OffscreenCanvas(0, 0);
        var context = c.getContext('2d');
        if (context && context.measureText) return c;
        return document.createElement('canvas');
    } catch (ex) {
        return document.createElement('canvas');
    }
}();
canvas.width = canvas.height = 10;
/**
 * Cached canvas element for measuring text
 *
 * @memberof PIXI.TextMetrics
 * @type {HTMLCanvasElement}
 * @private
 */ TextMetrics1._canvas = canvas;
/**
 * Cache for context to use.
 *
 * @memberof PIXI.TextMetrics
 * @type {CanvasRenderingContext2D}
 * @private
 */ TextMetrics1._context = canvas.getContext('2d');
/**
 * Cache of {@see PIXI.TextMetrics.FontMetrics} objects.
 *
 * @memberof PIXI.TextMetrics
 * @type {Object}
 * @private
 */ TextMetrics1._fonts = {
};
/**
 * String used for calculate font metrics.
 * These characters are all tall to help calculate the height required for text.
 *
 * @static
 * @memberof PIXI.TextMetrics
 * @name METRICS_STRING
 * @type {string}
 * @default |ÉqÅ
 */ TextMetrics1.METRICS_STRING = '|ÉqÅ';
/**
 * Baseline symbol for calculate font metrics.
 *
 * @static
 * @memberof PIXI.TextMetrics
 * @name BASELINE_SYMBOL
 * @type {string}
 * @default M
 */ TextMetrics1.BASELINE_SYMBOL = 'M';
/**
 * Baseline multiplier for calculate font metrics.
 *
 * @static
 * @memberof PIXI.TextMetrics
 * @name BASELINE_MULTIPLIER
 * @type {number}
 * @default 1.4
 */ TextMetrics1.BASELINE_MULTIPLIER = 1.4;
/**
 * Height multiplier for setting height of canvas to calculate font metrics.
 *
 * @static
 * @memberof PIXI.TextMetrics
 * @name HEIGHT_MULTIPLIER
 * @type {number}
 * @default 2.00
 */ TextMetrics1.HEIGHT_MULTIPLIER = 2;
/**
 * Cache of new line chars.
 *
 * @memberof PIXI.TextMetrics
 * @type {number[]}
 * @private
 */ TextMetrics1._newlines = [
    10,
    13
];
/**
 * Cache of breaking spaces.
 *
 * @memberof PIXI.TextMetrics
 * @type {number[]}
 * @private
 */ TextMetrics1._breakingSpaces = [
    9,
    32,
    8192,
    8193,
    8194,
    8195,
    8196,
    8197,
    8198,
    8200,
    8201,
    8202,
    8287,
    12288
];
/**
 * A number, or a string containing a number.
 *
 * @memberof PIXI
 * @typedef {object} IFontMetrics
 * @property {number} ascent - Font ascent
 * @property {number} descent - Font descent
 * @property {number} fontSize - Font size
 */ var defaultDestroyOptions = {
    texture: true,
    children: false,
    baseTexture: true
};
/**
 * A Text Object will create a line or multiple lines of text.
 *
 * The text is created using the [Canvas API](https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API).
 *
 * The primary advantage of this class over BitmapText is that you have great control over the style of the text,
 * which you can change at runtime.
 *
 * The primary disadvantages is that each piece of text has it's own texture, which can use more memory.
 * When text changes, this texture has to be re-generated and re-uploaded to the GPU, taking up time.
 *
 * To split a line you can use '\n' in your text string, or, on the `style` object,
 * change its `wordWrap` property to true and and give the `wordWrapWidth` property a value.
 *
 * A Text can be created directly from a string and a style object,
 * which can be generated [here](https://pixijs.io/pixi-text-style).
 *
 * ```js
 * let text = new PIXI.Text('This is a PixiJS text',{fontFamily : 'Arial', fontSize: 24, fill : 0xff1010, align : 'center'});
 * ```
 *
 * @class
 * @extends PIXI.Sprite
 * @memberof PIXI
 */ var Text1 = function(_super) {
    __extends(Text2, _super);
    /**
     * @param {string} text - The string that you would like the text to display
     * @param {object|PIXI.TextStyle} [style] - The style parameters
     * @param {HTMLCanvasElement} [canvas] - The canvas element for drawing text
     */ function Text2(text, style, canvas1) {
        var _this = this;
        var ownCanvas = false;
        if (!canvas1) {
            canvas1 = document.createElement('canvas');
            ownCanvas = true;
        }
        canvas1.width = 3;
        canvas1.height = 3;
        var texture = _core.Texture.from(canvas1);
        texture.orig = new _math.Rectangle();
        texture.trim = new _math.Rectangle();
        _this = _super.call(this, texture) || this;
        /**
         * Keep track if this Text object created it's own canvas
         * element (`true`) or uses the constructor argument (`false`).
         * Used to workaround a GC issues with Safari < 13 when
         * destroying Text. See `destroy` for more info.
         *
         * @member {boolean}
         * @private
         */ _this._ownCanvas = ownCanvas;
        /**
         * The canvas element that everything is drawn to
         *
         * @member {HTMLCanvasElement}
         */ _this.canvas = canvas1;
        /**
         * The canvas 2d context that everything is drawn with
         * @member {CanvasRenderingContext2D}
         */ _this.context = _this.canvas.getContext('2d');
        /**
         * The resolution / device pixel ratio of the canvas.
         * This is set to automatically match the renderer resolution by default, but can be overridden by setting manually.
         * @member {number}
         * @default PIXI.settings.RESOLUTION
         */ _this._resolution = _settings.settings.RESOLUTION;
        _this._autoResolution = true;
        /**
         * Private tracker for the current text.
         *
         * @member {string}
         * @private
         */ _this._text = null;
        /**
         * Private tracker for the current style.
         *
         * @member {object}
         * @private
         */ _this._style = null;
        /**
         * Private listener to track style changes.
         *
         * @member {Function}
         * @private
         */ _this._styleListener = null;
        /**
         * Private tracker for the current font.
         *
         * @member {string}
         * @private
         */ _this._font = '';
        _this.text = text;
        _this.style = style;
        _this.localStyleID = -1;
        return _this;
    }
    /**
     * Renders text to its canvas, and updates its texture.
     * By default this is used internally to ensure the texture is correct before rendering,
     * but it can be used called externally, for example from this class to 'pre-generate' the texture from a piece of text,
     * and then shared across multiple Sprites.
     *
     * @param {boolean} respectDirty - Whether to abort updating the text if the Text isn't dirty and the function is called.
     */ Text2.prototype.updateText = function(respectDirty) {
        var style = this._style;
        // check if style has changed..
        if (this.localStyleID !== style.styleID) {
            this.dirty = true;
            this.localStyleID = style.styleID;
        }
        if (!this.dirty && respectDirty) return;
        this._font = this._style.toFontString();
        var context = this.context;
        var measured = TextMetrics1.measureText(this._text || ' ', this._style, this._style.wordWrap, this.canvas);
        var width = measured.width;
        var height = measured.height;
        var lines = measured.lines;
        var lineHeight = measured.lineHeight;
        var lineWidths = measured.lineWidths;
        var maxLineWidth = measured.maxLineWidth;
        var fontProperties = measured.fontProperties;
        this.canvas.width = Math.ceil(Math.ceil(Math.max(1, width) + style.padding * 2) * this._resolution);
        this.canvas.height = Math.ceil(Math.ceil(Math.max(1, height) + style.padding * 2) * this._resolution);
        context.scale(this._resolution, this._resolution);
        context.clearRect(0, 0, this.canvas.width, this.canvas.height);
        context.font = this._font;
        context.lineWidth = style.strokeThickness;
        context.textBaseline = style.textBaseline;
        context.lineJoin = style.lineJoin;
        context.miterLimit = style.miterLimit;
        var linePositionX;
        var linePositionY;
        // require 2 passes if a shadow; the first to draw the drop shadow, the second to draw the text
        var passesCount = style.dropShadow ? 2 : 1;
        // For v4, we drew text at the colours of the drop shadow underneath the normal text. This gave the correct zIndex,
        // but features such as alpha and shadowblur did not look right at all, since we were using actual text as a shadow.
        //
        // For v5.0.0, we moved over to just use the canvas API for drop shadows, which made them look much nicer and more
        // visually please, but now because the stroke is drawn and then the fill, drop shadows would appear on both the fill
        // and the stroke; and fill drop shadows would appear over the top of the stroke.
        //
        // For v5.1.1, the new route is to revert to v4 style of drawing text first to get the drop shadows underneath normal
        // text, but instead drawing text in the correct location, we'll draw it off screen (-paddingY), and then adjust the
        // drop shadow so only that appears on screen (+paddingY). Now we'll have the correct draw order of the shadow
        // beneath the text, whilst also having the proper text shadow styling.
        for(var i = 0; i < passesCount; ++i){
            var isShadowPass = style.dropShadow && i === 0;
            // we only want the drop shadow, so put text way off-screen
            var dsOffsetText = isShadowPass ? Math.ceil(Math.max(1, height) + style.padding * 2) : 0;
            var dsOffsetShadow = dsOffsetText * this._resolution;
            if (isShadowPass) {
                // On Safari, text with gradient and drop shadows together do not position correctly
                // if the scale of the canvas is not 1: https://bugs.webkit.org/show_bug.cgi?id=197689
                // Therefore we'll set the styles to be a plain black whilst generating this drop shadow
                context.fillStyle = 'black';
                context.strokeStyle = 'black';
                var dropShadowColor = style.dropShadowColor;
                var rgb = _utils.hex2rgb(typeof dropShadowColor === 'number' ? dropShadowColor : _utils.string2hex(dropShadowColor));
                context.shadowColor = "rgba(" + rgb[0] * 255 + "," + rgb[1] * 255 + "," + rgb[2] * 255 + "," + style.dropShadowAlpha + ")";
                context.shadowBlur = style.dropShadowBlur;
                context.shadowOffsetX = Math.cos(style.dropShadowAngle) * style.dropShadowDistance;
                context.shadowOffsetY = Math.sin(style.dropShadowAngle) * style.dropShadowDistance + dsOffsetShadow;
            } else {
                // set canvas text styles
                context.fillStyle = this._generateFillStyle(style, lines, measured);
                // TODO: Can't have different types for getter and setter. The getter shouldn't have the number type as
                //       the setter converts to string. See this thread for more details:
                //       https://github.com/microsoft/TypeScript/issues/2521
                context.strokeStyle = style.stroke;
                context.shadowColor = 'black';
                context.shadowBlur = 0;
                context.shadowOffsetX = 0;
                context.shadowOffsetY = 0;
            }
            var linePositionYShift = (lineHeight - fontProperties.fontSize) / 2;
            if (!Text2.nextLineHeightBehavior || lineHeight - fontProperties.fontSize < 0) linePositionYShift = 0;
            // draw lines line by line
            for(var i_1 = 0; i_1 < lines.length; i_1++){
                linePositionX = style.strokeThickness / 2;
                linePositionY = style.strokeThickness / 2 + i_1 * lineHeight + fontProperties.ascent + linePositionYShift;
                if (style.align === 'right') linePositionX += maxLineWidth - lineWidths[i_1];
                else if (style.align === 'center') linePositionX += (maxLineWidth - lineWidths[i_1]) / 2;
                if (style.stroke && style.strokeThickness) this.drawLetterSpacing(lines[i_1], linePositionX + style.padding, linePositionY + style.padding - dsOffsetText, true);
                if (style.fill) this.drawLetterSpacing(lines[i_1], linePositionX + style.padding, linePositionY + style.padding - dsOffsetText);
            }
        }
        this.updateTexture();
    };
    /**
     * Render the text with letter-spacing.
     * @param {string} text - The text to draw
     * @param {number} x - Horizontal position to draw the text
     * @param {number} y - Vertical position to draw the text
     * @param {boolean} [isStroke=false] - Is this drawing for the outside stroke of the
     *  text? If not, it's for the inside fill
     * @private
     */ Text2.prototype.drawLetterSpacing = function(text, x, y, isStroke) {
        if (isStroke === void 0) isStroke = false;
        var style = this._style;
        // letterSpacing of 0 means normal
        var letterSpacing = style.letterSpacing;
        if (letterSpacing === 0) {
            if (isStroke) this.context.strokeText(text, x, y);
            else this.context.fillText(text, x, y);
            return;
        }
        var currentPosition = x;
        // Using Array.from correctly splits characters whilst keeping emoji together.
        // This is not supported on IE as it requires ES6, so regular text splitting occurs.
        // This also doesn't account for emoji that are multiple emoji put together to make something else.
        // Handling all of this would require a big library itself.
        // https://medium.com/@giltayar/iterating-over-emoji-characters-the-es6-way-f06e4589516
        // https://github.com/orling/grapheme-splitter
        var stringArray = Array.from ? Array.from(text) : text.split('');
        var previousWidth = this.context.measureText(text).width;
        var currentWidth = 0;
        for(var i = 0; i < stringArray.length; ++i){
            var currentChar = stringArray[i];
            if (isStroke) this.context.strokeText(currentChar, currentPosition, y);
            else this.context.fillText(currentChar, currentPosition, y);
            currentWidth = this.context.measureText(text.substring(i + 1)).width;
            currentPosition += previousWidth - currentWidth + letterSpacing;
            previousWidth = currentWidth;
        }
    };
    /**
     * Updates texture size based on canvas size
     *
     * @private
     */ Text2.prototype.updateTexture = function() {
        var canvas1 = this.canvas;
        if (this._style.trim) {
            var trimmed = _utils.trimCanvas(canvas1);
            if (trimmed.data) {
                canvas1.width = trimmed.width;
                canvas1.height = trimmed.height;
                this.context.putImageData(trimmed.data, 0, 0);
            }
        }
        var texture = this._texture;
        var style = this._style;
        var padding = style.trim ? 0 : style.padding;
        var baseTexture = texture.baseTexture;
        texture.trim.width = texture._frame.width = canvas1.width / this._resolution;
        texture.trim.height = texture._frame.height = canvas1.height / this._resolution;
        texture.trim.x = -padding;
        texture.trim.y = -padding;
        texture.orig.width = texture._frame.width - padding * 2;
        texture.orig.height = texture._frame.height - padding * 2;
        // call sprite onTextureUpdate to update scale if _width or _height were set
        this._onTextureUpdate();
        baseTexture.setRealSize(canvas1.width, canvas1.height, this._resolution);
        texture.updateUvs();
        // Recursively updates transform of all objects from the root to this one
        this._recursivePostUpdateTransform();
        this.dirty = false;
    };
    /**
     * Renders the object using the WebGL renderer
     *
     * @protected
     * @param {PIXI.Renderer} renderer - The renderer
     */ Text2.prototype._render = function(renderer) {
        if (this._autoResolution && this._resolution !== renderer.resolution) {
            this._resolution = renderer.resolution;
            this.dirty = true;
        }
        this.updateText(true);
        _super.prototype._render.call(this, renderer);
    };
    /**
     * Gets the local bounds of the text object.
     *
     * @param {PIXI.Rectangle} rect - The output rectangle.
     * @return {PIXI.Rectangle} The bounds.
     */ Text2.prototype.getLocalBounds = function(rect) {
        this.updateText(true);
        return _super.prototype.getLocalBounds.call(this, rect);
    };
    /**
     * calculates the bounds of the Text as a rectangle. The bounds calculation takes the worldTransform into account.
     * @protected
     */ Text2.prototype._calculateBounds = function() {
        this.updateText(true);
        this.calculateVertices();
        // if we have already done this on THIS frame.
        this._bounds.addQuad(this.vertexData);
    };
    /**
     * Generates the fill style. Can automatically generate a gradient based on the fill style being an array
     *
     * @private
     * @param {object} style - The style.
     * @param {string[]} lines - The lines of text.
     * @return {string|number|CanvasGradient} The fill style
     */ Text2.prototype._generateFillStyle = function(style, lines, metrics) {
        // TODO: Can't have different types for getter and setter. The getter shouldn't have the number type as
        //       the setter converts to string. See this thread for more details:
        //       https://github.com/microsoft/TypeScript/issues/2521
        var fillStyle = style.fill;
        if (!Array.isArray(fillStyle)) return fillStyle;
        else if (fillStyle.length === 1) return fillStyle[0];
        // the gradient will be evenly spaced out according to how large the array is.
        // ['#FF0000', '#00FF00', '#0000FF'] would created stops at 0.25, 0.5 and 0.75
        var gradient;
        // a dropshadow will enlarge the canvas and result in the gradient being
        // generated with the incorrect dimensions
        var dropShadowCorrection = style.dropShadow ? style.dropShadowDistance : 0;
        // should also take padding into account, padding can offset the gradient
        var padding = style.padding || 0;
        var width = this.canvas.width / this._resolution - dropShadowCorrection - padding * 2;
        var height = this.canvas.height / this._resolution - dropShadowCorrection - padding * 2;
        // make a copy of the style settings, so we can manipulate them later
        var fill = fillStyle.slice();
        var fillGradientStops = style.fillGradientStops.slice();
        // wanting to evenly distribute the fills. So an array of 4 colours should give fills of 0.25, 0.5 and 0.75
        if (!fillGradientStops.length) {
            var lengthPlus1 = fill.length + 1;
            for(var i = 1; i < lengthPlus1; ++i)fillGradientStops.push(i / lengthPlus1);
        }
        // stop the bleeding of the last gradient on the line above to the top gradient of the this line
        // by hard defining the first gradient colour at point 0, and last gradient colour at point 1
        fill.unshift(fillStyle[0]);
        fillGradientStops.unshift(0);
        fill.push(fillStyle[fillStyle.length - 1]);
        fillGradientStops.push(1);
        if (style.fillGradientType === TEXT_GRADIENT.LINEAR_VERTICAL) {
            // start the gradient at the top center of the canvas, and end at the bottom middle of the canvas
            gradient = this.context.createLinearGradient(width / 2, padding, width / 2, height + padding);
            // we need to repeat the gradient so that each individual line of text has the same vertical gradient effect
            // ['#FF0000', '#00FF00', '#0000FF'] over 2 lines would create stops at 0.125, 0.25, 0.375, 0.625, 0.75, 0.875
            // Actual height of the text itself, not counting spacing for lineHeight/leading/dropShadow etc
            var textHeight = metrics.fontProperties.fontSize + style.strokeThickness;
            for(var i = 0; i < lines.length; i++){
                var lastLineBottom = metrics.lineHeight * (i - 1) + textHeight;
                var thisLineTop = metrics.lineHeight * i;
                var thisLineGradientStart = thisLineTop;
                // Handle case where last & this line overlap
                if (i > 0 && lastLineBottom > thisLineTop) thisLineGradientStart = (thisLineTop + lastLineBottom) / 2;
                var thisLineBottom = thisLineTop + textHeight;
                var nextLineTop = metrics.lineHeight * (i + 1);
                var thisLineGradientEnd = thisLineBottom;
                // Handle case where this & next line overlap
                if (i + 1 < lines.length && nextLineTop < thisLineBottom) thisLineGradientEnd = (thisLineBottom + nextLineTop) / 2;
                // textHeight, but as a 0-1 size in global gradient stop space
                var gradStopLineHeight = (thisLineGradientEnd - thisLineGradientStart) / height;
                for(var j = 0; j < fill.length; j++){
                    // 0-1 stop point for the current line, multiplied to global space afterwards
                    var lineStop = 0;
                    if (typeof fillGradientStops[j] === 'number') lineStop = fillGradientStops[j];
                    else lineStop = j / fill.length;
                    var globalStop = Math.min(1, Math.max(0, thisLineGradientStart / height + lineStop * gradStopLineHeight));
                    // There's potential for floating point precision issues at the seams between gradient repeats.
                    globalStop = Number(globalStop.toFixed(5));
                    gradient.addColorStop(globalStop, fill[j]);
                }
            }
        } else {
            // start the gradient at the center left of the canvas, and end at the center right of the canvas
            gradient = this.context.createLinearGradient(padding, height / 2, width + padding, height / 2);
            // can just evenly space out the gradients in this case, as multiple lines makes no difference
            // to an even left to right gradient
            var totalIterations = fill.length + 1;
            var currentIteration = 1;
            for(var i = 0; i < fill.length; i++){
                var stop = void 0;
                if (typeof fillGradientStops[i] === 'number') stop = fillGradientStops[i];
                else stop = currentIteration / totalIterations;
                gradient.addColorStop(stop, fill[i]);
                currentIteration++;
            }
        }
        return gradient;
    };
    /**
     * Destroys this text object.
     * Note* Unlike a Sprite, a Text object will automatically destroy its baseTexture and texture as
     * the majority of the time the texture will not be shared with any other Sprites.
     *
     * @param {object|boolean} [options] - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.children=false] - if set to true, all the children will have their
     *  destroy method called as well. 'options' will be passed on to those calls.
     * @param {boolean} [options.texture=true] - Should it destroy the current texture of the sprite as well
     * @param {boolean} [options.baseTexture=true] - Should it destroy the base texture of the sprite as well
     */ Text2.prototype.destroy = function(options) {
        if (typeof options === 'boolean') options = {
            children: options
        };
        options = Object.assign({
        }, defaultDestroyOptions, options);
        _super.prototype.destroy.call(this, options);
        // set canvas width and height to 0 to workaround memory leak in Safari < 13
        // https://stackoverflow.com/questions/52532614/total-canvas-memory-use-exceeds-the-maximum-limit-safari-12
        if (this._ownCanvas) this.canvas.height = this.canvas.width = 0;
        // make sure to reset the the context and canvas.. dont want this hanging around in memory!
        this.context = null;
        this.canvas = null;
        this._style = null;
    };
    Object.defineProperty(Text2.prototype, "width", {
        /**
         * The width of the Text, setting this will actually modify the scale to achieve the value set
         *
         * @member {number}
         */ get: function() {
            this.updateText(true);
            return Math.abs(this.scale.x) * this._texture.orig.width;
        },
        set: function(value) {
            this.updateText(true);
            var s = _utils.sign(this.scale.x) || 1;
            this.scale.x = s * value / this._texture.orig.width;
            this._width = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Text2.prototype, "height", {
        /**
         * The height of the Text, setting this will actually modify the scale to achieve the value set
         *
         * @member {number}
         */ get: function() {
            this.updateText(true);
            return Math.abs(this.scale.y) * this._texture.orig.height;
        },
        set: function(value) {
            this.updateText(true);
            var s = _utils.sign(this.scale.y) || 1;
            this.scale.y = s * value / this._texture.orig.height;
            this._height = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Text2.prototype, "style", {
        /**
         * Set the style of the text. Set up an event listener to listen for changes on the style
         * object and mark the text as dirty.
         *
         * @member {object|PIXI.TextStyle}
         */ get: function() {
            // TODO: Can't have different types for getter and setter. The getter shouldn't have the ITextStyle
            //       since the setter creates the TextStyle. See this thread for more details:
            //       https://github.com/microsoft/TypeScript/issues/2521
            return this._style;
        },
        set: function(style) {
            style = style || {
            };
            if (style instanceof TextStyle) this._style = style;
            else this._style = new TextStyle(style);
            this.localStyleID = -1;
            this.dirty = true;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Text2.prototype, "text", {
        /**
         * Set the copy for the text object. To split a line you can use '\n'.
         *
         * @member {string}
         */ get: function() {
            return this._text;
        },
        set: function(text) {
            text = String(text === null || text === undefined ? '' : text);
            if (this._text === text) return;
            this._text = text;
            this.dirty = true;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Text2.prototype, "resolution", {
        /**
         * The resolution / device pixel ratio of the canvas.
         * This is set to automatically match the renderer resolution by default, but can be overridden by setting manually.
         * @member {number}
         * @default 1
         */ get: function() {
            return this._resolution;
        },
        set: function(value) {
            this._autoResolution = false;
            if (this._resolution === value) return;
            this._resolution = value;
            this.dirty = true;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * New behavior for `lineHeight` that's meant to mimic HTML text. A value of `true` will
     * make sure the first baseline is offset by the `lineHeight` value if it is greater than `fontSize`.
     * A value of `false` will use the legacy behavior and not change the baseline of the first line.
     * In the next major release, we'll enable this by default.
     *
     * @static
     * @memberof PIXI.Text
     * @member {boolean} nextLineHeightBehavior
     * @default false
     */ Text2.nextLineHeightBehavior = false;
    return Text2;
}(_sprite.Sprite);

},{"@pixi/sprite":"aeiZG","@pixi/core":"d0INm","@pixi/settings":"habh9","@pixi/math":"1qR3C","@pixi/utils":"joR65","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aeiZG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Sprite", ()=>Sprite1
);
/*!
 * @pixi/sprite - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/sprite is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _constants = require("@pixi/constants");
var _core = require("@pixi/core");
var _display = require("@pixi/display");
var _math = require("@pixi/math");
var _settings = require("@pixi/settings");
var _utils = require("@pixi/utils");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var tempPoint = new _math.Point();
var indices = new Uint16Array([
    0,
    1,
    2,
    0,
    2,
    3
]);
/**
 * The Sprite object is the base for all textured objects that are rendered to the screen
*
 * A sprite can be created directly from an image like this:
 *
 * ```js
 * let sprite = PIXI.Sprite.from('assets/image.png');
 * ```
 *
 * The more efficient way to create sprites is using a {@link PIXI.Spritesheet},
 * as swapping base textures when rendering to the screen is inefficient.
 *
 * ```js
 * PIXI.Loader.shared.add("assets/spritesheet.json").load(setup);
 *
 * function setup() {
 *   let sheet = PIXI.Loader.shared.resources["assets/spritesheet.json"].spritesheet;
 *   let sprite = new PIXI.Sprite(sheet.textures["image.png"]);
 *   ...
 * }
 * ```
 *
 * @class
 * @extends PIXI.Container
 * @memberof PIXI
 */ var Sprite1 = function(_super) {
    __extends(Sprite2, _super);
    /**
     * @param {PIXI.Texture} [texture] - The texture for this sprite.
     */ function Sprite2(texture) {
        var _this = _super.call(this) || this;
        /**
         * The anchor point defines the normalized coordinates
         * in the texture that map to the position of this
         * sprite.
         *
         * By default, this is `(0,0)` (or `texture.defaultAnchor`
         * if you have modified that), which means the position
         * `(x,y)` of this `Sprite` will be the top-left corner.
         *
         * Note: Updating `texture.defaultAnchor` after
         * constructing a `Sprite` does _not_ update its anchor.
         *
         * {@link https://docs.cocos2d-x.org/cocos2d-x/en/sprites/manipulation.html}
         *
         * @default `texture.defaultAnchor`
         * @member {PIXI.ObservablePoint}
         * @private
         */ _this._anchor = new _math.ObservablePoint(_this._onAnchorUpdate, _this, texture ? texture.defaultAnchor.x : 0, texture ? texture.defaultAnchor.y : 0);
        /**
         * The texture that the sprite is using
         *
         * @private
         * @member {PIXI.Texture}
         */ _this._texture = null;
        /**
         * The width of the sprite (this is initially set by the texture)
         *
         * @protected
         * @member {number}
         */ _this._width = 0;
        /**
         * The height of the sprite (this is initially set by the texture)
         *
         * @protected
         * @member {number}
         */ _this._height = 0;
        /**
         * The tint applied to the sprite. This is a hex value. A value of 0xFFFFFF will remove any tint effect.
         *
         * @private
         * @member {number}
         * @default 0xFFFFFF
         */ _this._tint = null;
        /**
         * The tint applied to the sprite. This is a RGB value. A value of 0xFFFFFF will remove any tint effect.
         *
         * @private
         * @member {number}
         * @default 16777215
         */ _this._tintRGB = null;
        _this.tint = 16777215;
        /**
         * The blend mode to be applied to the sprite. Apply a value of `PIXI.BLEND_MODES.NORMAL` to reset the blend mode.
         *
         * @member {number}
         * @default PIXI.BLEND_MODES.NORMAL
         * @see PIXI.BLEND_MODES
         */ _this.blendMode = _constants.BLEND_MODES.NORMAL;
        /**
         * Cached tint value so we can tell when the tint is changed.
         * Value is used for 2d CanvasRenderer.
         *
         * @protected
         * @member {number}
         * @default 0xFFFFFF
         */ _this._cachedTint = 16777215;
        /**
         * this is used to store the uvs data of the sprite, assigned at the same time
         * as the vertexData in calculateVertices()
         *
         * @private
         * @member {Float32Array}
         */ _this.uvs = null;
        // call texture setter
        _this.texture = texture || _core.Texture.EMPTY;
        /**
         * this is used to store the vertex data of the sprite (basically a quad)
         *
         * @private
         * @member {Float32Array}
         */ _this.vertexData = new Float32Array(8);
        /**
         * This is used to calculate the bounds of the object IF it is a trimmed sprite
         *
         * @private
         * @member {Float32Array}
         */ _this.vertexTrimmedData = null;
        _this._transformID = -1;
        _this._textureID = -1;
        _this._transformTrimmedID = -1;
        _this._textureTrimmedID = -1;
        // Batchable stuff..
        // TODO could make this a mixin?
        _this.indices = indices;
        /**
         * Plugin that is responsible for rendering this element.
         * Allows to customize the rendering process without overriding '_render' & '_renderCanvas' methods.
         *
         * @member {string}
         * @default 'batch'
         */ _this.pluginName = 'batch';
        /**
         * used to fast check if a sprite is.. a sprite!
         * @member {boolean}
         */ _this.isSprite = true;
        /**
         * Internal roundPixels field
         *
         * @member {boolean}
         * @private
         */ _this._roundPixels = _settings.settings.ROUND_PIXELS;
        return _this;
    }
    /**
     * When the texture is updated, this event will fire to update the scale and frame
     *
     * @protected
     */ Sprite2.prototype._onTextureUpdate = function() {
        this._textureID = -1;
        this._textureTrimmedID = -1;
        this._cachedTint = 16777215;
        // so if _width is 0 then width was not set..
        if (this._width) this.scale.x = _utils.sign(this.scale.x) * this._width / this._texture.orig.width;
        if (this._height) this.scale.y = _utils.sign(this.scale.y) * this._height / this._texture.orig.height;
    };
    /**
     * Called when the anchor position updates.
     *
     * @private
     */ Sprite2.prototype._onAnchorUpdate = function() {
        this._transformID = -1;
        this._transformTrimmedID = -1;
    };
    /**
     * calculates worldTransform * vertices, store it in vertexData
     */ Sprite2.prototype.calculateVertices = function() {
        var texture = this._texture;
        if (this._transformID === this.transform._worldID && this._textureID === texture._updateID) return;
        // update texture UV here, because base texture can be changed without calling `_onTextureUpdate`
        if (this._textureID !== texture._updateID) this.uvs = this._texture._uvs.uvsFloat32;
        this._transformID = this.transform._worldID;
        this._textureID = texture._updateID;
        // set the vertex data
        var wt = this.transform.worldTransform;
        var a = wt.a;
        var b = wt.b;
        var c = wt.c;
        var d = wt.d;
        var tx = wt.tx;
        var ty = wt.ty;
        var vertexData = this.vertexData;
        var trim = texture.trim;
        var orig = texture.orig;
        var anchor = this._anchor;
        var w0 = 0;
        var w1 = 0;
        var h0 = 0;
        var h1 = 0;
        if (trim) {
            // if the sprite is trimmed and is not a tilingsprite then we need to add the extra
            // space before transforming the sprite coords.
            w1 = trim.x - anchor._x * orig.width;
            w0 = w1 + trim.width;
            h1 = trim.y - anchor._y * orig.height;
            h0 = h1 + trim.height;
        } else {
            w1 = -anchor._x * orig.width;
            w0 = w1 + orig.width;
            h1 = -anchor._y * orig.height;
            h0 = h1 + orig.height;
        }
        // xy
        vertexData[0] = a * w1 + c * h1 + tx;
        vertexData[1] = d * h1 + b * w1 + ty;
        // xy
        vertexData[2] = a * w0 + c * h1 + tx;
        vertexData[3] = d * h1 + b * w0 + ty;
        // xy
        vertexData[4] = a * w0 + c * h0 + tx;
        vertexData[5] = d * h0 + b * w0 + ty;
        // xy
        vertexData[6] = a * w1 + c * h0 + tx;
        vertexData[7] = d * h0 + b * w1 + ty;
        if (this._roundPixels) {
            var resolution = _settings.settings.RESOLUTION;
            for(var i = 0; i < vertexData.length; ++i)vertexData[i] = Math.round((vertexData[i] * resolution | 0) / resolution);
        }
    };
    /**
     * calculates worldTransform * vertices for a non texture with a trim. store it in vertexTrimmedData
     * This is used to ensure that the true width and height of a trimmed texture is respected
     */ Sprite2.prototype.calculateTrimmedVertices = function() {
        if (!this.vertexTrimmedData) this.vertexTrimmedData = new Float32Array(8);
        else if (this._transformTrimmedID === this.transform._worldID && this._textureTrimmedID === this._texture._updateID) return;
        this._transformTrimmedID = this.transform._worldID;
        this._textureTrimmedID = this._texture._updateID;
        // lets do some special trim code!
        var texture = this._texture;
        var vertexData = this.vertexTrimmedData;
        var orig = texture.orig;
        var anchor = this._anchor;
        // lets calculate the new untrimmed bounds..
        var wt = this.transform.worldTransform;
        var a = wt.a;
        var b = wt.b;
        var c = wt.c;
        var d = wt.d;
        var tx = wt.tx;
        var ty = wt.ty;
        var w1 = -anchor._x * orig.width;
        var w0 = w1 + orig.width;
        var h1 = -anchor._y * orig.height;
        var h0 = h1 + orig.height;
        // xy
        vertexData[0] = a * w1 + c * h1 + tx;
        vertexData[1] = d * h1 + b * w1 + ty;
        // xy
        vertexData[2] = a * w0 + c * h1 + tx;
        vertexData[3] = d * h1 + b * w0 + ty;
        // xy
        vertexData[4] = a * w0 + c * h0 + tx;
        vertexData[5] = d * h0 + b * w0 + ty;
        // xy
        vertexData[6] = a * w1 + c * h0 + tx;
        vertexData[7] = d * h0 + b * w1 + ty;
    };
    /**
    *
    * Renders the object using the WebGL renderer
    *
    * @protected
    * @param {PIXI.Renderer} renderer - The webgl renderer to use.
    */ Sprite2.prototype._render = function(renderer) {
        this.calculateVertices();
        renderer.batch.setObjectRenderer(renderer.plugins[this.pluginName]);
        renderer.plugins[this.pluginName].render(this);
    };
    /**
     * Updates the bounds of the sprite.
     *
     * @protected
     */ Sprite2.prototype._calculateBounds = function() {
        var trim = this._texture.trim;
        var orig = this._texture.orig;
        // First lets check to see if the current texture has a trim..
        if (!trim || trim.width === orig.width && trim.height === orig.height) {
            // no trim! lets use the usual calculations..
            this.calculateVertices();
            this._bounds.addQuad(this.vertexData);
        } else {
            // lets calculate a special trimmed bounds...
            this.calculateTrimmedVertices();
            this._bounds.addQuad(this.vertexTrimmedData);
        }
    };
    /**
     * Gets the local bounds of the sprite object.
     *
     * @param {PIXI.Rectangle} [rect] - Optional output rectangle.
     * @return {PIXI.Rectangle} The bounds.
     */ Sprite2.prototype.getLocalBounds = function(rect) {
        // we can do a fast local bounds if the sprite has no children!
        if (this.children.length === 0) {
            this._bounds.minX = this._texture.orig.width * -this._anchor._x;
            this._bounds.minY = this._texture.orig.height * -this._anchor._y;
            this._bounds.maxX = this._texture.orig.width * (1 - this._anchor._x);
            this._bounds.maxY = this._texture.orig.height * (1 - this._anchor._y);
            if (!rect) {
                if (!this._localBoundsRect) this._localBoundsRect = new _math.Rectangle();
                rect = this._localBoundsRect;
            }
            return this._bounds.getRectangle(rect);
        }
        return _super.prototype.getLocalBounds.call(this, rect);
    };
    /**
     * Tests if a point is inside this sprite
     *
     * @param {PIXI.IPointData} point - the point to test
     * @return {boolean} the result of the test
     */ Sprite2.prototype.containsPoint = function(point) {
        this.worldTransform.applyInverse(point, tempPoint);
        var width = this._texture.orig.width;
        var height = this._texture.orig.height;
        var x1 = -width * this.anchor.x;
        var y1 = 0;
        if (tempPoint.x >= x1 && tempPoint.x < x1 + width) {
            y1 = -height * this.anchor.y;
            if (tempPoint.y >= y1 && tempPoint.y < y1 + height) return true;
        }
        return false;
    };
    /**
     * Destroys this sprite and optionally its texture and children
     *
     * @param {object|boolean} [options] - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.children=false] - if set to true, all the children will have their destroy
     *      method called as well. 'options' will be passed on to those calls.
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the sprite as well
     * @param {boolean} [options.baseTexture=false] - Should it destroy the base texture of the sprite as well
     */ Sprite2.prototype.destroy = function(options) {
        _super.prototype.destroy.call(this, options);
        this._texture.off('update', this._onTextureUpdate, this);
        this._anchor = null;
        var destroyTexture = typeof options === 'boolean' ? options : options && options.texture;
        if (destroyTexture) {
            var destroyBaseTexture = typeof options === 'boolean' ? options : options && options.baseTexture;
            this._texture.destroy(!!destroyBaseTexture);
        }
        this._texture = null;
    };
    // some helper functions..
    /**
     * Helper function that creates a new sprite based on the source you provide.
     * The source can be - frame id, image url, video url, canvas element, video element, base texture
     *
     * @static
     * @param {string|PIXI.Texture|HTMLCanvasElement|HTMLVideoElement} source - Source to create texture from
     * @param {object} [options] - See {@link PIXI.BaseTexture}'s constructor for options.
     * @return {PIXI.Sprite} The newly created sprite
     */ Sprite2.from = function(source, options) {
        var texture = source instanceof _core.Texture ? source : _core.Texture.from(source, options);
        return new Sprite2(texture);
    };
    Object.defineProperty(Sprite2.prototype, "roundPixels", {
        get: function() {
            return this._roundPixels;
        },
        /**
         * If true PixiJS will Math.floor() x/y values when rendering, stopping pixel interpolation.
         * Advantages can include sharper image quality (like text) and faster rendering on canvas.
         * The main disadvantage is movement of objects may appear less smooth.
         * To set the global default, change {@link PIXI.settings.ROUND_PIXELS}
         *
         * @member {boolean}
         * @default false
         */ set: function(value) {
            if (this._roundPixels !== value) this._transformID = -1;
            this._roundPixels = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Sprite2.prototype, "width", {
        /**
         * The width of the sprite, setting this will actually modify the scale to achieve the value set
         *
         * @member {number}
         */ get: function() {
            return Math.abs(this.scale.x) * this._texture.orig.width;
        },
        set: function(value) {
            var s = _utils.sign(this.scale.x) || 1;
            this.scale.x = s * value / this._texture.orig.width;
            this._width = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Sprite2.prototype, "height", {
        /**
         * The height of the sprite, setting this will actually modify the scale to achieve the value set
         *
         * @member {number}
         */ get: function() {
            return Math.abs(this.scale.y) * this._texture.orig.height;
        },
        set: function(value) {
            var s = _utils.sign(this.scale.y) || 1;
            this.scale.y = s * value / this._texture.orig.height;
            this._height = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Sprite2.prototype, "anchor", {
        /**
         * The anchor sets the origin point of the sprite. The default value is taken from the {@link PIXI.Texture|Texture}
         * and passed to the constructor.
         *
         * The default is `(0,0)`, this means the sprite's origin is the top left.
         *
         * Setting the anchor to `(0.5,0.5)` means the sprite's origin is centered.
         *
         * Setting the anchor to `(1,1)` would mean the sprite's origin point will be the bottom right corner.
         *
         * If you pass only single parameter, it will set both x and y to the same value as shown in the example below.
         *
         * @example
         * const sprite = new PIXI.Sprite(texture);
         * sprite.anchor.set(0.5); // This will set the origin to center. (0.5) is same as (0.5, 0.5).
         *
         * @member {PIXI.ObservablePoint}
         */ get: function() {
            return this._anchor;
        },
        set: function(value) {
            this._anchor.copyFrom(value);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Sprite2.prototype, "tint", {
        /**
         * The tint applied to the sprite. This is a hex value.
         * A value of 0xFFFFFF will remove any tint effect.
         *
         * @member {number}
         * @default 0xFFFFFF
         */ get: function() {
            return this._tint;
        },
        set: function(value) {
            this._tint = value;
            this._tintRGB = (value >> 16) + (value & 65280) + ((value & 255) << 16);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Sprite2.prototype, "texture", {
        /**
         * The texture that the sprite is using
         *
         * @member {PIXI.Texture}
         */ get: function() {
            return this._texture;
        },
        set: function(value) {
            if (this._texture === value) return;
            if (this._texture) this._texture.off('update', this._onTextureUpdate, this);
            this._texture = value || _core.Texture.EMPTY;
            this._cachedTint = 16777215;
            this._textureID = -1;
            this._textureTrimmedID = -1;
            if (value) {
                // wait for the texture to load
                if (value.baseTexture.valid) this._onTextureUpdate();
                else value.once('update', this._onTextureUpdate, this);
            }
        },
        enumerable: false,
        configurable: true
    });
    return Sprite2;
}(_display.Container);

},{"@pixi/constants":"lqjFh","@pixi/core":"d0INm","@pixi/display":"hQqz5","@pixi/math":"1qR3C","@pixi/settings":"habh9","@pixi/utils":"joR65","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9ABv3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Spritesheet", ()=>Spritesheet
);
parcelHelpers.export(exports, "SpritesheetLoader", ()=>SpritesheetLoader
);
/*!
 * @pixi/spritesheet - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/spritesheet is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _math = require("@pixi/math");
var _core = require("@pixi/core");
var _utils = require("@pixi/utils");
var _loaders = require("@pixi/loaders");
/**
 * Utility class for maintaining reference to a collection
 * of Textures on a single Spritesheet.
 *
 * To access a sprite sheet from your code pass its JSON data file to Pixi's loader:
 *
 * ```js
 * PIXI.Loader.shared.add("images/spritesheet.json").load(setup);
 *
 * function setup() {
 *   let sheet = PIXI.Loader.shared.resources["images/spritesheet.json"].spritesheet;
 *   ...
 * }
 * ```
 * With the `sheet.textures` you can create Sprite objects,`sheet.animations` can be used to create an AnimatedSprite.
 *
 * Sprite sheets can be packed using tools like {@link https://codeandweb.com/texturepacker|TexturePacker},
 * {@link https://renderhjs.net/shoebox/|Shoebox} or {@link https://github.com/krzysztof-o/spritesheet.js|Spritesheet.js}.
 * Default anchor points (see {@link PIXI.Texture#defaultAnchor}) and grouping of animation sprites are currently only
 * supported by TexturePacker.
 *
 * @class
 * @memberof PIXI
 */ var Spritesheet = function() {
    /**
     * @param {PIXI.BaseTexture|PIXI.Texture} baseTexture - Reference to the source BaseTexture object.
     * @param {Object} data - Spritesheet image data.
     * @param {string} [resolutionFilename] - The filename to consider when determining
     *        the resolution of the spritesheet. If not provided, the imageUrl will
     *        be used on the BaseTexture.
     */ function Spritesheet1(texture, data, resolutionFilename) {
        if (resolutionFilename === void 0) resolutionFilename = null;
        /**
         * Reference to original source image from the Loader. This reference is retained so we
         * can destroy the Texture later on. It is never used internally.
         * @type {PIXI.Texture}
         * @private
         */ this._texture = texture instanceof _core.Texture ? texture : null;
        /**
         * Reference to ths source texture.
         * @type {PIXI.BaseTexture}
         */ this.baseTexture = texture instanceof _core.BaseTexture ? texture : this._texture.baseTexture;
        /**
         * A map containing all textures of the sprite sheet.
         * Can be used to create a {@link PIXI.Sprite|Sprite}:
         * ```js
         * new PIXI.Sprite(sheet.textures["image.png"]);
         * ```
         * @member {Object}
         */ this.textures = {
        };
        /**
         * A map containing the textures for each animation.
         * Can be used to create an {@link PIXI.AnimatedSprite|AnimatedSprite}:
         * ```js
         * new PIXI.AnimatedSprite(sheet.animations["anim_name"])
         * ```
         * @member {Object}
         */ this.animations = {
        };
        /**
         * Reference to the original JSON data.
         * @type {Object}
         */ this.data = data;
        var resource = this.baseTexture.resource;
        /**
         * The resolution of the spritesheet.
         * @type {number}
         */ this.resolution = this._updateResolution(resolutionFilename || (resource ? resource.url : null));
        /**
         * Map of spritesheet frames.
         * @type {Object}
         * @private
         */ this._frames = this.data.frames;
        /**
         * Collection of frame names.
         * @type {string[]}
         * @private
         */ this._frameKeys = Object.keys(this._frames);
        /**
         * Current batch index being processed.
         * @type {number}
         * @private
         */ this._batchIndex = 0;
        /**
         * Callback when parse is completed.
         * @type {Function}
         * @private
         */ this._callback = null;
    }
    /**
     * Generate the resolution from the filename or fallback
     * to the meta.scale field of the JSON data.
     *
     * @private
     * @param {string} resolutionFilename - The filename to use for resolving
     *        the default resolution.
     * @return {number} Resolution to use for spritesheet.
     */ Spritesheet1.prototype._updateResolution = function(resolutionFilename) {
        if (resolutionFilename === void 0) resolutionFilename = null;
        var scale = this.data.meta.scale;
        // Use a defaultValue of `null` to check if a url-based resolution is set
        var resolution = _utils.getResolutionOfUrl(resolutionFilename, null);
        // No resolution found via URL
        if (resolution === null) // Use the scale value or default to 1
        resolution = scale !== undefined ? parseFloat(scale) : 1;
        // For non-1 resolutions, update baseTexture
        if (resolution !== 1) this.baseTexture.setResolution(resolution);
        return resolution;
    };
    /**
     * Parser spritesheet from loaded data. This is done asynchronously
     * to prevent creating too many Texture within a single process.
     *
     * @param {Function} callback - Callback when complete returns
     *        a map of the Textures for this spritesheet.
     */ Spritesheet1.prototype.parse = function(callback) {
        this._batchIndex = 0;
        this._callback = callback;
        if (this._frameKeys.length <= Spritesheet1.BATCH_SIZE) {
            this._processFrames(0);
            this._processAnimations();
            this._parseComplete();
        } else this._nextBatch();
    };
    /**
     * Process a batch of frames
     *
     * @private
     * @param {number} initialFrameIndex - The index of frame to start.
     */ Spritesheet1.prototype._processFrames = function(initialFrameIndex) {
        var frameIndex = initialFrameIndex;
        var maxFrames = Spritesheet1.BATCH_SIZE;
        while(frameIndex - initialFrameIndex < maxFrames && frameIndex < this._frameKeys.length){
            var i = this._frameKeys[frameIndex];
            var data = this._frames[i];
            var rect = data.frame;
            if (rect) {
                var frame = null;
                var trim = null;
                var sourceSize = data.trimmed !== false && data.sourceSize ? data.sourceSize : data.frame;
                var orig = new _math.Rectangle(0, 0, Math.floor(sourceSize.w) / this.resolution, Math.floor(sourceSize.h) / this.resolution);
                if (data.rotated) frame = new _math.Rectangle(Math.floor(rect.x) / this.resolution, Math.floor(rect.y) / this.resolution, Math.floor(rect.h) / this.resolution, Math.floor(rect.w) / this.resolution);
                else frame = new _math.Rectangle(Math.floor(rect.x) / this.resolution, Math.floor(rect.y) / this.resolution, Math.floor(rect.w) / this.resolution, Math.floor(rect.h) / this.resolution);
                //  Check to see if the sprite is trimmed
                if (data.trimmed !== false && data.spriteSourceSize) trim = new _math.Rectangle(Math.floor(data.spriteSourceSize.x) / this.resolution, Math.floor(data.spriteSourceSize.y) / this.resolution, Math.floor(rect.w) / this.resolution, Math.floor(rect.h) / this.resolution);
                this.textures[i] = new _core.Texture(this.baseTexture, frame, orig, trim, data.rotated ? 2 : 0, data.anchor);
                // lets also add the frame to pixi's global cache for 'from' and 'fromLoader' functions
                _core.Texture.addToCache(this.textures[i], i);
            }
            frameIndex++;
        }
    };
    /**
     * Parse animations config
     *
     * @private
     */ Spritesheet1.prototype._processAnimations = function() {
        var animations = this.data.animations || {
        };
        for(var animName in animations){
            this.animations[animName] = [];
            for(var i = 0; i < animations[animName].length; i++){
                var frameName = animations[animName][i];
                this.animations[animName].push(this.textures[frameName]);
            }
        }
    };
    /**
     * The parse has completed.
     *
     * @private
     */ Spritesheet1.prototype._parseComplete = function() {
        var callback = this._callback;
        this._callback = null;
        this._batchIndex = 0;
        callback.call(this, this.textures);
    };
    /**
     * Begin the next batch of textures.
     *
     * @private
     */ Spritesheet1.prototype._nextBatch = function() {
        var _this = this;
        this._processFrames(this._batchIndex * Spritesheet1.BATCH_SIZE);
        this._batchIndex++;
        setTimeout(function() {
            if (_this._batchIndex * Spritesheet1.BATCH_SIZE < _this._frameKeys.length) _this._nextBatch();
            else {
                _this._processAnimations();
                _this._parseComplete();
            }
        }, 0);
    };
    /**
     * Destroy Spritesheet and don't use after this.
     *
     * @param {boolean} [destroyBase=false] - Whether to destroy the base texture as well
     */ Spritesheet1.prototype.destroy = function(destroyBase) {
        var _a;
        if (destroyBase === void 0) destroyBase = false;
        for(var i in this.textures)this.textures[i].destroy();
        this._frames = null;
        this._frameKeys = null;
        this.data = null;
        this.textures = null;
        if (destroyBase) {
            (_a = this._texture) === null || _a === void 0 || _a.destroy();
            this.baseTexture.destroy();
        }
        this._texture = null;
        this.baseTexture = null;
    };
    /**
     * The maximum number of Textures to build per process.
     *
     * @type {number}
     * @default 1000
     */ Spritesheet1.BATCH_SIZE = 1000;
    return Spritesheet1;
}();
/**
 * Reference to Spritesheet object created.
 * @member {PIXI.Spritesheet} spritesheet
 * @memberof PIXI.LoaderResource
 * @instance
 */ /**
 * Dictionary of textures from Spritesheet.
 * @member {object<string, PIXI.Texture>} textures
 * @memberof PIXI.LoaderResource
 * @instance
 */ /**
 * {@link PIXI.Loader} middleware for loading texture atlases that have been created with
 * TexturePacker or similar JSON-based spritesheet.
 *
 * This middleware automatically generates Texture resources.
 *
 * If you're using Webpack or other bundlers and plan on bundling the atlas' JSON,
 * use the {@link PIXI.Spritesheet} class to directly parse the JSON.
 *
 * The Loader's image Resource name is automatically appended with `"_image"`.
 * If a Resource with this name is already loaded, the Loader will skip parsing the
 * Spritesheet. The code below will generate an internal Loader Resource called `"myatlas_image"`.
 *
 * @example
 * loader.add('myatlas', 'path/to/myatlas.json');
 * loader.load(() => {
 *   loader.resources.myatlas; // atlas JSON resource
 *   loader.resources.myatlas_image; // atlas Image resource
 * });
 *
 * @class
 * @memberof PIXI
 * @implements PIXI.ILoaderPlugin
 */ var SpritesheetLoader = function() {
    function SpritesheetLoader1() {
    }
    /**
     * Called after a resource is loaded.
     * @see PIXI.Loader.loaderMiddleware
     * @param {PIXI.LoaderResource} resource
     * @param {function} next
     */ SpritesheetLoader1.use = function(resource, next) {
        var _a, _b;
        // because this is middleware, it execute in loader context. `this` = loader
        var loader = this;
        var imageResourceName = resource.name + "_image";
        // skip if no data, its not json, it isn't spritesheet data, or the image resource already exists
        if (!resource.data || resource.type !== _loaders.LoaderResource.TYPE.JSON || !resource.data.frames || loader.resources[imageResourceName]) {
            next();
            return;
        }
        // Check and add the multi atlas
        // Heavily influenced and based on https://github.com/rocket-ua/pixi-tps-loader/blob/master/src/ResourceLoader.js
        // eslint-disable-next-line camelcase
        var multiPacks = (_b = (_a = resource.data) === null || _a === void 0 ? void 0 : _a.meta) === null || _b === void 0 ? void 0 : _b.related_multi_packs;
        if (Array.isArray(multiPacks)) {
            var _loop_1 = function(item) {
                if (typeof item !== 'string') return "continue";
                var itemName = item.replace('.json', '');
                var itemUrl = _utils.url.resolve(resource.url.replace(loader.baseUrl, ''), item);
                // Check if the file wasn't already added as multipacks are redundant
                if (loader.resources[itemName] || Object.values(loader.resources).some(function(r) {
                    return _utils.url.format(_utils.url.parse(r.url)) === itemUrl;
                })) return "continue";
                var options = {
                    crossOrigin: resource.crossOrigin,
                    loadType: _loaders.LoaderResource.LOAD_TYPE.XHR,
                    xhrType: _loaders.LoaderResource.XHR_RESPONSE_TYPE.JSON,
                    parentResource: resource,
                    metadata: resource.metadata
                };
                loader.add(itemName, itemUrl, options);
            };
            for(var _i = 0, multiPacks_1 = multiPacks; _i < multiPacks_1.length; _i++){
                var item = multiPacks_1[_i];
                _loop_1(item);
            }
        }
        var loadOptions = {
            crossOrigin: resource.crossOrigin,
            metadata: resource.metadata.imageMetadata,
            parentResource: resource
        };
        var resourcePath = SpritesheetLoader1.getResourcePath(resource, loader.baseUrl);
        // load the image for this sheet
        loader.add(imageResourceName, resourcePath, loadOptions, function onImageLoad(res) {
            if (res.error) {
                next(res.error);
                return;
            }
            var spritesheet = new Spritesheet(res.texture, resource.data, resource.url);
            spritesheet.parse(function() {
                resource.spritesheet = spritesheet;
                resource.textures = spritesheet.textures;
                next();
            });
        });
    };
    /**
     * Get the spritesheets root path
     * @param {PIXI.LoaderResource} resource - Resource to check path
     * @param {string} baseUrl - Base root url
     */ SpritesheetLoader1.getResourcePath = function(resource, baseUrl) {
        // Prepend url path unless the resource image is a data url
        if (resource.isDataUrl) return resource.data.meta.image;
        return _utils.url.resolve(resource.url.replace(baseUrl, ''), resource.data.meta.image);
    };
    return SpritesheetLoader1;
}();

},{"@pixi/math":"1qR3C","@pixi/core":"d0INm","@pixi/utils":"joR65","@pixi/loaders":"1PTMa","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"29NuY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "TilingSprite", ()=>TilingSprite1
);
parcelHelpers.export(exports, "TilingSpriteRenderer", ()=>TilingSpriteRenderer1
);
/*!
 * @pixi/sprite-tiling - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/sprite-tiling is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
var _math = require("@pixi/math");
var _sprite = require("@pixi/sprite");
var _constants = require("@pixi/constants");
var _utils = require("@pixi/utils");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var tempPoint = new _math.Point();
/**
 * A tiling sprite is a fast way of rendering a tiling image.
 *
 * @class
 * @extends PIXI.Sprite
 * @memberof PIXI
 */ var TilingSprite1 = function(_super) {
    __extends(TilingSprite2, _super);
    /**
     * @param {PIXI.Texture} texture - the texture of the tiling sprite
     * @param {number} [width=100] - the width of the tiling sprite
     * @param {number} [height=100] - the height of the tiling sprite
     */ function TilingSprite2(texture, width, height) {
        if (width === void 0) width = 100;
        if (height === void 0) height = 100;
        var _this = _super.call(this, texture) || this;
        /**
         * Tile transform
         *
         * @member {PIXI.Transform}
         */ _this.tileTransform = new _math.Transform();
        /**
         * The with of the tiling sprite
         *
         * @member {number}
         * @private
         */ _this._width = width;
        /**
         * The height of the tiling sprite
         *
         * @member {number}
         * @private
         */ _this._height = height;
        /**
         * matrix that is applied to UV to get the coords in Texture normalized space to coords in BaseTexture space
         *
         * @member {PIXI.TextureMatrix}
         */ _this.uvMatrix = _this.texture.uvMatrix || new _core.TextureMatrix(texture);
        /**
         * Plugin that is responsible for rendering this element.
         * Allows to customize the rendering process without overriding '_render' method.
         *
         * @member {string}
         * @default 'tilingSprite'
         */ _this.pluginName = 'tilingSprite';
        /**
         * Flags whether the tiling pattern should originate from the origin instead of the top-left corner in
         * local space.
         *
         * This will make the texture coordinates assigned to each vertex dependent on the value of the anchor. Without
         * this, the top-left corner always gets the (0, 0) texture coordinate.
         *
         * @member {boolean}
         * @default false
         */ _this.uvRespectAnchor = false;
        return _this;
    }
    Object.defineProperty(TilingSprite2.prototype, "clampMargin", {
        /**
         * Changes frame clamping in corresponding textureTransform, shortcut
         * Change to -0.5 to add a pixel to the edge, recommended for transparent trimmed textures in atlas
         *
         * @default 0.5
         * @member {number}
         */ get: function() {
            return this.uvMatrix.clampMargin;
        },
        set: function(value) {
            this.uvMatrix.clampMargin = value;
            this.uvMatrix.update(true);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TilingSprite2.prototype, "tileScale", {
        /**
         * The scaling of the image that is being tiled
         *
         * @member {PIXI.ObservablePoint}
         */ get: function() {
            return this.tileTransform.scale;
        },
        set: function(value) {
            this.tileTransform.scale.copyFrom(value);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TilingSprite2.prototype, "tilePosition", {
        /**
         * The offset of the image that is being tiled
         *
         * @member {PIXI.ObservablePoint}
         */ get: function() {
            return this.tileTransform.position;
        },
        set: function(value) {
            this.tileTransform.position.copyFrom(value);
        },
        enumerable: false,
        configurable: true
    });
    /**
     * @protected
     */ TilingSprite2.prototype._onTextureUpdate = function() {
        if (this.uvMatrix) this.uvMatrix.texture = this._texture;
        this._cachedTint = 16777215;
    };
    /**
     * Renders the object using the WebGL renderer
     *
     * @protected
     * @param {PIXI.Renderer} renderer - The renderer
     */ TilingSprite2.prototype._render = function(renderer) {
        // tweak our texture temporarily..
        var texture = this._texture;
        if (!texture || !texture.valid) return;
        this.tileTransform.updateLocalTransform();
        this.uvMatrix.update();
        renderer.batch.setObjectRenderer(renderer.plugins[this.pluginName]);
        renderer.plugins[this.pluginName].render(this);
    };
    /**
     * Updates the bounds of the tiling sprite.
     *
     * @protected
     */ TilingSprite2.prototype._calculateBounds = function() {
        var minX = this._width * -this._anchor._x;
        var minY = this._height * -this._anchor._y;
        var maxX = this._width * (1 - this._anchor._x);
        var maxY = this._height * (1 - this._anchor._y);
        this._bounds.addFrame(this.transform, minX, minY, maxX, maxY);
    };
    /**
     * Gets the local bounds of the sprite object.
     *
     * @param {PIXI.Rectangle} [rect] - Optional output rectangle.
     * @return {PIXI.Rectangle} The bounds.
     */ TilingSprite2.prototype.getLocalBounds = function(rect) {
        // we can do a fast local bounds if the sprite has no children!
        if (this.children.length === 0) {
            this._bounds.minX = this._width * -this._anchor._x;
            this._bounds.minY = this._height * -this._anchor._y;
            this._bounds.maxX = this._width * (1 - this._anchor._x);
            this._bounds.maxY = this._height * (1 - this._anchor._y);
            if (!rect) {
                if (!this._localBoundsRect) this._localBoundsRect = new _math.Rectangle();
                rect = this._localBoundsRect;
            }
            return this._bounds.getRectangle(rect);
        }
        return _super.prototype.getLocalBounds.call(this, rect);
    };
    /**
     * Checks if a point is inside this tiling sprite.
     *
     * @param {PIXI.IPointData} point - the point to check
     * @return {boolean} Whether or not the sprite contains the point.
     */ TilingSprite2.prototype.containsPoint = function(point) {
        this.worldTransform.applyInverse(point, tempPoint);
        var width = this._width;
        var height = this._height;
        var x1 = -width * this.anchor._x;
        if (tempPoint.x >= x1 && tempPoint.x < x1 + width) {
            var y1 = -height * this.anchor._y;
            if (tempPoint.y >= y1 && tempPoint.y < y1 + height) return true;
        }
        return false;
    };
    /**
     * Destroys this sprite and optionally its texture and children
     *
     * @param {object|boolean} [options] - Options parameter. A boolean will act as if all options
     *  have been set to that value
     * @param {boolean} [options.children=false] - if set to true, all the children will have their destroy
     *      method called as well. 'options' will be passed on to those calls.
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the sprite as well
     * @param {boolean} [options.baseTexture=false] - Should it destroy the base texture of the sprite as well
     */ TilingSprite2.prototype.destroy = function(options) {
        _super.prototype.destroy.call(this, options);
        this.tileTransform = null;
        this.uvMatrix = null;
    };
    /**
     * Helper function that creates a new tiling sprite based on the source you provide.
     * The source can be - frame id, image url, video url, canvas element, video element, base texture
     *
     * @static
     * @param {string|PIXI.Texture|HTMLCanvasElement|HTMLVideoElement} source - Source to create texture from
     * @param {Object} options - See {@link PIXI.BaseTexture}'s constructor for options.
     * @param {number} options.width - required width of the tiling sprite
     * @param {number} options.height - required height of the tiling sprite
     * @return {PIXI.TilingSprite} The newly created texture
     */ TilingSprite2.from = function(source, options) {
        var texture = source instanceof _core.Texture ? source : _core.Texture.from(source, options);
        return new TilingSprite2(texture, options.width, options.height);
    };
    Object.defineProperty(TilingSprite2.prototype, "width", {
        /**
         * The width of the sprite, setting this will actually modify the scale to achieve the value set
         *
         * @member {number}
         */ get: function() {
            return this._width;
        },
        set: function(value) {
            this._width = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(TilingSprite2.prototype, "height", {
        /**
         * The height of the TilingSprite, setting this will actually modify the scale to achieve the value set
         *
         * @member {number}
         */ get: function() {
            return this._height;
        },
        set: function(value) {
            this._height = value;
        },
        enumerable: false,
        configurable: true
    });
    return TilingSprite2;
}(_sprite.Sprite);
var vertex = "attribute vec2 aVertexPosition;\nattribute vec2 aTextureCoord;\n\nuniform mat3 projectionMatrix;\nuniform mat3 translationMatrix;\nuniform mat3 uTransform;\n\nvarying vec2 vTextureCoord;\n\nvoid main(void)\n{\n    gl_Position = vec4((projectionMatrix * translationMatrix * vec3(aVertexPosition, 1.0)).xy, 0.0, 1.0);\n\n    vTextureCoord = (uTransform * vec3(aTextureCoord, 1.0)).xy;\n}\n";
var fragment = "varying vec2 vTextureCoord;\n\nuniform sampler2D uSampler;\nuniform vec4 uColor;\nuniform mat3 uMapCoord;\nuniform vec4 uClampFrame;\nuniform vec2 uClampOffset;\n\nvoid main(void)\n{\n    vec2 coord = vTextureCoord + ceil(uClampOffset - vTextureCoord);\n    coord = (uMapCoord * vec3(coord, 1.0)).xy;\n    coord = clamp(coord, uClampFrame.xy, uClampFrame.zw);\n\n    vec4 texSample = texture2D(uSampler, coord);\n    gl_FragColor = texSample * uColor;\n}\n";
var fragmentSimple = "varying vec2 vTextureCoord;\n\nuniform sampler2D uSampler;\nuniform vec4 uColor;\n\nvoid main(void)\n{\n    vec4 sample = texture2D(uSampler, vTextureCoord);\n    gl_FragColor = sample * uColor;\n}\n";
var tempMat = new _math.Matrix();
/**
 * WebGL renderer plugin for tiling sprites
 *
 * @class
 * @memberof PIXI
 * @extends PIXI.ObjectRenderer
 */ var TilingSpriteRenderer1 = function(_super) {
    __extends(TilingSpriteRenderer2, _super);
    /**
     * constructor for renderer
     *
     * @param {PIXI.Renderer} renderer - The renderer this tiling awesomeness works for.
     */ function TilingSpriteRenderer2(renderer) {
        var _this = _super.call(this, renderer) || this;
        var uniforms = {
            globals: _this.renderer.globalUniforms
        };
        _this.shader = _core.Shader.from(vertex, fragment, uniforms);
        _this.simpleShader = _core.Shader.from(vertex, fragmentSimple, uniforms);
        _this.quad = new _core.QuadUv();
        /**
         * The WebGL state in which this renderer will work.
         *
         * @member {PIXI.State}
         * @readonly
         */ _this.state = _core.State.for2d();
        return _this;
    }
    /**
     *
     * @param {PIXI.TilingSprite} ts - tilingSprite to be rendered
     */ TilingSpriteRenderer2.prototype.render = function(ts) {
        var renderer = this.renderer;
        var quad = this.quad;
        var vertices = quad.vertices;
        vertices[0] = vertices[6] = ts._width * -ts.anchor.x;
        vertices[1] = vertices[3] = ts._height * -ts.anchor.y;
        vertices[2] = vertices[4] = ts._width * (1 - ts.anchor.x);
        vertices[5] = vertices[7] = ts._height * (1 - ts.anchor.y);
        var anchorX = ts.uvRespectAnchor ? ts.anchor.x : 0;
        var anchorY = ts.uvRespectAnchor ? ts.anchor.y : 0;
        vertices = quad.uvs;
        vertices[0] = vertices[6] = -anchorX;
        vertices[1] = vertices[3] = -anchorY;
        vertices[2] = vertices[4] = 1 - anchorX;
        vertices[5] = vertices[7] = 1 - anchorY;
        quad.invalidate();
        var tex = ts._texture;
        var baseTex = tex.baseTexture;
        var lt = ts.tileTransform.localTransform;
        var uv = ts.uvMatrix;
        var isSimple = baseTex.isPowerOfTwo && tex.frame.width === baseTex.width && tex.frame.height === baseTex.height;
        // auto, force repeat wrapMode for big tiling textures
        if (isSimple) {
            if (!baseTex._glTextures[renderer.CONTEXT_UID]) {
                if (baseTex.wrapMode === _constants.WRAP_MODES.CLAMP) baseTex.wrapMode = _constants.WRAP_MODES.REPEAT;
            } else isSimple = baseTex.wrapMode !== _constants.WRAP_MODES.CLAMP;
        }
        var shader = isSimple ? this.simpleShader : this.shader;
        var w = tex.width;
        var h = tex.height;
        var W = ts._width;
        var H = ts._height;
        tempMat.set(lt.a * w / W, lt.b * w / H, lt.c * h / W, lt.d * h / H, lt.tx / W, lt.ty / H);
        // that part is the same as above:
        // tempMat.identity();
        // tempMat.scale(tex.width, tex.height);
        // tempMat.prepend(lt);
        // tempMat.scale(1.0 / ts._width, 1.0 / ts._height);
        tempMat.invert();
        if (isSimple) tempMat.prepend(uv.mapCoord);
        else {
            shader.uniforms.uMapCoord = uv.mapCoord.toArray(true);
            shader.uniforms.uClampFrame = uv.uClampFrame;
            shader.uniforms.uClampOffset = uv.uClampOffset;
        }
        shader.uniforms.uTransform = tempMat.toArray(true);
        shader.uniforms.uColor = _utils.premultiplyTintToRgba(ts.tint, ts.worldAlpha, shader.uniforms.uColor, baseTex.alphaMode);
        shader.uniforms.translationMatrix = ts.transform.worldTransform.toArray(true);
        shader.uniforms.uSampler = tex;
        renderer.shader.bind(shader);
        renderer.geometry.bind(quad);
        this.state.blendMode = _utils.correctBlendMode(ts.blendMode, baseTex.alphaMode);
        renderer.state.set(this.state);
        renderer.geometry.draw(this.renderer.gl.TRIANGLES, 6, 0);
    };
    return TilingSpriteRenderer2;
}(_core.ObjectRenderer);

},{"@pixi/core":"d0INm","@pixi/math":"1qR3C","@pixi/sprite":"aeiZG","@pixi/constants":"lqjFh","@pixi/utils":"joR65","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"h5Lr7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BitmapFont", ()=>BitmapFont
);
parcelHelpers.export(exports, "BitmapFontData", ()=>BitmapFontData
);
parcelHelpers.export(exports, "BitmapFontLoader", ()=>BitmapFontLoader
);
parcelHelpers.export(exports, "BitmapText", ()=>BitmapText1
);
/*!
 * @pixi/text-bitmap - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/text-bitmap is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _math = require("@pixi/math");
var _settings = require("@pixi/settings");
var _mesh = require("@pixi/mesh");
var _utils = require("@pixi/utils");
var _core = require("@pixi/core");
var _text = require("@pixi/text");
var _display = require("@pixi/display");
var _loaders = require("@pixi/loaders");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/* eslint-disable max-len */ /**
 * Normalized parsed data from .fnt files.
 *
 * @class
 * @memberof PIXI
 */ var BitmapFontData = function() {
    function BitmapFontData1() {
        /**
         * @member {PIXI.IBitmapFontDataInfo[]}
         * @readOnly
         */ this.info = [];
        /**
         * @member {PIXI.IBitmapFontDataCommon[]}
         * @readOnly
         */ this.common = [];
        /**
         * @member {PIXI.IBitmapFontDataPage[]}
         * @readOnly
         */ this.page = [];
        /**
         * @member {PIXI.IBitmapFontDataChar[]}
         * @readOnly
         */ this.char = [];
        /**
         * @member {PIXI.IBitmapFontDataKerning[]}
         * @readOnly
         */ this.kerning = [];
    }
    return BitmapFontData1;
}();
/**
 * @memberof PIXI
 * @typedef {object} IBitmapFontDataInfo
 * @property {string} face
 * @property {number} size
 */ /**
 * @memberof PIXI
 * @typedef {object} IBitmapFontDataCommon
 * @property {number} lineHeight
 */ /**
 * @memberof PIXI
 * @typedef {object} IBitmapFontDataPage
 * @property {number} id
 * @property {string} file
 */ /**
 * @memberof PIXI
 * @typedef {object} IBitmapFontDataChar
 * @property {string} id
 * @property {number} page
 * @property {number} x
 * @property {number} y
 * @property {number} width
 * @property {number} height
 * @property {number} xoffset
 * @property {number} yoffset
 * @property {number} xadvance
 */ /**
 * @memberof PIXI
 * @typedef {object} IBitmapFontDataKerning
 * @property {number} first
 * @property {number} second
 * @property {number} amount
 */ /**
 * BitmapFont format that's Text-based.
 *
 * @class
 * @private
 */ var TextFormat = function() {
    function TextFormat1() {
    }
    /**
     * Check if resource refers to txt font data.
     *
     * @static
     * @private
     * @param {any} data
     * @return {boolean} True if resource could be treated as font data, false otherwise.
     */ TextFormat1.test = function(data) {
        return typeof data === 'string' && data.indexOf('info face=') === 0;
    };
    /**
     * Convert text font data to a javascript object.
     *
     * @static
     * @private
     * @param {string} txt - Raw string data to be converted
     * @return {PIXI.BitmapFontData} Parsed font data
     */ TextFormat1.parse = function(txt) {
        // Retrieve data item
        var items = txt.match(/^[a-z]+\s+.+$/gm);
        var rawData = {
            info: [],
            common: [],
            page: [],
            char: [],
            chars: [],
            kerning: [],
            kernings: []
        };
        for(var i in items){
            // Extract item name
            var name = items[i].match(/^[a-z]+/gm)[0];
            // Extract item attribute list as string ex.: "width=10"
            var attributeList = items[i].match(/[a-zA-Z]+=([^\s"']+|"([^"]*)")/gm);
            // Convert attribute list into an object
            var itemData = {
            };
            for(var i_1 in attributeList){
                // Split key-value pairs
                var split = attributeList[i_1].split('=');
                var key = split[0];
                // Remove eventual quotes from value
                var strValue = split[1].replace(/"/gm, '');
                // Try to convert value into float
                var floatValue = parseFloat(strValue);
                // Use string value case float value is NaN
                var value = isNaN(floatValue) ? strValue : floatValue;
                itemData[key] = value;
            }
            // Push current item to the resulting data
            rawData[name].push(itemData);
        }
        var font = new BitmapFontData();
        rawData.info.forEach(function(info) {
            return font.info.push({
                face: info.face,
                size: parseInt(info.size, 10)
            });
        });
        rawData.common.forEach(function(common) {
            return font.common.push({
                lineHeight: parseInt(common.lineHeight, 10)
            });
        });
        rawData.page.forEach(function(page) {
            return font.page.push({
                id: parseInt(page.id, 10),
                file: page.file
            });
        });
        rawData.char.forEach(function(char) {
            return font.char.push({
                id: parseInt(char.id, 10),
                page: parseInt(char.page, 10),
                x: parseInt(char.x, 10),
                y: parseInt(char.y, 10),
                width: parseInt(char.width, 10),
                height: parseInt(char.height, 10),
                xoffset: parseInt(char.xoffset, 10),
                yoffset: parseInt(char.yoffset, 10),
                xadvance: parseInt(char.xadvance, 10)
            });
        });
        rawData.kerning.forEach(function(kerning) {
            return font.kerning.push({
                first: parseInt(kerning.first, 10),
                second: parseInt(kerning.second, 10),
                amount: parseInt(kerning.amount, 10)
            });
        });
        return font;
    };
    return TextFormat1;
}();
/**
 * BitmapFont format that's XML-based.
 *
 * @class
 * @private
 */ var XMLFormat = function() {
    function XMLFormat1() {
    }
    /**
     * Check if resource refers to xml font data.
     *
     * @static
     * @private
     * @param {any} data
     * @return {boolean} True if resource could be treated as font data, false otherwise.
     */ XMLFormat1.test = function(data) {
        return data instanceof XMLDocument && data.getElementsByTagName('page').length && data.getElementsByTagName('info')[0].getAttribute('face') !== null;
    };
    /**
     * Convert the XML into BitmapFontData that we can use.
     *
     * @static
     * @private
     * @param {XMLDocument} xml
     * @return {BitmapFontData} Data to use for BitmapFont
     */ XMLFormat1.parse = function(xml) {
        var data = new BitmapFontData();
        var info = xml.getElementsByTagName('info');
        var common = xml.getElementsByTagName('common');
        var page = xml.getElementsByTagName('page');
        var char = xml.getElementsByTagName('char');
        var kerning = xml.getElementsByTagName('kerning');
        for(var i = 0; i < info.length; i++)data.info.push({
            face: info[i].getAttribute('face'),
            size: parseInt(info[i].getAttribute('size'), 10)
        });
        for(var i = 0; i < common.length; i++)data.common.push({
            lineHeight: parseInt(common[i].getAttribute('lineHeight'), 10)
        });
        for(var i = 0; i < page.length; i++)data.page.push({
            id: parseInt(page[i].getAttribute('id'), 10) || 0,
            file: page[i].getAttribute('file')
        });
        for(var i = 0; i < char.length; i++){
            var letter = char[i];
            data.char.push({
                id: parseInt(letter.getAttribute('id'), 10),
                page: parseInt(letter.getAttribute('page'), 10) || 0,
                x: parseInt(letter.getAttribute('x'), 10),
                y: parseInt(letter.getAttribute('y'), 10),
                width: parseInt(letter.getAttribute('width'), 10),
                height: parseInt(letter.getAttribute('height'), 10),
                xoffset: parseInt(letter.getAttribute('xoffset'), 10),
                yoffset: parseInt(letter.getAttribute('yoffset'), 10),
                xadvance: parseInt(letter.getAttribute('xadvance'), 10)
            });
        }
        for(var i = 0; i < kerning.length; i++)data.kerning.push({
            first: parseInt(kerning[i].getAttribute('first'), 10),
            second: parseInt(kerning[i].getAttribute('second'), 10),
            amount: parseInt(kerning[i].getAttribute('amount'), 10)
        });
        return data;
    };
    return XMLFormat1;
}();
/**
 * BitmapFont format that's XML-based.
 *
 * @class
 * @private
 */ var XMLStringFormat = function() {
    function XMLStringFormat1() {
    }
    /**
     * Check if resource refers to text xml font data.
     *
     * @static
     * @private
     * @param {any} data
     * @return {boolean} True if resource could be treated as font data, false otherwise.
     */ XMLStringFormat1.test = function(data) {
        if (typeof data === 'string' && data.indexOf('<font>') > -1) {
            var xml = new self.DOMParser().parseFromString(data, 'text/xml');
            return XMLFormat.test(xml);
        }
        return false;
    };
    /**
     * Convert the text XML into BitmapFontData that we can use.
     *
     * @static
     * @private
     * @param {string} xmlTxt
     * @return {BitmapFontData} Data to use for BitmapFont
     */ XMLStringFormat1.parse = function(xmlTxt) {
        var xml = new self.DOMParser().parseFromString(xmlTxt, 'text/xml');
        return XMLFormat.parse(xml);
    };
    return XMLStringFormat1;
}();
// Registered formats, maybe make this extensible in the future?
var formats = [
    TextFormat,
    XMLFormat,
    XMLStringFormat
];
/**
 * Auto-detect BitmapFont parsing format based on data.
 * @private
 * @param {any} data - Data to detect format
 * @return {any} Format or null
 */ function autoDetectFormat(data) {
    for(var i = 0; i < formats.length; i++){
        if (formats[i].test(data)) return formats[i];
    }
    return null;
}
// TODO: Prevent code duplication b/w generateFillStyle & Text#generateFillStyle
/**
 * Generates the fill style. Can automatically generate a gradient based on the fill style being an array
 *
 * @private
 * @param {object} style - The style.
 * @param {string[]} lines - The lines of text.
 * @return {string|number|CanvasGradient} The fill style
 */ function generateFillStyle(canvas, context, style, resolution, lines, metrics) {
    // TODO: Can't have different types for getter and setter. The getter shouldn't have the number type as
    //       the setter converts to string. See this thread for more details:
    //       https://github.com/microsoft/TypeScript/issues/2521
    var fillStyle = style.fill;
    if (!Array.isArray(fillStyle)) return fillStyle;
    else if (fillStyle.length === 1) return fillStyle[0];
    // the gradient will be evenly spaced out according to how large the array is.
    // ['#FF0000', '#00FF00', '#0000FF'] would created stops at 0.25, 0.5 and 0.75
    var gradient;
    // a dropshadow will enlarge the canvas and result in the gradient being
    // generated with the incorrect dimensions
    var dropShadowCorrection = style.dropShadow ? style.dropShadowDistance : 0;
    // should also take padding into account, padding can offset the gradient
    var padding = style.padding || 0;
    var width = canvas.width / resolution - dropShadowCorrection - padding * 2;
    var height = canvas.height / resolution - dropShadowCorrection - padding * 2;
    // make a copy of the style settings, so we can manipulate them later
    var fill = fillStyle.slice();
    var fillGradientStops = style.fillGradientStops.slice();
    // wanting to evenly distribute the fills. So an array of 4 colours should give fills of 0.25, 0.5 and 0.75
    if (!fillGradientStops.length) {
        var lengthPlus1 = fill.length + 1;
        for(var i = 1; i < lengthPlus1; ++i)fillGradientStops.push(i / lengthPlus1);
    }
    // stop the bleeding of the last gradient on the line above to the top gradient of the this line
    // by hard defining the first gradient colour at point 0, and last gradient colour at point 1
    fill.unshift(fillStyle[0]);
    fillGradientStops.unshift(0);
    fill.push(fillStyle[fillStyle.length - 1]);
    fillGradientStops.push(1);
    if (style.fillGradientType === _text.TEXT_GRADIENT.LINEAR_VERTICAL) {
        // start the gradient at the top center of the canvas, and end at the bottom middle of the canvas
        gradient = context.createLinearGradient(width / 2, padding, width / 2, height + padding);
        // we need to repeat the gradient so that each individual line of text has the same vertical gradient effect
        // ['#FF0000', '#00FF00', '#0000FF'] over 2 lines would create stops at 0.125, 0.25, 0.375, 0.625, 0.75, 0.875
        // There's potential for floating point precision issues at the seams between gradient repeats.
        // The loop below generates the stops in order, so track the last generated one to prevent
        // floating point precision from making us go the teeniest bit backwards, resulting in
        // the first and last colors getting swapped.
        var lastIterationStop = 0;
        // Actual height of the text itself, not counting spacing for lineHeight/leading/dropShadow etc
        var textHeight = metrics.fontProperties.fontSize + style.strokeThickness;
        // textHeight, but as a 0-1 size in global gradient stop space
        var gradStopLineHeight = textHeight / height;
        for(var i = 0; i < lines.length; i++){
            var thisLineTop = metrics.lineHeight * i;
            for(var j = 0; j < fill.length; j++){
                // 0-1 stop point for the current line, multiplied to global space afterwards
                var lineStop = 0;
                if (typeof fillGradientStops[j] === 'number') lineStop = fillGradientStops[j];
                else lineStop = j / fill.length;
                var globalStop = thisLineTop / height + lineStop * gradStopLineHeight;
                // Prevent color stop generation going backwards from floating point imprecision
                var clampedStop = Math.max(lastIterationStop, globalStop);
                clampedStop = Math.min(clampedStop, 1); // Cap at 1 as well for safety's sake to avoid a possible throw.
                gradient.addColorStop(clampedStop, fill[j]);
                lastIterationStop = clampedStop;
            }
        }
    } else {
        // start the gradient at the center left of the canvas, and end at the center right of the canvas
        gradient = context.createLinearGradient(padding, height / 2, width + padding, height / 2);
        // can just evenly space out the gradients in this case, as multiple lines makes no difference
        // to an even left to right gradient
        var totalIterations = fill.length + 1;
        var currentIteration = 1;
        for(var i = 0; i < fill.length; i++){
            var stop = void 0;
            if (typeof fillGradientStops[i] === 'number') stop = fillGradientStops[i];
            else stop = currentIteration / totalIterations;
            gradient.addColorStop(stop, fill[i]);
            currentIteration++;
        }
    }
    return gradient;
}
// TODO: Prevent code duplication b/w drawGlyph & Text#updateText
/**
 * Draws the glyph `metrics.text` on the given canvas.
 *
 * Ignored because not directly exposed.
 *
 * @ignore
 * @param {HTMLCanvasElement} canvas
 * @param {CanvasRenderingContext2D} context
 * @param {TextMetrics} metrics
 * @param {number} x
 * @param {number} y
 * @param {number} resolution
 * @param {TextStyle} style
 */ function drawGlyph(canvas, context, metrics, x, y, resolution, style) {
    var char = metrics.text;
    var fontProperties = metrics.fontProperties;
    context.translate(x, y);
    context.scale(resolution, resolution);
    var tx = style.strokeThickness / 2;
    var ty = -(style.strokeThickness / 2);
    context.font = style.toFontString();
    context.lineWidth = style.strokeThickness;
    context.textBaseline = style.textBaseline;
    context.lineJoin = style.lineJoin;
    context.miterLimit = style.miterLimit;
    // set canvas text styles
    context.fillStyle = generateFillStyle(canvas, context, style, resolution, [
        char
    ], metrics);
    context.strokeStyle = style.stroke;
    var dropShadowColor = style.dropShadowColor;
    var rgb = _utils.hex2rgb(typeof dropShadowColor === 'number' ? dropShadowColor : _utils.string2hex(dropShadowColor));
    if (style.dropShadow) {
        context.shadowColor = "rgba(" + rgb[0] * 255 + "," + rgb[1] * 255 + "," + rgb[2] * 255 + "," + style.dropShadowAlpha + ")";
        context.shadowBlur = style.dropShadowBlur;
        context.shadowOffsetX = Math.cos(style.dropShadowAngle) * style.dropShadowDistance;
        context.shadowOffsetY = Math.sin(style.dropShadowAngle) * style.dropShadowDistance;
    } else {
        context.shadowColor = 'black';
        context.shadowBlur = 0;
        context.shadowOffsetX = 0;
        context.shadowOffsetY = 0;
    }
    if (style.stroke && style.strokeThickness) context.strokeText(char, tx, ty + metrics.lineHeight - fontProperties.descent);
    if (style.fill) context.fillText(char, tx, ty + metrics.lineHeight - fontProperties.descent);
    context.setTransform(1, 0, 0, 1, 0, 0); // defaults needed for older browsers (e.g. Opera 29)
    context.fillStyle = 'rgba(0, 0, 0, 0)';
}
/**
 * Processes the passed character set data and returns a flattened array of all the characters.
 *
 * Ignored because not directly exposed.
 *
 * @ignore
 * @param {string | string[] | string[][] } chars
 * @returns {string[]}
 */ function resolveCharacters(chars) {
    // Split the chars string into individual characters
    if (typeof chars === 'string') chars = [
        chars
    ];
    // Handle an array of characters+ranges
    var result = [];
    for(var i = 0, j = chars.length; i < j; i++){
        var item = chars[i];
        // Handle range delimited by start/end chars
        if (Array.isArray(item)) {
            if (item.length !== 2) throw new Error("[BitmapFont]: Invalid character range length, expecting 2 got " + item.length + ".");
            var startCode = item[0].charCodeAt(0);
            var endCode = item[1].charCodeAt(0);
            if (endCode < startCode) throw new Error('[BitmapFont]: Invalid character range.');
            for(var i_1 = startCode, j_1 = endCode; i_1 <= j_1; i_1++)result.push(String.fromCharCode(i_1));
        } else result.push.apply(result, item.split(''));
    }
    if (result.length === 0) throw new Error('[BitmapFont]: Empty set when resolving characters.');
    return result;
}
/**
 * BitmapFont represents a typeface available for use with the BitmapText class. Use the `install`
 * method for adding a font to be used.
 *
 * @class
 * @memberof PIXI
 */ var BitmapFont = function() {
    /**
     * @param {PIXI.BitmapFontData} data
     * @param {PIXI.Texture[]|Object.<string, PIXI.Texture>} textures
     * @param {boolean} ownsTextures - Setting to `true` will destroy page textures
     *        when the font is uninstalled.
     */ function BitmapFont1(data, textures, ownsTextures) {
        var info = data.info[0];
        var common = data.common[0];
        var page = data.page[0];
        var res = _utils.getResolutionOfUrl(page.file);
        var pageTextures = {
        };
        this._ownsTextures = ownsTextures;
        /**
         * The name of the font face.
         *
         * @member {string}
         * @readonly
         */ this.font = info.face;
        /**
         * The size of the font face in pixels.
         *
         * @member {number}
         * @readonly
         */ this.size = info.size;
        /**
         * The line-height of the font face in pixels.
         *
         * @member {number}
         * @readonly
         */ this.lineHeight = common.lineHeight / res;
        /**
         * The map of characters by character code.
         *
         * @member {object}
         * @readonly
         */ this.chars = {
        };
        /**
         * The map of base page textures (i.e., sheets of glyphs).
         *
         * @member {object}
         * @readonly
         * @private
         */ this.pageTextures = pageTextures;
        // Convert the input Texture, Textures or object
        // into a page Texture lookup by "id"
        for(var i = 0; i < data.page.length; i++){
            var _a = data.page[i], id = _a.id, file = _a.file;
            pageTextures[id] = textures instanceof Array ? textures[i] : textures[file];
        }
        // parse letters
        for(var i = 0; i < data.char.length; i++){
            var _b = data.char[i], id = _b.id, page_1 = _b.page;
            var _c = data.char[i], x = _c.x, y = _c.y, width = _c.width, height = _c.height, xoffset = _c.xoffset, yoffset = _c.yoffset, xadvance = _c.xadvance;
            x /= res;
            y /= res;
            width /= res;
            height /= res;
            xoffset /= res;
            yoffset /= res;
            xadvance /= res;
            var rect = new _math.Rectangle(x + pageTextures[page_1].frame.x / res, y + pageTextures[page_1].frame.y / res, width, height);
            this.chars[id] = {
                xOffset: xoffset,
                yOffset: yoffset,
                xAdvance: xadvance,
                kerning: {
                },
                texture: new _core.Texture(pageTextures[page_1].baseTexture, rect),
                page: page_1
            };
        }
        // parse kernings
        for(var i = 0; i < data.kerning.length; i++){
            var _d = data.kerning[i], first = _d.first, second = _d.second, amount = _d.amount;
            first /= res;
            second /= res;
            amount /= res;
            if (this.chars[second]) this.chars[second].kerning[first] = amount;
        }
    }
    /**
     * Remove references to created glyph textures.
     */ BitmapFont1.prototype.destroy = function() {
        for(var id in this.chars){
            this.chars[id].texture.destroy();
            this.chars[id].texture = null;
        }
        for(var id in this.pageTextures){
            if (this._ownsTextures) this.pageTextures[id].destroy(true);
            this.pageTextures[id] = null;
        }
        // Set readonly null.
        this.chars = null;
        this.pageTextures = null;
    };
    /**
     * Register a new bitmap font.
     *
     * @static
     * @param {XMLDocument|string|PIXI.BitmapFontData} data - The
     *        characters map that could be provided as xml or raw string.
     * @param {Object.<string, PIXI.Texture>|PIXI.Texture|PIXI.Texture[]}
     *        textures - List of textures for each page.
     * @param managedTexture - Set to `true` to destroy page textures
     *        when the font is uninstalled. By default fonts created with
     *        `BitmapFont.from` or from the `BitmapFontLoader` are `true`.
     * @return {PIXI.BitmapFont} Result font object with font, size, lineHeight
     *         and char fields.
     */ BitmapFont1.install = function(data, textures, ownsTextures) {
        var fontData;
        if (data instanceof BitmapFontData) fontData = data;
        else {
            var format = autoDetectFormat(data);
            if (!format) throw new Error('Unrecognized data format for font.');
            fontData = format.parse(data);
        }
        // Single texture, convert to list
        if (textures instanceof _core.Texture) textures = [
            textures
        ];
        var font = new BitmapFont1(fontData, textures, ownsTextures);
        BitmapFont1.available[font.font] = font;
        return font;
    };
    /**
     * Remove bitmap font by name.
     *
     * @static
     * @param name - Name of the font to uninstall.
     */ BitmapFont1.uninstall = function(name) {
        var font = BitmapFont1.available[name];
        if (!font) throw new Error("No font found named '" + name + "'");
        font.destroy();
        delete BitmapFont1.available[name];
    };
    /**
     * Generates a bitmap-font for the given style and character set. This does not support
     * kernings yet. With `style` properties, only the following non-layout properties are used:
     *
     * - {@link PIXI.TextStyle#dropShadow|dropShadow}
     * - {@link PIXI.TextStyle#dropShadowDistance|dropShadowDistance}
     * - {@link PIXI.TextStyle#dropShadowColor|dropShadowColor}
     * - {@link PIXI.TextStyle#dropShadowBlur|dropShadowBlur}
     * - {@link PIXI.TextStyle#dropShadowAngle|dropShadowAngle}
     * - {@link PIXI.TextStyle#fill|fill}
     * - {@link PIXI.TextStyle#fillGradientStops|fillGradientStops}
     * - {@link PIXI.TextStyle#fillGradientType|fillGradientType}
     * - {@link PIXI.TextStyle#fontFamily|fontFamily}
     * - {@link PIXI.TextStyle#fontSize|fontSize}
     * - {@link PIXI.TextStyle#fontVariant|fontVariant}
     * - {@link PIXI.TextStyle#fontWeight|fontWeight}
     * - {@link PIXI.TextStyle#lineJoin|lineJoin}
     * - {@link PIXI.TextStyle#miterLimit|miterLimit}
     * - {@link PIXI.TextStyle#stroke|stroke}
     * - {@link PIXI.TextStyle#strokeThickness|strokeThickness}
     * - {@link PIXI.TextStyle#textBaseline|textBaseline}
     *
     * @param {string} name - The name of the custom font to use with BitmapText.
     * @param {object|PIXI.TextStyle} [style] - Style options to render with BitmapFont.
     * @param {PIXI.IBitmapFontOptions} [options] - Setup options for font or name of the font.
     * @param {string|string[]|string[][]} [options.chars=PIXI.BitmapFont.ALPHANUMERIC] - characters included
     *      in the font set. You can also use ranges. For example, `[['a', 'z'], ['A', 'Z'], "!@#$%^&*()~{}[] "]`.
     *      Don't forget to include spaces ' ' in your character set!
     * @param {number} [options.resolution=1] - Render resolution for glyphs.
     * @param {number} [options.textureWidth=512] - Optional width of atlas, smaller values to reduce memory.
     * @param {number} [options.textureHeight=512] - Optional height of atlas, smaller values to reduce memory.
     * @param {number} [options.padding=4] - Padding between glyphs on texture atlas.
     * @return {PIXI.BitmapFont} Font generated by style options.
     * @static
     * @example
     * PIXI.BitmapFont.from("TitleFont", {
     *     fontFamily: "Arial",
     *     fontSize: 12,
     *     strokeThickness: 2,
     *     fill: "purple"
     * });
     *
     * const title = new PIXI.BitmapText("This is the title", { fontName: "TitleFont" });
     */ BitmapFont1.from = function(name, textStyle, options) {
        if (!name) throw new Error('[BitmapFont] Property `name` is required.');
        var _a = Object.assign({
        }, BitmapFont1.defaultOptions, options), chars = _a.chars, padding = _a.padding, resolution = _a.resolution, textureWidth = _a.textureWidth, textureHeight = _a.textureHeight;
        var charsList = resolveCharacters(chars);
        var style = textStyle instanceof _text.TextStyle ? textStyle : new _text.TextStyle(textStyle);
        var lineWidth = textureWidth;
        var fontData = new BitmapFontData();
        fontData.info[0] = {
            face: style.fontFamily,
            size: style.fontSize
        };
        fontData.common[0] = {
            lineHeight: style.fontSize
        };
        var positionX = 0;
        var positionY = 0;
        var canvas;
        var context;
        var baseTexture;
        var maxCharHeight = 0;
        var textures = [];
        for(var i = 0; i < charsList.length; i++){
            if (!canvas) {
                canvas = document.createElement('canvas');
                canvas.width = textureWidth;
                canvas.height = textureHeight;
                context = canvas.getContext('2d');
                baseTexture = new _core.BaseTexture(canvas, {
                    resolution: resolution
                });
                textures.push(new _core.Texture(baseTexture));
                fontData.page.push({
                    id: textures.length - 1,
                    file: ''
                });
            }
            // Measure glyph dimensions
            var metrics = _text.TextMetrics.measureText(charsList[i], style, false, canvas);
            var width = metrics.width;
            var height = Math.ceil(metrics.height);
            // This is ugly - but italics are given more space so they don't overlap
            var textureGlyphWidth = Math.ceil((style.fontStyle === 'italic' ? 2 : 1) * width);
            // Can't fit char anymore: next canvas please!
            if (positionY >= textureHeight - height * resolution) {
                if (positionY === 0) // We don't want user debugging an infinite loop (or do we? :)
                throw new Error("[BitmapFont] textureHeight " + textureHeight + "px is " + ("too small for " + style.fontSize + "px fonts"));
                --i;
                // Create new atlas once current has filled up
                canvas = null;
                context = null;
                baseTexture = null;
                positionY = 0;
                positionX = 0;
                maxCharHeight = 0;
                continue;
            }
            maxCharHeight = Math.max(height + metrics.fontProperties.descent, maxCharHeight);
            // Wrap line once full row has been rendered
            if (textureGlyphWidth * resolution + positionX >= lineWidth) {
                --i;
                positionY += maxCharHeight * resolution;
                positionY = Math.ceil(positionY);
                positionX = 0;
                maxCharHeight = 0;
                continue;
            }
            drawGlyph(canvas, context, metrics, positionX, positionY, resolution, style);
            // Unique (numeric) ID mapping to this glyph
            var id = metrics.text.charCodeAt(0);
            // Create a texture holding just the glyph
            fontData.char.push({
                id: id,
                page: textures.length - 1,
                x: positionX / resolution,
                y: positionY / resolution,
                width: textureGlyphWidth,
                height: height,
                xoffset: 0,
                yoffset: 0,
                xadvance: Math.ceil(width - (style.dropShadow ? style.dropShadowDistance : 0) - (style.stroke ? style.strokeThickness : 0))
            });
            positionX += (textureGlyphWidth + 2 * padding) * resolution;
            positionX = Math.ceil(positionX);
        }
        // Brute-force kerning info, this can be expensive b/c it's an O(n²),
        // but we're using measureText which is native and fast.
        for(var i = 0, len = charsList.length; i < len; i++){
            var first = charsList[i];
            for(var j = 0; j < len; j++){
                var second = charsList[j];
                var c1 = context.measureText(first).width;
                var c2 = context.measureText(second).width;
                var total = context.measureText(first + second).width;
                var amount = total - (c1 + c2);
                if (amount) fontData.kerning.push({
                    first: first.charCodeAt(0),
                    second: second.charCodeAt(0),
                    amount: amount
                });
            }
        }
        var font = new BitmapFont1(fontData, textures, true);
        // Make it easier to replace a font
        if (BitmapFont1.available[name] !== undefined) BitmapFont1.uninstall(name);
        BitmapFont1.available[name] = font;
        return font;
    };
    /**
     * This character set includes all the letters in the alphabet (both lower- and upper- case).
     * @readonly
     * @static
     * @member {string[][]}
     * @example
     * BitmapFont.from("ExampleFont", style, { chars: BitmapFont.ALPHA })
     */ BitmapFont1.ALPHA = [
        [
            'a',
            'z'
        ],
        [
            'A',
            'Z'
        ],
        ' '
    ];
    /**
     * This character set includes all decimal digits (from 0 to 9).
     * @readonly
     * @static
     * @member {string[][]}
     * @example
     * BitmapFont.from("ExampleFont", style, { chars: BitmapFont.NUMERIC })
     */ BitmapFont1.NUMERIC = [
        [
            '0',
            '9'
        ]
    ];
    /**
     * This character set is the union of `BitmapFont.ALPHA` and `BitmapFont.NUMERIC`.
     * @readonly
     * @static
     * @member {string[][]}
     */ BitmapFont1.ALPHANUMERIC = [
        [
            'a',
            'z'
        ],
        [
            'A',
            'Z'
        ],
        [
            '0',
            '9'
        ],
        ' '
    ];
    /**
     * This character set consists of all the ASCII table.
     * @readonly
     * @static
     * @member {string[][]}
     * @see http://www.asciitable.com/
     */ BitmapFont1.ASCII = [
        [
            ' ',
            '~'
        ]
    ];
    /**
     * Collection of default options when using `BitmapFont.from`.
     *
     * @readonly
     * @static
     * @member {PIXI.IBitmapFontOptions}
     * @property {number} resolution=1
     * @property {number} textureWidth=512
     * @property {number} textureHeight=512
     * @property {number} padding=4
     * @property {string|string[]|string[][]} chars = PIXI.BitmapFont.ALPHANUMERIC
     */ BitmapFont1.defaultOptions = {
        resolution: 1,
        textureWidth: 512,
        textureHeight: 512,
        padding: 4,
        chars: BitmapFont1.ALPHANUMERIC
    };
    /**
     * Collection of available/installed fonts.
     *
     * @readonly
     * @static
     * @member {Object.<string, PIXI.BitmapFont>}
     */ BitmapFont1.available = {
    };
    return BitmapFont1;
}();
/**
 * @memberof PIXI
 * @interface IBitmapFontOptions
 * @property {string | string[] | string[][]} [chars=PIXI.BitmapFont.ALPHANUMERIC] - the character set to generate
 * @property {number} [resolution=1] - the resolution for rendering
 * @property {number} [padding=4] - the padding between glyphs in the atlas
 * @property {number} [textureWidth=512] - the width of the texture atlas
 * @property {number} [textureHeight=512] - the height of the texture atlas
 */ var pageMeshDataPool = [];
var charRenderDataPool = [];
/**
 * A BitmapText object will create a line or multiple lines of text using bitmap font.
 *
 * The primary advantage of this class over Text is that all of your textures are pre-generated and loading,
 * meaning that rendering is fast, and changing text has no performance implications.
 *
 * Supporting character sets other than latin, such as CJK languages, may be impractical due to the number of characters.
 *
 * To split a line you can use '\n', '\r' or '\r\n' in your string.
 *
 * PixiJS can auto-generate fonts on-the-fly using BitmapFont or use fnt files provided by:
 * http://www.angelcode.com/products/bmfont/ for Windows or
 * http://www.bmglyph.com/ for Mac.
 *
 * A BitmapText can only be created when the font is loaded.
 *
 * ```js
 * // in this case the font is in a file called 'desyrel.fnt'
 * let bitmapText = new PIXI.BitmapText("text using a fancy font!", {
 *   fontName: "Desyrel",
 *   fontSize: 35,
 *   align: "right"
 * });
 * ```
 *
 * @class
 * @extends PIXI.Container
 * @memberof PIXI
 */ var BitmapText1 = function(_super) {
    __extends(BitmapText2, _super);
    /**
     * @param {string} text - A string that you would like the text to display.
     * @param {object} style - The style parameters.
     * @param {string} style.fontName - The installed BitmapFont name.
     * @param {number} [style.fontSize] - The size of the font in pixels, e.g. 24. If undefined,
     *.     this will default to the BitmapFont size.
     * @param {string} [style.align='left'] - Alignment for multiline text ('left', 'center', 'right' or 'justify'),
     *      does not affect single line text.
     * @param {number} [style.tint=0xFFFFFF] - The tint color.
     * @param {number} [style.letterSpacing=0] - The amount of spacing between letters.
     * @param {number} [style.maxWidth=0] - The max width of the text before line wrapping.
     */ function BitmapText2(text, style) {
        if (style === void 0) style = {
        };
        var _this = _super.call(this) || this;
        _this._tint = 16777215;
        // Apply the defaults
        var _a = Object.assign({
        }, BitmapText2.styleDefaults, style), align = _a.align, tint = _a.tint, maxWidth = _a.maxWidth, letterSpacing = _a.letterSpacing, fontName = _a.fontName, fontSize = _a.fontSize;
        if (!BitmapFont.available[fontName]) throw new Error("Missing BitmapFont \"" + fontName + "\"");
        /**
         * Collection of page mesh data.
         *
         * @member {object}
         * @private
         */ _this._activePagesMeshData = [];
        /**
         * Private tracker for the width of the overall text
         *
         * @member {number}
         * @private
         */ _this._textWidth = 0;
        /**
         * Private tracker for the height of the overall text
         *
         * @member {number}
         * @private
         */ _this._textHeight = 0;
        /**
         * Private tracker for the current text align.
         *
         * @member {string}
         * @private
         */ _this._align = align;
        /**
         * Private tracker for the current tint.
         *
         * @member {number}
         * @private
         */ _this._tint = tint;
        /**
         * Private tracker for the current font name.
         *
         * @member {string}
         * @private
         */ _this._fontName = fontName;
        /**
         * Private tracker for the current font size.
         *
         * @member {number}
         * @private
         */ _this._fontSize = fontSize || BitmapFont.available[fontName].size;
        /**
         * Private tracker for the current text.
         *
         * @member {string}
         * @private
         */ _this._text = text;
        /**
         * The max width of this bitmap text in pixels. If the text provided is longer than the
         * value provided, line breaks will be automatically inserted in the last whitespace.
         * Disable by setting value to 0
         *
         * @member {number}
         * @private
         */ _this._maxWidth = maxWidth;
        /**
         * The max line height. This is useful when trying to use the total height of the Text,
         * ie: when trying to vertically align. (Internally used)
         *
         * @member {number}
         * @private
         */ _this._maxLineHeight = 0;
        /**
         * Letter spacing. This is useful for setting the space between characters.
         * @member {number}
         * @private
         */ _this._letterSpacing = letterSpacing;
        /**
         * Text anchor. read-only
         *
         * @member {PIXI.ObservablePoint}
         * @private
         */ _this._anchor = new _math.ObservablePoint(function() {
            _this.dirty = true;
        }, _this, 0, 0);
        /**
         * If true PixiJS will Math.floor() x/y values when rendering
         *
         * @member {boolean}
         * @default PIXI.settings.ROUND_PIXELS
         */ _this._roundPixels = _settings.settings.ROUND_PIXELS;
        /**
         * Set to `true` if the BitmapText needs to be redrawn.
         *
         * @member {boolean}
         */ _this.dirty = true;
        /**
         * Cached char texture is destroyed when BitmapText is destroyed
         * @member {Record<number, Texture>}
         * @private
         */ _this._textureCache = {
        };
        return _this;
    }
    /**
     * Renders text and updates it when needed. This should only be called
     * if the BitmapFont is regenerated.
     */ BitmapText2.prototype.updateText = function() {
        var _a;
        var data = BitmapFont.available[this._fontName];
        var scale = this._fontSize / data.size;
        var pos = new _math.Point();
        var chars = [];
        var lineWidths = [];
        var lineSpaces = [];
        var text = this._text.replace(/(?:\r\n|\r)/g, '\n') || ' ';
        var textLength = text.length;
        var maxWidth = this._maxWidth * data.size / this._fontSize;
        var prevCharCode = null;
        var lastLineWidth = 0;
        var maxLineWidth = 0;
        var line = 0;
        var lastBreakPos = -1;
        var lastBreakWidth = 0;
        var spacesRemoved = 0;
        var maxLineHeight = 0;
        var spaceCount = 0;
        for(var i = 0; i < textLength; i++){
            var charCode = text.charCodeAt(i);
            var char = text.charAt(i);
            if (/(?:\s)/.test(char)) {
                lastBreakPos = i;
                lastBreakWidth = lastLineWidth;
                spaceCount++;
            }
            if (char === '\r' || char === '\n') {
                lineWidths.push(lastLineWidth);
                lineSpaces.push(-1);
                maxLineWidth = Math.max(maxLineWidth, lastLineWidth);
                ++line;
                ++spacesRemoved;
                pos.x = 0;
                pos.y += data.lineHeight;
                prevCharCode = null;
                spaceCount = 0;
                continue;
            }
            var charData = data.chars[charCode];
            if (!charData) continue;
            if (prevCharCode && charData.kerning[prevCharCode]) pos.x += charData.kerning[prevCharCode];
            var charRenderData = charRenderDataPool.pop() || {
                texture: _core.Texture.EMPTY,
                line: 0,
                charCode: 0,
                prevSpaces: 0,
                position: new _math.Point()
            };
            charRenderData.texture = charData.texture;
            charRenderData.line = line;
            charRenderData.charCode = charCode;
            charRenderData.position.x = pos.x + charData.xOffset + this._letterSpacing / 2;
            charRenderData.position.y = pos.y + charData.yOffset;
            charRenderData.prevSpaces = spaceCount;
            chars.push(charRenderData);
            lastLineWidth = charRenderData.position.x + charData.texture.orig.width; // Use charRenderData position!
            pos.x += charData.xAdvance + this._letterSpacing;
            maxLineHeight = Math.max(maxLineHeight, charData.yOffset + charData.texture.height);
            prevCharCode = charCode;
            if (lastBreakPos !== -1 && maxWidth > 0 && pos.x > maxWidth) {
                ++spacesRemoved;
                _utils.removeItems(chars, 1 + lastBreakPos - spacesRemoved, 1 + i - lastBreakPos);
                i = lastBreakPos;
                lastBreakPos = -1;
                lineWidths.push(lastBreakWidth);
                lineSpaces.push(chars.length > 0 ? chars[chars.length - 1].prevSpaces : 0);
                maxLineWidth = Math.max(maxLineWidth, lastBreakWidth);
                line++;
                pos.x = 0;
                pos.y += data.lineHeight;
                prevCharCode = null;
                spaceCount = 0;
            }
        }
        var lastChar = text.charAt(text.length - 1);
        if (lastChar !== '\r' && lastChar !== '\n') {
            if (/(?:\s)/.test(lastChar)) lastLineWidth = lastBreakWidth;
            lineWidths.push(lastLineWidth);
            maxLineWidth = Math.max(maxLineWidth, lastLineWidth);
            lineSpaces.push(-1);
        }
        var lineAlignOffsets = [];
        for(var i = 0; i <= line; i++){
            var alignOffset = 0;
            if (this._align === 'right') alignOffset = maxLineWidth - lineWidths[i];
            else if (this._align === 'center') alignOffset = (maxLineWidth - lineWidths[i]) / 2;
            else if (this._align === 'justify') alignOffset = lineSpaces[i] < 0 ? 0 : (maxLineWidth - lineWidths[i]) / lineSpaces[i];
            lineAlignOffsets.push(alignOffset);
        }
        var lenChars = chars.length;
        var pagesMeshData = {
        };
        var newPagesMeshData = [];
        var activePagesMeshData = this._activePagesMeshData;
        for(var i = 0; i < activePagesMeshData.length; i++)pageMeshDataPool.push(activePagesMeshData[i]);
        for(var i = 0; i < lenChars; i++){
            var texture = chars[i].texture;
            var baseTextureUid = texture.baseTexture.uid;
            if (!pagesMeshData[baseTextureUid]) {
                var pageMeshData = pageMeshDataPool.pop();
                if (!pageMeshData) {
                    var geometry = new _mesh.MeshGeometry();
                    var material = new _mesh.MeshMaterial(_core.Texture.EMPTY);
                    var mesh = new _mesh.Mesh(geometry, material);
                    pageMeshData = {
                        index: 0,
                        indexCount: 0,
                        vertexCount: 0,
                        uvsCount: 0,
                        total: 0,
                        mesh: mesh,
                        vertices: null,
                        uvs: null,
                        indices: null
                    };
                }
                // reset data..
                pageMeshData.index = 0;
                pageMeshData.indexCount = 0;
                pageMeshData.vertexCount = 0;
                pageMeshData.uvsCount = 0;
                pageMeshData.total = 0;
                // TODO need to get page texture here somehow..
                var _textureCache = this._textureCache;
                _textureCache[baseTextureUid] = _textureCache[baseTextureUid] || new _core.Texture(texture.baseTexture);
                pageMeshData.mesh.texture = _textureCache[baseTextureUid];
                pageMeshData.mesh.tint = this._tint;
                newPagesMeshData.push(pageMeshData);
                pagesMeshData[baseTextureUid] = pageMeshData;
            }
            pagesMeshData[baseTextureUid].total++;
        }
        // lets find any previously active pageMeshDatas that are no longer required for
        // the updated text (if any), removed and return them to the pool.
        for(var i = 0; i < activePagesMeshData.length; i++)if (newPagesMeshData.indexOf(activePagesMeshData[i]) === -1) this.removeChild(activePagesMeshData[i].mesh);
        // next lets add any new meshes, that have not yet been added to this BitmapText
        // we only add if its not already a child of this BitmapObject
        for(var i = 0; i < newPagesMeshData.length; i++)if (newPagesMeshData[i].mesh.parent !== this) this.addChild(newPagesMeshData[i].mesh);
        // active page mesh datas are set to be the new pages added.
        this._activePagesMeshData = newPagesMeshData;
        for(var i in pagesMeshData){
            var pageMeshData = pagesMeshData[i];
            var total = pageMeshData.total;
            // lets only allocate new buffers if we can fit the new text in the current ones..
            // unless that is, we will be batching. Currently batching dose not respect the size property of mesh
            if (!(((_a = pageMeshData.indices) === null || _a === void 0 ? void 0 : _a.length) > 6 * total) || pageMeshData.vertices.length < _mesh.Mesh.BATCHABLE_SIZE * 2) {
                pageMeshData.vertices = new Float32Array(8 * total);
                pageMeshData.uvs = new Float32Array(8 * total);
                pageMeshData.indices = new Uint16Array(6 * total);
            } else {
                var total_1 = pageMeshData.total;
                var vertices = pageMeshData.vertices;
                // Clear the garbage at the end of the vertices buffer. This will prevent the bounds miscalculation.
                for(var i_1 = total_1 * 8; i_1 < vertices.length; i_1++)vertices[i_1] = 0;
            }
            // as a buffer maybe bigger than the current word, we set the size of the meshMaterial
            // to match the number of letters needed
            pageMeshData.mesh.size = 6 * total;
        }
        for(var i = 0; i < lenChars; i++){
            var char = chars[i];
            var offset = char.position.x + lineAlignOffsets[char.line] * (this._align === 'justify' ? char.prevSpaces : 1);
            if (this._roundPixels) offset = Math.round(offset);
            var xPos = offset * scale;
            var yPos = char.position.y * scale;
            var texture = char.texture;
            var pageMesh = pagesMeshData[texture.baseTexture.uid];
            var textureFrame = texture.frame;
            var textureUvs = texture._uvs;
            var index = pageMesh.index++;
            pageMesh.indices[index * 6 + 0] = 0 + index * 4;
            pageMesh.indices[index * 6 + 1] = 1 + index * 4;
            pageMesh.indices[index * 6 + 2] = 2 + index * 4;
            pageMesh.indices[index * 6 + 3] = 0 + index * 4;
            pageMesh.indices[index * 6 + 4] = 2 + index * 4;
            pageMesh.indices[index * 6 + 5] = 3 + index * 4;
            pageMesh.vertices[index * 8 + 0] = xPos;
            pageMesh.vertices[index * 8 + 1] = yPos;
            pageMesh.vertices[index * 8 + 2] = xPos + textureFrame.width * scale;
            pageMesh.vertices[index * 8 + 3] = yPos;
            pageMesh.vertices[index * 8 + 4] = xPos + textureFrame.width * scale;
            pageMesh.vertices[index * 8 + 5] = yPos + textureFrame.height * scale;
            pageMesh.vertices[index * 8 + 6] = xPos;
            pageMesh.vertices[index * 8 + 7] = yPos + textureFrame.height * scale;
            pageMesh.uvs[index * 8 + 0] = textureUvs.x0;
            pageMesh.uvs[index * 8 + 1] = textureUvs.y0;
            pageMesh.uvs[index * 8 + 2] = textureUvs.x1;
            pageMesh.uvs[index * 8 + 3] = textureUvs.y1;
            pageMesh.uvs[index * 8 + 4] = textureUvs.x2;
            pageMesh.uvs[index * 8 + 5] = textureUvs.y2;
            pageMesh.uvs[index * 8 + 6] = textureUvs.x3;
            pageMesh.uvs[index * 8 + 7] = textureUvs.y3;
        }
        this._textWidth = maxLineWidth * scale;
        this._textHeight = (pos.y + data.lineHeight) * scale;
        for(var i in pagesMeshData){
            var pageMeshData = pagesMeshData[i];
            // apply anchor
            if (this.anchor.x !== 0 || this.anchor.y !== 0) {
                var vertexCount = 0;
                var anchorOffsetX = this._textWidth * this.anchor.x;
                var anchorOffsetY = this._textHeight * this.anchor.y;
                for(var i_2 = 0; i_2 < pageMeshData.total; i_2++){
                    pageMeshData.vertices[vertexCount++] -= anchorOffsetX;
                    pageMeshData.vertices[vertexCount++] -= anchorOffsetY;
                    pageMeshData.vertices[vertexCount++] -= anchorOffsetX;
                    pageMeshData.vertices[vertexCount++] -= anchorOffsetY;
                    pageMeshData.vertices[vertexCount++] -= anchorOffsetX;
                    pageMeshData.vertices[vertexCount++] -= anchorOffsetY;
                    pageMeshData.vertices[vertexCount++] -= anchorOffsetX;
                    pageMeshData.vertices[vertexCount++] -= anchorOffsetY;
                }
            }
            this._maxLineHeight = maxLineHeight * scale;
            var vertexBuffer = pageMeshData.mesh.geometry.getBuffer('aVertexPosition');
            var textureBuffer = pageMeshData.mesh.geometry.getBuffer('aTextureCoord');
            var indexBuffer = pageMeshData.mesh.geometry.getIndex();
            vertexBuffer.data = pageMeshData.vertices;
            textureBuffer.data = pageMeshData.uvs;
            indexBuffer.data = pageMeshData.indices;
            vertexBuffer.update();
            textureBuffer.update();
            indexBuffer.update();
        }
        for(var i = 0; i < chars.length; i++)charRenderDataPool.push(chars[i]);
    };
    /**
     * Updates the transform of this object
     *
     * @private
     */ BitmapText2.prototype.updateTransform = function() {
        this.validate();
        this.containerUpdateTransform();
    };
    /**
     * Validates text before calling parent's getLocalBounds
     *
     * @return {PIXI.Rectangle} The rectangular bounding area
     */ BitmapText2.prototype.getLocalBounds = function() {
        this.validate();
        return _super.prototype.getLocalBounds.call(this);
    };
    /**
     * Updates text when needed
     *
     * @private
     */ BitmapText2.prototype.validate = function() {
        if (this.dirty) {
            this.updateText();
            this.dirty = false;
        }
    };
    Object.defineProperty(BitmapText2.prototype, "tint", {
        /**
         * The tint of the BitmapText object.
         *
         * @member {number}
         * @default 0xffffff
         */ get: function() {
            return this._tint;
        },
        set: function(value) {
            if (this._tint === value) return;
            this._tint = value;
            for(var i = 0; i < this._activePagesMeshData.length; i++)this._activePagesMeshData[i].mesh.tint = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "align", {
        /**
         * The alignment of the BitmapText object.
         *
         * @member {string}
         * @default 'left'
         */ get: function() {
            return this._align;
        },
        set: function(value) {
            if (this._align !== value) {
                this._align = value;
                this.dirty = true;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "fontName", {
        /**
         * The name of the BitmapFont.
         *
         * @member {string}
         */ get: function() {
            return this._fontName;
        },
        set: function(value) {
            if (!BitmapFont.available[value]) throw new Error("Missing BitmapFont \"" + value + "\"");
            if (this._fontName !== value) {
                this._fontName = value;
                this.dirty = true;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "fontSize", {
        /**
         * The size of the font to display.
         *
         * @member {number}
         */ get: function() {
            return this._fontSize;
        },
        set: function(value) {
            if (this._fontSize !== value) {
                this._fontSize = value;
                this.dirty = true;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "anchor", {
        /**
         * The anchor sets the origin point of the text.
         *
         * The default is `(0,0)`, this means the text's origin is the top left.
         *
         * Setting the anchor to `(0.5,0.5)` means the text's origin is centered.
         *
         * Setting the anchor to `(1,1)` would mean the text's origin point will be the bottom right corner.
         *
         * @member {PIXI.Point | number}
         */ get: function() {
            return this._anchor;
        },
        set: function(value) {
            if (typeof value === 'number') this._anchor.set(value);
            else this._anchor.copyFrom(value);
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "text", {
        /**
         * The text of the BitmapText object.
         *
         * @member {string}
         */ get: function() {
            return this._text;
        },
        set: function(text) {
            text = String(text === null || text === undefined ? '' : text);
            if (this._text === text) return;
            this._text = text;
            this.dirty = true;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "maxWidth", {
        /**
         * The max width of this bitmap text in pixels. If the text provided is longer than the
         * value provided, line breaks will be automatically inserted in the last whitespace.
         * Disable by setting the value to 0.
         *
         * @member {number}
         */ get: function() {
            return this._maxWidth;
        },
        set: function(value) {
            if (this._maxWidth === value) return;
            this._maxWidth = value;
            this.dirty = true;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "maxLineHeight", {
        /**
         * The max line height. This is useful when trying to use the total height of the Text,
         * i.e. when trying to vertically align.
         *
         * @member {number}
         * @readonly
         */ get: function() {
            this.validate();
            return this._maxLineHeight;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "textWidth", {
        /**
         * The width of the overall text, different from fontSize,
         * which is defined in the style object.
         *
         * @member {number}
         * @readonly
         */ get: function() {
            this.validate();
            return this._textWidth;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "letterSpacing", {
        /**
         * Additional space between characters.
         *
         * @member {number}
         */ get: function() {
            return this._letterSpacing;
        },
        set: function(value) {
            if (this._letterSpacing !== value) {
                this._letterSpacing = value;
                this.dirty = true;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "roundPixels", {
        /**
         * If true PixiJS will Math.floor() x/y values when rendering, stopping pixel interpolation.
         * Advantages can include sharper image quality (like text) and faster rendering on canvas.
         * The main disadvantage is movement of objects may appear less smooth.
         * To set the global default, change {@link PIXI.settings.ROUND_PIXELS}
         *
         * @member {boolean}
         * @default PIXI.settings.ROUND_PIXELS
         */ get: function() {
            return this._roundPixels;
        },
        set: function(value) {
            if (value !== this._roundPixels) {
                this._roundPixels = value;
                this.dirty = true;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BitmapText2.prototype, "textHeight", {
        /**
         * The height of the overall text, different from fontSize,
         * which is defined in the style object.
         *
         * @member {number}
         * @readonly
         */ get: function() {
            this.validate();
            return this._textHeight;
        },
        enumerable: false,
        configurable: true
    });
    BitmapText2.prototype.destroy = function(options) {
        var _textureCache = this._textureCache;
        for(var id in _textureCache){
            var texture = _textureCache[id];
            texture.destroy();
            delete _textureCache[id];
        }
        this._textureCache = null;
        _super.prototype.destroy.call(this, options);
    };
    BitmapText2.styleDefaults = {
        align: 'left',
        tint: 16777215,
        maxWidth: 0,
        letterSpacing: 0
    };
    return BitmapText2;
}(_display.Container);
/**
 * {@link PIXI.Loader Loader} middleware for loading
 * bitmap-based fonts suitable for using with {@link PIXI.BitmapText}.
 * @class
 * @memberof PIXI
 * @implements PIXI.ILoaderPlugin
 */ var BitmapFontLoader = function() {
    function BitmapFontLoader1() {
    }
    /**
     * Called when the plugin is installed.
     *
     * @see PIXI.Loader.registerPlugin
     */ BitmapFontLoader1.add = function() {
        _loaders.LoaderResource.setExtensionXhrType('fnt', _loaders.LoaderResource.XHR_RESPONSE_TYPE.TEXT);
    };
    /**
     * Called after a resource is loaded.
     * @see PIXI.Loader.loaderMiddleware
     * @param {PIXI.LoaderResource} resource
     * @param {function} next
     */ BitmapFontLoader1.use = function(resource, next) {
        var format = autoDetectFormat(resource.data);
        // Resource was not recognised as any of the expected font data format
        if (!format) {
            next();
            return;
        }
        var baseUrl = BitmapFontLoader1.getBaseUrl(this, resource);
        var data = format.parse(resource.data);
        var textures = {
        };
        // Handle completed, when the number of textures
        // load is the same number as references in the fnt file
        var completed = function(page) {
            textures[page.metadata.pageFile] = page.texture;
            if (Object.keys(textures).length === data.page.length) {
                resource.bitmapFont = BitmapFont.install(data, textures, true);
                next();
            }
        };
        for(var i = 0; i < data.page.length; ++i){
            var pageFile = data.page[i].file;
            var url = baseUrl + pageFile;
            var exists = false;
            // incase the image is loaded outside
            // using the same loader, resource will be available
            for(var name in this.resources){
                var bitmapResource = this.resources[name];
                if (bitmapResource.url === url) {
                    bitmapResource.metadata.pageFile = pageFile;
                    if (bitmapResource.texture) completed(bitmapResource);
                    else bitmapResource.onAfterMiddleware.add(completed);
                    exists = true;
                    break;
                }
            }
            // texture is not loaded, we'll attempt to add
            // it to the load and add the texture to the list
            if (!exists) {
                // Standard loading options for images
                var options = {
                    crossOrigin: resource.crossOrigin,
                    loadType: _loaders.LoaderResource.LOAD_TYPE.IMAGE,
                    metadata: Object.assign({
                        pageFile: pageFile
                    }, resource.metadata.imageMetadata),
                    parentResource: resource
                };
                this.add(url, options, completed);
            }
        }
    };
    /**
     * Get folder path from a resource
     * @private
     * @param {PIXI.Loader} loader
     * @param {PIXI.LoaderResource} resource
     * @return {string}
     */ BitmapFontLoader1.getBaseUrl = function(loader, resource) {
        var resUrl = !resource.isDataUrl ? BitmapFontLoader1.dirname(resource.url) : '';
        if (resource.isDataUrl) {
            if (resUrl === '.') resUrl = '';
            if (loader.baseUrl && resUrl) // if baseurl has a trailing slash then add one to resUrl so the replace works below
            {
                if (loader.baseUrl.charAt(loader.baseUrl.length - 1) === '/') resUrl += '/';
            }
        }
        // remove baseUrl from resUrl
        resUrl = resUrl.replace(loader.baseUrl, '');
        // if there is an resUrl now, it needs a trailing slash. Ensure that it does if the string isn't empty.
        if (resUrl && resUrl.charAt(resUrl.length - 1) !== '/') resUrl += '/';
        return resUrl;
    };
    /**
     * Replacement for NodeJS's path.dirname
     * @private
     * @param {string} url - Path to get directory for
     */ BitmapFontLoader1.dirname = function(url) {
        var dir = url.replace(/\\/g, '/') // convert windows notation to UNIX notation, URL-safe because it's a forbidden character
        .replace(/\/$/, '') // replace trailing slash
        .replace(/\/[^\/]*$/, ''); // remove everything after the last
        // File request is relative, use current directory
        if (dir === url) return '.';
        else if (dir === '') return '/';
        return dir;
    };
    return BitmapFontLoader1;
}();

},{"@pixi/math":"1qR3C","@pixi/settings":"habh9","@pixi/mesh":"a96bk","@pixi/utils":"joR65","@pixi/core":"d0INm","@pixi/text":"fmwBo","@pixi/display":"hQqz5","@pixi/loaders":"1PTMa","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"a96bk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "Mesh", ()=>Mesh1
);
parcelHelpers.export(exports, "MeshBatchUvs", ()=>MeshBatchUvs
);
parcelHelpers.export(exports, "MeshGeometry", ()=>MeshGeometry1
);
parcelHelpers.export(exports, "MeshMaterial", ()=>MeshMaterial1
);
/*!
 * @pixi/mesh - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/mesh is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
var _math = require("@pixi/math");
var _constants = require("@pixi/constants");
var _display = require("@pixi/display");
var _settings = require("@pixi/settings");
var _utils = require("@pixi/utils");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * Class controls cache for UV mapping from Texture normal space to BaseTexture normal space.
 *
 * @class
 * @memberof PIXI
 */ var MeshBatchUvs = function() {
    /**
     * @param {PIXI.Buffer} uvBuffer - Buffer with normalized uv's
     * @param {PIXI.TextureMatrix} uvMatrix - Material UV matrix
     */ function MeshBatchUvs1(uvBuffer, uvMatrix) {
        /**
         * Buffer with normalized UV's
         * @member {PIXI.Buffer}
         */ this.uvBuffer = uvBuffer;
        /**
         * Material UV matrix
         * @member {PIXI.TextureMatrix}
         */ this.uvMatrix = uvMatrix;
        /**
         * UV Buffer data
         * @member {Float32Array}
         * @readonly
         */ this.data = null;
        this._bufferUpdateId = -1;
        this._textureUpdateId = -1;
        this._updateID = 0;
    }
    /**
     * updates
     *
     * @param {boolean} [forceUpdate] - force the update
     */ MeshBatchUvs1.prototype.update = function(forceUpdate) {
        if (!forceUpdate && this._bufferUpdateId === this.uvBuffer._updateID && this._textureUpdateId === this.uvMatrix._updateID) return;
        this._bufferUpdateId = this.uvBuffer._updateID;
        this._textureUpdateId = this.uvMatrix._updateID;
        var data = this.uvBuffer.data;
        if (!this.data || this.data.length !== data.length) this.data = new Float32Array(data.length);
        this.uvMatrix.multiplyUvs(data, this.data);
        this._updateID++;
    };
    return MeshBatchUvs1;
}();
var tempPoint = new _math.Point();
var tempPolygon = new _math.Polygon();
/**
 * Base mesh class.
 *
 * This class empowers you to have maximum flexibility to render any kind of WebGL visuals you can think of.
 * This class assumes a certain level of WebGL knowledge.
 * If you know a bit this should abstract enough away to make you life easier!
 *
 * Pretty much ALL WebGL can be broken down into the following:
 * - Geometry - The structure and data for the mesh. This can include anything from positions, uvs, normals, colors etc..
 * - Shader - This is the shader that PixiJS will render the geometry with (attributes in the shader must match the geometry)
 * - State - This is the state of WebGL required to render the mesh.
 *
 * Through a combination of the above elements you can render anything you want, 2D or 3D!
 *
 * @class
 * @extends PIXI.Container
 * @memberof PIXI
 */ var Mesh1 = function(_super) {
    __extends(Mesh2, _super);
    /**
     * @param {PIXI.Geometry} geometry - the geometry the mesh will use
     * @param {PIXI.MeshMaterial} shader - the shader the mesh will use
     * @param {PIXI.State} [state] - the state that the WebGL context is required to be in to render the mesh
     *        if no state is provided, uses {@link PIXI.State.for2d} to create a 2D state for PixiJS.
     * @param {number} [drawMode=PIXI.DRAW_MODES.TRIANGLES] - the drawMode, can be any of the PIXI.DRAW_MODES consts
     */ function Mesh2(geometry, shader, state, drawMode) {
        if (drawMode === void 0) drawMode = _constants.DRAW_MODES.TRIANGLES;
        var _this = _super.call(this) || this;
        /**
         * Includes vertex positions, face indices, normals, colors, UVs, and
         * custom attributes within buffers, reducing the cost of passing all
         * this data to the GPU. Can be shared between multiple Mesh objects.
         * @member {PIXI.Geometry}
         * @readonly
         */ _this.geometry = geometry;
        geometry.refCount++;
        /**
         * Represents the vertex and fragment shaders that processes the geometry and runs on the GPU.
         * Can be shared between multiple Mesh objects.
         * @member {PIXI.Shader|PIXI.MeshMaterial}
         */ _this.shader = shader;
        /**
         * Represents the WebGL state the Mesh required to render, excludes shader and geometry. E.g.,
         * blend mode, culling, depth testing, direction of rendering triangles, backface, etc.
         * @member {PIXI.State}
         */ _this.state = state || _core.State.for2d();
        /**
         * The way the Mesh should be drawn, can be any of the {@link PIXI.DRAW_MODES} constants.
         *
         * @member {number}
         * @see PIXI.DRAW_MODES
         */ _this.drawMode = drawMode;
        /**
         * Typically the index of the IndexBuffer where to start drawing.
         * @member {number}
         * @default 0
         */ _this.start = 0;
        /**
         * How much of the geometry to draw, by default `0` renders everything.
         * @member {number}
         * @default 0
         */ _this.size = 0;
        /**
         * these are used as easy access for batching
         * @member {Float32Array}
         * @private
         */ _this.uvs = null;
        /**
         * these are used as easy access for batching
         * @member {Uint16Array}
         * @private
         */ _this.indices = null;
        /**
         * this is the caching layer used by the batcher
         * @member {Float32Array}
         * @private
         */ _this.vertexData = new Float32Array(1);
        /**
         * If geometry is changed used to decide to re-transform
         * the vertexData.
         * @member {number}
         * @private
         */ _this.vertexDirty = -1;
        _this._transformID = -1;
        /**
         * Internal roundPixels field
         *
         * @member {boolean}
         * @private
         */ _this._roundPixels = _settings.settings.ROUND_PIXELS;
        /**
         * Batched UV's are cached for atlas textures
         * @member {PIXI.MeshBatchUvs}
         * @private
         */ _this.batchUvs = null;
        return _this;
    }
    Object.defineProperty(Mesh2.prototype, "uvBuffer", {
        /**
         * To change mesh uv's, change its uvBuffer data and increment its _updateID.
         * @member {PIXI.Buffer}
         * @readonly
         */ get: function() {
            return this.geometry.buffers[1];
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Mesh2.prototype, "verticesBuffer", {
        /**
         * To change mesh vertices, change its uvBuffer data and increment its _updateID.
         * Incrementing _updateID is optional because most of Mesh objects do it anyway.
         * @member {PIXI.Buffer}
         * @readonly
         */ get: function() {
            return this.geometry.buffers[0];
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Mesh2.prototype, "material", {
        get: function() {
            return this.shader;
        },
        /**
         * Alias for {@link PIXI.Mesh#shader}.
         * @member {PIXI.MeshMaterial}
         */ set: function(value) {
            this.shader = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Mesh2.prototype, "blendMode", {
        get: function() {
            return this.state.blendMode;
        },
        /**
         * The blend mode to be applied to the Mesh. Apply a value of
         * `PIXI.BLEND_MODES.NORMAL` to reset the blend mode.
         *
         * @member {number}
         * @default PIXI.BLEND_MODES.NORMAL;
         * @see PIXI.BLEND_MODES
         */ set: function(value) {
            this.state.blendMode = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Mesh2.prototype, "roundPixels", {
        get: function() {
            return this._roundPixels;
        },
        /**
         * If true PixiJS will Math.floor() x/y values when rendering, stopping pixel interpolation.
         * Advantages can include sharper image quality (like text) and faster rendering on canvas.
         * The main disadvantage is movement of objects may appear less smooth.
         * To set the global default, change {@link PIXI.settings.ROUND_PIXELS}
         *
         * @member {boolean}
         * @default false
         */ set: function(value) {
            if (this._roundPixels !== value) this._transformID = -1;
            this._roundPixels = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Mesh2.prototype, "tint", {
        /**
         * The multiply tint applied to the Mesh. This is a hex value. A value of
         * `0xFFFFFF` will remove any tint effect.
         *
         * Null for non-MeshMaterial shaders
         * @member {number}
         * @default 0xFFFFFF
         */ get: function() {
            return 'tint' in this.shader ? this.shader.tint : null;
        },
        set: function(value) {
            this.shader.tint = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(Mesh2.prototype, "texture", {
        /**
         * The texture that the Mesh uses.
         *
         * Null for non-MeshMaterial shaders
         * @member {PIXI.Texture}
         */ get: function() {
            return 'texture' in this.shader ? this.shader.texture : null;
        },
        set: function(value) {
            this.shader.texture = value;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Standard renderer draw.
     * @protected
     * @param {PIXI.Renderer} renderer - Instance to renderer.
     */ Mesh2.prototype._render = function(renderer) {
        // set properties for batching..
        // TODO could use a different way to grab verts?
        var vertices = this.geometry.buffers[0].data;
        var shader = this.shader;
        // TODO benchmark check for attribute size..
        if (shader.batchable && this.drawMode === _constants.DRAW_MODES.TRIANGLES && vertices.length < Mesh2.BATCHABLE_SIZE * 2) this._renderToBatch(renderer);
        else this._renderDefault(renderer);
    };
    /**
     * Standard non-batching way of rendering.
     * @protected
     * @param {PIXI.Renderer} renderer - Instance to renderer.
     */ Mesh2.prototype._renderDefault = function(renderer) {
        var shader = this.shader;
        shader.alpha = this.worldAlpha;
        if (shader.update) shader.update();
        renderer.batch.flush();
        // bind and sync uniforms..
        shader.uniforms.translationMatrix = this.transform.worldTransform.toArray(true);
        renderer.shader.bind(shader);
        // set state..
        renderer.state.set(this.state);
        // bind the geometry...
        renderer.geometry.bind(this.geometry, shader);
        // then render it
        renderer.geometry.draw(this.drawMode, this.size, this.start, this.geometry.instanceCount);
    };
    /**
     * Rendering by using the Batch system.
     * @protected
     * @param {PIXI.Renderer} renderer - Instance to renderer.
     */ Mesh2.prototype._renderToBatch = function(renderer) {
        var geometry = this.geometry;
        var shader = this.shader;
        if (shader.uvMatrix) {
            shader.uvMatrix.update();
            this.calculateUvs();
        }
        // set properties for batching..
        this.calculateVertices();
        this.indices = geometry.indexBuffer.data;
        this._tintRGB = shader._tintRGB;
        this._texture = shader.texture;
        var pluginName = this.material.pluginName;
        renderer.batch.setObjectRenderer(renderer.plugins[pluginName]);
        renderer.plugins[pluginName].render(this);
    };
    /**
     * Updates vertexData field based on transform and vertices
     */ Mesh2.prototype.calculateVertices = function() {
        var geometry = this.geometry;
        var verticesBuffer = geometry.buffers[0];
        var vertices = verticesBuffer.data;
        var vertexDirtyId = verticesBuffer._updateID;
        if (vertexDirtyId === this.vertexDirty && this._transformID === this.transform._worldID) return;
        this._transformID = this.transform._worldID;
        if (this.vertexData.length !== vertices.length) this.vertexData = new Float32Array(vertices.length);
        var wt = this.transform.worldTransform;
        var a = wt.a;
        var b = wt.b;
        var c = wt.c;
        var d = wt.d;
        var tx = wt.tx;
        var ty = wt.ty;
        var vertexData = this.vertexData;
        for(var i = 0; i < vertexData.length / 2; i++){
            var x = vertices[i * 2];
            var y = vertices[i * 2 + 1];
            vertexData[i * 2] = a * x + c * y + tx;
            vertexData[i * 2 + 1] = b * x + d * y + ty;
        }
        if (this._roundPixels) {
            var resolution = _settings.settings.RESOLUTION;
            for(var i = 0; i < vertexData.length; ++i)vertexData[i] = Math.round((vertexData[i] * resolution | 0) / resolution);
        }
        this.vertexDirty = vertexDirtyId;
    };
    /**
     * Updates uv field based on from geometry uv's or batchUvs
     */ Mesh2.prototype.calculateUvs = function() {
        var geomUvs = this.geometry.buffers[1];
        var shader = this.shader;
        if (!shader.uvMatrix.isSimple) {
            if (!this.batchUvs) this.batchUvs = new MeshBatchUvs(geomUvs, shader.uvMatrix);
            this.batchUvs.update();
            this.uvs = this.batchUvs.data;
        } else this.uvs = geomUvs.data;
    };
    /**
     * Updates the bounds of the mesh as a rectangle. The bounds calculation takes the worldTransform into account.
     * there must be a aVertexPosition attribute present in the geometry for bounds to be calculated correctly.
     *
     * @protected
     */ Mesh2.prototype._calculateBounds = function() {
        this.calculateVertices();
        this._bounds.addVertexData(this.vertexData, 0, this.vertexData.length);
    };
    /**
     * Tests if a point is inside this mesh. Works only for PIXI.DRAW_MODES.TRIANGLES.
     *
     * @param {PIXI.IPointData} point - the point to test
     * @return {boolean} the result of the test
     */ Mesh2.prototype.containsPoint = function(point) {
        if (!this.getBounds().contains(point.x, point.y)) return false;
        this.worldTransform.applyInverse(point, tempPoint);
        var vertices = this.geometry.getBuffer('aVertexPosition').data;
        var points = tempPolygon.points;
        var indices = this.geometry.getIndex().data;
        var len = indices.length;
        var step = this.drawMode === 4 ? 3 : 1;
        for(var i = 0; i + 2 < len; i += step){
            var ind0 = indices[i] * 2;
            var ind1 = indices[i + 1] * 2;
            var ind2 = indices[i + 2] * 2;
            points[0] = vertices[ind0];
            points[1] = vertices[ind0 + 1];
            points[2] = vertices[ind1];
            points[3] = vertices[ind1 + 1];
            points[4] = vertices[ind2];
            points[5] = vertices[ind2 + 1];
            if (tempPolygon.contains(tempPoint.x, tempPoint.y)) return true;
        }
        return false;
    };
    /**
     * Destroys the Mesh object.
     *
     * @param {object|boolean} [options] - Options parameter. A boolean will act as if all
     *  options have been set to that value
     * @param {boolean} [options.children=false] - if set to true, all the children will have
     *  their destroy method called as well. 'options' will be passed on to those calls.
     */ Mesh2.prototype.destroy = function(options) {
        _super.prototype.destroy.call(this, options);
        this.geometry.refCount--;
        if (this.geometry.refCount === 0) this.geometry.dispose();
        if (this._cachedTexture) {
            this._cachedTexture.destroy();
            this._cachedTexture = null;
        }
        this.geometry = null;
        this.shader = null;
        this.state = null;
        this.uvs = null;
        this.indices = null;
        this.vertexData = null;
    };
    /**
     * The maximum number of vertices to consider batchable. Generally, the complexity
     * of the geometry.
     * @memberof PIXI.Mesh
     * @static
     * @member {number} BATCHABLE_SIZE
     */ Mesh2.BATCHABLE_SIZE = 100;
    return Mesh2;
}(_display.Container);
var fragment = "varying vec2 vTextureCoord;\nuniform vec4 uColor;\n\nuniform sampler2D uSampler;\n\nvoid main(void)\n{\n    gl_FragColor = texture2D(uSampler, vTextureCoord) * uColor;\n}\n";
var vertex = "attribute vec2 aVertexPosition;\nattribute vec2 aTextureCoord;\n\nuniform mat3 projectionMatrix;\nuniform mat3 translationMatrix;\nuniform mat3 uTextureMatrix;\n\nvarying vec2 vTextureCoord;\n\nvoid main(void)\n{\n    gl_Position = vec4((projectionMatrix * translationMatrix * vec3(aVertexPosition, 1.0)).xy, 0.0, 1.0);\n\n    vTextureCoord = (uTextureMatrix * vec3(aTextureCoord, 1.0)).xy;\n}\n";
/**
 * Slightly opinionated default shader for PixiJS 2D objects.
 * @class
 * @memberof PIXI
 * @extends PIXI.Shader
 */ var MeshMaterial1 = function(_super) {
    __extends(MeshMaterial2, _super);
    /**
     * @param {PIXI.Texture} uSampler - Texture that material uses to render.
     * @param {object} [options] - Additional options
     * @param {number} [options.alpha=1] - Default alpha.
     * @param {number} [options.tint=0xFFFFFF] - Default tint.
     * @param {string} [options.pluginName='batch'] - Renderer plugin for batching.
     * @param {PIXI.Program} [options.program=0xFFFFFF] - Custom program.
     * @param {object} [options.uniforms] - Custom uniforms.
     */ function MeshMaterial2(uSampler, options) {
        var _this = this;
        var uniforms = {
            uSampler: uSampler,
            alpha: 1,
            uTextureMatrix: _math.Matrix.IDENTITY,
            uColor: new Float32Array([
                1,
                1,
                1,
                1
            ])
        };
        // Set defaults
        options = Object.assign({
            tint: 16777215,
            alpha: 1,
            pluginName: 'batch'
        }, options);
        if (options.uniforms) Object.assign(uniforms, options.uniforms);
        _this = _super.call(this, options.program || _core.Program.from(vertex, fragment), uniforms) || this;
        /**
         * Only do update if tint or alpha changes.
         * @member {boolean}
         * @private
         * @default false
         */ _this._colorDirty = false;
        /**
         * TextureMatrix instance for this Mesh, used to track Texture changes
         *
         * @member {PIXI.TextureMatrix}
         * @readonly
         */ _this.uvMatrix = new _core.TextureMatrix(uSampler);
        /**
         * `true` if shader can be batch with the renderer's batch system.
         * @member {boolean}
         * @default true
         */ _this.batchable = options.program === undefined;
        /**
         * Renderer plugin for batching
         *
         * @member {string}
         * @default 'batch'
         */ _this.pluginName = options.pluginName;
        _this.tint = options.tint;
        _this.alpha = options.alpha;
        return _this;
    }
    Object.defineProperty(MeshMaterial2.prototype, "texture", {
        /**
         * Reference to the texture being rendered.
         * @member {PIXI.Texture}
         */ get: function() {
            return this.uniforms.uSampler;
        },
        set: function(value) {
            if (this.uniforms.uSampler !== value) {
                this.uniforms.uSampler = value;
                this.uvMatrix.texture = value;
            }
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(MeshMaterial2.prototype, "alpha", {
        get: function() {
            return this._alpha;
        },
        /**
         * This gets automatically set by the object using this.
         *
         * @default 1
         * @member {number}
         */ set: function(value) {
            if (value === this._alpha) return;
            this._alpha = value;
            this._colorDirty = true;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(MeshMaterial2.prototype, "tint", {
        get: function() {
            return this._tint;
        },
        /**
         * Multiply tint for the material.
         * @member {number}
         * @default 0xFFFFFF
         */ set: function(value) {
            if (value === this._tint) return;
            this._tint = value;
            this._tintRGB = (value >> 16) + (value & 65280) + ((value & 255) << 16);
            this._colorDirty = true;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Gets called automatically by the Mesh. Intended to be overridden for custom
     * MeshMaterial objects.
     */ MeshMaterial2.prototype.update = function() {
        if (this._colorDirty) {
            this._colorDirty = false;
            var baseTexture = this.texture.baseTexture;
            _utils.premultiplyTintToRgba(this._tint, this._alpha, this.uniforms.uColor, baseTexture.alphaMode);
        }
        if (this.uvMatrix.update()) this.uniforms.uTextureMatrix = this.uvMatrix.mapCoord;
    };
    return MeshMaterial2;
}(_core.Shader);
/**
 * Standard 2D geometry used in PixiJS.
 *
 * Geometry can be defined without passing in a style or data if required.
 *
 * ```js
 * const geometry = new PIXI.Geometry();
 *
 * geometry.addAttribute('positions', [0, 0, 100, 0, 100, 100, 0, 100], 2);
 * geometry.addAttribute('uvs', [0,0,1,0,1,1,0,1], 2);
 * geometry.addIndex([0,1,2,1,3,2]);
 *
 * ```
 * @class
 * @memberof PIXI
 * @extends PIXI.Geometry
 */ var MeshGeometry1 = function(_super) {
    __extends(MeshGeometry2, _super);
    /**
     * @param {Float32Array|number[]} [vertices] - Positional data on geometry.
     * @param {Float32Array|number[]} [uvs] - Texture UVs.
     * @param {Uint16Array|number[]} [index] - IndexBuffer
     */ function MeshGeometry2(vertices, uvs, index) {
        var _this = _super.call(this) || this;
        var verticesBuffer = new _core.Buffer(vertices);
        var uvsBuffer = new _core.Buffer(uvs, true);
        var indexBuffer = new _core.Buffer(index, true, true);
        _this.addAttribute('aVertexPosition', verticesBuffer, 2, false, _constants.TYPES.FLOAT).addAttribute('aTextureCoord', uvsBuffer, 2, false, _constants.TYPES.FLOAT).addIndex(indexBuffer);
        /**
         * Dirty flag to limit update calls on Mesh. For example,
         * limiting updates on a single Mesh instance with a shared Geometry
         * within the render loop.
         * @private
         * @member {number}
         * @default -1
         */ _this._updateId = -1;
        return _this;
    }
    Object.defineProperty(MeshGeometry2.prototype, "vertexDirtyId", {
        /**
         * If the vertex position is updated.
         * @member {number}
         * @readonly
         * @private
         */ get: function() {
            return this.buffers[0]._updateID;
        },
        enumerable: false,
        configurable: true
    });
    return MeshGeometry2;
}(_core.Geometry);

},{"@pixi/core":"d0INm","@pixi/math":"1qR3C","@pixi/constants":"lqjFh","@pixi/display":"hQqz5","@pixi/settings":"habh9","@pixi/utils":"joR65","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ck9sM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AlphaFilter", ()=>AlphaFilter1
);
/*!
 * @pixi/filter-alpha - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/filter-alpha is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var fragment = "varying vec2 vTextureCoord;\n\nuniform sampler2D uSampler;\nuniform float uAlpha;\n\nvoid main(void)\n{\n   gl_FragColor = texture2D(uSampler, vTextureCoord) * uAlpha;\n}\n";
/**
 * Simplest filter - applies alpha.
 *
 * Use this instead of Container's alpha property to avoid visual layering of individual elements.
 * AlphaFilter applies alpha evenly across the entire display object and any opaque elements it contains.
 * If elements are not opaque, they will blend with each other anyway.
 *
 * Very handy if you want to use common features of all filters:
 *
 * 1. Assign a blendMode to this filter, blend all elements inside display object with background.
 *
 * 2. To use clipping in display coordinates, assign a filterArea to the same container that has this filter.
 *
 * @class
 * @extends PIXI.Filter
 * @memberof PIXI.filters
 */ var AlphaFilter1 = function(_super) {
    __extends(AlphaFilter2, _super);
    /**
     * @param {number} [alpha=1] - Amount of alpha from 0 to 1, where 0 is transparent
     */ function AlphaFilter2(alpha) {
        if (alpha === void 0) alpha = 1;
        var _this = _super.call(this, _core.defaultVertex, fragment, {
            uAlpha: 1
        }) || this;
        _this.alpha = alpha;
        return _this;
    }
    Object.defineProperty(AlphaFilter2.prototype, "alpha", {
        /**
         * Coefficient for alpha multiplication
         *
         * @member {number}
         * @default 1
         */ get: function() {
            return this.uniforms.uAlpha;
        },
        set: function(value) {
            this.uniforms.uAlpha = value;
        },
        enumerable: false,
        configurable: true
    });
    return AlphaFilter2;
}(_core.Filter);

},{"@pixi/core":"d0INm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7vdNI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BlurFilter", ()=>BlurFilter1
);
parcelHelpers.export(exports, "BlurFilterPass", ()=>BlurFilterPass1
);
/*!
 * @pixi/filter-blur - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/filter-blur is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
var _settings = require("@pixi/settings");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var vertTemplate = "\n    attribute vec2 aVertexPosition;\n\n    uniform mat3 projectionMatrix;\n\n    uniform float strength;\n\n    varying vec2 vBlurTexCoords[%size%];\n\n    uniform vec4 inputSize;\n    uniform vec4 outputFrame;\n\n    vec4 filterVertexPosition( void )\n    {\n        vec2 position = aVertexPosition * max(outputFrame.zw, vec2(0.)) + outputFrame.xy;\n\n        return vec4((projectionMatrix * vec3(position, 1.0)).xy, 0.0, 1.0);\n    }\n\n    vec2 filterTextureCoord( void )\n    {\n        return aVertexPosition * (outputFrame.zw * inputSize.zw);\n    }\n\n    void main(void)\n    {\n        gl_Position = filterVertexPosition();\n\n        vec2 textureCoord = filterTextureCoord();\n        %blur%\n    }";
function generateBlurVertSource(kernelSize, x) {
    var halfLength = Math.ceil(kernelSize / 2);
    var vertSource = vertTemplate;
    var blurLoop = '';
    var template;
    if (x) template = 'vBlurTexCoords[%index%] =  textureCoord + vec2(%sampleIndex% * strength, 0.0);';
    else template = 'vBlurTexCoords[%index%] =  textureCoord + vec2(0.0, %sampleIndex% * strength);';
    for(var i = 0; i < kernelSize; i++){
        var blur = template.replace('%index%', i.toString());
        blur = blur.replace('%sampleIndex%', i - (halfLength - 1) + ".0");
        blurLoop += blur;
        blurLoop += '\n';
    }
    vertSource = vertSource.replace('%blur%', blurLoop);
    vertSource = vertSource.replace('%size%', kernelSize.toString());
    return vertSource;
}
var GAUSSIAN_VALUES = {
    5: [
        0.153388,
        0.221461,
        0.250301
    ],
    7: [
        0.071303,
        0.131514,
        0.189879,
        0.214607
    ],
    9: [
        0.028532,
        0.067234,
        0.124009,
        0.179044,
        0.20236
    ],
    11: [
        0.0093,
        0.028002,
        0.065984,
        0.121703,
        0.175713,
        0.198596
    ],
    13: [
        0.002406,
        0.009255,
        0.027867,
        0.065666,
        0.121117,
        0.174868,
        0.197641
    ],
    15: [
        0.000489,
        0.002403,
        0.009246,
        0.02784,
        0.065602,
        0.120999,
        0.174697,
        0.197448
    ]
};
var fragTemplate = [
    'varying vec2 vBlurTexCoords[%size%];',
    'uniform sampler2D uSampler;',
    'void main(void)',
    '{',
    '    gl_FragColor = vec4(0.0);',
    '    %blur%',
    '}'
].join('\n');
function generateBlurFragSource(kernelSize) {
    var kernel = GAUSSIAN_VALUES[kernelSize];
    var halfLength = kernel.length;
    var fragSource = fragTemplate;
    var blurLoop = '';
    var template = 'gl_FragColor += texture2D(uSampler, vBlurTexCoords[%index%]) * %value%;';
    var value;
    for(var i = 0; i < kernelSize; i++){
        var blur = template.replace('%index%', i.toString());
        value = i;
        if (i >= halfLength) value = kernelSize - i - 1;
        blur = blur.replace('%value%', kernel[value].toString());
        blurLoop += blur;
        blurLoop += '\n';
    }
    fragSource = fragSource.replace('%blur%', blurLoop);
    fragSource = fragSource.replace('%size%', kernelSize.toString());
    return fragSource;
}
/*!
 * @pixi/constants - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/constants is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ /**
 * Different types of environments for WebGL.
 *
 * @static
 * @memberof PIXI
 * @name ENV
 * @enum {number}
 * @property {number} WEBGL_LEGACY - Used for older v1 WebGL devices. PixiJS will aim to ensure compatibility
 *  with older / less advanced devices. If you experience unexplained flickering prefer this environment.
 * @property {number} WEBGL - Version 1 of WebGL
 * @property {number} WEBGL2 - Version 2 of WebGL
 */ var ENV;
(function(ENV1) {
    ENV1[ENV1["WEBGL_LEGACY"] = 0] = "WEBGL_LEGACY";
    ENV1[ENV1["WEBGL"] = 1] = "WEBGL";
    ENV1[ENV1["WEBGL2"] = 2] = "WEBGL2";
})(ENV || (ENV = {
}));
/**
 * Constant to identify the Renderer Type.
 *
 * @static
 * @memberof PIXI
 * @name RENDERER_TYPE
 * @enum {number}
 * @property {number} UNKNOWN - Unknown render type.
 * @property {number} WEBGL - WebGL render type.
 * @property {number} CANVAS - Canvas render type.
 */ var RENDERER_TYPE;
(function(RENDERER_TYPE1) {
    RENDERER_TYPE1[RENDERER_TYPE1["UNKNOWN"] = 0] = "UNKNOWN";
    RENDERER_TYPE1[RENDERER_TYPE1["WEBGL"] = 1] = "WEBGL";
    RENDERER_TYPE1[RENDERER_TYPE1["CANVAS"] = 2] = "CANVAS";
})(RENDERER_TYPE || (RENDERER_TYPE = {
}));
/**
 * Bitwise OR of masks that indicate the buffers to be cleared.
 *
 * @static
 * @memberof PIXI
 * @name BUFFER_BITS
 * @enum {number}
 * @property {number} COLOR - Indicates the buffers currently enabled for color writing.
 * @property {number} DEPTH - Indicates the depth buffer.
 * @property {number} STENCIL - Indicates the stencil buffer.
 */ var BUFFER_BITS;
(function(BUFFER_BITS1) {
    BUFFER_BITS1[BUFFER_BITS1["COLOR"] = 16384] = "COLOR";
    BUFFER_BITS1[BUFFER_BITS1["DEPTH"] = 256] = "DEPTH";
    BUFFER_BITS1[BUFFER_BITS1["STENCIL"] = 1024] = "STENCIL";
})(BUFFER_BITS || (BUFFER_BITS = {
}));
/**
 * Various blend modes supported by PIXI.
 *
 * IMPORTANT - The WebGL renderer only supports the NORMAL, ADD, MULTIPLY and SCREEN blend modes.
 * Anything else will silently act like NORMAL.
 *
 * @memberof PIXI
 * @name BLEND_MODES
 * @enum {number}
 * @property {number} NORMAL
 * @property {number} ADD
 * @property {number} MULTIPLY
 * @property {number} SCREEN
 * @property {number} OVERLAY
 * @property {number} DARKEN
 * @property {number} LIGHTEN
 * @property {number} COLOR_DODGE
 * @property {number} COLOR_BURN
 * @property {number} HARD_LIGHT
 * @property {number} SOFT_LIGHT
 * @property {number} DIFFERENCE
 * @property {number} EXCLUSION
 * @property {number} HUE
 * @property {number} SATURATION
 * @property {number} COLOR
 * @property {number} LUMINOSITY
 * @property {number} NORMAL_NPM
 * @property {number} ADD_NPM
 * @property {number} SCREEN_NPM
 * @property {number} NONE
 * @property {number} SRC_IN
 * @property {number} SRC_OUT
 * @property {number} SRC_ATOP
 * @property {number} DST_OVER
 * @property {number} DST_IN
 * @property {number} DST_OUT
 * @property {number} DST_ATOP
 * @property {number} SUBTRACT
 * @property {number} SRC_OVER
 * @property {number} ERASE
 * @property {number} XOR
 */ var BLEND_MODES;
(function(BLEND_MODES1) {
    BLEND_MODES1[BLEND_MODES1["NORMAL"] = 0] = "NORMAL";
    BLEND_MODES1[BLEND_MODES1["ADD"] = 1] = "ADD";
    BLEND_MODES1[BLEND_MODES1["MULTIPLY"] = 2] = "MULTIPLY";
    BLEND_MODES1[BLEND_MODES1["SCREEN"] = 3] = "SCREEN";
    BLEND_MODES1[BLEND_MODES1["OVERLAY"] = 4] = "OVERLAY";
    BLEND_MODES1[BLEND_MODES1["DARKEN"] = 5] = "DARKEN";
    BLEND_MODES1[BLEND_MODES1["LIGHTEN"] = 6] = "LIGHTEN";
    BLEND_MODES1[BLEND_MODES1["COLOR_DODGE"] = 7] = "COLOR_DODGE";
    BLEND_MODES1[BLEND_MODES1["COLOR_BURN"] = 8] = "COLOR_BURN";
    BLEND_MODES1[BLEND_MODES1["HARD_LIGHT"] = 9] = "HARD_LIGHT";
    BLEND_MODES1[BLEND_MODES1["SOFT_LIGHT"] = 10] = "SOFT_LIGHT";
    BLEND_MODES1[BLEND_MODES1["DIFFERENCE"] = 11] = "DIFFERENCE";
    BLEND_MODES1[BLEND_MODES1["EXCLUSION"] = 12] = "EXCLUSION";
    BLEND_MODES1[BLEND_MODES1["HUE"] = 13] = "HUE";
    BLEND_MODES1[BLEND_MODES1["SATURATION"] = 14] = "SATURATION";
    BLEND_MODES1[BLEND_MODES1["COLOR"] = 15] = "COLOR";
    BLEND_MODES1[BLEND_MODES1["LUMINOSITY"] = 16] = "LUMINOSITY";
    BLEND_MODES1[BLEND_MODES1["NORMAL_NPM"] = 17] = "NORMAL_NPM";
    BLEND_MODES1[BLEND_MODES1["ADD_NPM"] = 18] = "ADD_NPM";
    BLEND_MODES1[BLEND_MODES1["SCREEN_NPM"] = 19] = "SCREEN_NPM";
    BLEND_MODES1[BLEND_MODES1["NONE"] = 20] = "NONE";
    BLEND_MODES1[BLEND_MODES1["SRC_OVER"] = 0] = "SRC_OVER";
    BLEND_MODES1[BLEND_MODES1["SRC_IN"] = 21] = "SRC_IN";
    BLEND_MODES1[BLEND_MODES1["SRC_OUT"] = 22] = "SRC_OUT";
    BLEND_MODES1[BLEND_MODES1["SRC_ATOP"] = 23] = "SRC_ATOP";
    BLEND_MODES1[BLEND_MODES1["DST_OVER"] = 24] = "DST_OVER";
    BLEND_MODES1[BLEND_MODES1["DST_IN"] = 25] = "DST_IN";
    BLEND_MODES1[BLEND_MODES1["DST_OUT"] = 26] = "DST_OUT";
    BLEND_MODES1[BLEND_MODES1["DST_ATOP"] = 27] = "DST_ATOP";
    BLEND_MODES1[BLEND_MODES1["ERASE"] = 26] = "ERASE";
    BLEND_MODES1[BLEND_MODES1["SUBTRACT"] = 28] = "SUBTRACT";
    BLEND_MODES1[BLEND_MODES1["XOR"] = 29] = "XOR";
})(BLEND_MODES || (BLEND_MODES = {
}));
/**
 * Various webgl draw modes. These can be used to specify which GL drawMode to use
 * under certain situations and renderers.
 *
 * @memberof PIXI
 * @static
 * @name DRAW_MODES
 * @enum {number}
 * @property {number} POINTS
 * @property {number} LINES
 * @property {number} LINE_LOOP
 * @property {number} LINE_STRIP
 * @property {number} TRIANGLES
 * @property {number} TRIANGLE_STRIP
 * @property {number} TRIANGLE_FAN
 */ var DRAW_MODES;
(function(DRAW_MODES1) {
    DRAW_MODES1[DRAW_MODES1["POINTS"] = 0] = "POINTS";
    DRAW_MODES1[DRAW_MODES1["LINES"] = 1] = "LINES";
    DRAW_MODES1[DRAW_MODES1["LINE_LOOP"] = 2] = "LINE_LOOP";
    DRAW_MODES1[DRAW_MODES1["LINE_STRIP"] = 3] = "LINE_STRIP";
    DRAW_MODES1[DRAW_MODES1["TRIANGLES"] = 4] = "TRIANGLES";
    DRAW_MODES1[DRAW_MODES1["TRIANGLE_STRIP"] = 5] = "TRIANGLE_STRIP";
    DRAW_MODES1[DRAW_MODES1["TRIANGLE_FAN"] = 6] = "TRIANGLE_FAN";
})(DRAW_MODES || (DRAW_MODES = {
}));
/**
 * Various GL texture/resources formats.
 *
 * @memberof PIXI
 * @static
 * @name FORMATS
 * @enum {number}
 * @property {number} RGBA=6408
 * @property {number} RGB=6407
 * @property {number} RG=33319
 * @property {number} RED=6403
 * @property {number} RGBA_INTEGER=36249
 * @property {number} RGB_INTEGER=36248
 * @property {number} RG_INTEGER=33320
 * @property {number} RED_INTEGER=36244
 * @property {number} ALPHA=6406
 * @property {number} LUMINANCE=6409
 * @property {number} LUMINANCE_ALPHA=6410
 * @property {number} DEPTH_COMPONENT=6402
 * @property {number} DEPTH_STENCIL=34041
 */ var FORMATS;
(function(FORMATS1) {
    FORMATS1[FORMATS1["RGBA"] = 6408] = "RGBA";
    FORMATS1[FORMATS1["RGB"] = 6407] = "RGB";
    FORMATS1[FORMATS1["RG"] = 33319] = "RG";
    FORMATS1[FORMATS1["RED"] = 6403] = "RED";
    FORMATS1[FORMATS1["RGBA_INTEGER"] = 36249] = "RGBA_INTEGER";
    FORMATS1[FORMATS1["RGB_INTEGER"] = 36248] = "RGB_INTEGER";
    FORMATS1[FORMATS1["RG_INTEGER"] = 33320] = "RG_INTEGER";
    FORMATS1[FORMATS1["RED_INTEGER"] = 36244] = "RED_INTEGER";
    FORMATS1[FORMATS1["ALPHA"] = 6406] = "ALPHA";
    FORMATS1[FORMATS1["LUMINANCE"] = 6409] = "LUMINANCE";
    FORMATS1[FORMATS1["LUMINANCE_ALPHA"] = 6410] = "LUMINANCE_ALPHA";
    FORMATS1[FORMATS1["DEPTH_COMPONENT"] = 6402] = "DEPTH_COMPONENT";
    FORMATS1[FORMATS1["DEPTH_STENCIL"] = 34041] = "DEPTH_STENCIL";
})(FORMATS || (FORMATS = {
}));
/**
 * Various GL target types.
 *
 * @memberof PIXI
 * @static
 * @name TARGETS
 * @enum {number}
 * @property {number} TEXTURE_2D=3553
 * @property {number} TEXTURE_CUBE_MAP=34067
 * @property {number} TEXTURE_2D_ARRAY=35866
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_X=34069
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_X=34070
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_Y=34071
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_Y=34072
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_Z=34073
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_Z=34074
 */ var TARGETS;
(function(TARGETS1) {
    TARGETS1[TARGETS1["TEXTURE_2D"] = 3553] = "TEXTURE_2D";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP"] = 34067] = "TEXTURE_CUBE_MAP";
    TARGETS1[TARGETS1["TEXTURE_2D_ARRAY"] = 35866] = "TEXTURE_2D_ARRAY";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_X"] = 34069] = "TEXTURE_CUBE_MAP_POSITIVE_X";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_X"] = 34070] = "TEXTURE_CUBE_MAP_NEGATIVE_X";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_Y"] = 34071] = "TEXTURE_CUBE_MAP_POSITIVE_Y";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_Y"] = 34072] = "TEXTURE_CUBE_MAP_NEGATIVE_Y";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_Z"] = 34073] = "TEXTURE_CUBE_MAP_POSITIVE_Z";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_Z"] = 34074] = "TEXTURE_CUBE_MAP_NEGATIVE_Z";
})(TARGETS || (TARGETS = {
}));
/**
 * Various GL data format types.
 *
 * @memberof PIXI
 * @static
 * @name TYPES
 * @enum {number}
 * @property {number} UNSIGNED_BYTE=5121
 * @property {number} UNSIGNED_SHORT=5123
 * @property {number} UNSIGNED_SHORT_5_6_5=33635
 * @property {number} UNSIGNED_SHORT_4_4_4_4=32819
 * @property {number} UNSIGNED_SHORT_5_5_5_1=32820
 * @property {number} UNSIGNED_INT=5125
 * @property {number} UNSIGNED_INT_10F_11F_11F_REV=35899
 * @property {number} UNSIGNED_INT_2_10_10_10_REV=33640
 * @property {number} UNSIGNED_INT_24_8=34042
 * @property {number} UNSIGNED_INT_5_9_9_9_REV=35902
 * @property {number} BYTE=5120
 * @property {number} SHORT=5122
 * @property {number} INT=5124
 * @property {number} FLOAT=5126
 * @property {number} FLOAT_32_UNSIGNED_INT_24_8_REV=36269
 * @property {number} HALF_FLOAT=36193
 */ var TYPES;
(function(TYPES1) {
    TYPES1[TYPES1["UNSIGNED_BYTE"] = 5121] = "UNSIGNED_BYTE";
    TYPES1[TYPES1["UNSIGNED_SHORT"] = 5123] = "UNSIGNED_SHORT";
    TYPES1[TYPES1["UNSIGNED_SHORT_5_6_5"] = 33635] = "UNSIGNED_SHORT_5_6_5";
    TYPES1[TYPES1["UNSIGNED_SHORT_4_4_4_4"] = 32819] = "UNSIGNED_SHORT_4_4_4_4";
    TYPES1[TYPES1["UNSIGNED_SHORT_5_5_5_1"] = 32820] = "UNSIGNED_SHORT_5_5_5_1";
    TYPES1[TYPES1["UNSIGNED_INT"] = 5125] = "UNSIGNED_INT";
    TYPES1[TYPES1["UNSIGNED_INT_10F_11F_11F_REV"] = 35899] = "UNSIGNED_INT_10F_11F_11F_REV";
    TYPES1[TYPES1["UNSIGNED_INT_2_10_10_10_REV"] = 33640] = "UNSIGNED_INT_2_10_10_10_REV";
    TYPES1[TYPES1["UNSIGNED_INT_24_8"] = 34042] = "UNSIGNED_INT_24_8";
    TYPES1[TYPES1["UNSIGNED_INT_5_9_9_9_REV"] = 35902] = "UNSIGNED_INT_5_9_9_9_REV";
    TYPES1[TYPES1["BYTE"] = 5120] = "BYTE";
    TYPES1[TYPES1["SHORT"] = 5122] = "SHORT";
    TYPES1[TYPES1["INT"] = 5124] = "INT";
    TYPES1[TYPES1["FLOAT"] = 5126] = "FLOAT";
    TYPES1[TYPES1["FLOAT_32_UNSIGNED_INT_24_8_REV"] = 36269] = "FLOAT_32_UNSIGNED_INT_24_8_REV";
    TYPES1[TYPES1["HALF_FLOAT"] = 36193] = "HALF_FLOAT";
})(TYPES || (TYPES = {
}));
/**
 * Various sampler types. Correspond to `sampler`, `isampler`, `usampler` GLSL types respectively.
 * WebGL1 works only with FLOAT.
 *
 * @memberof PIXI
 * @static
 * @name SAMPLER_TYPES
 * @enum {number}
 * @property {number} FLOAT=0
 * @property {number} INT=1
 * @property {number} UINT=2
 */ var SAMPLER_TYPES;
(function(SAMPLER_TYPES1) {
    SAMPLER_TYPES1[SAMPLER_TYPES1["FLOAT"] = 0] = "FLOAT";
    SAMPLER_TYPES1[SAMPLER_TYPES1["INT"] = 1] = "INT";
    SAMPLER_TYPES1[SAMPLER_TYPES1["UINT"] = 2] = "UINT";
})(SAMPLER_TYPES || (SAMPLER_TYPES = {
}));
/**
 * The scale modes that are supported by pixi.
 *
 * The {@link PIXI.settings.SCALE_MODE} scale mode affects the default scaling mode of future operations.
 * It can be re-assigned to either LINEAR or NEAREST, depending upon suitability.
 *
 * @memberof PIXI
 * @static
 * @name SCALE_MODES
 * @enum {number}
 * @property {number} LINEAR Smooth scaling
 * @property {number} NEAREST Pixelating scaling
 */ var SCALE_MODES;
(function(SCALE_MODES1) {
    SCALE_MODES1[SCALE_MODES1["NEAREST"] = 0] = "NEAREST";
    SCALE_MODES1[SCALE_MODES1["LINEAR"] = 1] = "LINEAR";
})(SCALE_MODES || (SCALE_MODES = {
}));
/**
 * The wrap modes that are supported by pixi.
 *
 * The {@link PIXI.settings.WRAP_MODE} wrap mode affects the default wrapping mode of future operations.
 * It can be re-assigned to either CLAMP or REPEAT, depending upon suitability.
 * If the texture is non power of two then clamp will be used regardless as WebGL can
 * only use REPEAT if the texture is po2.
 *
 * This property only affects WebGL.
 *
 * @name WRAP_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} CLAMP - The textures uvs are clamped
 * @property {number} REPEAT - The texture uvs tile and repeat
 * @property {number} MIRRORED_REPEAT - The texture uvs tile and repeat with mirroring
 */ var WRAP_MODES;
(function(WRAP_MODES1) {
    WRAP_MODES1[WRAP_MODES1["CLAMP"] = 33071] = "CLAMP";
    WRAP_MODES1[WRAP_MODES1["REPEAT"] = 10497] = "REPEAT";
    WRAP_MODES1[WRAP_MODES1["MIRRORED_REPEAT"] = 33648] = "MIRRORED_REPEAT";
})(WRAP_MODES || (WRAP_MODES = {
}));
/**
 * Mipmap filtering modes that are supported by pixi.
 *
 * The {@link PIXI.settings.MIPMAP_TEXTURES} affects default texture filtering.
 * Mipmaps are generated for a baseTexture if its `mipmap` field is `ON`,
 * or its `POW2` and texture dimensions are powers of 2.
 * Due to platform restriction, `ON` option will work like `POW2` for webgl-1.
 *
 * This property only affects WebGL.
 *
 * @name MIPMAP_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} OFF - No mipmaps
 * @property {number} POW2 - Generate mipmaps if texture dimensions are pow2
 * @property {number} ON - Always generate mipmaps
 * @property {number} ON_MANUAL - Use mipmaps, but do not auto-generate them; this is used with a resource
 *   that supports buffering each level-of-detail.
 */ var MIPMAP_MODES;
(function(MIPMAP_MODES1) {
    MIPMAP_MODES1[MIPMAP_MODES1["OFF"] = 0] = "OFF";
    MIPMAP_MODES1[MIPMAP_MODES1["POW2"] = 1] = "POW2";
    MIPMAP_MODES1[MIPMAP_MODES1["ON"] = 2] = "ON";
    MIPMAP_MODES1[MIPMAP_MODES1["ON_MANUAL"] = 3] = "ON_MANUAL";
})(MIPMAP_MODES || (MIPMAP_MODES = {
}));
/**
 * How to treat textures with premultiplied alpha
 *
 * @name ALPHA_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NO_PREMULTIPLIED_ALPHA - Source is not premultiplied, leave it like that.
 *  Option for compressed and data textures that are created from typed arrays.
 * @property {number} PREMULTIPLY_ON_UPLOAD - Source is not premultiplied, premultiply on upload.
 *  Default option, used for all loaded images.
 * @property {number} PREMULTIPLIED_ALPHA - Source is already premultiplied
 *  Example: spine atlases with `_pma` suffix.
 * @property {number} NPM - Alias for NO_PREMULTIPLIED_ALPHA.
 * @property {number} UNPACK - Default option, alias for PREMULTIPLY_ON_UPLOAD.
 * @property {number} PMA - Alias for PREMULTIPLIED_ALPHA.
 */ var ALPHA_MODES;
(function(ALPHA_MODES1) {
    ALPHA_MODES1[ALPHA_MODES1["NPM"] = 0] = "NPM";
    ALPHA_MODES1[ALPHA_MODES1["UNPACK"] = 1] = "UNPACK";
    ALPHA_MODES1[ALPHA_MODES1["PMA"] = 2] = "PMA";
    ALPHA_MODES1[ALPHA_MODES1["NO_PREMULTIPLIED_ALPHA"] = 0] = "NO_PREMULTIPLIED_ALPHA";
    ALPHA_MODES1[ALPHA_MODES1["PREMULTIPLY_ON_UPLOAD"] = 1] = "PREMULTIPLY_ON_UPLOAD";
    ALPHA_MODES1[ALPHA_MODES1["PREMULTIPLY_ALPHA"] = 2] = "PREMULTIPLY_ALPHA";
})(ALPHA_MODES || (ALPHA_MODES = {
}));
/**
 * Configure whether filter textures are cleared after binding.
 *
 * Filter textures need not be cleared if the filter does not use pixel blending. {@link CLEAR_MODES.BLIT} will detect
 * this and skip clearing as an optimization.
 *
 * @name CLEAR_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} BLEND - Do not clear the filter texture. The filter's output will blend on top of the output texture.
 * @property {number} CLEAR - Always clear the filter texture.
 * @property {number} BLIT - Clear only if {@link FilterSystem.forceClear} is set or if the filter uses pixel blending.
 * @property {number} NO - Alias for BLEND, same as `false` in earlier versions
 * @property {number} YES - Alias for CLEAR, same as `true` in earlier versions
 * @property {number} AUTO - Alias for BLIT
 */ var CLEAR_MODES;
(function(CLEAR_MODES1) {
    CLEAR_MODES1[CLEAR_MODES1["NO"] = 0] = "NO";
    CLEAR_MODES1[CLEAR_MODES1["YES"] = 1] = "YES";
    CLEAR_MODES1[CLEAR_MODES1["AUTO"] = 2] = "AUTO";
    CLEAR_MODES1[CLEAR_MODES1["BLEND"] = 0] = "BLEND";
    CLEAR_MODES1[CLEAR_MODES1["CLEAR"] = 1] = "CLEAR";
    CLEAR_MODES1[CLEAR_MODES1["BLIT"] = 2] = "BLIT";
})(CLEAR_MODES || (CLEAR_MODES = {
}));
/**
 * The gc modes that are supported by pixi.
 *
 * The {@link PIXI.settings.GC_MODE} Garbage Collection mode for PixiJS textures is AUTO
 * If set to GC_MODE, the renderer will occasionally check textures usage. If they are not
 * used for a specified period of time they will be removed from the GPU. They will of course
 * be uploaded again when they are required. This is a silent behind the scenes process that
 * should ensure that the GPU does not  get filled up.
 *
 * Handy for mobile devices!
 * This property only affects WebGL.
 *
 * @name GC_MODES
 * @enum {number}
 * @static
 * @memberof PIXI
 * @property {number} AUTO - Garbage collection will happen periodically automatically
 * @property {number} MANUAL - Garbage collection will need to be called manually
 */ var GC_MODES;
(function(GC_MODES1) {
    GC_MODES1[GC_MODES1["AUTO"] = 0] = "AUTO";
    GC_MODES1[GC_MODES1["MANUAL"] = 1] = "MANUAL";
})(GC_MODES || (GC_MODES = {
}));
/**
 * Constants that specify float precision in shaders.
 *
 * @name PRECISION
 * @memberof PIXI
 * @constant
 * @static
 * @enum {string}
 * @property {string} LOW='lowp'
 * @property {string} MEDIUM='mediump'
 * @property {string} HIGH='highp'
 */ var PRECISION;
(function(PRECISION1) {
    PRECISION1["LOW"] = "lowp";
    PRECISION1["MEDIUM"] = "mediump";
    PRECISION1["HIGH"] = "highp";
})(PRECISION || (PRECISION = {
}));
/**
 * Constants for mask implementations.
 * We use `type` suffix because it leads to very different behaviours
 *
 * @name MASK_TYPES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NONE - Mask is ignored
 * @property {number} SCISSOR - Scissor mask, rectangle on screen, cheap
 * @property {number} STENCIL - Stencil mask, 1-bit, medium, works only if renderer supports stencil
 * @property {number} SPRITE - Mask that uses SpriteMaskFilter, uses temporary RenderTexture
 */ var MASK_TYPES;
(function(MASK_TYPES1) {
    MASK_TYPES1[MASK_TYPES1["NONE"] = 0] = "NONE";
    MASK_TYPES1[MASK_TYPES1["SCISSOR"] = 1] = "SCISSOR";
    MASK_TYPES1[MASK_TYPES1["STENCIL"] = 2] = "STENCIL";
    MASK_TYPES1[MASK_TYPES1["SPRITE"] = 3] = "SPRITE";
})(MASK_TYPES || (MASK_TYPES = {
}));
/**
 * Constants for multi-sampling antialiasing.
 *
 * @see PIXI.Framebuffer#multisample
 *
 * @name MSAA_QUALITY
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NONE - No multisampling for this renderTexture
 * @property {number} LOW - Try 2 samples
 * @property {number} MEDIUM - Try 4 samples
 * @property {number} HIGH - Try 8 samples
 */ var MSAA_QUALITY;
(function(MSAA_QUALITY1) {
    MSAA_QUALITY1[MSAA_QUALITY1["NONE"] = 0] = "NONE";
    MSAA_QUALITY1[MSAA_QUALITY1["LOW"] = 2] = "LOW";
    MSAA_QUALITY1[MSAA_QUALITY1["MEDIUM"] = 4] = "MEDIUM";
    MSAA_QUALITY1[MSAA_QUALITY1["HIGH"] = 8] = "HIGH";
})(MSAA_QUALITY || (MSAA_QUALITY = {
}));
/**
 * Constants for various buffer types in Pixi
 *
 * @see PIXI.BUFFER_TYPE
 *
 * @name BUFFER_TYPE
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} ELEMENT_ARRAY_BUFFER - buffer type for using as an index buffer
 * @property {number} ARRAY_BUFFER - buffer type for using attribute data
 * @property {number} UNIFORM_BUFFER - the buffer type is for uniform buffer objects
 */ var BUFFER_TYPE;
(function(BUFFER_TYPE1) {
    BUFFER_TYPE1[BUFFER_TYPE1["ELEMENT_ARRAY_BUFFER"] = 34963] = "ELEMENT_ARRAY_BUFFER";
    BUFFER_TYPE1[BUFFER_TYPE1["ARRAY_BUFFER"] = 34962] = "ARRAY_BUFFER";
    // NOT YET SUPPORTED
    BUFFER_TYPE1[BUFFER_TYPE1["UNIFORM_BUFFER"] = 35345] = "UNIFORM_BUFFER";
})(BUFFER_TYPE || (BUFFER_TYPE = {
}));
/**
 * The BlurFilterPass applies a horizontal or vertical Gaussian blur to an object.
 *
 * @class
 * @extends PIXI.Filter
 * @memberof PIXI.filters
 */ var BlurFilterPass1 = function(_super) {
    __extends(BlurFilterPass2, _super);
    /**
     * @param {boolean} horizontal - Do pass along the x-axis (`true`) or y-axis (`false`).
     * @param {number} [strength=8] - The strength of the blur filter.
     * @param {number} [quality=4] - The quality of the blur filter.
     * @param {number} [resolution=PIXI.settings.FILTER_RESOLUTION] - The resolution of the blur filter.
     * @param {number} [kernelSize=5] - The kernelSize of the blur filter.Options: 5, 7, 9, 11, 13, 15.
     */ function BlurFilterPass2(horizontal, strength, quality, resolution, kernelSize) {
        if (strength === void 0) strength = 8;
        if (quality === void 0) quality = 4;
        if (resolution === void 0) resolution = _settings.settings.FILTER_RESOLUTION;
        if (kernelSize === void 0) kernelSize = 5;
        var _this = this;
        var vertSrc = generateBlurVertSource(kernelSize, horizontal);
        var fragSrc = generateBlurFragSource(kernelSize);
        _this = _super.call(this, // vertex shader
        vertSrc, // fragment shader
        fragSrc) || this;
        _this.horizontal = horizontal;
        _this.resolution = resolution;
        _this._quality = 0;
        _this.quality = quality;
        _this.blur = strength;
        return _this;
    }
    /**
     * Applies the filter.
     *
     * @param {PIXI.FilterSystem} filterManager - The manager.
     * @param {PIXI.RenderTexture} input - The input target.
     * @param {PIXI.RenderTexture} output - The output target.
     * @param {PIXI.CLEAR_MODES} clearMode - How to clear
     */ BlurFilterPass2.prototype.apply = function(filterManager, input, output, clearMode) {
        if (output) {
            if (this.horizontal) this.uniforms.strength = 1 / output.width * (output.width / input.width);
            else this.uniforms.strength = 1 / output.height * (output.height / input.height);
        } else if (this.horizontal) this.uniforms.strength = 1 / filterManager.renderer.width * (filterManager.renderer.width / input.width);
        else this.uniforms.strength = 1 / filterManager.renderer.height * (filterManager.renderer.height / input.height); // eslint-disable-line
        // screen space!
        this.uniforms.strength *= this.strength;
        this.uniforms.strength /= this.passes;
        if (this.passes === 1) filterManager.applyFilter(this, input, output, clearMode);
        else {
            var renderTarget = filterManager.getFilterTexture();
            var renderer = filterManager.renderer;
            var flip = input;
            var flop = renderTarget;
            this.state.blend = false;
            filterManager.applyFilter(this, flip, flop, CLEAR_MODES.CLEAR);
            for(var i = 1; i < this.passes - 1; i++){
                filterManager.bindAndClear(flip, CLEAR_MODES.BLIT);
                this.uniforms.uSampler = flop;
                var temp = flop;
                flop = flip;
                flip = temp;
                renderer.shader.bind(this);
                renderer.geometry.draw(5);
            }
            this.state.blend = true;
            filterManager.applyFilter(this, flop, output, clearMode);
            filterManager.returnFilterTexture(renderTarget);
        }
    };
    Object.defineProperty(BlurFilterPass2.prototype, "blur", {
        /**
         * Sets the strength of both the blur.
         *
         * @member {number}
         * @default 16
         */ get: function() {
            return this.strength;
        },
        set: function(value) {
            this.padding = 1 + Math.abs(value) * 2;
            this.strength = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BlurFilterPass2.prototype, "quality", {
        /**
         * Sets the quality of the blur by modifying the number of passes. More passes means higher
         * quality bluring but the lower the performance.
         *
         * @member {number}
         * @default 4
         */ get: function() {
            return this._quality;
        },
        set: function(value) {
            this._quality = value;
            this.passes = value;
        },
        enumerable: false,
        configurable: true
    });
    return BlurFilterPass2;
}(_core.Filter);
/**
 * The BlurFilter applies a Gaussian blur to an object.
 *
 * The strength of the blur can be set for the x-axis and y-axis separately.
 *
 * @class
 * @extends PIXI.Filter
 * @memberof PIXI.filters
 */ var BlurFilter1 = function(_super) {
    __extends(BlurFilter2, _super);
    /**
     * @param {number} [strength=8] - The strength of the blur filter.
     * @param {number} [quality=4] - The quality of the blur filter.
     * @param {number} [resolution=PIXI.settings.FILTER_RESOLUTION] - The resolution of the blur filter.
     * @param {number} [kernelSize=5] - The kernelSize of the blur filter.Options: 5, 7, 9, 11, 13, 15.
     */ function BlurFilter2(strength, quality, resolution, kernelSize) {
        if (strength === void 0) strength = 8;
        if (quality === void 0) quality = 4;
        if (resolution === void 0) resolution = _settings.settings.FILTER_RESOLUTION;
        if (kernelSize === void 0) kernelSize = 5;
        var _this = _super.call(this) || this;
        _this.blurXFilter = new BlurFilterPass1(true, strength, quality, resolution, kernelSize);
        _this.blurYFilter = new BlurFilterPass1(false, strength, quality, resolution, kernelSize);
        _this.resolution = resolution;
        _this.quality = quality;
        _this.blur = strength;
        _this.repeatEdgePixels = false;
        return _this;
    }
    /**
     * Applies the filter.
     *
     * @param {PIXI.FilterSystem} filterManager - The manager.
     * @param {PIXI.RenderTexture} input - The input target.
     * @param {PIXI.RenderTexture} output - The output target.
     * @param {PIXI.CLEAR_MODES} clearMode - How to clear
     */ BlurFilter2.prototype.apply = function(filterManager, input, output, clearMode) {
        var xStrength = Math.abs(this.blurXFilter.strength);
        var yStrength = Math.abs(this.blurYFilter.strength);
        if (xStrength && yStrength) {
            var renderTarget = filterManager.getFilterTexture();
            this.blurXFilter.apply(filterManager, input, renderTarget, CLEAR_MODES.CLEAR);
            this.blurYFilter.apply(filterManager, renderTarget, output, clearMode);
            filterManager.returnFilterTexture(renderTarget);
        } else if (yStrength) this.blurYFilter.apply(filterManager, input, output, clearMode);
        else this.blurXFilter.apply(filterManager, input, output, clearMode);
    };
    BlurFilter2.prototype.updatePadding = function() {
        if (this._repeatEdgePixels) this.padding = 0;
        else this.padding = Math.max(Math.abs(this.blurXFilter.strength), Math.abs(this.blurYFilter.strength)) * 2;
    };
    Object.defineProperty(BlurFilter2.prototype, "blur", {
        /**
         * Sets the strength of both the blurX and blurY properties simultaneously
         *
         * @member {number}
         * @default 2
         */ get: function() {
            return this.blurXFilter.blur;
        },
        set: function(value) {
            this.blurXFilter.blur = this.blurYFilter.blur = value;
            this.updatePadding();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BlurFilter2.prototype, "quality", {
        /**
         * Sets the number of passes for blur. More passes means higher quality bluring.
         *
         * @member {number}
         * @default 1
         */ get: function() {
            return this.blurXFilter.quality;
        },
        set: function(value) {
            this.blurXFilter.quality = this.blurYFilter.quality = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BlurFilter2.prototype, "blurX", {
        /**
         * Sets the strength of the blurX property
         *
         * @member {number}
         * @default 2
         */ get: function() {
            return this.blurXFilter.blur;
        },
        set: function(value) {
            this.blurXFilter.blur = value;
            this.updatePadding();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BlurFilter2.prototype, "blurY", {
        /**
         * Sets the strength of the blurY property
         *
         * @member {number}
         * @default 2
         */ get: function() {
            return this.blurYFilter.blur;
        },
        set: function(value) {
            this.blurYFilter.blur = value;
            this.updatePadding();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BlurFilter2.prototype, "blendMode", {
        /**
         * Sets the blendmode of the filter
         *
         * @member {number}
         * @default PIXI.BLEND_MODES.NORMAL
         */ get: function() {
            return this.blurYFilter.blendMode;
        },
        set: function(value) {
            this.blurYFilter.blendMode = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(BlurFilter2.prototype, "repeatEdgePixels", {
        /**
         * If set to true the edge of the target will be clamped
         *
         * @member {boolean}
         * @default false
         */ get: function() {
            return this._repeatEdgePixels;
        },
        set: function(value) {
            this._repeatEdgePixels = value;
            this.updatePadding();
        },
        enumerable: false,
        configurable: true
    });
    return BlurFilter2;
}(_core.Filter);

},{"@pixi/core":"d0INm","@pixi/settings":"habh9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cz6Dl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ColorMatrixFilter", ()=>ColorMatrixFilter1
);
/*!
 * @pixi/filter-color-matrix - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/filter-color-matrix is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var fragment = "varying vec2 vTextureCoord;\nuniform sampler2D uSampler;\nuniform float m[20];\nuniform float uAlpha;\n\nvoid main(void)\n{\n    vec4 c = texture2D(uSampler, vTextureCoord);\n\n    if (uAlpha == 0.0) {\n        gl_FragColor = c;\n        return;\n    }\n\n    // Un-premultiply alpha before applying the color matrix. See issue #3539.\n    if (c.a > 0.0) {\n      c.rgb /= c.a;\n    }\n\n    vec4 result;\n\n    result.r = (m[0] * c.r);\n        result.r += (m[1] * c.g);\n        result.r += (m[2] * c.b);\n        result.r += (m[3] * c.a);\n        result.r += m[4];\n\n    result.g = (m[5] * c.r);\n        result.g += (m[6] * c.g);\n        result.g += (m[7] * c.b);\n        result.g += (m[8] * c.a);\n        result.g += m[9];\n\n    result.b = (m[10] * c.r);\n       result.b += (m[11] * c.g);\n       result.b += (m[12] * c.b);\n       result.b += (m[13] * c.a);\n       result.b += m[14];\n\n    result.a = (m[15] * c.r);\n       result.a += (m[16] * c.g);\n       result.a += (m[17] * c.b);\n       result.a += (m[18] * c.a);\n       result.a += m[19];\n\n    vec3 rgb = mix(c.rgb, result.rgb, uAlpha);\n\n    // Premultiply alpha again.\n    rgb *= result.a;\n\n    gl_FragColor = vec4(rgb, result.a);\n}\n";
/**
 * The ColorMatrixFilter class lets you apply a 5x4 matrix transformation on the RGBA
 * color and alpha values of every pixel on your displayObject to produce a result
 * with a new set of RGBA color and alpha values. It's pretty powerful!
 *
 * ```js
 *  let colorMatrix = new PIXI.filters.ColorMatrixFilter();
 *  container.filters = [colorMatrix];
 *  colorMatrix.contrast(2);
 * ```
 * @author Clément Chenebault <clement@goodboydigital.com>
 * @class
 * @extends PIXI.Filter
 * @memberof PIXI.filters
 */ var ColorMatrixFilter1 = function(_super) {
    __extends(ColorMatrixFilter2, _super);
    function ColorMatrixFilter2() {
        var _this = this;
        var uniforms = {
            m: new Float32Array([
                1,
                0,
                0,
                0,
                0,
                0,
                1,
                0,
                0,
                0,
                0,
                0,
                1,
                0,
                0,
                0,
                0,
                0,
                1,
                0
            ]),
            uAlpha: 1
        };
        _this = _super.call(this, _core.defaultFilterVertex, fragment, uniforms) || this;
        _this.alpha = 1;
        return _this;
    }
    /**
     * Transforms current matrix and set the new one
     *
     * @param {number[]} matrix - 5x4 matrix
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype._loadMatrix = function(matrix, multiply) {
        if (multiply === void 0) multiply = false;
        var newMatrix = matrix;
        if (multiply) {
            this._multiply(newMatrix, this.uniforms.m, matrix);
            newMatrix = this._colorMatrix(newMatrix);
        }
        // set the new matrix
        this.uniforms.m = newMatrix;
    };
    /**
     * Multiplies two mat5's
     *
     * @private
     * @param {number[]} out - 5x4 matrix the receiving matrix
     * @param {number[]} a - 5x4 matrix the first operand
     * @param {number[]} b - 5x4 matrix the second operand
     * @returns {number[]} 5x4 matrix
     */ ColorMatrixFilter2.prototype._multiply = function(out, a, b) {
        // Red Channel
        out[0] = a[0] * b[0] + a[1] * b[5] + a[2] * b[10] + a[3] * b[15];
        out[1] = a[0] * b[1] + a[1] * b[6] + a[2] * b[11] + a[3] * b[16];
        out[2] = a[0] * b[2] + a[1] * b[7] + a[2] * b[12] + a[3] * b[17];
        out[3] = a[0] * b[3] + a[1] * b[8] + a[2] * b[13] + a[3] * b[18];
        out[4] = a[0] * b[4] + a[1] * b[9] + a[2] * b[14] + a[3] * b[19] + a[4];
        // Green Channel
        out[5] = a[5] * b[0] + a[6] * b[5] + a[7] * b[10] + a[8] * b[15];
        out[6] = a[5] * b[1] + a[6] * b[6] + a[7] * b[11] + a[8] * b[16];
        out[7] = a[5] * b[2] + a[6] * b[7] + a[7] * b[12] + a[8] * b[17];
        out[8] = a[5] * b[3] + a[6] * b[8] + a[7] * b[13] + a[8] * b[18];
        out[9] = a[5] * b[4] + a[6] * b[9] + a[7] * b[14] + a[8] * b[19] + a[9];
        // Blue Channel
        out[10] = a[10] * b[0] + a[11] * b[5] + a[12] * b[10] + a[13] * b[15];
        out[11] = a[10] * b[1] + a[11] * b[6] + a[12] * b[11] + a[13] * b[16];
        out[12] = a[10] * b[2] + a[11] * b[7] + a[12] * b[12] + a[13] * b[17];
        out[13] = a[10] * b[3] + a[11] * b[8] + a[12] * b[13] + a[13] * b[18];
        out[14] = a[10] * b[4] + a[11] * b[9] + a[12] * b[14] + a[13] * b[19] + a[14];
        // Alpha Channel
        out[15] = a[15] * b[0] + a[16] * b[5] + a[17] * b[10] + a[18] * b[15];
        out[16] = a[15] * b[1] + a[16] * b[6] + a[17] * b[11] + a[18] * b[16];
        out[17] = a[15] * b[2] + a[16] * b[7] + a[17] * b[12] + a[18] * b[17];
        out[18] = a[15] * b[3] + a[16] * b[8] + a[17] * b[13] + a[18] * b[18];
        out[19] = a[15] * b[4] + a[16] * b[9] + a[17] * b[14] + a[18] * b[19] + a[19];
        return out;
    };
    /**
     * Create a Float32 Array and normalize the offset component to 0-1
     *
     * @private
     * @param {number[]} matrix - 5x4 matrix
     * @return {number[]} 5x4 matrix with all values between 0-1
     */ ColorMatrixFilter2.prototype._colorMatrix = function(matrix) {
        // Create a Float32 Array and normalize the offset component to 0-1
        var m = new Float32Array(matrix);
        m[4] /= 255;
        m[9] /= 255;
        m[14] /= 255;
        m[19] /= 255;
        return m;
    };
    /**
     * Adjusts brightness
     *
     * @param {number} b - value of the brigthness (0-1, where 0 is black)
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.brightness = function(b, multiply) {
        var matrix = [
            b,
            0,
            0,
            0,
            0,
            0,
            b,
            0,
            0,
            0,
            0,
            0,
            b,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Sets each channel on the diagonal of the color matrix.
     * This can be used to achieve a tinting effect on Containers similar to the tint field of some
     * display objects like Sprite, Text, Graphics, and Mesh.
     *
     * @param {number} color - Color of the tint. This is a hex value.
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.tint = function(color, multiply) {
        var r = color >> 16 & 255;
        var g = color >> 8 & 255;
        var b = color & 255;
        var matrix = [
            r / 255,
            0,
            0,
            0,
            0,
            0,
            g / 255,
            0,
            0,
            0,
            0,
            0,
            b / 255,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Set the matrices in grey scales
     *
     * @param {number} scale - value of the grey (0-1, where 0 is black)
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.greyscale = function(scale, multiply) {
        var matrix = [
            scale,
            scale,
            scale,
            0,
            0,
            scale,
            scale,
            scale,
            0,
            0,
            scale,
            scale,
            scale,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Set the black and white matrice.
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.blackAndWhite = function(multiply) {
        var matrix = [
            0.3,
            0.6,
            0.1,
            0,
            0,
            0.3,
            0.6,
            0.1,
            0,
            0,
            0.3,
            0.6,
            0.1,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Set the hue property of the color
     *
     * @param {number} rotation - in degrees
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.hue = function(rotation, multiply) {
        rotation = (rotation || 0) / 180 * Math.PI;
        var cosR = Math.cos(rotation);
        var sinR = Math.sin(rotation);
        var sqrt = Math.sqrt;
        /* a good approximation for hue rotation
         This matrix is far better than the versions with magic luminance constants
         formerly used here, but also used in the starling framework (flash) and known from this
         old part of the internet: quasimondo.com/archives/000565.php

         This new matrix is based on rgb cube rotation in space. Look here for a more descriptive
         implementation as a shader not a general matrix:
         https://github.com/evanw/glfx.js/blob/58841c23919bd59787effc0333a4897b43835412/src/filters/adjust/huesaturation.js

         This is the source for the code:
         see http://stackoverflow.com/questions/8507885/shift-hue-of-an-rgb-color/8510751#8510751
         */ var w = 1 / 3;
        var sqrW = sqrt(w); // weight is
        var a00 = cosR + (1 - cosR) * w;
        var a01 = w * (1 - cosR) - sqrW * sinR;
        var a02 = w * (1 - cosR) + sqrW * sinR;
        var a10 = w * (1 - cosR) + sqrW * sinR;
        var a11 = cosR + w * (1 - cosR);
        var a12 = w * (1 - cosR) - sqrW * sinR;
        var a20 = w * (1 - cosR) - sqrW * sinR;
        var a21 = w * (1 - cosR) + sqrW * sinR;
        var a22 = cosR + w * (1 - cosR);
        var matrix = [
            a00,
            a01,
            a02,
            0,
            0,
            a10,
            a11,
            a12,
            0,
            0,
            a20,
            a21,
            a22,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Set the contrast matrix, increase the separation between dark and bright
     * Increase contrast : shadows darker and highlights brighter
     * Decrease contrast : bring the shadows up and the highlights down
     *
     * @param {number} amount - value of the contrast (0-1)
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.contrast = function(amount, multiply) {
        var v = (amount || 0) + 1;
        var o = -0.5 * (v - 1);
        var matrix = [
            v,
            0,
            0,
            0,
            o,
            0,
            v,
            0,
            0,
            o,
            0,
            0,
            v,
            0,
            o,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Set the saturation matrix, increase the separation between colors
     * Increase saturation : increase contrast, brightness, and sharpness
     *
     * @param {number} amount - The saturation amount (0-1)
     * @param {boolean} [multiply] - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.saturate = function(amount, multiply) {
        if (amount === void 0) amount = 0;
        var x = amount * 2 / 3 + 1;
        var y = (x - 1) * -0.5;
        var matrix = [
            x,
            y,
            y,
            0,
            0,
            y,
            x,
            y,
            0,
            0,
            y,
            y,
            x,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Desaturate image (remove color)
     *
     * Call the saturate function
     *
     */ ColorMatrixFilter2.prototype.desaturate = function() {
        this.saturate(-1);
    };
    /**
     * Negative image (inverse of classic rgb matrix)
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.negative = function(multiply) {
        var matrix = [
            -1,
            0,
            0,
            1,
            0,
            0,
            -1,
            0,
            1,
            0,
            0,
            0,
            -1,
            1,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Sepia image
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.sepia = function(multiply) {
        var matrix = [
            0.393,
            0.7689999,
            0.18899999,
            0,
            0,
            0.349,
            0.6859999,
            0.16799999,
            0,
            0,
            0.272,
            0.5339999,
            0.13099999,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Color motion picture process invented in 1916 (thanks Dominic Szablewski)
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.technicolor = function(multiply) {
        var matrix = [
            1.9125277891456083,
            -0.8545344976951645,
            -0.09155508482755585,
            0,
            11.793603434377337,
            -0.3087833385928097,
            1.7658908555458428,
            -0.10601743074722245,
            0,
            -70.35205161461398,
            -0.231103377548616,
            -0.7501899197440212,
            1.847597816108189,
            0,
            30.950940869491138,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Polaroid filter
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.polaroid = function(multiply) {
        var matrix = [
            1.438,
            -0.062,
            -0.062,
            0,
            0,
            -0.122,
            1.378,
            -0.122,
            0,
            0,
            -0.016,
            -0.016,
            1.483,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Filter who transforms : Red -> Blue and Blue -> Red
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.toBGR = function(multiply) {
        var matrix = [
            0,
            0,
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Color reversal film introduced by Eastman Kodak in 1935. (thanks Dominic Szablewski)
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.kodachrome = function(multiply) {
        var matrix = [
            1.1285582396593525,
            -0.3967382283601348,
            -0.03992559172921793,
            0,
            63.72958762196502,
            -0.16404339962244616,
            1.0835251566291304,
            -0.05498805115633132,
            0,
            24.732407896706203,
            -0.16786010706155763,
            -0.5603416277695248,
            1.6014850761964943,
            0,
            35.62982807460946,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Brown delicious browni filter (thanks Dominic Szablewski)
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.browni = function(multiply) {
        var matrix = [
            0.5997023498159715,
            0.34553243048391263,
            -0.2708298674538042,
            0,
            47.43192855600873,
            -0.037703249837783157,
            0.8609577587992641,
            0.15059552388459913,
            0,
            -36.96841498319127,
            0.24113635128153335,
            -0.07441037908422492,
            0.44972182064877153,
            0,
            -7.562075277591283,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Vintage filter (thanks Dominic Szablewski)
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.vintage = function(multiply) {
        var matrix = [
            0.6279345635605994,
            0.3202183420819367,
            -0.03965408211312453,
            0,
            9.651285835294123,
            0.02578397704808868,
            0.6441188644374771,
            0.03259127616149294,
            0,
            7.462829176470591,
            0.0466055556782719,
            -0.0851232987247891,
            0.5241648018700465,
            0,
            5.159190588235296,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * We don't know exactly what it does, kind of gradient map, but funny to play with!
     *
     * @param {number} desaturation - Tone values.
     * @param {number} toned - Tone values.
     * @param {number} lightColor - Tone values, example: `0xFFE580`
     * @param {number} darkColor - Tone values, example: `0xFFE580`
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.colorTone = function(desaturation, toned, lightColor, darkColor, multiply) {
        desaturation = desaturation || 0.2;
        toned = toned || 0.15;
        lightColor = lightColor || 16770432;
        darkColor = darkColor || 3375104;
        var lR = (lightColor >> 16 & 255) / 255;
        var lG = (lightColor >> 8 & 255) / 255;
        var lB = (lightColor & 255) / 255;
        var dR = (darkColor >> 16 & 255) / 255;
        var dG = (darkColor >> 8 & 255) / 255;
        var dB = (darkColor & 255) / 255;
        var matrix = [
            0.3,
            0.59,
            0.11,
            0,
            0,
            lR,
            lG,
            lB,
            desaturation,
            0,
            dR,
            dG,
            dB,
            toned,
            0,
            lR - dR,
            lG - dG,
            lB - dB,
            0,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Night effect
     *
     * @param {number} intensity - The intensity of the night effect.
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.night = function(intensity, multiply) {
        intensity = intensity || 0.1;
        var matrix = [
            intensity * -2,
            -intensity,
            0,
            0,
            0,
            -intensity,
            0,
            intensity,
            0,
            0,
            0,
            intensity,
            intensity * 2,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Predator effect
     *
     * Erase the current matrix by setting a new indepent one
     *
     * @param {number} amount - how much the predator feels his future victim
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.predator = function(amount, multiply) {
        var matrix = [
            // row 1
            11.224130630493164 * amount,
            -4.794486999511719 * amount,
            -2.8746118545532227 * amount,
            0 * amount,
            0.40342438220977783 * amount,
            // row 2
            -3.6330697536468506 * amount,
            9.193157196044922 * amount,
            -2.951810836791992 * amount,
            0 * amount,
            -1.316135048866272 * amount,
            // row 3
            -3.2184197902679443 * amount,
            -4.2375030517578125 * amount,
            7.476448059082031 * amount,
            0 * amount,
            0.8044459223747253 * amount,
            // row 4
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * LSD effect
     *
     * Multiply the current matrix
     *
     * @param {boolean} multiply - if true, current matrix and matrix are multiplied. If false,
     *  just set the current matrix with @param matrix
     */ ColorMatrixFilter2.prototype.lsd = function(multiply) {
        var matrix = [
            2,
            -0.4,
            0.5,
            0,
            0,
            -0.5,
            2,
            -0.4,
            0,
            0,
            -0.4,
            -0.5,
            3,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, multiply);
    };
    /**
     * Erase the current matrix by setting the default one
     *
     */ ColorMatrixFilter2.prototype.reset = function() {
        var matrix = [
            1,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            1,
            0,
            0,
            0,
            0,
            0,
            1,
            0
        ];
        this._loadMatrix(matrix, false);
    };
    Object.defineProperty(ColorMatrixFilter2.prototype, "matrix", {
        /**
         * The matrix of the color matrix filter
         *
         * @member {number[]}
         * @default [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]
         */ get: function() {
            return this.uniforms.m;
        },
        set: function(value) {
            this.uniforms.m = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(ColorMatrixFilter2.prototype, "alpha", {
        /**
         * The opacity value to use when mixing the original and resultant colors.
         *
         * When the value is 0, the original color is used without modification.
         * When the value is 1, the result color is used.
         * When in the range (0, 1) the color is interpolated between the original and result by this amount.
         *
         * @member {number}
         * @default 1
         */ get: function() {
            return this.uniforms.uAlpha;
        },
        set: function(value) {
            this.uniforms.uAlpha = value;
        },
        enumerable: false,
        configurable: true
    });
    return ColorMatrixFilter2;
}(_core.Filter);
// Americanized alias
ColorMatrixFilter1.prototype.grayscale = ColorMatrixFilter1.prototype.greyscale;

},{"@pixi/core":"d0INm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eENq5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "DisplacementFilter", ()=>DisplacementFilter1
);
/*!
 * @pixi/filter-displacement - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/filter-displacement is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
var _math = require("@pixi/math");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var fragment = "varying vec2 vFilterCoord;\nvarying vec2 vTextureCoord;\n\nuniform vec2 scale;\nuniform mat2 rotation;\nuniform sampler2D uSampler;\nuniform sampler2D mapSampler;\n\nuniform highp vec4 inputSize;\nuniform vec4 inputClamp;\n\nvoid main(void)\n{\n  vec4 map =  texture2D(mapSampler, vFilterCoord);\n\n  map -= 0.5;\n  map.xy = scale * inputSize.zw * (rotation * map.xy);\n\n  gl_FragColor = texture2D(uSampler, clamp(vec2(vTextureCoord.x + map.x, vTextureCoord.y + map.y), inputClamp.xy, inputClamp.zw));\n}\n";
var vertex = "attribute vec2 aVertexPosition;\n\nuniform mat3 projectionMatrix;\nuniform mat3 filterMatrix;\n\nvarying vec2 vTextureCoord;\nvarying vec2 vFilterCoord;\n\nuniform vec4 inputSize;\nuniform vec4 outputFrame;\n\nvec4 filterVertexPosition( void )\n{\n    vec2 position = aVertexPosition * max(outputFrame.zw, vec2(0.)) + outputFrame.xy;\n\n    return vec4((projectionMatrix * vec3(position, 1.0)).xy, 0.0, 1.0);\n}\n\nvec2 filterTextureCoord( void )\n{\n    return aVertexPosition * (outputFrame.zw * inputSize.zw);\n}\n\nvoid main(void)\n{\n\tgl_Position = filterVertexPosition();\n\tvTextureCoord = filterTextureCoord();\n\tvFilterCoord = ( filterMatrix * vec3( vTextureCoord, 1.0)  ).xy;\n}\n";
/**
 * The DisplacementFilter class uses the pixel values from the specified texture
 * (called the displacement map) to perform a displacement of an object.
 *
 * You can use this filter to apply all manor of crazy warping effects.
 * Currently the `r` property of the texture is used to offset the `x`
 * and the `g` property of the texture is used to offset the `y`.
 *
 * The way it works is it uses the values of the displacement map to look up the
 * correct pixels to output. This means it's not technically moving the original.
 * Instead, it's starting at the output and asking "which pixel from the original goes here".
 * For example, if a displacement map pixel has `red = 1` and the filter scale is `20`,
 * this filter will output the pixel approximately 20 pixels to the right of the original.
 *
 * @class
 * @extends PIXI.Filter
 * @memberof PIXI.filters
 */ var DisplacementFilter1 = function(_super) {
    __extends(DisplacementFilter2, _super);
    /**
     * @param {PIXI.Sprite} sprite - The sprite used for the displacement map. (make sure its added to the scene!)
     * @param {number} [scale] - The scale of the displacement
     */ function DisplacementFilter2(sprite, scale) {
        var _this = this;
        var maskMatrix = new _math.Matrix();
        sprite.renderable = false;
        _this = _super.call(this, vertex, fragment, {
            mapSampler: sprite._texture,
            filterMatrix: maskMatrix,
            scale: {
                x: 1,
                y: 1
            },
            rotation: new Float32Array([
                1,
                0,
                0,
                1
            ])
        }) || this;
        _this.maskSprite = sprite;
        _this.maskMatrix = maskMatrix;
        if (scale === null || scale === undefined) scale = 20;
        /**
         * scaleX, scaleY for displacements
         * @member {PIXI.Point}
         */ _this.scale = new _math.Point(scale, scale);
        return _this;
    }
    /**
     * Applies the filter.
     *
     * @param {PIXI.FilterSystem} filterManager - The manager.
     * @param {PIXI.RenderTexture} input - The input target.
     * @param {PIXI.RenderTexture} output - The output target.
     * @param {PIXI.CLEAR_MODES} clearMode - clearMode.
     */ DisplacementFilter2.prototype.apply = function(filterManager, input, output, clearMode) {
        // fill maskMatrix with _normalized sprite texture coords_
        this.uniforms.filterMatrix = filterManager.calculateSpriteMatrix(this.maskMatrix, this.maskSprite);
        this.uniforms.scale.x = this.scale.x;
        this.uniforms.scale.y = this.scale.y;
        // Extract rotation from world transform
        var wt = this.maskSprite.worldTransform;
        var lenX = Math.sqrt(wt.a * wt.a + wt.b * wt.b);
        var lenY = Math.sqrt(wt.c * wt.c + wt.d * wt.d);
        if (lenX !== 0 && lenY !== 0) {
            this.uniforms.rotation[0] = wt.a / lenX;
            this.uniforms.rotation[1] = wt.b / lenX;
            this.uniforms.rotation[2] = wt.c / lenY;
            this.uniforms.rotation[3] = wt.d / lenY;
        }
        // draw the filter...
        filterManager.applyFilter(this, input, output, clearMode);
    };
    Object.defineProperty(DisplacementFilter2.prototype, "map", {
        /**
         * The texture used for the displacement map. Must be power of 2 sized texture.
         *
         * @member {PIXI.Texture}
         */ get: function() {
            return this.uniforms.mapSampler;
        },
        set: function(value) {
            this.uniforms.mapSampler = value;
        },
        enumerable: false,
        configurable: true
    });
    return DisplacementFilter2;
}(_core.Filter);

},{"@pixi/core":"d0INm","@pixi/math":"1qR3C","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5UHC7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "FXAAFilter", ()=>FXAAFilter1
);
/*!
 * @pixi/filter-fxaa - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/filter-fxaa is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var vertex = "\nattribute vec2 aVertexPosition;\n\nuniform mat3 projectionMatrix;\n\nvarying vec2 v_rgbNW;\nvarying vec2 v_rgbNE;\nvarying vec2 v_rgbSW;\nvarying vec2 v_rgbSE;\nvarying vec2 v_rgbM;\n\nvarying vec2 vFragCoord;\n\nuniform vec4 inputSize;\nuniform vec4 outputFrame;\n\nvec4 filterVertexPosition( void )\n{\n    vec2 position = aVertexPosition * max(outputFrame.zw, vec2(0.)) + outputFrame.xy;\n\n    return vec4((projectionMatrix * vec3(position, 1.0)).xy, 0.0, 1.0);\n}\n\nvoid texcoords(vec2 fragCoord, vec2 inverseVP,\n               out vec2 v_rgbNW, out vec2 v_rgbNE,\n               out vec2 v_rgbSW, out vec2 v_rgbSE,\n               out vec2 v_rgbM) {\n    v_rgbNW = (fragCoord + vec2(-1.0, -1.0)) * inverseVP;\n    v_rgbNE = (fragCoord + vec2(1.0, -1.0)) * inverseVP;\n    v_rgbSW = (fragCoord + vec2(-1.0, 1.0)) * inverseVP;\n    v_rgbSE = (fragCoord + vec2(1.0, 1.0)) * inverseVP;\n    v_rgbM = vec2(fragCoord * inverseVP);\n}\n\nvoid main(void) {\n\n   gl_Position = filterVertexPosition();\n\n   vFragCoord = aVertexPosition * outputFrame.zw;\n\n   texcoords(vFragCoord, inputSize.zw, v_rgbNW, v_rgbNE, v_rgbSW, v_rgbSE, v_rgbM);\n}\n";
var fragment = "varying vec2 v_rgbNW;\nvarying vec2 v_rgbNE;\nvarying vec2 v_rgbSW;\nvarying vec2 v_rgbSE;\nvarying vec2 v_rgbM;\n\nvarying vec2 vFragCoord;\nuniform sampler2D uSampler;\nuniform highp vec4 inputSize;\n\n\n/**\n Basic FXAA implementation based on the code on geeks3d.com with the\n modification that the texture2DLod stuff was removed since it's\n unsupported by WebGL.\n\n --\n\n From:\n https://github.com/mitsuhiko/webgl-meincraft\n\n Copyright (c) 2011 by Armin Ronacher.\n\n Some rights reserved.\n\n Redistribution and use in source and binary forms, with or without\n modification, are permitted provided that the following conditions are\n met:\n\n * Redistributions of source code must retain the above copyright\n notice, this list of conditions and the following disclaimer.\n\n * Redistributions in binary form must reproduce the above\n copyright notice, this list of conditions and the following\n disclaimer in the documentation and/or other materials provided\n with the distribution.\n\n * The names of the contributors may not be used to endorse or\n promote products derived from this software without specific\n prior written permission.\n\n THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\n A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\n OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\n LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\n DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\n THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\n OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n */\n\n#ifndef FXAA_REDUCE_MIN\n#define FXAA_REDUCE_MIN   (1.0/ 128.0)\n#endif\n#ifndef FXAA_REDUCE_MUL\n#define FXAA_REDUCE_MUL   (1.0 / 8.0)\n#endif\n#ifndef FXAA_SPAN_MAX\n#define FXAA_SPAN_MAX     8.0\n#endif\n\n//optimized version for mobile, where dependent\n//texture reads can be a bottleneck\nvec4 fxaa(sampler2D tex, vec2 fragCoord, vec2 inverseVP,\n          vec2 v_rgbNW, vec2 v_rgbNE,\n          vec2 v_rgbSW, vec2 v_rgbSE,\n          vec2 v_rgbM) {\n    vec4 color;\n    vec3 rgbNW = texture2D(tex, v_rgbNW).xyz;\n    vec3 rgbNE = texture2D(tex, v_rgbNE).xyz;\n    vec3 rgbSW = texture2D(tex, v_rgbSW).xyz;\n    vec3 rgbSE = texture2D(tex, v_rgbSE).xyz;\n    vec4 texColor = texture2D(tex, v_rgbM);\n    vec3 rgbM  = texColor.xyz;\n    vec3 luma = vec3(0.299, 0.587, 0.114);\n    float lumaNW = dot(rgbNW, luma);\n    float lumaNE = dot(rgbNE, luma);\n    float lumaSW = dot(rgbSW, luma);\n    float lumaSE = dot(rgbSE, luma);\n    float lumaM  = dot(rgbM,  luma);\n    float lumaMin = min(lumaM, min(min(lumaNW, lumaNE), min(lumaSW, lumaSE)));\n    float lumaMax = max(lumaM, max(max(lumaNW, lumaNE), max(lumaSW, lumaSE)));\n\n    mediump vec2 dir;\n    dir.x = -((lumaNW + lumaNE) - (lumaSW + lumaSE));\n    dir.y =  ((lumaNW + lumaSW) - (lumaNE + lumaSE));\n\n    float dirReduce = max((lumaNW + lumaNE + lumaSW + lumaSE) *\n                          (0.25 * FXAA_REDUCE_MUL), FXAA_REDUCE_MIN);\n\n    float rcpDirMin = 1.0 / (min(abs(dir.x), abs(dir.y)) + dirReduce);\n    dir = min(vec2(FXAA_SPAN_MAX, FXAA_SPAN_MAX),\n              max(vec2(-FXAA_SPAN_MAX, -FXAA_SPAN_MAX),\n                  dir * rcpDirMin)) * inverseVP;\n\n    vec3 rgbA = 0.5 * (\n                       texture2D(tex, fragCoord * inverseVP + dir * (1.0 / 3.0 - 0.5)).xyz +\n                       texture2D(tex, fragCoord * inverseVP + dir * (2.0 / 3.0 - 0.5)).xyz);\n    vec3 rgbB = rgbA * 0.5 + 0.25 * (\n                                     texture2D(tex, fragCoord * inverseVP + dir * -0.5).xyz +\n                                     texture2D(tex, fragCoord * inverseVP + dir * 0.5).xyz);\n\n    float lumaB = dot(rgbB, luma);\n    if ((lumaB < lumaMin) || (lumaB > lumaMax))\n        color = vec4(rgbA, texColor.a);\n    else\n        color = vec4(rgbB, texColor.a);\n    return color;\n}\n\nvoid main() {\n\n      vec4 color;\n\n      color = fxaa(uSampler, vFragCoord, inputSize.zw, v_rgbNW, v_rgbNE, v_rgbSW, v_rgbSE, v_rgbM);\n\n      gl_FragColor = color;\n}\n";
/**
 * Basic FXAA (Fast Approximate Anti-Aliasing) implementation based on the code on geeks3d.com
 * with the modification that the texture2DLod stuff was removed since it is unsupported by WebGL.
 *
 * @see https://github.com/mitsuhiko/webgl-meincraft
 *
 * @class
 * @extends PIXI.Filter
 * @memberof PIXI.filters
 *
 */ var FXAAFilter1 = function(_super) {
    __extends(FXAAFilter2, _super);
    function FXAAFilter2() {
        // TODO - needs work
        return _super.call(this, vertex, fragment) || this;
    }
    return FXAAFilter2;
}(_core.Filter);

},{"@pixi/core":"d0INm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fRToZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "NoiseFilter", ()=>NoiseFilter1
);
/*!
 * @pixi/filter-noise - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/filter-noise is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var fragment = "precision highp float;\n\nvarying vec2 vTextureCoord;\nvarying vec4 vColor;\n\nuniform float uNoise;\nuniform float uSeed;\nuniform sampler2D uSampler;\n\nfloat rand(vec2 co)\n{\n    return fract(sin(dot(co.xy, vec2(12.9898, 78.233))) * 43758.5453);\n}\n\nvoid main()\n{\n    vec4 color = texture2D(uSampler, vTextureCoord);\n    float randomValue = rand(gl_FragCoord.xy * uSeed);\n    float diff = (randomValue - 0.5) * uNoise;\n\n    // Un-premultiply alpha before applying the color matrix. See issue #3539.\n    if (color.a > 0.0) {\n        color.rgb /= color.a;\n    }\n\n    color.r += diff;\n    color.g += diff;\n    color.b += diff;\n\n    // Premultiply alpha again.\n    color.rgb *= color.a;\n\n    gl_FragColor = color;\n}\n";
/**
 * A Noise effect filter.
 *
 * original filter: https://github.com/evanw/glfx.js/blob/master/src/filters/adjust/noise.js
 *
 * @class
 * @extends PIXI.Filter
 * @memberof PIXI.filters
 * @author Vico @vicocotea
 */ var NoiseFilter1 = function(_super) {
    __extends(NoiseFilter2, _super);
    /**
     * @param {number} [noise=0.5] - The noise intensity, should be a normalized value in the range [0, 1].
     * @param {number} [seed] - A random seed for the noise generation. Default is `Math.random()`.
     */ function NoiseFilter2(noise, seed) {
        if (noise === void 0) noise = 0.5;
        if (seed === void 0) seed = Math.random();
        var _this = _super.call(this, _core.defaultFilterVertex, fragment, {
            uNoise: 0,
            uSeed: 0
        }) || this;
        _this.noise = noise;
        _this.seed = seed;
        return _this;
    }
    Object.defineProperty(NoiseFilter2.prototype, "noise", {
        /**
         * The amount of noise to apply, this value should be in the range (0, 1].
         *
         * @member {number}
         * @default 0.5
         */ get: function() {
            return this.uniforms.uNoise;
        },
        set: function(value) {
            this.uniforms.uNoise = value;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(NoiseFilter2.prototype, "seed", {
        /**
         * A seed value to apply to the random noise generation. `Math.random()` is a good value to use.
         *
         * @member {number}
         */ get: function() {
            return this.uniforms.uSeed;
        },
        set: function(value) {
            this.uniforms.uSeed = value;
        },
        enumerable: false,
        configurable: true
    });
    return NoiseFilter2;
}(_core.Filter);

},{"@pixi/core":"d0INm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fYfiT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "CacheData", ()=>CacheData
);
/*!
 * @pixi/mixin-cache-as-bitmap - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/mixin-cache-as-bitmap is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
var _sprite = require("@pixi/sprite");
var _display = require("@pixi/display");
var _math = require("@pixi/math");
var _utils = require("@pixi/utils");
var _settings = require("@pixi/settings");
/*!
 * @pixi/constants - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/constants is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ /**
 * Different types of environments for WebGL.
 *
 * @static
 * @memberof PIXI
 * @name ENV
 * @enum {number}
 * @property {number} WEBGL_LEGACY - Used for older v1 WebGL devices. PixiJS will aim to ensure compatibility
 *  with older / less advanced devices. If you experience unexplained flickering prefer this environment.
 * @property {number} WEBGL - Version 1 of WebGL
 * @property {number} WEBGL2 - Version 2 of WebGL
 */ var ENV;
(function(ENV1) {
    ENV1[ENV1["WEBGL_LEGACY"] = 0] = "WEBGL_LEGACY";
    ENV1[ENV1["WEBGL"] = 1] = "WEBGL";
    ENV1[ENV1["WEBGL2"] = 2] = "WEBGL2";
})(ENV || (ENV = {
}));
/**
 * Constant to identify the Renderer Type.
 *
 * @static
 * @memberof PIXI
 * @name RENDERER_TYPE
 * @enum {number}
 * @property {number} UNKNOWN - Unknown render type.
 * @property {number} WEBGL - WebGL render type.
 * @property {number} CANVAS - Canvas render type.
 */ var RENDERER_TYPE;
(function(RENDERER_TYPE1) {
    RENDERER_TYPE1[RENDERER_TYPE1["UNKNOWN"] = 0] = "UNKNOWN";
    RENDERER_TYPE1[RENDERER_TYPE1["WEBGL"] = 1] = "WEBGL";
    RENDERER_TYPE1[RENDERER_TYPE1["CANVAS"] = 2] = "CANVAS";
})(RENDERER_TYPE || (RENDERER_TYPE = {
}));
/**
 * Bitwise OR of masks that indicate the buffers to be cleared.
 *
 * @static
 * @memberof PIXI
 * @name BUFFER_BITS
 * @enum {number}
 * @property {number} COLOR - Indicates the buffers currently enabled for color writing.
 * @property {number} DEPTH - Indicates the depth buffer.
 * @property {number} STENCIL - Indicates the stencil buffer.
 */ var BUFFER_BITS;
(function(BUFFER_BITS1) {
    BUFFER_BITS1[BUFFER_BITS1["COLOR"] = 16384] = "COLOR";
    BUFFER_BITS1[BUFFER_BITS1["DEPTH"] = 256] = "DEPTH";
    BUFFER_BITS1[BUFFER_BITS1["STENCIL"] = 1024] = "STENCIL";
})(BUFFER_BITS || (BUFFER_BITS = {
}));
/**
 * Various blend modes supported by PIXI.
 *
 * IMPORTANT - The WebGL renderer only supports the NORMAL, ADD, MULTIPLY and SCREEN blend modes.
 * Anything else will silently act like NORMAL.
 *
 * @memberof PIXI
 * @name BLEND_MODES
 * @enum {number}
 * @property {number} NORMAL
 * @property {number} ADD
 * @property {number} MULTIPLY
 * @property {number} SCREEN
 * @property {number} OVERLAY
 * @property {number} DARKEN
 * @property {number} LIGHTEN
 * @property {number} COLOR_DODGE
 * @property {number} COLOR_BURN
 * @property {number} HARD_LIGHT
 * @property {number} SOFT_LIGHT
 * @property {number} DIFFERENCE
 * @property {number} EXCLUSION
 * @property {number} HUE
 * @property {number} SATURATION
 * @property {number} COLOR
 * @property {number} LUMINOSITY
 * @property {number} NORMAL_NPM
 * @property {number} ADD_NPM
 * @property {number} SCREEN_NPM
 * @property {number} NONE
 * @property {number} SRC_IN
 * @property {number} SRC_OUT
 * @property {number} SRC_ATOP
 * @property {number} DST_OVER
 * @property {number} DST_IN
 * @property {number} DST_OUT
 * @property {number} DST_ATOP
 * @property {number} SUBTRACT
 * @property {number} SRC_OVER
 * @property {number} ERASE
 * @property {number} XOR
 */ var BLEND_MODES;
(function(BLEND_MODES1) {
    BLEND_MODES1[BLEND_MODES1["NORMAL"] = 0] = "NORMAL";
    BLEND_MODES1[BLEND_MODES1["ADD"] = 1] = "ADD";
    BLEND_MODES1[BLEND_MODES1["MULTIPLY"] = 2] = "MULTIPLY";
    BLEND_MODES1[BLEND_MODES1["SCREEN"] = 3] = "SCREEN";
    BLEND_MODES1[BLEND_MODES1["OVERLAY"] = 4] = "OVERLAY";
    BLEND_MODES1[BLEND_MODES1["DARKEN"] = 5] = "DARKEN";
    BLEND_MODES1[BLEND_MODES1["LIGHTEN"] = 6] = "LIGHTEN";
    BLEND_MODES1[BLEND_MODES1["COLOR_DODGE"] = 7] = "COLOR_DODGE";
    BLEND_MODES1[BLEND_MODES1["COLOR_BURN"] = 8] = "COLOR_BURN";
    BLEND_MODES1[BLEND_MODES1["HARD_LIGHT"] = 9] = "HARD_LIGHT";
    BLEND_MODES1[BLEND_MODES1["SOFT_LIGHT"] = 10] = "SOFT_LIGHT";
    BLEND_MODES1[BLEND_MODES1["DIFFERENCE"] = 11] = "DIFFERENCE";
    BLEND_MODES1[BLEND_MODES1["EXCLUSION"] = 12] = "EXCLUSION";
    BLEND_MODES1[BLEND_MODES1["HUE"] = 13] = "HUE";
    BLEND_MODES1[BLEND_MODES1["SATURATION"] = 14] = "SATURATION";
    BLEND_MODES1[BLEND_MODES1["COLOR"] = 15] = "COLOR";
    BLEND_MODES1[BLEND_MODES1["LUMINOSITY"] = 16] = "LUMINOSITY";
    BLEND_MODES1[BLEND_MODES1["NORMAL_NPM"] = 17] = "NORMAL_NPM";
    BLEND_MODES1[BLEND_MODES1["ADD_NPM"] = 18] = "ADD_NPM";
    BLEND_MODES1[BLEND_MODES1["SCREEN_NPM"] = 19] = "SCREEN_NPM";
    BLEND_MODES1[BLEND_MODES1["NONE"] = 20] = "NONE";
    BLEND_MODES1[BLEND_MODES1["SRC_OVER"] = 0] = "SRC_OVER";
    BLEND_MODES1[BLEND_MODES1["SRC_IN"] = 21] = "SRC_IN";
    BLEND_MODES1[BLEND_MODES1["SRC_OUT"] = 22] = "SRC_OUT";
    BLEND_MODES1[BLEND_MODES1["SRC_ATOP"] = 23] = "SRC_ATOP";
    BLEND_MODES1[BLEND_MODES1["DST_OVER"] = 24] = "DST_OVER";
    BLEND_MODES1[BLEND_MODES1["DST_IN"] = 25] = "DST_IN";
    BLEND_MODES1[BLEND_MODES1["DST_OUT"] = 26] = "DST_OUT";
    BLEND_MODES1[BLEND_MODES1["DST_ATOP"] = 27] = "DST_ATOP";
    BLEND_MODES1[BLEND_MODES1["ERASE"] = 26] = "ERASE";
    BLEND_MODES1[BLEND_MODES1["SUBTRACT"] = 28] = "SUBTRACT";
    BLEND_MODES1[BLEND_MODES1["XOR"] = 29] = "XOR";
})(BLEND_MODES || (BLEND_MODES = {
}));
/**
 * Various webgl draw modes. These can be used to specify which GL drawMode to use
 * under certain situations and renderers.
 *
 * @memberof PIXI
 * @static
 * @name DRAW_MODES
 * @enum {number}
 * @property {number} POINTS
 * @property {number} LINES
 * @property {number} LINE_LOOP
 * @property {number} LINE_STRIP
 * @property {number} TRIANGLES
 * @property {number} TRIANGLE_STRIP
 * @property {number} TRIANGLE_FAN
 */ var DRAW_MODES;
(function(DRAW_MODES1) {
    DRAW_MODES1[DRAW_MODES1["POINTS"] = 0] = "POINTS";
    DRAW_MODES1[DRAW_MODES1["LINES"] = 1] = "LINES";
    DRAW_MODES1[DRAW_MODES1["LINE_LOOP"] = 2] = "LINE_LOOP";
    DRAW_MODES1[DRAW_MODES1["LINE_STRIP"] = 3] = "LINE_STRIP";
    DRAW_MODES1[DRAW_MODES1["TRIANGLES"] = 4] = "TRIANGLES";
    DRAW_MODES1[DRAW_MODES1["TRIANGLE_STRIP"] = 5] = "TRIANGLE_STRIP";
    DRAW_MODES1[DRAW_MODES1["TRIANGLE_FAN"] = 6] = "TRIANGLE_FAN";
})(DRAW_MODES || (DRAW_MODES = {
}));
/**
 * Various GL texture/resources formats.
 *
 * @memberof PIXI
 * @static
 * @name FORMATS
 * @enum {number}
 * @property {number} RGBA=6408
 * @property {number} RGB=6407
 * @property {number} RG=33319
 * @property {number} RED=6403
 * @property {number} RGBA_INTEGER=36249
 * @property {number} RGB_INTEGER=36248
 * @property {number} RG_INTEGER=33320
 * @property {number} RED_INTEGER=36244
 * @property {number} ALPHA=6406
 * @property {number} LUMINANCE=6409
 * @property {number} LUMINANCE_ALPHA=6410
 * @property {number} DEPTH_COMPONENT=6402
 * @property {number} DEPTH_STENCIL=34041
 */ var FORMATS;
(function(FORMATS1) {
    FORMATS1[FORMATS1["RGBA"] = 6408] = "RGBA";
    FORMATS1[FORMATS1["RGB"] = 6407] = "RGB";
    FORMATS1[FORMATS1["RG"] = 33319] = "RG";
    FORMATS1[FORMATS1["RED"] = 6403] = "RED";
    FORMATS1[FORMATS1["RGBA_INTEGER"] = 36249] = "RGBA_INTEGER";
    FORMATS1[FORMATS1["RGB_INTEGER"] = 36248] = "RGB_INTEGER";
    FORMATS1[FORMATS1["RG_INTEGER"] = 33320] = "RG_INTEGER";
    FORMATS1[FORMATS1["RED_INTEGER"] = 36244] = "RED_INTEGER";
    FORMATS1[FORMATS1["ALPHA"] = 6406] = "ALPHA";
    FORMATS1[FORMATS1["LUMINANCE"] = 6409] = "LUMINANCE";
    FORMATS1[FORMATS1["LUMINANCE_ALPHA"] = 6410] = "LUMINANCE_ALPHA";
    FORMATS1[FORMATS1["DEPTH_COMPONENT"] = 6402] = "DEPTH_COMPONENT";
    FORMATS1[FORMATS1["DEPTH_STENCIL"] = 34041] = "DEPTH_STENCIL";
})(FORMATS || (FORMATS = {
}));
/**
 * Various GL target types.
 *
 * @memberof PIXI
 * @static
 * @name TARGETS
 * @enum {number}
 * @property {number} TEXTURE_2D=3553
 * @property {number} TEXTURE_CUBE_MAP=34067
 * @property {number} TEXTURE_2D_ARRAY=35866
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_X=34069
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_X=34070
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_Y=34071
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_Y=34072
 * @property {number} TEXTURE_CUBE_MAP_POSITIVE_Z=34073
 * @property {number} TEXTURE_CUBE_MAP_NEGATIVE_Z=34074
 */ var TARGETS;
(function(TARGETS1) {
    TARGETS1[TARGETS1["TEXTURE_2D"] = 3553] = "TEXTURE_2D";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP"] = 34067] = "TEXTURE_CUBE_MAP";
    TARGETS1[TARGETS1["TEXTURE_2D_ARRAY"] = 35866] = "TEXTURE_2D_ARRAY";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_X"] = 34069] = "TEXTURE_CUBE_MAP_POSITIVE_X";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_X"] = 34070] = "TEXTURE_CUBE_MAP_NEGATIVE_X";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_Y"] = 34071] = "TEXTURE_CUBE_MAP_POSITIVE_Y";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_Y"] = 34072] = "TEXTURE_CUBE_MAP_NEGATIVE_Y";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_POSITIVE_Z"] = 34073] = "TEXTURE_CUBE_MAP_POSITIVE_Z";
    TARGETS1[TARGETS1["TEXTURE_CUBE_MAP_NEGATIVE_Z"] = 34074] = "TEXTURE_CUBE_MAP_NEGATIVE_Z";
})(TARGETS || (TARGETS = {
}));
/**
 * Various GL data format types.
 *
 * @memberof PIXI
 * @static
 * @name TYPES
 * @enum {number}
 * @property {number} UNSIGNED_BYTE=5121
 * @property {number} UNSIGNED_SHORT=5123
 * @property {number} UNSIGNED_SHORT_5_6_5=33635
 * @property {number} UNSIGNED_SHORT_4_4_4_4=32819
 * @property {number} UNSIGNED_SHORT_5_5_5_1=32820
 * @property {number} UNSIGNED_INT=5125
 * @property {number} UNSIGNED_INT_10F_11F_11F_REV=35899
 * @property {number} UNSIGNED_INT_2_10_10_10_REV=33640
 * @property {number} UNSIGNED_INT_24_8=34042
 * @property {number} UNSIGNED_INT_5_9_9_9_REV=35902
 * @property {number} BYTE=5120
 * @property {number} SHORT=5122
 * @property {number} INT=5124
 * @property {number} FLOAT=5126
 * @property {number} FLOAT_32_UNSIGNED_INT_24_8_REV=36269
 * @property {number} HALF_FLOAT=36193
 */ var TYPES;
(function(TYPES1) {
    TYPES1[TYPES1["UNSIGNED_BYTE"] = 5121] = "UNSIGNED_BYTE";
    TYPES1[TYPES1["UNSIGNED_SHORT"] = 5123] = "UNSIGNED_SHORT";
    TYPES1[TYPES1["UNSIGNED_SHORT_5_6_5"] = 33635] = "UNSIGNED_SHORT_5_6_5";
    TYPES1[TYPES1["UNSIGNED_SHORT_4_4_4_4"] = 32819] = "UNSIGNED_SHORT_4_4_4_4";
    TYPES1[TYPES1["UNSIGNED_SHORT_5_5_5_1"] = 32820] = "UNSIGNED_SHORT_5_5_5_1";
    TYPES1[TYPES1["UNSIGNED_INT"] = 5125] = "UNSIGNED_INT";
    TYPES1[TYPES1["UNSIGNED_INT_10F_11F_11F_REV"] = 35899] = "UNSIGNED_INT_10F_11F_11F_REV";
    TYPES1[TYPES1["UNSIGNED_INT_2_10_10_10_REV"] = 33640] = "UNSIGNED_INT_2_10_10_10_REV";
    TYPES1[TYPES1["UNSIGNED_INT_24_8"] = 34042] = "UNSIGNED_INT_24_8";
    TYPES1[TYPES1["UNSIGNED_INT_5_9_9_9_REV"] = 35902] = "UNSIGNED_INT_5_9_9_9_REV";
    TYPES1[TYPES1["BYTE"] = 5120] = "BYTE";
    TYPES1[TYPES1["SHORT"] = 5122] = "SHORT";
    TYPES1[TYPES1["INT"] = 5124] = "INT";
    TYPES1[TYPES1["FLOAT"] = 5126] = "FLOAT";
    TYPES1[TYPES1["FLOAT_32_UNSIGNED_INT_24_8_REV"] = 36269] = "FLOAT_32_UNSIGNED_INT_24_8_REV";
    TYPES1[TYPES1["HALF_FLOAT"] = 36193] = "HALF_FLOAT";
})(TYPES || (TYPES = {
}));
/**
 * Various sampler types. Correspond to `sampler`, `isampler`, `usampler` GLSL types respectively.
 * WebGL1 works only with FLOAT.
 *
 * @memberof PIXI
 * @static
 * @name SAMPLER_TYPES
 * @enum {number}
 * @property {number} FLOAT=0
 * @property {number} INT=1
 * @property {number} UINT=2
 */ var SAMPLER_TYPES;
(function(SAMPLER_TYPES1) {
    SAMPLER_TYPES1[SAMPLER_TYPES1["FLOAT"] = 0] = "FLOAT";
    SAMPLER_TYPES1[SAMPLER_TYPES1["INT"] = 1] = "INT";
    SAMPLER_TYPES1[SAMPLER_TYPES1["UINT"] = 2] = "UINT";
})(SAMPLER_TYPES || (SAMPLER_TYPES = {
}));
/**
 * The scale modes that are supported by pixi.
 *
 * The {@link PIXI.settings.SCALE_MODE} scale mode affects the default scaling mode of future operations.
 * It can be re-assigned to either LINEAR or NEAREST, depending upon suitability.
 *
 * @memberof PIXI
 * @static
 * @name SCALE_MODES
 * @enum {number}
 * @property {number} LINEAR Smooth scaling
 * @property {number} NEAREST Pixelating scaling
 */ var SCALE_MODES;
(function(SCALE_MODES1) {
    SCALE_MODES1[SCALE_MODES1["NEAREST"] = 0] = "NEAREST";
    SCALE_MODES1[SCALE_MODES1["LINEAR"] = 1] = "LINEAR";
})(SCALE_MODES || (SCALE_MODES = {
}));
/**
 * The wrap modes that are supported by pixi.
 *
 * The {@link PIXI.settings.WRAP_MODE} wrap mode affects the default wrapping mode of future operations.
 * It can be re-assigned to either CLAMP or REPEAT, depending upon suitability.
 * If the texture is non power of two then clamp will be used regardless as WebGL can
 * only use REPEAT if the texture is po2.
 *
 * This property only affects WebGL.
 *
 * @name WRAP_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} CLAMP - The textures uvs are clamped
 * @property {number} REPEAT - The texture uvs tile and repeat
 * @property {number} MIRRORED_REPEAT - The texture uvs tile and repeat with mirroring
 */ var WRAP_MODES;
(function(WRAP_MODES1) {
    WRAP_MODES1[WRAP_MODES1["CLAMP"] = 33071] = "CLAMP";
    WRAP_MODES1[WRAP_MODES1["REPEAT"] = 10497] = "REPEAT";
    WRAP_MODES1[WRAP_MODES1["MIRRORED_REPEAT"] = 33648] = "MIRRORED_REPEAT";
})(WRAP_MODES || (WRAP_MODES = {
}));
/**
 * Mipmap filtering modes that are supported by pixi.
 *
 * The {@link PIXI.settings.MIPMAP_TEXTURES} affects default texture filtering.
 * Mipmaps are generated for a baseTexture if its `mipmap` field is `ON`,
 * or its `POW2` and texture dimensions are powers of 2.
 * Due to platform restriction, `ON` option will work like `POW2` for webgl-1.
 *
 * This property only affects WebGL.
 *
 * @name MIPMAP_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} OFF - No mipmaps
 * @property {number} POW2 - Generate mipmaps if texture dimensions are pow2
 * @property {number} ON - Always generate mipmaps
 * @property {number} ON_MANUAL - Use mipmaps, but do not auto-generate them; this is used with a resource
 *   that supports buffering each level-of-detail.
 */ var MIPMAP_MODES;
(function(MIPMAP_MODES1) {
    MIPMAP_MODES1[MIPMAP_MODES1["OFF"] = 0] = "OFF";
    MIPMAP_MODES1[MIPMAP_MODES1["POW2"] = 1] = "POW2";
    MIPMAP_MODES1[MIPMAP_MODES1["ON"] = 2] = "ON";
    MIPMAP_MODES1[MIPMAP_MODES1["ON_MANUAL"] = 3] = "ON_MANUAL";
})(MIPMAP_MODES || (MIPMAP_MODES = {
}));
/**
 * How to treat textures with premultiplied alpha
 *
 * @name ALPHA_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NO_PREMULTIPLIED_ALPHA - Source is not premultiplied, leave it like that.
 *  Option for compressed and data textures that are created from typed arrays.
 * @property {number} PREMULTIPLY_ON_UPLOAD - Source is not premultiplied, premultiply on upload.
 *  Default option, used for all loaded images.
 * @property {number} PREMULTIPLIED_ALPHA - Source is already premultiplied
 *  Example: spine atlases with `_pma` suffix.
 * @property {number} NPM - Alias for NO_PREMULTIPLIED_ALPHA.
 * @property {number} UNPACK - Default option, alias for PREMULTIPLY_ON_UPLOAD.
 * @property {number} PMA - Alias for PREMULTIPLIED_ALPHA.
 */ var ALPHA_MODES;
(function(ALPHA_MODES1) {
    ALPHA_MODES1[ALPHA_MODES1["NPM"] = 0] = "NPM";
    ALPHA_MODES1[ALPHA_MODES1["UNPACK"] = 1] = "UNPACK";
    ALPHA_MODES1[ALPHA_MODES1["PMA"] = 2] = "PMA";
    ALPHA_MODES1[ALPHA_MODES1["NO_PREMULTIPLIED_ALPHA"] = 0] = "NO_PREMULTIPLIED_ALPHA";
    ALPHA_MODES1[ALPHA_MODES1["PREMULTIPLY_ON_UPLOAD"] = 1] = "PREMULTIPLY_ON_UPLOAD";
    ALPHA_MODES1[ALPHA_MODES1["PREMULTIPLY_ALPHA"] = 2] = "PREMULTIPLY_ALPHA";
})(ALPHA_MODES || (ALPHA_MODES = {
}));
/**
 * Configure whether filter textures are cleared after binding.
 *
 * Filter textures need not be cleared if the filter does not use pixel blending. {@link CLEAR_MODES.BLIT} will detect
 * this and skip clearing as an optimization.
 *
 * @name CLEAR_MODES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} BLEND - Do not clear the filter texture. The filter's output will blend on top of the output texture.
 * @property {number} CLEAR - Always clear the filter texture.
 * @property {number} BLIT - Clear only if {@link FilterSystem.forceClear} is set or if the filter uses pixel blending.
 * @property {number} NO - Alias for BLEND, same as `false` in earlier versions
 * @property {number} YES - Alias for CLEAR, same as `true` in earlier versions
 * @property {number} AUTO - Alias for BLIT
 */ var CLEAR_MODES;
(function(CLEAR_MODES1) {
    CLEAR_MODES1[CLEAR_MODES1["NO"] = 0] = "NO";
    CLEAR_MODES1[CLEAR_MODES1["YES"] = 1] = "YES";
    CLEAR_MODES1[CLEAR_MODES1["AUTO"] = 2] = "AUTO";
    CLEAR_MODES1[CLEAR_MODES1["BLEND"] = 0] = "BLEND";
    CLEAR_MODES1[CLEAR_MODES1["CLEAR"] = 1] = "CLEAR";
    CLEAR_MODES1[CLEAR_MODES1["BLIT"] = 2] = "BLIT";
})(CLEAR_MODES || (CLEAR_MODES = {
}));
/**
 * The gc modes that are supported by pixi.
 *
 * The {@link PIXI.settings.GC_MODE} Garbage Collection mode for PixiJS textures is AUTO
 * If set to GC_MODE, the renderer will occasionally check textures usage. If they are not
 * used for a specified period of time they will be removed from the GPU. They will of course
 * be uploaded again when they are required. This is a silent behind the scenes process that
 * should ensure that the GPU does not  get filled up.
 *
 * Handy for mobile devices!
 * This property only affects WebGL.
 *
 * @name GC_MODES
 * @enum {number}
 * @static
 * @memberof PIXI
 * @property {number} AUTO - Garbage collection will happen periodically automatically
 * @property {number} MANUAL - Garbage collection will need to be called manually
 */ var GC_MODES;
(function(GC_MODES1) {
    GC_MODES1[GC_MODES1["AUTO"] = 0] = "AUTO";
    GC_MODES1[GC_MODES1["MANUAL"] = 1] = "MANUAL";
})(GC_MODES || (GC_MODES = {
}));
/**
 * Constants that specify float precision in shaders.
 *
 * @name PRECISION
 * @memberof PIXI
 * @constant
 * @static
 * @enum {string}
 * @property {string} LOW='lowp'
 * @property {string} MEDIUM='mediump'
 * @property {string} HIGH='highp'
 */ var PRECISION;
(function(PRECISION1) {
    PRECISION1["LOW"] = "lowp";
    PRECISION1["MEDIUM"] = "mediump";
    PRECISION1["HIGH"] = "highp";
})(PRECISION || (PRECISION = {
}));
/**
 * Constants for mask implementations.
 * We use `type` suffix because it leads to very different behaviours
 *
 * @name MASK_TYPES
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NONE - Mask is ignored
 * @property {number} SCISSOR - Scissor mask, rectangle on screen, cheap
 * @property {number} STENCIL - Stencil mask, 1-bit, medium, works only if renderer supports stencil
 * @property {number} SPRITE - Mask that uses SpriteMaskFilter, uses temporary RenderTexture
 */ var MASK_TYPES;
(function(MASK_TYPES1) {
    MASK_TYPES1[MASK_TYPES1["NONE"] = 0] = "NONE";
    MASK_TYPES1[MASK_TYPES1["SCISSOR"] = 1] = "SCISSOR";
    MASK_TYPES1[MASK_TYPES1["STENCIL"] = 2] = "STENCIL";
    MASK_TYPES1[MASK_TYPES1["SPRITE"] = 3] = "SPRITE";
})(MASK_TYPES || (MASK_TYPES = {
}));
/**
 * Constants for multi-sampling antialiasing.
 *
 * @see PIXI.Framebuffer#multisample
 *
 * @name MSAA_QUALITY
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} NONE - No multisampling for this renderTexture
 * @property {number} LOW - Try 2 samples
 * @property {number} MEDIUM - Try 4 samples
 * @property {number} HIGH - Try 8 samples
 */ var MSAA_QUALITY;
(function(MSAA_QUALITY1) {
    MSAA_QUALITY1[MSAA_QUALITY1["NONE"] = 0] = "NONE";
    MSAA_QUALITY1[MSAA_QUALITY1["LOW"] = 2] = "LOW";
    MSAA_QUALITY1[MSAA_QUALITY1["MEDIUM"] = 4] = "MEDIUM";
    MSAA_QUALITY1[MSAA_QUALITY1["HIGH"] = 8] = "HIGH";
})(MSAA_QUALITY || (MSAA_QUALITY = {
}));
/**
 * Constants for various buffer types in Pixi
 *
 * @see PIXI.BUFFER_TYPE
 *
 * @name BUFFER_TYPE
 * @memberof PIXI
 * @static
 * @enum {number}
 * @property {number} ELEMENT_ARRAY_BUFFER - buffer type for using as an index buffer
 * @property {number} ARRAY_BUFFER - buffer type for using attribute data
 * @property {number} UNIFORM_BUFFER - the buffer type is for uniform buffer objects
 */ var BUFFER_TYPE;
(function(BUFFER_TYPE1) {
    BUFFER_TYPE1[BUFFER_TYPE1["ELEMENT_ARRAY_BUFFER"] = 34963] = "ELEMENT_ARRAY_BUFFER";
    BUFFER_TYPE1[BUFFER_TYPE1["ARRAY_BUFFER"] = 34962] = "ARRAY_BUFFER";
    // NOT YET SUPPORTED
    BUFFER_TYPE1[BUFFER_TYPE1["UNIFORM_BUFFER"] = 35345] = "UNIFORM_BUFFER";
})(BUFFER_TYPE || (BUFFER_TYPE = {
}));
var _tempMatrix = new _math.Matrix();
_display.DisplayObject.prototype._cacheAsBitmap = false;
_display.DisplayObject.prototype._cacheData = null;
_display.DisplayObject.prototype._cacheAsBitmapResolution = null;
_display.DisplayObject.prototype._cacheAsBitmapMultisample = MSAA_QUALITY.NONE;
// figured there's no point adding ALL the extra variables to prototype.
// this model can hold the information needed. This can also be generated on demand as
// most objects are not cached as bitmaps.
/**
 * @class
 * @ignore
 * @private
 */ var CacheData = function() {
    function CacheData1() {
        this.textureCacheId = null;
        this.originalRender = null;
        this.originalRenderCanvas = null;
        this.originalCalculateBounds = null;
        this.originalGetLocalBounds = null;
        this.originalUpdateTransform = null;
        this.originalDestroy = null;
        this.originalMask = null;
        this.originalFilterArea = null;
        this.originalContainsPoint = null;
        this.sprite = null;
    }
    return CacheData1;
}();
Object.defineProperties(_display.DisplayObject.prototype, {
    /**
     * The resolution to use for cacheAsBitmap. By default this will use the renderer's resolution
     * but can be overriden for performance. Lower values will reduce memory usage at the expense
     * of render quality. A falsey value of `null` or `0` will default to the renderer's resolution.
     * If `cacheAsBitmap` is set to `true`, this will re-render with the new resolution.
     *
     * @member {number} cacheAsBitmapResolution
     * @memberof PIXI.DisplayObject#
     * @default null
     */ cacheAsBitmapResolution: {
        get: function() {
            return this._cacheAsBitmapResolution;
        },
        set: function(resolution) {
            if (resolution === this._cacheAsBitmapResolution) return;
            this._cacheAsBitmapResolution = resolution;
            if (this.cacheAsBitmap) {
                // Toggle to re-render at the new resolution
                this.cacheAsBitmap = false;
                this.cacheAsBitmap = true;
            }
        }
    },
    /**
     * The number of samples to use for cacheAsBitmap. If set to `null`, the renderer's
     * sample count is used.
     * If `cacheAsBitmap` is set to `true`, this will re-render with the new number of samples.
     *
     * @member {number} cacheAsBitmapMultisample
     * @memberof PIXI.DisplayObject#
     * @default PIXI.MSAA_QUALITY.NONE
     */ cacheAsBitmapMultisample: {
        get: function() {
            return this._cacheAsBitmapMultisample;
        },
        set: function(multisample) {
            if (multisample === this._cacheAsBitmapMultisample) return;
            this._cacheAsBitmapMultisample = multisample;
            if (this.cacheAsBitmap) {
                // Toggle to re-render with new multisample
                this.cacheAsBitmap = false;
                this.cacheAsBitmap = true;
            }
        }
    },
    /**
     * Set this to true if you want this display object to be cached as a bitmap.
     * This basically takes a snap shot of the display object as it is at that moment. It can
     * provide a performance benefit for complex static displayObjects.
     * To remove simply set this property to `false`
     *
     * IMPORTANT GOTCHA - Make sure that all your textures are preloaded BEFORE setting this property to true
     * as it will take a snapshot of what is currently there. If the textures have not loaded then they will not appear.
     *
     * @member {boolean}
     * @memberof PIXI.DisplayObject#
     */ cacheAsBitmap: {
        get: function() {
            return this._cacheAsBitmap;
        },
        set: function(value) {
            if (this._cacheAsBitmap === value) return;
            this._cacheAsBitmap = value;
            var data;
            if (value) {
                if (!this._cacheData) this._cacheData = new CacheData();
                data = this._cacheData;
                data.originalRender = this.render;
                data.originalRenderCanvas = this.renderCanvas;
                data.originalUpdateTransform = this.updateTransform;
                data.originalCalculateBounds = this.calculateBounds;
                data.originalGetLocalBounds = this.getLocalBounds;
                data.originalDestroy = this.destroy;
                data.originalContainsPoint = this.containsPoint;
                data.originalMask = this._mask;
                data.originalFilterArea = this.filterArea;
                this.render = this._renderCached;
                this.renderCanvas = this._renderCachedCanvas;
                this.destroy = this._cacheAsBitmapDestroy;
            } else {
                data = this._cacheData;
                if (data.sprite) this._destroyCachedDisplayObject();
                this.render = data.originalRender;
                this.renderCanvas = data.originalRenderCanvas;
                this.calculateBounds = data.originalCalculateBounds;
                this.getLocalBounds = data.originalGetLocalBounds;
                this.destroy = data.originalDestroy;
                this.updateTransform = data.originalUpdateTransform;
                this.containsPoint = data.originalContainsPoint;
                this._mask = data.originalMask;
                this.filterArea = data.originalFilterArea;
            }
        }
    }
});
/**
 * Renders a cached version of the sprite with WebGL
 *
 * @private
 * @method _renderCached
 * @memberof PIXI.DisplayObject#
 * @param {PIXI.Renderer} renderer - the WebGL renderer
 */ _display.DisplayObject.prototype._renderCached = function _renderCached(renderer) {
    if (!this.visible || this.worldAlpha <= 0 || !this.renderable) return;
    this._initCachedDisplayObject(renderer);
    this._cacheData.sprite.transform._worldID = this.transform._worldID;
    this._cacheData.sprite.worldAlpha = this.worldAlpha;
    this._cacheData.sprite._render(renderer);
};
/**
 * Prepares the WebGL renderer to cache the sprite
 *
 * @private
 * @method _initCachedDisplayObject
 * @memberof PIXI.DisplayObject#
 * @param {PIXI.Renderer} renderer - the WebGL renderer
 */ _display.DisplayObject.prototype._initCachedDisplayObject = function _initCachedDisplayObject(renderer) {
    var _a;
    if (this._cacheData && this._cacheData.sprite) return;
    // make sure alpha is set to 1 otherwise it will get rendered as invisible!
    var cacheAlpha = this.alpha;
    this.alpha = 1;
    // first we flush anything left in the renderer (otherwise it would get rendered to the cached texture)
    renderer.batch.flush();
    // this.filters= [];
    // next we find the dimensions of the untransformed object
    // this function also calls updatetransform on all its children as part of the measuring.
    // This means we don't need to update the transform again in this function
    // TODO pass an object to clone too? saves having to create a new one each time!
    var bounds = this.getLocalBounds(null, true).clone();
    // add some padding!
    if (this.filters) {
        var padding = this.filters[0].padding;
        bounds.pad(padding);
    }
    bounds.ceil(_settings.settings.RESOLUTION);
    // for now we cache the current renderTarget that the WebGL renderer is currently using.
    // this could be more elegant..
    var cachedRenderTexture = renderer.renderTexture.current;
    var cachedSourceFrame = renderer.renderTexture.sourceFrame.clone();
    var cachedDestinationFrame = renderer.renderTexture.destinationFrame.clone();
    var cachedProjectionTransform = renderer.projection.transform;
    // We also store the filter stack - I will definitely look to change how this works a little later down the line.
    // const stack = renderer.filterManager.filterStack;
    // this renderTexture will be used to store the cached DisplayObject
    var renderTexture = _core.RenderTexture.create({
        width: bounds.width,
        height: bounds.height,
        resolution: this.cacheAsBitmapResolution || renderer.resolution,
        multisample: (_a = this.cacheAsBitmapMultisample) !== null && _a !== void 0 ? _a : renderer.multisample
    });
    var textureCacheId = "cacheAsBitmap_" + _utils.uid();
    this._cacheData.textureCacheId = textureCacheId;
    _core.BaseTexture.addToCache(renderTexture.baseTexture, textureCacheId);
    _core.Texture.addToCache(renderTexture, textureCacheId);
    // need to set //
    var m = this.transform.localTransform.copyTo(_tempMatrix).invert().translate(-bounds.x, -bounds.y);
    // set all properties to there original so we can render to a texture
    this.render = this._cacheData.originalRender;
    renderer.render(this, {
        renderTexture: renderTexture,
        clear: true,
        transform: m,
        skipUpdateTransform: false
    });
    renderer.framebuffer.blit();
    // now restore the state be setting the new properties
    renderer.projection.transform = cachedProjectionTransform;
    renderer.renderTexture.bind(cachedRenderTexture, cachedSourceFrame, cachedDestinationFrame);
    // renderer.filterManager.filterStack = stack;
    this.render = this._renderCached;
    // the rest is the same as for Canvas
    this.updateTransform = this.displayObjectUpdateTransform;
    this.calculateBounds = this._calculateCachedBounds;
    this.getLocalBounds = this._getCachedLocalBounds;
    this._mask = null;
    this.filterArea = null;
    this.alpha = cacheAlpha;
    // create our cached sprite
    var cachedSprite = new _sprite.Sprite(renderTexture);
    cachedSprite.transform.worldTransform = this.transform.worldTransform;
    cachedSprite.anchor.x = -(bounds.x / bounds.width);
    cachedSprite.anchor.y = -(bounds.y / bounds.height);
    cachedSprite.alpha = cacheAlpha;
    cachedSprite._bounds = this._bounds;
    this._cacheData.sprite = cachedSprite;
    this.transform._parentID = -1;
    // restore the transform of the cached sprite to avoid the nasty flicker..
    if (!this.parent) {
        this.enableTempParent();
        this.updateTransform();
        this.disableTempParent(null);
    } else this.updateTransform();
    // map the hit test..
    this.containsPoint = cachedSprite.containsPoint.bind(cachedSprite);
};
/**
 * Renders a cached version of the sprite with canvas
 *
 * @private
 * @method _renderCachedCanvas
 * @memberof PIXI.DisplayObject#
 * @param {PIXI.CanvasRenderer} renderer - The canvas renderer
 */ _display.DisplayObject.prototype._renderCachedCanvas = function _renderCachedCanvas(renderer) {
    if (!this.visible || this.worldAlpha <= 0 || !this.renderable) return;
    this._initCachedDisplayObjectCanvas(renderer);
    this._cacheData.sprite.worldAlpha = this.worldAlpha;
    this._cacheData.sprite._renderCanvas(renderer);
};
// TODO this can be the same as the WebGL version.. will need to do a little tweaking first though..
/**
 * Prepares the Canvas renderer to cache the sprite
 *
 * @private
 * @method _initCachedDisplayObjectCanvas
 * @memberof PIXI.DisplayObject#
 * @param {PIXI.CanvasRenderer} renderer - The canvas renderer
 */ _display.DisplayObject.prototype._initCachedDisplayObjectCanvas = function _initCachedDisplayObjectCanvas(renderer) {
    if (this._cacheData && this._cacheData.sprite) return;
    // get bounds actually transforms the object for us already!
    var bounds = this.getLocalBounds(null, true);
    var cacheAlpha = this.alpha;
    this.alpha = 1;
    var cachedRenderTarget = renderer.context;
    var cachedProjectionTransform = renderer._projTransform;
    bounds.ceil(_settings.settings.RESOLUTION);
    var renderTexture = _core.RenderTexture.create({
        width: bounds.width,
        height: bounds.height
    });
    var textureCacheId = "cacheAsBitmap_" + _utils.uid();
    this._cacheData.textureCacheId = textureCacheId;
    _core.BaseTexture.addToCache(renderTexture.baseTexture, textureCacheId);
    _core.Texture.addToCache(renderTexture, textureCacheId);
    // need to set //
    var m = _tempMatrix;
    this.transform.localTransform.copyTo(m);
    m.invert();
    m.tx -= bounds.x;
    m.ty -= bounds.y;
    // m.append(this.transform.worldTransform.)
    // set all properties to there original so we can render to a texture
    this.renderCanvas = this._cacheData.originalRenderCanvas;
    renderer.render(this, {
        renderTexture: renderTexture,
        clear: true,
        transform: m,
        skipUpdateTransform: false
    });
    // now restore the state be setting the new properties
    renderer.context = cachedRenderTarget;
    renderer._projTransform = cachedProjectionTransform;
    this.renderCanvas = this._renderCachedCanvas;
    // the rest is the same as for WebGL
    this.updateTransform = this.displayObjectUpdateTransform;
    this.calculateBounds = this._calculateCachedBounds;
    this.getLocalBounds = this._getCachedLocalBounds;
    this._mask = null;
    this.filterArea = null;
    this.alpha = cacheAlpha;
    // create our cached sprite
    var cachedSprite = new _sprite.Sprite(renderTexture);
    cachedSprite.transform.worldTransform = this.transform.worldTransform;
    cachedSprite.anchor.x = -(bounds.x / bounds.width);
    cachedSprite.anchor.y = -(bounds.y / bounds.height);
    cachedSprite.alpha = cacheAlpha;
    cachedSprite._bounds = this._bounds;
    this._cacheData.sprite = cachedSprite;
    this.transform._parentID = -1;
    // restore the transform of the cached sprite to avoid the nasty flicker..
    if (!this.parent) {
        this.parent = renderer._tempDisplayObjectParent;
        this.updateTransform();
        this.parent = null;
    } else this.updateTransform();
    // map the hit test..
    this.containsPoint = cachedSprite.containsPoint.bind(cachedSprite);
};
/**
 * Calculates the bounds of the cached sprite
 *
 * @private
 * @method
 */ _display.DisplayObject.prototype._calculateCachedBounds = function _calculateCachedBounds() {
    this._bounds.clear();
    this._cacheData.sprite.transform._worldID = this.transform._worldID;
    this._cacheData.sprite._calculateBounds();
    this._bounds.updateID = this._boundsID;
};
/**
 * Gets the bounds of the cached sprite.
 *
 * @private
 * @method
 * @return {Rectangle} The local bounds.
 */ _display.DisplayObject.prototype._getCachedLocalBounds = function _getCachedLocalBounds() {
    return this._cacheData.sprite.getLocalBounds(null);
};
/**
 * Destroys the cached sprite.
 *
 * @private
 * @method
 */ _display.DisplayObject.prototype._destroyCachedDisplayObject = function _destroyCachedDisplayObject() {
    this._cacheData.sprite._texture.destroy(true);
    this._cacheData.sprite = null;
    _core.BaseTexture.removeFromCache(this._cacheData.textureCacheId);
    _core.Texture.removeFromCache(this._cacheData.textureCacheId);
    this._cacheData.textureCacheId = null;
};
/**
 * Destroys the cached object.
 *
 * @private
 * @method
 * @param {object|boolean} [options] - Options parameter. A boolean will act as if all options
 *  have been set to that value.
 *  Used when destroying containers, see the Container.destroy method.
 */ _display.DisplayObject.prototype._cacheAsBitmapDestroy = function _cacheAsBitmapDestroy(options) {
    this.cacheAsBitmap = false;
    this.destroy(options);
};

},{"@pixi/core":"d0INm","@pixi/sprite":"aeiZG","@pixi/display":"hQqz5","@pixi/math":"1qR3C","@pixi/utils":"joR65","@pixi/settings":"habh9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1wORs":[function(require,module,exports) {
/*!
 * @pixi/mixin-get-child-by-name - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/mixin-get-child-by-name is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _display = require("@pixi/display");
/**
 * The instance name of the object.
 *
 * @memberof PIXI.DisplayObject#
 * @member {string} name
 */ _display.DisplayObject.prototype.name = null;
/**
 * Returns the display object in the container.
 *
 * Recursive searches are done in a preorder traversal.
 *
 * @method getChildByName
 * @memberof PIXI.Container#
 * @param {string} name - Instance name.
 * @param {boolean}[deep=false] - Whether to search recursively
 * @return {PIXI.DisplayObject} The child with the specified name.
 */ _display.Container.prototype.getChildByName = function getChildByName(name, deep) {
    for(var i = 0, j = this.children.length; i < j; i++){
        if (this.children[i].name === name) return this.children[i];
    }
    if (deep) for(var i = 0, j = this.children.length; i < j; i++){
        var child = this.children[i];
        if (!child.getChildByName) continue;
        var target = this.children[i].getChildByName(name, true);
        if (target) return target;
    }
    return null;
};

},{"@pixi/display":"hQqz5"}],"4IZbg":[function(require,module,exports) {
/*!
 * @pixi/mixin-get-global-position - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/mixin-get-global-position is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _display = require("@pixi/display");
var _math = require("@pixi/math");
/**
 * Returns the global position of the displayObject. Does not depend on object scale, rotation and pivot.
 *
 * @method getGlobalPosition
 * @memberof PIXI.DisplayObject#
 * @param {PIXI.Point} [point=new PIXI.Point()] - The point to write the global value to.
 * @param {boolean} [skipUpdate=false] - Setting to true will stop the transforms of the scene graph from
 *  being updated. This means the calculation returned MAY be out of date BUT will give you a
 *  nice performance boost.
 * @return {PIXI.Point} The updated point.
 */ _display.DisplayObject.prototype.getGlobalPosition = function getGlobalPosition(point, skipUpdate) {
    if (point === void 0) point = new _math.Point();
    if (skipUpdate === void 0) skipUpdate = false;
    if (this.parent) this.parent.toGlobal(this.position, point, skipUpdate);
    else {
        point.x = this.position.x;
        point.y = this.position.y;
    }
    return point;
};

},{"@pixi/display":"hQqz5","@pixi/math":"1qR3C"}],"dJlOc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "NineSlicePlane", ()=>NineSlicePlane1
);
parcelHelpers.export(exports, "PlaneGeometry", ()=>PlaneGeometry1
);
parcelHelpers.export(exports, "RopeGeometry", ()=>RopeGeometry1
);
parcelHelpers.export(exports, "SimpleMesh", ()=>SimpleMesh1
);
parcelHelpers.export(exports, "SimplePlane", ()=>SimplePlane1
);
parcelHelpers.export(exports, "SimpleRope", ()=>SimpleRope1
);
/*!
 * @pixi/mesh-extras - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/mesh-extras is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _mesh = require("@pixi/mesh");
var _constants = require("@pixi/constants");
var _core = require("@pixi/core");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * @memberof PIXI
 */ var PlaneGeometry1 = function(_super) {
    __extends(PlaneGeometry2, _super);
    /**
     * @param width - The width of the plane.
     * @param height - The height of the plane.
     * @param segWidth - Number of horizontal segments.
     * @param segHeight - Number of vertical segments.
     */ function PlaneGeometry2(width, height, segWidth, segHeight) {
        if (width === void 0) width = 100;
        if (height === void 0) height = 100;
        if (segWidth === void 0) segWidth = 10;
        if (segHeight === void 0) segHeight = 10;
        var _this = _super.call(this) || this;
        _this.segWidth = segWidth;
        _this.segHeight = segHeight;
        _this.width = width;
        _this.height = height;
        _this.build();
        return _this;
    }
    /**
     * Refreshes plane coordinates
     * @private
     */ PlaneGeometry2.prototype.build = function() {
        var total = this.segWidth * this.segHeight;
        var verts = [];
        var uvs = [];
        var indices = [];
        var segmentsX = this.segWidth - 1;
        var segmentsY = this.segHeight - 1;
        var sizeX = this.width / segmentsX;
        var sizeY = this.height / segmentsY;
        for(var i = 0; i < total; i++){
            var x = i % this.segWidth;
            var y = i / this.segWidth | 0;
            verts.push(x * sizeX, y * sizeY);
            uvs.push(x / segmentsX, y / segmentsY);
        }
        var totalSub = segmentsX * segmentsY;
        for(var i = 0; i < totalSub; i++){
            var xpos = i % segmentsX;
            var ypos = i / segmentsX | 0;
            var value = ypos * this.segWidth + xpos;
            var value2 = ypos * this.segWidth + xpos + 1;
            var value3 = (ypos + 1) * this.segWidth + xpos;
            var value4 = (ypos + 1) * this.segWidth + xpos + 1;
            indices.push(value, value2, value3, value2, value4, value3);
        }
        this.buffers[0].data = new Float32Array(verts);
        this.buffers[1].data = new Float32Array(uvs);
        this.indexBuffer.data = new Uint16Array(indices);
        // ensure that the changes are uploaded
        this.buffers[0].update();
        this.buffers[1].update();
        this.indexBuffer.update();
    };
    return PlaneGeometry2;
}(_mesh.MeshGeometry);
/**
 * RopeGeometry allows you to draw a geometry across several points and then manipulate these points.
 *
 * ```js
 * for (let i = 0; i < 20; i++) {
 *     points.push(new PIXI.Point(i * 50, 0));
 * };
 * const rope = new PIXI.RopeGeometry(100, points);
 * ```
 *
 * @class
 * @extends PIXI.MeshGeometry
 * @memberof PIXI
 *
 */ var RopeGeometry1 = function(_super) {
    __extends(RopeGeometry2, _super);
    /**
     * @param {number} [width=200] - The width (i.e., thickness) of the rope.
     * @param {PIXI.Point[]} [points] - An array of {@link PIXI.Point} objects to construct this rope.
     * @param {number} [textureScale=0] - By default the rope texture will be stretched to match
     *     rope length. If textureScale is positive this value will be treated as a scaling
     *     factor and the texture will preserve its aspect ratio instead. To create a tiling rope
     *     set baseTexture.wrapMode to {@link PIXI.WRAP_MODES.REPEAT} and use a power of two texture,
     *     then set textureScale=1 to keep the original texture pixel size.
     *     In order to reduce alpha channel artifacts provide a larger texture and downsample -
     *     i.e. set textureScale=0.5 to scale it down twice.
     */ function RopeGeometry2(width, points, textureScale) {
        if (width === void 0) width = 200;
        if (textureScale === void 0) textureScale = 0;
        var _this = _super.call(this, new Float32Array(points.length * 4), new Float32Array(points.length * 4), new Uint16Array((points.length - 1) * 6)) || this;
        /**
         * An array of points that determine the rope
         * @member {PIXI.Point[]}
         */ _this.points = points;
        /**
         * The width (i.e., thickness) of the rope.
         * @member {number}
         * @readOnly
         */ _this._width = width;
        /**
         * Rope texture scale, if zero then the rope texture is stretched.
         * @member {number}
         * @readOnly
         */ _this.textureScale = textureScale;
        _this.build();
        return _this;
    }
    Object.defineProperty(RopeGeometry2.prototype, "width", {
        /**
         * The width (i.e., thickness) of the rope.
         * @member {number}
         * @readOnly
         */ get: function() {
            return this._width;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Refreshes Rope indices and uvs
     * @private
     */ RopeGeometry2.prototype.build = function() {
        var points = this.points;
        if (!points) return;
        var vertexBuffer = this.getBuffer('aVertexPosition');
        var uvBuffer = this.getBuffer('aTextureCoord');
        var indexBuffer = this.getIndex();
        // if too little points, or texture hasn't got UVs set yet just move on.
        if (points.length < 1) return;
        // if the number of points has changed we will need to recreate the arraybuffers
        if (vertexBuffer.data.length / 4 !== points.length) {
            vertexBuffer.data = new Float32Array(points.length * 4);
            uvBuffer.data = new Float32Array(points.length * 4);
            indexBuffer.data = new Uint16Array((points.length - 1) * 6);
        }
        var uvs = uvBuffer.data;
        var indices = indexBuffer.data;
        uvs[0] = 0;
        uvs[1] = 0;
        uvs[2] = 0;
        uvs[3] = 1;
        var amount = 0;
        var prev = points[0];
        var textureWidth = this._width * this.textureScale;
        var total = points.length; // - 1;
        for(var i = 0; i < total; i++){
            // time to do some smart drawing!
            var index = i * 4;
            if (this.textureScale > 0) {
                // calculate pixel distance from previous point
                var dx = prev.x - points[i].x;
                var dy = prev.y - points[i].y;
                var distance = Math.sqrt(dx * dx + dy * dy);
                prev = points[i];
                amount += distance / textureWidth;
            } else // stretch texture
            amount = i / (total - 1);
            uvs[index] = amount;
            uvs[index + 1] = 0;
            uvs[index + 2] = amount;
            uvs[index + 3] = 1;
        }
        var indexCount = 0;
        for(var i = 0; i < total - 1; i++){
            var index = i * 2;
            indices[indexCount++] = index;
            indices[indexCount++] = index + 1;
            indices[indexCount++] = index + 2;
            indices[indexCount++] = index + 2;
            indices[indexCount++] = index + 1;
            indices[indexCount++] = index + 3;
        }
        // ensure that the changes are uploaded
        uvBuffer.update();
        indexBuffer.update();
        this.updateVertices();
    };
    /**
     * refreshes vertices of Rope mesh
     */ RopeGeometry2.prototype.updateVertices = function() {
        var points = this.points;
        if (points.length < 1) return;
        var lastPoint = points[0];
        var nextPoint;
        var perpX = 0;
        var perpY = 0;
        var vertices = this.buffers[0].data;
        var total = points.length;
        for(var i = 0; i < total; i++){
            var point = points[i];
            var index = i * 4;
            if (i < points.length - 1) nextPoint = points[i + 1];
            else nextPoint = point;
            perpY = -(nextPoint.x - lastPoint.x);
            perpX = nextPoint.y - lastPoint.y;
            var perpLength = Math.sqrt(perpX * perpX + perpY * perpY);
            var num = this.textureScale > 0 ? this.textureScale * this._width / 2 : this._width / 2;
            perpX /= perpLength;
            perpY /= perpLength;
            perpX *= num;
            perpY *= num;
            vertices[index] = point.x + perpX;
            vertices[index + 1] = point.y + perpY;
            vertices[index + 2] = point.x - perpX;
            vertices[index + 3] = point.y - perpY;
            lastPoint = point;
        }
        this.buffers[0].update();
    };
    RopeGeometry2.prototype.update = function() {
        if (this.textureScale > 0) this.build(); // we need to update UVs
        else this.updateVertices();
    };
    return RopeGeometry2;
}(_mesh.MeshGeometry);
/**
 * The rope allows you to draw a texture across several points and then manipulate these points
 *
 *```js
 * for (let i = 0; i < 20; i++) {
 *     points.push(new PIXI.Point(i * 50, 0));
 * };
 * let rope = new PIXI.SimpleRope(PIXI.Texture.from("snake.png"), points);
 *  ```
 *
 * @class
 * @extends PIXI.Mesh
 * @memberof PIXI
 *
 */ var SimpleRope1 = function(_super) {
    __extends(SimpleRope2, _super);
    /**
     * @param {PIXI.Texture} texture - The texture to use on the rope.
     * @param {PIXI.Point[]} points - An array of {@link PIXI.Point} objects to construct this rope.
     * @param {number} [textureScale=0] - Optional. Positive values scale rope texture
     * keeping its aspect ratio. You can reduce alpha channel artifacts by providing a larger texture
     * and downsampling here. If set to zero, texture will be stretched instead.
     */ function SimpleRope2(texture, points, textureScale) {
        if (textureScale === void 0) textureScale = 0;
        var _this = this;
        var ropeGeometry = new RopeGeometry1(texture.height, points, textureScale);
        var meshMaterial = new _mesh.MeshMaterial(texture);
        if (textureScale > 0) // attempt to set UV wrapping, will fail on non-power of two textures
        texture.baseTexture.wrapMode = _constants.WRAP_MODES.REPEAT;
        _this = _super.call(this, ropeGeometry, meshMaterial) || this;
        /**
         * re-calculate vertices by rope points each frame
         *
         * @member {boolean}
         */ _this.autoUpdate = true;
        return _this;
    }
    SimpleRope2.prototype._render = function(renderer) {
        var geometry = this.geometry;
        if (this.autoUpdate || geometry._width !== this.shader.texture.height) {
            geometry._width = this.shader.texture.height;
            geometry.update();
        }
        _super.prototype._render.call(this, renderer);
    };
    return SimpleRope2;
}(_mesh.Mesh);
/**
 * The SimplePlane allows you to draw a texture across several points and then manipulate these points
 *
 *```js
 * for (let i = 0; i < 20; i++) {
 *     points.push(new PIXI.Point(i * 50, 0));
 * };
 * let SimplePlane = new PIXI.SimplePlane(PIXI.Texture.from("snake.png"), points);
 *  ```
 *
 * @class
 * @extends PIXI.Mesh
 * @memberof PIXI
 *
 */ var SimplePlane1 = function(_super) {
    __extends(SimplePlane2, _super);
    /**
     * @param {PIXI.Texture} texture - The texture to use on the SimplePlane.
     * @param {number} verticesX - The number of vertices in the x-axis
     * @param {number} verticesY - The number of vertices in the y-axis
     */ function SimplePlane2(texture, verticesX, verticesY) {
        var _this = this;
        var planeGeometry = new PlaneGeometry1(texture.width, texture.height, verticesX, verticesY);
        var meshMaterial = new _mesh.MeshMaterial(_core.Texture.WHITE);
        _this = _super.call(this, planeGeometry, meshMaterial) || this;
        // lets call the setter to ensure all necessary updates are performed
        _this.texture = texture;
        _this.autoResize = true;
        return _this;
    }
    /**
     * Method used for overrides, to do something in case texture frame was changed.
     * Meshes based on plane can override it and change more details based on texture.
     */ SimplePlane2.prototype.textureUpdated = function() {
        this._textureID = this.shader.texture._updateID;
        var geometry = this.geometry;
        var _a = this.shader.texture, width = _a.width, height = _a.height;
        if (this.autoResize && (geometry.width !== width || geometry.height !== height)) {
            geometry.width = this.shader.texture.width;
            geometry.height = this.shader.texture.height;
            geometry.build();
        }
    };
    Object.defineProperty(SimplePlane2.prototype, "texture", {
        get: function() {
            return this.shader.texture;
        },
        set: function(value) {
            // Track texture same way sprite does.
            // For generated meshes like NineSlicePlane it can change the geometry.
            // Unfortunately, this method might not work if you directly change texture in material.
            if (this.shader.texture === value) return;
            this.shader.texture = value;
            this._textureID = -1;
            if (value.baseTexture.valid) this.textureUpdated();
            else value.once('update', this.textureUpdated, this);
        },
        enumerable: false,
        configurable: true
    });
    SimplePlane2.prototype._render = function(renderer) {
        if (this._textureID !== this.shader.texture._updateID) this.textureUpdated();
        _super.prototype._render.call(this, renderer);
    };
    SimplePlane2.prototype.destroy = function(options) {
        this.shader.texture.off('update', this.textureUpdated, this);
        _super.prototype.destroy.call(this, options);
    };
    return SimplePlane2;
}(_mesh.Mesh);
/**
 * The Simple Mesh class mimics Mesh in PixiJS v4, providing easy-to-use constructor arguments.
 * For more robust customization, use {@link PIXI.Mesh}.
 *
 * @class
 * @extends PIXI.Mesh
 * @memberof PIXI
 */ var SimpleMesh1 = function(_super) {
    __extends(SimpleMesh2, _super);
    /**
     * @param {PIXI.Texture} [texture=Texture.EMPTY] - The texture to use
     * @param {Float32Array} [vertices] - if you want to specify the vertices
     * @param {Float32Array} [uvs] - if you want to specify the uvs
     * @param {Uint16Array} [indices] - if you want to specify the indices
     * @param {number} [drawMode] - the drawMode, can be any of the Mesh.DRAW_MODES consts
     */ function SimpleMesh2(texture, vertices, uvs, indices, drawMode) {
        if (texture === void 0) texture = _core.Texture.EMPTY;
        var _this = this;
        var geometry = new _mesh.MeshGeometry(vertices, uvs, indices);
        geometry.getBuffer('aVertexPosition').static = false;
        var meshMaterial = new _mesh.MeshMaterial(texture);
        _this = _super.call(this, geometry, meshMaterial, null, drawMode) || this;
        /**
         * upload vertices buffer each frame
         * @member {boolean}
         */ _this.autoUpdate = true;
        return _this;
    }
    Object.defineProperty(SimpleMesh2.prototype, "vertices", {
        /**
         * Collection of vertices data.
         * @member {Float32Array}
         */ get: function() {
            return this.geometry.getBuffer('aVertexPosition').data;
        },
        set: function(value) {
            this.geometry.getBuffer('aVertexPosition').data = value;
        },
        enumerable: false,
        configurable: true
    });
    SimpleMesh2.prototype._render = function(renderer) {
        if (this.autoUpdate) this.geometry.getBuffer('aVertexPosition').update();
        _super.prototype._render.call(this, renderer);
    };
    return SimpleMesh2;
}(_mesh.Mesh);
var DEFAULT_BORDER_SIZE = 10;
/**
 * The NineSlicePlane allows you to stretch a texture using 9-slice scaling. The corners will remain unscaled (useful
 * for buttons with rounded corners for example) and the other areas will be scaled horizontally and or vertically
 *
 *```js
 * let Plane9 = new PIXI.NineSlicePlane(PIXI.Texture.from('BoxWithRoundedCorners.png'), 15, 15, 15, 15);
 *  ```
 * <pre>
 *      A                          B
 *    +---+----------------------+---+
 *  C | 1 |          2           | 3 |
 *    +---+----------------------+---+
 *    |   |                      |   |
 *    | 4 |          5           | 6 |
 *    |   |                      |   |
 *    +---+----------------------+---+
 *  D | 7 |          8           | 9 |
 *    +---+----------------------+---+

 *  When changing this objects width and/or height:
 *     areas 1 3 7 and 9 will remain unscaled.
 *     areas 2 and 8 will be stretched horizontally
 *     areas 4 and 6 will be stretched vertically
 *     area 5 will be stretched both horizontally and vertically
 * </pre>
 *
 * @class
 * @extends PIXI.SimplePlane
 * @memberof PIXI
 *
 */ var NineSlicePlane1 = function(_super) {
    __extends(NineSlicePlane2, _super);
    /**
     * @param {PIXI.Texture} texture - The texture to use on the NineSlicePlane.
     * @param {number} [leftWidth=10] - size of the left vertical bar (A)
     * @param {number} [topHeight=10] - size of the top horizontal bar (C)
     * @param {number} [rightWidth=10] - size of the right vertical bar (B)
     * @param {number} [bottomHeight=10] - size of the bottom horizontal bar (D)
     */ function NineSlicePlane2(texture, leftWidth, topHeight, rightWidth, bottomHeight) {
        if (leftWidth === void 0) leftWidth = DEFAULT_BORDER_SIZE;
        if (topHeight === void 0) topHeight = DEFAULT_BORDER_SIZE;
        if (rightWidth === void 0) rightWidth = DEFAULT_BORDER_SIZE;
        if (bottomHeight === void 0) bottomHeight = DEFAULT_BORDER_SIZE;
        var _this = _super.call(this, _core.Texture.WHITE, 4, 4) || this;
        _this._origWidth = texture.orig.width;
        _this._origHeight = texture.orig.height;
        /**
         * The width of the NineSlicePlane, setting this will actually modify the vertices and UV's of this plane
         *
         * @member {number}
         * @override
         */ _this._width = _this._origWidth;
        /**
         * The height of the NineSlicePlane, setting this will actually modify the vertices and UV's of this plane
         *
         * @member {number}
         * @override
         */ _this._height = _this._origHeight;
        /**
         * The width of the left column (a)
         *
         * @member {number}
         * @private
         */ _this._leftWidth = leftWidth;
        /**
         * The width of the right column (b)
         *
         * @member {number}
         * @private
         */ _this._rightWidth = rightWidth;
        /**
         * The height of the top row (c)
         *
         * @member {number}
         * @private
         */ _this._topHeight = topHeight;
        /**
         * The height of the bottom row (d)
         *
         * @member {number}
         * @private
         */ _this._bottomHeight = bottomHeight;
        // lets call the setter to ensure all necessary updates are performed
        _this.texture = texture;
        return _this;
    }
    NineSlicePlane2.prototype.textureUpdated = function() {
        this._textureID = this.shader.texture._updateID;
        this._refresh();
    };
    Object.defineProperty(NineSlicePlane2.prototype, "vertices", {
        get: function() {
            return this.geometry.getBuffer('aVertexPosition').data;
        },
        set: function(value) {
            this.geometry.getBuffer('aVertexPosition').data = value;
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Updates the horizontal vertices.
     *
     */ NineSlicePlane2.prototype.updateHorizontalVertices = function() {
        var vertices = this.vertices;
        var scale = this._getMinScale();
        vertices[9] = vertices[11] = vertices[13] = vertices[15] = this._topHeight * scale;
        vertices[17] = vertices[19] = vertices[21] = vertices[23] = this._height - this._bottomHeight * scale;
        vertices[25] = vertices[27] = vertices[29] = vertices[31] = this._height;
    };
    /**
     * Updates the vertical vertices.
     *
     */ NineSlicePlane2.prototype.updateVerticalVertices = function() {
        var vertices = this.vertices;
        var scale = this._getMinScale();
        vertices[2] = vertices[10] = vertices[18] = vertices[26] = this._leftWidth * scale;
        vertices[4] = vertices[12] = vertices[20] = vertices[28] = this._width - this._rightWidth * scale;
        vertices[6] = vertices[14] = vertices[22] = vertices[30] = this._width;
    };
    /**
     * Returns the smaller of a set of vertical and horizontal scale of nine slice corners.
     *
     * @return {number} Smaller number of vertical and horizontal scale.
     * @private
     */ NineSlicePlane2.prototype._getMinScale = function() {
        var w = this._leftWidth + this._rightWidth;
        var scaleW = this._width > w ? 1 : this._width / w;
        var h = this._topHeight + this._bottomHeight;
        var scaleH = this._height > h ? 1 : this._height / h;
        var scale = Math.min(scaleW, scaleH);
        return scale;
    };
    Object.defineProperty(NineSlicePlane2.prototype, "width", {
        /**
         * The width of the NineSlicePlane, setting this will actually modify the vertices and UV's of this plane
         *
         * @member {number}
         */ get: function() {
            return this._width;
        },
        set: function(value) {
            this._width = value;
            this._refresh();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(NineSlicePlane2.prototype, "height", {
        /**
         * The height of the NineSlicePlane, setting this will actually modify the vertices and UV's of this plane
         *
         * @member {number}
         */ get: function() {
            return this._height;
        },
        set: function(value) {
            this._height = value;
            this._refresh();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(NineSlicePlane2.prototype, "leftWidth", {
        /**
         * The width of the left column
         *
         * @member {number}
         */ get: function() {
            return this._leftWidth;
        },
        set: function(value) {
            this._leftWidth = value;
            this._refresh();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(NineSlicePlane2.prototype, "rightWidth", {
        /**
         * The width of the right column
         *
         * @member {number}
         */ get: function() {
            return this._rightWidth;
        },
        set: function(value) {
            this._rightWidth = value;
            this._refresh();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(NineSlicePlane2.prototype, "topHeight", {
        /**
         * The height of the top row
         *
         * @member {number}
         */ get: function() {
            return this._topHeight;
        },
        set: function(value) {
            this._topHeight = value;
            this._refresh();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(NineSlicePlane2.prototype, "bottomHeight", {
        /**
         * The height of the bottom row
         *
         * @member {number}
         */ get: function() {
            return this._bottomHeight;
        },
        set: function(value) {
            this._bottomHeight = value;
            this._refresh();
        },
        enumerable: false,
        configurable: true
    });
    /**
     * Refreshes NineSlicePlane coords. All of them.
     */ NineSlicePlane2.prototype._refresh = function() {
        var texture = this.texture;
        var uvs = this.geometry.buffers[1].data;
        this._origWidth = texture.orig.width;
        this._origHeight = texture.orig.height;
        var _uvw = 1 / this._origWidth;
        var _uvh = 1 / this._origHeight;
        uvs[0] = uvs[8] = uvs[16] = uvs[24] = 0;
        uvs[1] = uvs[3] = uvs[5] = uvs[7] = 0;
        uvs[6] = uvs[14] = uvs[22] = uvs[30] = 1;
        uvs[25] = uvs[27] = uvs[29] = uvs[31] = 1;
        uvs[2] = uvs[10] = uvs[18] = uvs[26] = _uvw * this._leftWidth;
        uvs[4] = uvs[12] = uvs[20] = uvs[28] = 1 - _uvw * this._rightWidth;
        uvs[9] = uvs[11] = uvs[13] = uvs[15] = _uvh * this._topHeight;
        uvs[17] = uvs[19] = uvs[21] = uvs[23] = 1 - _uvh * this._bottomHeight;
        this.updateHorizontalVertices();
        this.updateVerticalVertices();
        this.geometry.buffers[0].update();
        this.geometry.buffers[1].update();
    };
    return NineSlicePlane2;
}(SimplePlane1);

},{"@pixi/mesh":"a96bk","@pixi/constants":"lqjFh","@pixi/core":"d0INm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3JjHI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * @memberof PIXI.AnimatedSprite
 * @typedef {object} FrameObject
 * @type {object}
 * @property {PIXI.Texture} texture - The {@link PIXI.Texture} of the frame
 * @property {number} time - the duration of the frame in ms
 */ parcelHelpers.export(exports, "AnimatedSprite", ()=>AnimatedSprite1
);
/*!
 * @pixi/sprite-animated - v6.1.3
 * Compiled Mon, 13 Sep 2021 15:29:31 UTC
 *
 * @pixi/sprite-animated is licensed under the MIT License.
 * http://www.opensource.org/licenses/mit-license
 */ var _core = require("@pixi/core");
var _sprite = require("@pixi/sprite");
var _ticker = require("@pixi/ticker");
/*! *****************************************************************************
Copyright (c) Microsoft Corporation. All rights reserved.
Licensed under the Apache License, Version 2.0 (the "License"); you may not use
this file except in compliance with the License. You may obtain a copy of the
License at http://www.apache.org/licenses/LICENSE-2.0

THIS CODE IS PROVIDED ON AN *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
MERCHANTABLITY OR NON-INFRINGEMENT.

See the Apache Version 2.0 License for specific language governing permissions
and limitations under the License.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (b1.hasOwnProperty(p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
/**
 * An AnimatedSprite is a simple way to display an animation depicted by a list of textures.
 *
 * ```js
 * let alienImages = ["image_sequence_01.png","image_sequence_02.png","image_sequence_03.png","image_sequence_04.png"];
 * let textureArray = [];
 *
 * for (let i=0; i < 4; i++)
 * {
 *      let texture = PIXI.Texture.from(alienImages[i]);
 *      textureArray.push(texture);
 * };
 *
 * let animatedSprite = new PIXI.AnimatedSprite(textureArray);
 * ```
 *
 * The more efficient and simpler way to create an animated sprite is using a {@link PIXI.Spritesheet}
 * containing the animation definitions:
 *
 * ```js
 * PIXI.Loader.shared.add("assets/spritesheet.json").load(setup);
 *
 * function setup() {
 *   let sheet = PIXI.Loader.shared.resources["assets/spritesheet.json"].spritesheet;
 *   animatedSprite = new PIXI.AnimatedSprite(sheet.animations["image_sequence"]);
 *   ...
 * }
 * ```
 *
 * @class
 * @extends PIXI.Sprite
 * @memberof PIXI
 */ var AnimatedSprite1 = function(_super) {
    __extends(AnimatedSprite2, _super);
    /**
     * @param {PIXI.Texture[]|PIXI.AnimatedSprite.FrameObject[]} textures - An array of {@link PIXI.Texture} or frame
     *  objects that make up the animation.
     * @param {boolean} [autoUpdate=true] - Whether to use PIXI.Ticker.shared to auto update animation time.
     */ function AnimatedSprite2(textures, autoUpdate) {
        if (autoUpdate === void 0) autoUpdate = true;
        var _this = _super.call(this, textures[0] instanceof _core.Texture ? textures[0] : textures[0].texture) || this;
        /**
         * @type {PIXI.Texture[]}
         * @private
         */ _this._textures = null;
        /**
         * @type {number[]}
         * @private
         */ _this._durations = null;
        /**
         * `true` uses PIXI.Ticker.shared to auto update animation time.
         *
         * @type {boolean}
         * @default true
         * @private
         */ _this._autoUpdate = autoUpdate;
        /**
         * `true` if the instance is currently connected to PIXI.Ticker.shared to auto update animation time.
         *
         * @type {boolean}
         * @default false
         * @private
         */ _this._isConnectedToTicker = false;
        /**
         * The speed that the AnimatedSprite will play at. Higher is faster, lower is slower.
         *
         * @member {number}
         * @default 1
         */ _this.animationSpeed = 1;
        /**
         * Whether or not the animate sprite repeats after playing.
         *
         * @member {boolean}
         * @default true
         */ _this.loop = true;
        /**
         * Update anchor to [Texture's defaultAnchor]{@link PIXI.Texture#defaultAnchor} when frame changes.
         *
         * Useful with [sprite sheet animations]{@link PIXI.Spritesheet#animations} created with tools.
         * Changing anchor for each frame allows to pin sprite origin to certain moving feature
         * of the frame (e.g. left foot).
         *
         * Note: Enabling this will override any previously set `anchor` on each frame change.
         *
         * @member {boolean}
         * @default false
         */ _this.updateAnchor = false;
        /**
         * User-assigned function to call when an AnimatedSprite finishes playing.
         *
         * @example
         * animation.onComplete = function () {
         *   // finished!
         * };
         * @member {Function}
         */ _this.onComplete = null;
        /**
         * User-assigned function to call when an AnimatedSprite changes which texture is being rendered.
         *
         * @example
         * animation.onFrameChange = function () {
         *   // updated!
         * };
         * @member {Function}
         */ _this.onFrameChange = null;
        /**
         * User-assigned function to call when `loop` is true, and an AnimatedSprite is played and
         * loops around to start again.
         *
         * @example
         * animation.onLoop = function () {
         *   // looped!
         * };
         * @member {Function}
         */ _this.onLoop = null;
        /**
         * Elapsed time since animation has been started, used internally to display current texture.
         *
         * @member {number}
         * @private
         */ _this._currentTime = 0;
        _this._playing = false;
        /**
         * The texture index that was displayed last time
         *
         * @member {number}
         * @private
         */ _this._previousFrame = null;
        _this.textures = textures;
        return _this;
    }
    /**
     * Stops the AnimatedSprite.
     *
     */ AnimatedSprite2.prototype.stop = function() {
        if (!this._playing) return;
        this._playing = false;
        if (this._autoUpdate && this._isConnectedToTicker) {
            _ticker.Ticker.shared.remove(this.update, this);
            this._isConnectedToTicker = false;
        }
    };
    /**
     * Plays the AnimatedSprite.
     *
     */ AnimatedSprite2.prototype.play = function() {
        if (this._playing) return;
        this._playing = true;
        if (this._autoUpdate && !this._isConnectedToTicker) {
            _ticker.Ticker.shared.add(this.update, this, _ticker.UPDATE_PRIORITY.HIGH);
            this._isConnectedToTicker = true;
        }
    };
    /**
     * Stops the AnimatedSprite and goes to a specific frame.
     *
     * @param {number} frameNumber - Frame index to stop at.
     */ AnimatedSprite2.prototype.gotoAndStop = function(frameNumber) {
        this.stop();
        var previousFrame = this.currentFrame;
        this._currentTime = frameNumber;
        if (previousFrame !== this.currentFrame) this.updateTexture();
    };
    /**
     * Goes to a specific frame and begins playing the AnimatedSprite.
     *
     * @param {number} frameNumber - Frame index to start at.
     */ AnimatedSprite2.prototype.gotoAndPlay = function(frameNumber) {
        var previousFrame = this.currentFrame;
        this._currentTime = frameNumber;
        if (previousFrame !== this.currentFrame) this.updateTexture();
        this.play();
    };
    /**
     * Updates the object transform for rendering.
     *
     * @param {number} deltaTime - Time since last tick.
     */ AnimatedSprite2.prototype.update = function(deltaTime) {
        if (!this._playing) return;
        var elapsed = this.animationSpeed * deltaTime;
        var previousFrame = this.currentFrame;
        if (this._durations !== null) {
            var lag = this._currentTime % 1 * this._durations[this.currentFrame];
            lag += elapsed / 60 * 1000;
            while(lag < 0){
                this._currentTime--;
                lag += this._durations[this.currentFrame];
            }
            var sign = Math.sign(this.animationSpeed * deltaTime);
            this._currentTime = Math.floor(this._currentTime);
            while(lag >= this._durations[this.currentFrame]){
                lag -= this._durations[this.currentFrame] * sign;
                this._currentTime += sign;
            }
            this._currentTime += lag / this._durations[this.currentFrame];
        } else this._currentTime += elapsed;
        if (this._currentTime < 0 && !this.loop) {
            this.gotoAndStop(0);
            if (this.onComplete) this.onComplete();
        } else if (this._currentTime >= this._textures.length && !this.loop) {
            this.gotoAndStop(this._textures.length - 1);
            if (this.onComplete) this.onComplete();
        } else if (previousFrame !== this.currentFrame) {
            if (this.loop && this.onLoop) {
                if (this.animationSpeed > 0 && this.currentFrame < previousFrame) this.onLoop();
                else if (this.animationSpeed < 0 && this.currentFrame > previousFrame) this.onLoop();
            }
            this.updateTexture();
        }
    };
    /**
     * Updates the displayed texture to match the current frame index.
     *
     * @private
     */ AnimatedSprite2.prototype.updateTexture = function() {
        var currentFrame = this.currentFrame;
        if (this._previousFrame === currentFrame) return;
        this._previousFrame = currentFrame;
        this._texture = this._textures[currentFrame];
        this._textureID = -1;
        this._textureTrimmedID = -1;
        this._cachedTint = 16777215;
        this.uvs = this._texture._uvs.uvsFloat32;
        if (this.updateAnchor) this._anchor.copyFrom(this._texture.defaultAnchor);
        if (this.onFrameChange) this.onFrameChange(this.currentFrame);
    };
    /**
     * Stops the AnimatedSprite and destroys it.
     *
     * @param {object|boolean} [options] - Options parameter. A boolean will act as if all options
     *  have been set to that value.
     * @param {boolean} [options.children=false] - If set to true, all the children will have their destroy
     *      method called as well. 'options' will be passed on to those calls.
     * @param {boolean} [options.texture=false] - Should it destroy the current texture of the sprite as well.
     * @param {boolean} [options.baseTexture=false] - Should it destroy the base texture of the sprite as well.
     */ AnimatedSprite2.prototype.destroy = function(options) {
        this.stop();
        _super.prototype.destroy.call(this, options);
        this.onComplete = null;
        this.onFrameChange = null;
        this.onLoop = null;
    };
    /**
     * A short hand way of creating an AnimatedSprite from an array of frame ids.
     *
     * @static
     * @param {string[]} frames - The array of frames ids the AnimatedSprite will use as its texture frames.
     * @return {PIXI.AnimatedSprite} The new animated sprite with the specified frames.
     */ AnimatedSprite2.fromFrames = function(frames) {
        var textures = [];
        for(var i = 0; i < frames.length; ++i)textures.push(_core.Texture.from(frames[i]));
        return new AnimatedSprite2(textures);
    };
    /**
     * A short hand way of creating an AnimatedSprite from an array of image ids.
     *
     * @static
     * @param {string[]} images - The array of image urls the AnimatedSprite will use as its texture frames.
     * @return {PIXI.AnimatedSprite} The new animate sprite with the specified images as frames.
     */ AnimatedSprite2.fromImages = function(images) {
        var textures = [];
        for(var i = 0; i < images.length; ++i)textures.push(_core.Texture.from(images[i]));
        return new AnimatedSprite2(textures);
    };
    Object.defineProperty(AnimatedSprite2.prototype, "totalFrames", {
        /**
         * The total number of frames in the AnimatedSprite. This is the same as number of textures
         * assigned to the AnimatedSprite.
         *
         * @readonly
         * @member {number}
         * @default 0
         */ get: function() {
            return this._textures.length;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(AnimatedSprite2.prototype, "textures", {
        /**
         * The array of textures used for this AnimatedSprite.
         *
         * @member {PIXI.Texture[]}
         */ get: function() {
            return this._textures;
        },
        set: function(value) {
            if (value[0] instanceof _core.Texture) {
                this._textures = value;
                this._durations = null;
            } else {
                this._textures = [];
                this._durations = [];
                for(var i = 0; i < value.length; i++){
                    this._textures.push(value[i].texture);
                    this._durations.push(value[i].time);
                }
            }
            this._previousFrame = null;
            this.gotoAndStop(0);
            this.updateTexture();
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(AnimatedSprite2.prototype, "currentFrame", {
        /**
        * The AnimatedSprites current frame index.
        *
        * @member {number}
        * @readonly
        */ get: function() {
            var currentFrame = Math.floor(this._currentTime) % this._textures.length;
            if (currentFrame < 0) currentFrame += this._textures.length;
            return currentFrame;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(AnimatedSprite2.prototype, "playing", {
        /**
         * Indicates if the AnimatedSprite is currently playing.
         *
         * @member {boolean}
         * @readonly
         */ get: function() {
            return this._playing;
        },
        enumerable: false,
        configurable: true
    });
    Object.defineProperty(AnimatedSprite2.prototype, "autoUpdate", {
        /**
         * Whether to use PIXI.Ticker.shared to auto update animation time
         *
         * @member {boolean}
         */ get: function() {
            return this._autoUpdate;
        },
        set: function(value) {
            if (value !== this._autoUpdate) {
                this._autoUpdate = value;
                if (!this._autoUpdate && this._isConnectedToTicker) {
                    _ticker.Ticker.shared.remove(this.update, this);
                    this._isConnectedToTicker = false;
                } else if (this._autoUpdate && !this._isConnectedToTicker && this._playing) {
                    _ticker.Ticker.shared.add(this.update, this);
                    this._isConnectedToTicker = true;
                }
            }
        },
        enumerable: false,
        configurable: true
    });
    return AnimatedSprite2;
}(_sprite.Sprite);

},{"@pixi/core":"d0INm","@pixi/sprite":"aeiZG","@pixi/ticker":"5j6Uq","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"itYag":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getContext", ()=>_global.getContext
);
parcelHelpers.export(exports, "setContext", ()=>_global.setContext
);
parcelHelpers.export(exports, "start", ()=>_global.start
);
parcelHelpers.export(exports, "supported", ()=>_audioContext.supported
);
/**
 * The current audio context time of the global [[Context]].
 * See [[Context.now]]
 * @category Core
 */ parcelHelpers.export(exports, "now", ()=>now
);
/**
 * The current audio context time of the global [[Context]] without the [[Context.lookAhead]]
 * See [[Context.immediate]]
 * @category Core
 */ parcelHelpers.export(exports, "immediate", ()=>immediate
);
parcelHelpers.export(exports, "Transport", ()=>Transport
);
/**
 * The Transport object belonging to the global Tone.js Context.
 * See [[Transport]]
 * @category Core
 */ parcelHelpers.export(exports, "getTransport", ()=>getTransport
);
parcelHelpers.export(exports, "Destination", ()=>Destination
);
parcelHelpers.export(exports, "Master", ()=>Master
);
/**
 * The Destination (output) belonging to the global Tone.js Context.
 * See [[Destination]]
 * @category Core
 */ parcelHelpers.export(exports, "getDestination", ()=>getDestination
);
parcelHelpers.export(exports, "Listener", ()=>Listener
);
/**
 * The [[Listener]] belonging to the global Tone.js Context.
 * @category Core
 */ parcelHelpers.export(exports, "getListener", ()=>getListener
);
parcelHelpers.export(exports, "Draw", ()=>Draw
);
/**
 * Get the singleton attached to the global context.
 * Draw is used to synchronize the draw frame with the Transport's callbacks.
 * See [[Draw]]
 * @category Core
 */ parcelHelpers.export(exports, "getDraw", ()=>getDraw
);
parcelHelpers.export(exports, "context", ()=>context
);
/**
 * Promise which resolves when all of the loading promises are resolved.
 * Alias for static [[ToneAudioBuffer.loaded]] method.
 * @category Core
 */ parcelHelpers.export(exports, "loaded", ()=>loaded
);
parcelHelpers.export(exports, "Buffer", ()=>Buffer
);
parcelHelpers.export(exports, "Buffers", ()=>Buffers
);
parcelHelpers.export(exports, "BufferSource", ()=>BufferSource
);
var _global = require("./core/Global");
var _toneAudioBuffer = require("./core/context/ToneAudioBuffer");
// this fills in name changes from 13.x to 14.x
var _toneAudioBuffers = require("./core/context/ToneAudioBuffers");
var _toneBufferSource = require("./source/buffer/ToneBufferSource");
var _classes = require("./classes");
parcelHelpers.exportAll(_classes, exports);
var _version = require("./version");
parcelHelpers.exportAll(_version, exports);
var _audioContext = require("./core/context/AudioContext");
function now() {
    return _global.getContext().now();
}
function immediate() {
    return _global.getContext().immediate();
}
const Transport = _global.getContext().transport;
function getTransport() {
    return _global.getContext().transport;
}
const Destination = _global.getContext().destination;
const Master = _global.getContext().destination;
function getDestination() {
    return _global.getContext().destination;
}
const Listener = _global.getContext().listener;
function getListener() {
    return _global.getContext().listener;
}
const Draw = _global.getContext().draw;
function getDraw() {
    return _global.getContext().draw;
}
const context = _global.getContext();
function loaded() {
    return _toneAudioBuffer.ToneAudioBuffer.loaded();
}
const Buffer = _toneAudioBuffer.ToneAudioBuffer;
const Buffers = _toneAudioBuffers.ToneAudioBuffers;
const BufferSource = _toneBufferSource.ToneBufferSource;

},{"./core/Global":"6b8rd","./classes":"bm3Bk","./version":"hDknC","./core/context/ToneAudioBuffer":"gpPIV","./core/context/AudioContext":"6cX1c","./core/context/ToneAudioBuffers":"g1eoF","./source/buffer/ToneBufferSource":"6y7FM","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6b8rd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Returns the default system-wide [[Context]]
 * @category Core
 */ parcelHelpers.export(exports, "getContext", ()=>getContext
);
/**
 * Set the default audio context
 * @category Core
 */ parcelHelpers.export(exports, "setContext", ()=>setContext
);
/**
 * Most browsers will not play _any_ audio until a user
 * clicks something (like a play button). Invoke this method
 * on a click or keypress event handler to start the audio context.
 * More about the Autoplay policy
 * [here](https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio)
 * @example
 * document.querySelector("button").addEventListener("click", async () => {
 * 	await Tone.start();
 * 	console.log("context started");
 * });
 * @category Core
 */ parcelHelpers.export(exports, "start", ()=>start
);
var _version = require("../version");
var _audioContext = require("./context/AudioContext");
var _context = require("./context/Context");
var _dummyContext = require("./context/DummyContext");
var _offlineContext = require("./context/OfflineContext");
var _advancedTypeCheck = require("./util/AdvancedTypeCheck");
/**
 * This dummy context is used to avoid throwing immediate errors when importing in Node.js
 */ const dummyContext = new _dummyContext.DummyContext();
/**
 * The global audio context which is getable and assignable through
 * getContext and setContext
 */ let globalContext = dummyContext;
function getContext() {
    if (globalContext === dummyContext && _audioContext.hasAudioContext) setContext(new _context.Context());
    return globalContext;
}
function setContext(context) {
    if (_advancedTypeCheck.isAudioContext(context)) globalContext = new _context.Context(context);
    else if (_advancedTypeCheck.isOfflineAudioContext(context)) globalContext = new _offlineContext.OfflineContext(context);
    else globalContext = context;
}
function start() {
    return globalContext.resume();
}
/**
 * Log Tone.js + version in the console.
 */ if (_audioContext.theWindow && !_audioContext.theWindow.TONE_SILENCE_LOGGING) {
    let prefix = "v";
    if (_version.version === "dev") prefix = "";
    const printString = ` * Tone.js ${prefix}${_version.version} * `;
    // eslint-disable-next-line no-console
    console.log(`%c${printString}`, "background: #000; color: #fff");
}

},{"../version":"hDknC","./context/AudioContext":"6cX1c","./context/Context":"44HXc","./context/DummyContext":"6ANrT","./context/OfflineContext":"KYtWQ","./util/AdvancedTypeCheck":"arR2z","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hDknC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "version", ()=>version
);
const version = "14.7.77";

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6cX1c":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Create a new AudioContext
 */ parcelHelpers.export(exports, "createAudioContext", ()=>createAudioContext
);
/**
 * Create a new OfflineAudioContext
 */ parcelHelpers.export(exports, "createOfflineAudioContext", ()=>createOfflineAudioContext
);
parcelHelpers.export(exports, "theWindow", ()=>theWindow
);
parcelHelpers.export(exports, "hasAudioContext", ()=>hasAudioContext
);
parcelHelpers.export(exports, "createAudioWorkletNode", ()=>createAudioWorkletNode
);
/**
 * This promise resolves to a boolean which indicates if the
 * functionality is supported within the currently used browse.
 * Taken from [standardized-audio-context](https://github.com/chrisguttandin/standardized-audio-context#issupported)
 */ parcelHelpers.export(exports, "supported", ()=>_standardizedAudioContext.isSupported
);
var _standardizedAudioContext = require("standardized-audio-context");
var _debug = require("../util/Debug");
var _typeCheck = require("../util/TypeCheck");
function createAudioContext(options) {
    return new _standardizedAudioContext.AudioContext(options);
}
function createOfflineAudioContext(channels, length, sampleRate) {
    return new _standardizedAudioContext.OfflineAudioContext(channels, length, sampleRate);
}
const theWindow = typeof self === "object" ? self : null;
const hasAudioContext = theWindow && (theWindow.hasOwnProperty("AudioContext") || theWindow.hasOwnProperty("webkitAudioContext"));
function createAudioWorkletNode(context, name, options) {
    _debug.assert(_typeCheck.isDefined(_standardizedAudioContext.AudioWorkletNode), "This node only works in a secure context (https or localhost)");
    // @ts-ignore
    return new _standardizedAudioContext.AudioWorkletNode(context, name, options);
}

},{"standardized-audio-context":"ef7FQ","../util/Debug":"bsxl9","../util/TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ef7FQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "AnalyserNode", ()=>analyserNodeConstructor
);
parcelHelpers.export(exports, "AudioBuffer", ()=>audioBufferConstructor
);
parcelHelpers.export(exports, "AudioBufferSourceNode", ()=>audioBufferSourceNodeConstructor
);
parcelHelpers.export(exports, "addAudioWorkletModule", ()=>addAudioWorkletModule
);
parcelHelpers.export(exports, "decodeAudioData", ()=>decodeAudioData
);
parcelHelpers.export(exports, "AudioContext", ()=>audioContextConstructor
);
parcelHelpers.export(exports, "AudioWorkletNode", ()=>audioWorkletNodeConstructor
);
parcelHelpers.export(exports, "BiquadFilterNode", ()=>biquadFilterNodeConstructor
);
parcelHelpers.export(exports, "ChannelMergerNode", ()=>channelMergerNodeConstructor
);
parcelHelpers.export(exports, "ChannelSplitterNode", ()=>channelSplitterNodeConstructor
);
parcelHelpers.export(exports, "ConvolverNode", ()=>convolverNodeConstructor
);
parcelHelpers.export(exports, "ConstantSourceNode", ()=>constantSourceNodeConstructor
);
parcelHelpers.export(exports, "DelayNode", ()=>delayNodeConstructor
);
parcelHelpers.export(exports, "DynamicsCompressorNode", ()=>dynamicsCompressorNodeConstructor
);
parcelHelpers.export(exports, "GainNode", ()=>gainNodeConstructor
);
parcelHelpers.export(exports, "IIRFilterNode", ()=>iIRFilterNodeConstructor
);
parcelHelpers.export(exports, "MediaElementAudioSourceNode", ()=>mediaElementAudioSourceNodeConstructor
);
parcelHelpers.export(exports, "MediaStreamAudioDestinationNode", ()=>mediaStreamAudioDestinationNodeConstructor
);
parcelHelpers.export(exports, "MediaStreamAudioSourceNode", ()=>mediaStreamAudioSourceNodeConstructor
);
parcelHelpers.export(exports, "MediaStreamTrackAudioSourceNode", ()=>mediaStreamTrackAudioSourceNodeConstructor
);
parcelHelpers.export(exports, "MinimalAudioContext", ()=>minimalAudioContextConstructor
);
parcelHelpers.export(exports, "MinimalOfflineAudioContext", ()=>minimalOfflineAudioContextConstructor
);
parcelHelpers.export(exports, "OfflineAudioContext", ()=>offlineAudioContextConstructor
);
parcelHelpers.export(exports, "OscillatorNode", ()=>oscillatorNodeConstructor
);
parcelHelpers.export(exports, "PannerNode", ()=>pannerNodeConstructor
);
parcelHelpers.export(exports, "PeriodicWave", ()=>periodicWaveConstructor
);
parcelHelpers.export(exports, "StereoPannerNode", ()=>stereoPannerNodeConstructor
);
parcelHelpers.export(exports, "WaveShaperNode", ()=>waveShaperNodeConstructor
);
parcelHelpers.export(exports, "isAnyAudioContext", ()=>isAnyAudioContext
);
parcelHelpers.export(exports, "isAnyAudioNode", ()=>isAnyAudioNode
);
parcelHelpers.export(exports, "isAnyAudioParam", ()=>isAnyAudioParam
);
parcelHelpers.export(exports, "isAnyOfflineAudioContext", ()=>isAnyOfflineAudioContext
);
parcelHelpers.export(exports, "isSupported", ()=>isSupported
);
var _automationEvents = require("automation-events");
var _abortError = require("./factories/abort-error");
var _addActiveInputConnectionToAudioNode = require("./factories/add-active-input-connection-to-audio-node");
var _addAudioNodeConnections = require("./factories/add-audio-node-connections");
var _addAudioParamConnections = require("./factories/add-audio-param-connections");
var _addAudioWorkletModule = require("./factories/add-audio-worklet-module");
var _addConnectionToAudioNode = require("./factories/add-connection-to-audio-node");
var _addPassiveInputConnectionToAudioNode = require("./factories/add-passive-input-connection-to-audio-node");
var _addSilentConnection = require("./factories/add-silent-connection");
var _addUnrenderedAudioWorkletNode = require("./factories/add-unrendered-audio-worklet-node");
var _analyserNodeConstructor = require("./factories/analyser-node-constructor");
var _analyserNodeRendererFactory = require("./factories/analyser-node-renderer-factory");
var _audioBufferConstructor = require("./factories/audio-buffer-constructor");
var _audioBufferSourceNodeConstructor = require("./factories/audio-buffer-source-node-constructor");
var _audioBufferSourceNodeRendererFactory = require("./factories/audio-buffer-source-node-renderer-factory");
var _audioContextConstructor = require("./factories/audio-context-constructor");
var _audioDestinationNodeConstructor = require("./factories/audio-destination-node-constructor");
var _audioDestinationNodeRendererFactory = require("./factories/audio-destination-node-renderer-factory");
var _audioListenerFactory = require("./factories/audio-listener-factory");
var _audioNodeConstructor = require("./factories/audio-node-constructor");
var _audioParamFactory = require("./factories/audio-param-factory");
var _audioParamRenderer = require("./factories/audio-param-renderer");
var _audioWorkletNodeConstructor = require("./factories/audio-worklet-node-constructor");
var _audioWorkletNodeRendererFactory = require("./factories/audio-worklet-node-renderer-factory");
var _baseAudioContextConstructor = require("./factories/base-audio-context-constructor");
var _biquadFilterNodeConstructor = require("./factories/biquad-filter-node-constructor");
var _biquadFilterNodeRendererFactory = require("./factories/biquad-filter-node-renderer-factory");
var _cacheTestResult = require("./factories/cache-test-result");
var _channelMergerNodeConstructor = require("./factories/channel-merger-node-constructor");
var _channelMergerNodeRendererFactory = require("./factories/channel-merger-node-renderer-factory");
var _channelSplitterNodeConstructor = require("./factories/channel-splitter-node-constructor");
var _channelSplitterNodeRendererFactory = require("./factories/channel-splitter-node-renderer-factory");
var _connectAudioParam = require("./factories/connect-audio-param");
var _connectMultipleOutputs = require("./factories/connect-multiple-outputs");
var _connectedNativeAudioBufferSourceNodeFactory = require("./factories/connected-native-audio-buffer-source-node-factory");
var _constantSourceNodeConstructor = require("./factories/constant-source-node-constructor");
var _constantSourceNodeRendererFactory = require("./factories/constant-source-node-renderer-factory");
var _convertNumberToUnsignedLong = require("./factories/convert-number-to-unsigned-long");
var _convolverNodeConstructor = require("./factories/convolver-node-constructor");
var _convolverNodeRendererFactory = require("./factories/convolver-node-renderer-factory");
var _createNativeOfflineAudioContext = require("./factories/create-native-offline-audio-context");
var _dataCloneError = require("./factories/data-clone-error");
var _decodeAudioData = require("./factories/decode-audio-data");
var _decrementCycleCounter = require("./factories/decrement-cycle-counter");
var _delayNodeConstructor = require("./factories/delay-node-constructor");
var _delayNodeRendererFactory = require("./factories/delay-node-renderer-factory");
var _deleteActiveInputConnectionToAudioNode = require("./factories/delete-active-input-connection-to-audio-node");
var _deleteUnrenderedAudioWorkletNode = require("./factories/delete-unrendered-audio-worklet-node");
var _detectCycles = require("./factories/detect-cycles");
var _disconnectMultipleOutputs = require("./factories/disconnect-multiple-outputs");
var _dynamicsCompressorNodeConstructor = require("./factories/dynamics-compressor-node-constructor");
var _dynamicsCompressorNodeRendererFactory = require("./factories/dynamics-compressor-node-renderer-factory");
var _encodingError = require("./factories/encoding-error");
var _evaluateSource = require("./factories/evaluate-source");
var _eventTargetConstructor = require("./factories/event-target-constructor");
var _exposeCurrentFrameAndCurrentTime = require("./factories/expose-current-frame-and-current-time");
var _fetchSource = require("./factories/fetch-source");
var _gainNodeConstructor = require("./factories/gain-node-constructor");
var _gainNodeRendererFactory = require("./factories/gain-node-renderer-factory");
var _getActiveAudioWorkletNodeInputs = require("./factories/get-active-audio-worklet-node-inputs");
var _getAudioNodeRenderer = require("./factories/get-audio-node-renderer");
var _getAudioNodeTailTime = require("./factories/get-audio-node-tail-time");
var _getAudioParamRenderer = require("./factories/get-audio-param-renderer");
var _getBackupOfflineAudioContext = require("./factories/get-backup-offline-audio-context");
var _getNativeContext = require("./factories/get-native-context");
var _getOrCreateBackupOfflineAudioContext = require("./factories/get-or-create-backup-offline-audio-context");
var _getUnrenderedAudioWorkletNodes = require("./factories/get-unrendered-audio-worklet-nodes");
var _iirFilterNodeConstructor = require("./factories/iir-filter-node-constructor");
var _iirFilterNodeRendererFactory = require("./factories/iir-filter-node-renderer-factory");
var _incrementCycleCounterFactory = require("./factories/increment-cycle-counter-factory");
var _indexSizeError = require("./factories/index-size-error");
var _invalidAccessError = require("./factories/invalid-access-error");
var _invalidStateError = require("./factories/invalid-state-error");
var _isAnyAudioContext = require("./factories/is-any-audio-context");
var _isAnyAudioNode = require("./factories/is-any-audio-node");
var _isAnyAudioParam = require("./factories/is-any-audio-param");
var _isAnyOfflineAudioContext = require("./factories/is-any-offline-audio-context");
var _isNativeAudioContext = require("./factories/is-native-audio-context");
var _isNativeAudioNode = require("./factories/is-native-audio-node");
var _isNativeAudioParam = require("./factories/is-native-audio-param");
var _isNativeContext = require("./factories/is-native-context");
var _isNativeOfflineAudioContext = require("./factories/is-native-offline-audio-context");
var _isSecureContext = require("./factories/is-secure-context");
var _isSupportedPromise = require("./factories/is-supported-promise");
var _mediaElementAudioSourceNodeConstructor = require("./factories/media-element-audio-source-node-constructor");
var _mediaStreamAudioDestinationNodeConstructor = require("./factories/media-stream-audio-destination-node-constructor");
var _mediaStreamAudioSourceNodeConstructor = require("./factories/media-stream-audio-source-node-constructor");
var _mediaStreamTrackAudioSourceNodeConstructor = require("./factories/media-stream-track-audio-source-node-constructor");
var _minimalAudioContextConstructor = require("./factories/minimal-audio-context-constructor");
var _minimalBaseAudioContextConstructor = require("./factories/minimal-base-audio-context-constructor");
var _minimalOfflineAudioContextConstructor = require("./factories/minimal-offline-audio-context-constructor");
var _monitorConnections = require("./factories/monitor-connections");
var _nativeAnalyserNodeFactory = require("./factories/native-analyser-node-factory");
var _nativeAudioBufferConstructor = require("./factories/native-audio-buffer-constructor");
var _nativeAudioBufferSourceNodeFactory = require("./factories/native-audio-buffer-source-node-factory");
var _nativeAudioContextConstructor = require("./factories/native-audio-context-constructor");
var _nativeAudioDestinationNode = require("./factories/native-audio-destination-node");
var _nativeAudioWorkletNodeConstructor = require("./factories/native-audio-worklet-node-constructor");
var _nativeAudioWorkletNodeFactory = require("./factories/native-audio-worklet-node-factory");
var _nativeAudioWorkletNodeFakerFactory = require("./factories/native-audio-worklet-node-faker-factory");
var _nativeBiquadFilterNode = require("./factories/native-biquad-filter-node");
var _nativeChannelMergerNodeFactory = require("./factories/native-channel-merger-node-factory");
var _nativeChannelSplitterNode = require("./factories/native-channel-splitter-node");
var _nativeConstantSourceNodeFactory = require("./factories/native-constant-source-node-factory");
var _nativeConstantSourceNodeFakerFactory = require("./factories/native-constant-source-node-faker-factory");
var _nativeConvolverNodeFactory = require("./factories/native-convolver-node-factory");
var _nativeDelayNode = require("./factories/native-delay-node");
var _nativeDynamicsCompressorNodeFactory = require("./factories/native-dynamics-compressor-node-factory");
var _nativeGainNode = require("./factories/native-gain-node");
var _nativeIirFilterNodeFactory = require("./factories/native-iir-filter-node-factory");
var _nativeIirFilterNodeFakerFactory = require("./factories/native-iir-filter-node-faker-factory");
var _nativeMediaElementAudioSourceNode = require("./factories/native-media-element-audio-source-node");
var _nativeMediaStreamAudioDestinationNode = require("./factories/native-media-stream-audio-destination-node");
var _nativeMediaStreamAudioSourceNode = require("./factories/native-media-stream-audio-source-node");
var _nativeMediaStreamTrackAudioSourceNodeFactory = require("./factories/native-media-stream-track-audio-source-node-factory");
var _nativeOfflineAudioContextConstructor = require("./factories/native-offline-audio-context-constructor");
var _nativeOscillatorNodeFactory = require("./factories/native-oscillator-node-factory");
var _nativePannerNodeFactory = require("./factories/native-panner-node-factory");
var _nativePannerNodeFakerFactory = require("./factories/native-panner-node-faker-factory");
var _nativePeriodicWaveFactory = require("./factories/native-periodic-wave-factory");
var _nativeScriptProcessorNode = require("./factories/native-script-processor-node");
var _nativeStereoPannerNodeFactory = require("./factories/native-stereo-panner-node-factory");
var _nativeStereoPannerNodeFakerFactory = require("./factories/native-stereo-panner-node-faker-factory");
var _nativeWaveShaperNodeFactory = require("./factories/native-wave-shaper-node-factory");
var _nativeWaveShaperNodeFakerFactory = require("./factories/native-wave-shaper-node-faker-factory");
var _notSupportedError = require("./factories/not-supported-error");
var _offlineAudioContextConstructor = require("./factories/offline-audio-context-constructor");
var _oscillatorNodeConstructor = require("./factories/oscillator-node-constructor");
var _oscillatorNodeRendererFactory = require("./factories/oscillator-node-renderer-factory");
var _pannerNodeConstructor = require("./factories/panner-node-constructor");
var _pannerNodeRendererFactory = require("./factories/panner-node-renderer-factory");
var _periodicWaveConstructor = require("./factories/periodic-wave-constructor");
var _renderAutomation = require("./factories/render-automation");
var _renderInputsOfAudioNode = require("./factories/render-inputs-of-audio-node");
var _renderInputsOfAudioParam = require("./factories/render-inputs-of-audio-param");
var _renderNativeOfflineAudioContext = require("./factories/render-native-offline-audio-context");
var _setActiveAudioWorkletNodeInputs = require("./factories/set-active-audio-worklet-node-inputs");
var _setAudioNodeTailTime = require("./factories/set-audio-node-tail-time");
var _startRendering = require("./factories/start-rendering");
var _stereoPannerNodeConstructor = require("./factories/stereo-panner-node-constructor");
var _stereoPannerNodeRendererFactory = require("./factories/stereo-panner-node-renderer-factory");
var _testAudioBufferConstructorSupport = require("./factories/test-audio-buffer-constructor-support");
var _testAudioBufferCopyChannelMethodsSubarraySupport = require("./factories/test-audio-buffer-copy-channel-methods-subarray-support");
var _testAudioContextCloseMethodSupport = require("./factories/test-audio-context-close-method-support");
var _testAudioContextDecodeAudioDataMethodTypeErrorSupport = require("./factories/test-audio-context-decode-audio-data-method-type-error-support");
var _testAudioContextOptionsSupport = require("./factories/test-audio-context-options-support");
var _testAudioNodeConnectMethodSupport = require("./factories/test-audio-node-connect-method-support");
var _testAudioWorkletProcessorNoOutputsSupport = require("./factories/test-audio-worklet-processor-no-outputs-support");
var _testAudioWorkletProcessorPostMessageSupport = require("./factories/test-audio-worklet-processor-post-message-support");
var _testChannelMergerNodeChannelCountSupport = require("./factories/test-channel-merger-node-channel-count-support");
var _testConstantSourceNodeAccurateSchedulingSupport = require("./factories/test-constant-source-node-accurate-scheduling-support");
var _testConvolverNodeBufferReassignabilitySupport = require("./factories/test-convolver-node-buffer-reassignability-support");
var _testConvolverNodeChannelCountSupport = require("./factories/test-convolver-node-channel-count-support");
var _testIsSecureContextSupport = require("./factories/test-is-secure-context-support");
var _testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = require("./factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support");
var _testOfflineAudioContextCurrentTimeSupport = require("./factories/test-offline-audio-context-current-time-support");
var _testStereoPannerNodeDefaultValueSupport = require("./factories/test-stereo-panner-node-default-value-support");
var _unknownError = require("./factories/unknown-error");
var _waveShaperNodeConstructor = require("./factories/wave-shaper-node-constructor");
var _waveShaperNodeRendererFactory = require("./factories/wave-shaper-node-renderer-factory");
var _window = require("./factories/window");
var _wrapAudioBufferCopyChannelMethods = require("./factories/wrap-audio-buffer-copy-channel-methods");
var _wrapAudioBufferCopyChannelMethodsOutOfBounds = require("./factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds");
var _wrapAudioBufferSourceNodeStopMethodNullifiedBuffer = require("./factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer");
var _wrapChannelMergerNode = require("./factories/wrap-channel-merger-node");
var _globals = require("./globals");
var _connectNativeAudioNodeToNativeAudioNode = require("./helpers/connect-native-audio-node-to-native-audio-node");
var _disconnectNativeAudioNodeFromNativeAudioNode = require("./helpers/disconnect-native-audio-node-from-native-audio-node");
var _getAudioNodeConnections = require("./helpers/get-audio-node-connections");
var _getAudioParamConnections = require("./helpers/get-audio-param-connections");
var _getEventListenersOfAudioNode = require("./helpers/get-event-listeners-of-audio-node");
var _getFirstSample = require("./helpers/get-first-sample");
var _getNativeAudioNode = require("./helpers/get-native-audio-node");
var _getNativeAudioParam = require("./helpers/get-native-audio-param");
var _getValueForKey = require("./helpers/get-value-for-key");
var _insertElementInSet = require("./helpers/insert-element-in-set");
var _isActiveAudioNode = require("./helpers/is-active-audio-node");
var _isDcCurve = require("./helpers/is-dc-curve");
var _isPartOfACycle = require("./helpers/is-part-of-a-cycle");
var _isPassiveAudioNode = require("./helpers/is-passive-audio-node");
var _overwriteAccessors = require("./helpers/overwrite-accessors");
var _pickElementFromSet = require("./helpers/pick-element-from-set");
var _sanitizeAudioWorkletNodeOptions = require("./helpers/sanitize-audio-worklet-node-options");
var _sanitizeChannelSplitterOptions = require("./helpers/sanitize-channel-splitter-options");
var _sanitizePeriodicWaveOptions = require("./helpers/sanitize-periodic-wave-options");
var _setValueAtTimeUntilPossible = require("./helpers/set-value-at-time-until-possible");
var _testAudioBufferCopyChannelMethodsOutOfBoundsSupport = require("./helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support");
var _testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = require("./helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support");
var _testAudioBufferSourceNodeStartMethodOffsetClampingSupport = require("./helpers/test-audio-buffer-source-node-start-method-offset-clamping-support");
var _testAudioBufferSourceNodeStopMethodNullifiedBufferSupport = require("./helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support");
var _testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = require("./helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support");
var _testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = require("./helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support");
var _testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = require("./helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support");
var _testAudioWorkletNodeOptionsClonability = require("./helpers/test-audio-worklet-node-options-clonability");
var _testDomExceptionConstructorSupport = require("./helpers/test-dom-exception-constructor-support");
var _testPromiseSupport = require("./helpers/test-promise-support");
var _testTransferablesSupport = require("./helpers/test-transferables-support");
var _wrapAudioBufferSourceNodeStartMethodOffsetClamping = require("./helpers/wrap-audio-buffer-source-node-start-method-offset-clamping");
var _wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = require("./helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls");
var _wrapEventListener = require("./helpers/wrap-event-listener");
/*
 * @todo Explicitly referencing the barrel file seems to be necessary when enabling the
 * isolatedModules compiler option.
 */ var _index = require("./interfaces/index");
parcelHelpers.exportAll(_index, exports);
var _index1 = require("./types/index");
parcelHelpers.exportAll(_index1, exports);
const addActiveInputConnectionToAudioNode = _addActiveInputConnectionToAudioNode.createAddActiveInputConnectionToAudioNode(_insertElementInSet.insertElementInSet);
const addPassiveInputConnectionToAudioNode = _addPassiveInputConnectionToAudioNode.createAddPassiveInputConnectionToAudioNode(_insertElementInSet.insertElementInSet);
const deleteActiveInputConnectionToAudioNode = _deleteActiveInputConnectionToAudioNode.createDeleteActiveInputConnectionToAudioNode(_pickElementFromSet.pickElementFromSet);
const audioNodeTailTimeStore = new WeakMap();
const getAudioNodeTailTime = _getAudioNodeTailTime.createGetAudioNodeTailTime(audioNodeTailTimeStore);
const cacheTestResult = _cacheTestResult.createCacheTestResult(new Map(), new WeakMap());
const window = _window.createWindow();
const createNativeAnalyserNode = _nativeAnalyserNodeFactory.createNativeAnalyserNodeFactory(cacheTestResult, _indexSizeError.createIndexSizeError);
const getAudioNodeRenderer = _getAudioNodeRenderer.createGetAudioNodeRenderer(_getAudioNodeConnections.getAudioNodeConnections);
const renderInputsOfAudioNode = _renderInputsOfAudioNode.createRenderInputsOfAudioNode(_getAudioNodeConnections.getAudioNodeConnections, getAudioNodeRenderer, _isPartOfACycle.isPartOfACycle);
const createAnalyserNodeRenderer = _analyserNodeRendererFactory.createAnalyserNodeRendererFactory(createNativeAnalyserNode, _getNativeAudioNode.getNativeAudioNode, renderInputsOfAudioNode);
const getNativeContext = _getNativeContext.createGetNativeContext(_globals.CONTEXT_STORE);
const nativeOfflineAudioContextConstructor = _nativeOfflineAudioContextConstructor.createNativeOfflineAudioContextConstructor(window);
const isNativeOfflineAudioContext = _isNativeOfflineAudioContext.createIsNativeOfflineAudioContext(nativeOfflineAudioContextConstructor);
const audioParamAudioNodeStore = new WeakMap();
const eventTargetConstructor = _eventTargetConstructor.createEventTargetConstructor(_wrapEventListener.wrapEventListener);
const nativeAudioContextConstructor = _nativeAudioContextConstructor.createNativeAudioContextConstructor(window);
const isNativeAudioContext = _isNativeAudioContext.createIsNativeAudioContext(nativeAudioContextConstructor);
const isNativeAudioNode = _isNativeAudioNode.createIsNativeAudioNode(window);
const isNativeAudioParam = _isNativeAudioParam.createIsNativeAudioParam(window);
const audioNodeConstructor = _audioNodeConstructor.createAudioNodeConstructor(_addAudioNodeConnections.createAddAudioNodeConnections(_globals.AUDIO_NODE_CONNECTIONS_STORE), _addConnectionToAudioNode.createAddConnectionToAudioNode(addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, _connectNativeAudioNodeToNativeAudioNode.connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, _disconnectNativeAudioNodeFromNativeAudioNode.disconnectNativeAudioNodeFromNativeAudioNode, _getAudioNodeConnections.getAudioNodeConnections, getAudioNodeTailTime, _getEventListenersOfAudioNode.getEventListenersOfAudioNode, _getNativeAudioNode.getNativeAudioNode, _insertElementInSet.insertElementInSet, _isActiveAudioNode.isActiveAudioNode, _isPartOfACycle.isPartOfACycle, _isPassiveAudioNode.isPassiveAudioNode), cacheTestResult, _incrementCycleCounterFactory.createIncrementCycleCounterFactory(_globals.CYCLE_COUNTERS, _disconnectNativeAudioNodeFromNativeAudioNode.disconnectNativeAudioNodeFromNativeAudioNode, _getAudioNodeConnections.getAudioNodeConnections, _getNativeAudioNode.getNativeAudioNode, _getNativeAudioParam.getNativeAudioParam, _isActiveAudioNode.isActiveAudioNode), _indexSizeError.createIndexSizeError, _invalidAccessError.createInvalidAccessError, _notSupportedError.createNotSupportedError, _decrementCycleCounter.createDecrementCycleCounter(_connectNativeAudioNodeToNativeAudioNode.connectNativeAudioNodeToNativeAudioNode, _globals.CYCLE_COUNTERS, _getAudioNodeConnections.getAudioNodeConnections, _getNativeAudioNode.getNativeAudioNode, _getNativeAudioParam.getNativeAudioParam, getNativeContext, _isActiveAudioNode.isActiveAudioNode, isNativeOfflineAudioContext), _detectCycles.createDetectCycles(audioParamAudioNodeStore, _getAudioNodeConnections.getAudioNodeConnections, _getValueForKey.getValueForKey), eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext);
const analyserNodeConstructor = _analyserNodeConstructor.createAnalyserNodeConstructor(audioNodeConstructor, createAnalyserNodeRenderer, _indexSizeError.createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext);
const audioBufferStore = new WeakSet();
const nativeAudioBufferConstructor = _nativeAudioBufferConstructor.createNativeAudioBufferConstructor(window);
const convertNumberToUnsignedLong = _convertNumberToUnsignedLong.createConvertNumberToUnsignedLong(new Uint32Array(1));
const wrapAudioBufferCopyChannelMethods = _wrapAudioBufferCopyChannelMethods.createWrapAudioBufferCopyChannelMethods(convertNumberToUnsignedLong, _indexSizeError.createIndexSizeError);
const wrapAudioBufferCopyChannelMethodsOutOfBounds = _wrapAudioBufferCopyChannelMethodsOutOfBounds.createWrapAudioBufferCopyChannelMethodsOutOfBounds(convertNumberToUnsignedLong);
const audioBufferConstructor = _audioBufferConstructor.createAudioBufferConstructor(audioBufferStore, cacheTestResult, _notSupportedError.createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, _testAudioBufferConstructorSupport.createTestAudioBufferConstructorSupport(nativeAudioBufferConstructor), wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
const addSilentConnection = _addSilentConnection.createAddSilentConnection(_nativeGainNode.createNativeGainNode);
const renderInputsOfAudioParam = _renderInputsOfAudioParam.createRenderInputsOfAudioParam(getAudioNodeRenderer, _getAudioParamConnections.getAudioParamConnections, _isPartOfACycle.isPartOfACycle);
const connectAudioParam = _connectAudioParam.createConnectAudioParam(renderInputsOfAudioParam);
const createNativeAudioBufferSourceNode = _nativeAudioBufferSourceNodeFactory.createNativeAudioBufferSourceNodeFactory(addSilentConnection, cacheTestResult, _testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport.testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, _testAudioBufferSourceNodeStartMethodOffsetClampingSupport.testAudioBufferSourceNodeStartMethodOffsetClampingSupport, _testAudioBufferSourceNodeStopMethodNullifiedBufferSupport.testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, _testAudioScheduledSourceNodeStartMethodNegativeParametersSupport.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport.testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, _testAudioScheduledSourceNodeStopMethodNegativeParametersSupport.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, _wrapAudioBufferSourceNodeStartMethodOffsetClamping.wrapAudioBufferSourceNodeStartMethodOffsetClamping, _wrapAudioBufferSourceNodeStopMethodNullifiedBuffer.createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer(_overwriteAccessors.overwriteAccessors), _wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls.wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);
const renderAutomation = _renderAutomation.createRenderAutomation(_getAudioParamRenderer.createGetAudioParamRenderer(_getAudioParamConnections.getAudioParamConnections), renderInputsOfAudioParam);
const createAudioBufferSourceNodeRenderer = _audioBufferSourceNodeRendererFactory.createAudioBufferSourceNodeRendererFactory(connectAudioParam, createNativeAudioBufferSourceNode, _getNativeAudioNode.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
const createAudioParam = _audioParamFactory.createAudioParamFactory(_addAudioParamConnections.createAddAudioParamConnections(_globals.AUDIO_PARAM_CONNECTIONS_STORE), audioParamAudioNodeStore, _globals.AUDIO_PARAM_STORE, _audioParamRenderer.createAudioParamRenderer, _automationEvents.createCancelAndHoldAutomationEvent, _automationEvents.createCancelScheduledValuesAutomationEvent, _automationEvents.createExponentialRampToValueAutomationEvent, _automationEvents.createLinearRampToValueAutomationEvent, _automationEvents.createSetTargetAutomationEvent, _automationEvents.createSetValueAutomationEvent, _automationEvents.createSetValueCurveAutomationEvent, nativeAudioContextConstructor, _setValueAtTimeUntilPossible.setValueAtTimeUntilPossible);
const audioBufferSourceNodeConstructor = _audioBufferSourceNodeConstructor.createAudioBufferSourceNodeConstructor(audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, _invalidStateError.createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, _wrapEventListener.wrapEventListener);
const audioDestinationNodeConstructor = _audioDestinationNodeConstructor.createAudioDestinationNodeConstructor(audioNodeConstructor, _audioDestinationNodeRendererFactory.createAudioDestinationNodeRenderer, _indexSizeError.createIndexSizeError, _invalidStateError.createInvalidStateError, _nativeAudioDestinationNode.createNativeAudioDestinationNodeFactory(_nativeGainNode.createNativeGainNode, _overwriteAccessors.overwriteAccessors), getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode);
const createBiquadFilterNodeRenderer = _biquadFilterNodeRendererFactory.createBiquadFilterNodeRendererFactory(connectAudioParam, _nativeBiquadFilterNode.createNativeBiquadFilterNode, _getNativeAudioNode.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
const setAudioNodeTailTime = _setAudioNodeTailTime.createSetAudioNodeTailTime(audioNodeTailTimeStore);
const biquadFilterNodeConstructor = _biquadFilterNodeConstructor.createBiquadFilterNodeConstructor(audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, _invalidAccessError.createInvalidAccessError, _nativeBiquadFilterNode.createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const monitorConnections = _monitorConnections.createMonitorConnections(_insertElementInSet.insertElementInSet, isNativeAudioNode);
const wrapChannelMergerNode = _wrapChannelMergerNode.createWrapChannelMergerNode(_invalidStateError.createInvalidStateError, monitorConnections);
const createNativeChannelMergerNode = _nativeChannelMergerNodeFactory.createNativeChannelMergerNodeFactory(nativeAudioContextConstructor, wrapChannelMergerNode);
const createChannelMergerNodeRenderer = _channelMergerNodeRendererFactory.createChannelMergerNodeRendererFactory(createNativeChannelMergerNode, _getNativeAudioNode.getNativeAudioNode, renderInputsOfAudioNode);
const channelMergerNodeConstructor = _channelMergerNodeConstructor.createChannelMergerNodeConstructor(audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext);
const createChannelSplitterNodeRenderer = _channelSplitterNodeRendererFactory.createChannelSplitterNodeRendererFactory(_nativeChannelSplitterNode.createNativeChannelSplitterNode, _getNativeAudioNode.getNativeAudioNode, renderInputsOfAudioNode);
const channelSplitterNodeConstructor = _channelSplitterNodeConstructor.createChannelSplitterNodeConstructor(audioNodeConstructor, createChannelSplitterNodeRenderer, _nativeChannelSplitterNode.createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, _sanitizeChannelSplitterOptions.sanitizeChannelSplitterOptions);
const createNativeConstantSourceNodeFaker = _nativeConstantSourceNodeFakerFactory.createNativeConstantSourceNodeFakerFactory(addSilentConnection, createNativeAudioBufferSourceNode, _nativeGainNode.createNativeGainNode, monitorConnections);
const createNativeConstantSourceNode = _nativeConstantSourceNodeFactory.createNativeConstantSourceNodeFactory(addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, _testAudioScheduledSourceNodeStartMethodNegativeParametersSupport.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _testAudioScheduledSourceNodeStopMethodNegativeParametersSupport.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport);
const createConstantSourceNodeRenderer = _constantSourceNodeRendererFactory.createConstantSourceNodeRendererFactory(connectAudioParam, createNativeConstantSourceNode, _getNativeAudioNode.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
const constantSourceNodeConstructor = _constantSourceNodeConstructor.createConstantSourceNodeConstructor(audioNodeConstructor, createAudioParam, createConstantSourceNodeRenderer, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, _wrapEventListener.wrapEventListener);
const createNativeConvolverNode = _nativeConvolverNodeFactory.createNativeConvolverNodeFactory(_notSupportedError.createNotSupportedError, _overwriteAccessors.overwriteAccessors);
const createConvolverNodeRenderer = _convolverNodeRendererFactory.createConvolverNodeRendererFactory(createNativeConvolverNode, _getNativeAudioNode.getNativeAudioNode, renderInputsOfAudioNode);
const convolverNodeConstructor = _convolverNodeConstructor.createConvolverNodeConstructor(audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createDelayNodeRenderer = _delayNodeRendererFactory.createDelayNodeRendererFactory(connectAudioParam, _nativeDelayNode.createNativeDelayNode, _getNativeAudioNode.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
const delayNodeConstructor = _delayNodeConstructor.createDelayNodeConstructor(audioNodeConstructor, createAudioParam, createDelayNodeRenderer, _nativeDelayNode.createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createNativeDynamicsCompressorNode = _nativeDynamicsCompressorNodeFactory.createNativeDynamicsCompressorNodeFactory(_notSupportedError.createNotSupportedError);
const createDynamicsCompressorNodeRenderer = _dynamicsCompressorNodeRendererFactory.createDynamicsCompressorNodeRendererFactory(connectAudioParam, createNativeDynamicsCompressorNode, _getNativeAudioNode.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
const dynamicsCompressorNodeConstructor = _dynamicsCompressorNodeConstructor.createDynamicsCompressorNodeConstructor(audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, _notSupportedError.createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createGainNodeRenderer = _gainNodeRendererFactory.createGainNodeRendererFactory(connectAudioParam, _nativeGainNode.createNativeGainNode, _getNativeAudioNode.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
const gainNodeConstructor = _gainNodeConstructor.createGainNodeConstructor(audioNodeConstructor, createAudioParam, createGainNodeRenderer, _nativeGainNode.createNativeGainNode, getNativeContext, isNativeOfflineAudioContext);
const createNativeIIRFilterNodeFaker = _nativeIirFilterNodeFakerFactory.createNativeIIRFilterNodeFakerFactory(_invalidAccessError.createInvalidAccessError, _invalidStateError.createInvalidStateError, _nativeScriptProcessorNode.createNativeScriptProcessorNode, _notSupportedError.createNotSupportedError);
const renderNativeOfflineAudioContext = _renderNativeOfflineAudioContext.createRenderNativeOfflineAudioContext(cacheTestResult, _nativeGainNode.createNativeGainNode, _nativeScriptProcessorNode.createNativeScriptProcessorNode, _testOfflineAudioContextCurrentTimeSupport.createTestOfflineAudioContextCurrentTimeSupport(_nativeGainNode.createNativeGainNode, nativeOfflineAudioContextConstructor));
const createIIRFilterNodeRenderer = _iirFilterNodeRendererFactory.createIIRFilterNodeRendererFactory(createNativeAudioBufferSourceNode, _getNativeAudioNode.getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
const createNativeIIRFilterNode = _nativeIirFilterNodeFactory.createNativeIIRFilterNodeFactory(createNativeIIRFilterNodeFaker);
const iIRFilterNodeConstructor = _iirFilterNodeConstructor.createIIRFilterNodeConstructor(audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createAudioListener = _audioListenerFactory.createAudioListenerFactory(createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, _nativeScriptProcessorNode.createNativeScriptProcessorNode, _notSupportedError.createNotSupportedError, _getFirstSample.getFirstSample, isNativeOfflineAudioContext, _overwriteAccessors.overwriteAccessors);
const unrenderedAudioWorkletNodeStore = new WeakMap();
const minimalBaseAudioContextConstructor = _minimalBaseAudioContextConstructor.createMinimalBaseAudioContextConstructor(audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, _wrapEventListener.wrapEventListener);
const createNativeOscillatorNode = _nativeOscillatorNodeFactory.createNativeOscillatorNodeFactory(addSilentConnection, cacheTestResult, _testAudioScheduledSourceNodeStartMethodNegativeParametersSupport.testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, _testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport.testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, _testAudioScheduledSourceNodeStopMethodNegativeParametersSupport.testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, _wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls.wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls);
const createOscillatorNodeRenderer = _oscillatorNodeRendererFactory.createOscillatorNodeRendererFactory(connectAudioParam, createNativeOscillatorNode, _getNativeAudioNode.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
const oscillatorNodeConstructor = _oscillatorNodeConstructor.createOscillatorNodeConstructor(audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, _wrapEventListener.wrapEventListener);
const createConnectedNativeAudioBufferSourceNode = _connectedNativeAudioBufferSourceNodeFactory.createConnectedNativeAudioBufferSourceNodeFactory(createNativeAudioBufferSourceNode);
const createNativeWaveShaperNodeFaker = _nativeWaveShaperNodeFakerFactory.createNativeWaveShaperNodeFakerFactory(createConnectedNativeAudioBufferSourceNode, _invalidStateError.createInvalidStateError, _nativeGainNode.createNativeGainNode, _isDcCurve.isDCCurve, monitorConnections);
const createNativeWaveShaperNode = _nativeWaveShaperNodeFactory.createNativeWaveShaperNodeFactory(createConnectedNativeAudioBufferSourceNode, _invalidStateError.createInvalidStateError, createNativeWaveShaperNodeFaker, _isDcCurve.isDCCurve, monitorConnections, nativeAudioContextConstructor, _overwriteAccessors.overwriteAccessors);
const createNativePannerNodeFaker = _nativePannerNodeFakerFactory.createNativePannerNodeFakerFactory(_connectNativeAudioNodeToNativeAudioNode.connectNativeAudioNodeToNativeAudioNode, _invalidStateError.createInvalidStateError, createNativeChannelMergerNode, _nativeGainNode.createNativeGainNode, _nativeScriptProcessorNode.createNativeScriptProcessorNode, createNativeWaveShaperNode, _notSupportedError.createNotSupportedError, _disconnectNativeAudioNodeFromNativeAudioNode.disconnectNativeAudioNodeFromNativeAudioNode, _getFirstSample.getFirstSample, monitorConnections);
const createNativePannerNode = _nativePannerNodeFactory.createNativePannerNodeFactory(createNativePannerNodeFaker);
const createPannerNodeRenderer = _pannerNodeRendererFactory.createPannerNodeRendererFactory(connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, _nativeGainNode.createNativeGainNode, createNativePannerNode, _getNativeAudioNode.getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
const pannerNodeConstructor = _pannerNodeConstructor.createPannerNodeConstructor(audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const createNativePeriodicWave = _nativePeriodicWaveFactory.createNativePeriodicWaveFactory(_indexSizeError.createIndexSizeError);
const periodicWaveConstructor = _periodicWaveConstructor.createPeriodicWaveConstructor(createNativePeriodicWave, getNativeContext, new WeakSet(), _sanitizePeriodicWaveOptions.sanitizePeriodicWaveOptions);
const nativeStereoPannerNodeFakerFactory = _nativeStereoPannerNodeFakerFactory.createNativeStereoPannerNodeFakerFactory(createNativeChannelMergerNode, _nativeChannelSplitterNode.createNativeChannelSplitterNode, _nativeGainNode.createNativeGainNode, createNativeWaveShaperNode, _notSupportedError.createNotSupportedError, monitorConnections);
const createNativeStereoPannerNode = _nativeStereoPannerNodeFactory.createNativeStereoPannerNodeFactory(nativeStereoPannerNodeFakerFactory, _notSupportedError.createNotSupportedError);
const createStereoPannerNodeRenderer = _stereoPannerNodeRendererFactory.createStereoPannerNodeRendererFactory(connectAudioParam, createNativeStereoPannerNode, _getNativeAudioNode.getNativeAudioNode, renderAutomation, renderInputsOfAudioNode);
const stereoPannerNodeConstructor = _stereoPannerNodeConstructor.createStereoPannerNodeConstructor(audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext);
const createWaveShaperNodeRenderer = _waveShaperNodeRendererFactory.createWaveShaperNodeRendererFactory(createNativeWaveShaperNode, _getNativeAudioNode.getNativeAudioNode, renderInputsOfAudioNode);
const waveShaperNodeConstructor = _waveShaperNodeConstructor.createWaveShaperNodeConstructor(audioNodeConstructor, _invalidStateError.createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime);
const isSecureContext = _isSecureContext.createIsSecureContext(window);
const exposeCurrentFrameAndCurrentTime = _exposeCurrentFrameAndCurrentTime.createExposeCurrentFrameAndCurrentTime(window);
const backupOfflineAudioContextStore = new WeakMap();
const getOrCreateBackupOfflineAudioContext = _getOrCreateBackupOfflineAudioContext.createGetOrCreateBackupOfflineAudioContext(backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor);
const nativeAudioWorkletNodeConstructor = _nativeAudioWorkletNodeConstructor.createNativeAudioWorkletNodeConstructor(window);
const addAudioWorkletModule = isSecureContext ? _addAudioWorkletModule.createAddAudioWorkletModule(cacheTestResult, _notSupportedError.createNotSupportedError, _evaluateSource.createEvaluateSource(window), exposeCurrentFrameAndCurrentTime, _fetchSource.createFetchSource(_abortError.createAbortError), getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, new WeakMap(), new WeakMap(), _testAudioWorkletProcessorPostMessageSupport.createTestAudioWorkletProcessorPostMessageSupport(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), // @todo window is guaranteed to be defined because isSecureContext checks that as well.
window) : undefined;
const isNativeContext = _isNativeContext.createIsNativeContext(isNativeAudioContext, isNativeOfflineAudioContext);
const decodeAudioData = _decodeAudioData.createDecodeAudioData(audioBufferStore, cacheTestResult, _dataCloneError.createDataCloneError, _encodingError.createEncodingError, new WeakSet(), getNativeContext, isNativeContext, _testAudioBufferCopyChannelMethodsOutOfBoundsSupport.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, _testPromiseSupport.testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
const baseAudioContextConstructor = _baseAudioContextConstructor.createBaseAudioContextConstructor(addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor);
const mediaElementAudioSourceNodeConstructor = _mediaElementAudioSourceNodeConstructor.createMediaElementAudioSourceNodeConstructor(audioNodeConstructor, _nativeMediaElementAudioSourceNode.createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);
const mediaStreamAudioDestinationNodeConstructor = _mediaStreamAudioDestinationNodeConstructor.createMediaStreamAudioDestinationNodeConstructor(audioNodeConstructor, _nativeMediaStreamAudioDestinationNode.createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext);
const mediaStreamAudioSourceNodeConstructor = _mediaStreamAudioSourceNodeConstructor.createMediaStreamAudioSourceNodeConstructor(audioNodeConstructor, _nativeMediaStreamAudioSourceNode.createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext);
const createNativeMediaStreamTrackAudioSourceNode = _nativeMediaStreamTrackAudioSourceNodeFactory.createNativeMediaStreamTrackAudioSourceNodeFactory(_invalidStateError.createInvalidStateError, isNativeOfflineAudioContext);
const mediaStreamTrackAudioSourceNodeConstructor = _mediaStreamTrackAudioSourceNodeConstructor.createMediaStreamTrackAudioSourceNodeConstructor(audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext);
const audioContextConstructor = _audioContextConstructor.createAudioContextConstructor(baseAudioContextConstructor, _invalidStateError.createInvalidStateError, _notSupportedError.createNotSupportedError, _unknownError.createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor);
const getUnrenderedAudioWorkletNodes = _getUnrenderedAudioWorkletNodes.createGetUnrenderedAudioWorkletNodes(unrenderedAudioWorkletNodeStore);
const addUnrenderedAudioWorkletNode = _addUnrenderedAudioWorkletNode.createAddUnrenderedAudioWorkletNode(getUnrenderedAudioWorkletNodes);
const connectMultipleOutputs = _connectMultipleOutputs.createConnectMultipleOutputs(_indexSizeError.createIndexSizeError);
const deleteUnrenderedAudioWorkletNode = _deleteUnrenderedAudioWorkletNode.createDeleteUnrenderedAudioWorkletNode(getUnrenderedAudioWorkletNodes);
const disconnectMultipleOutputs = _disconnectMultipleOutputs.createDisconnectMultipleOutputs(_indexSizeError.createIndexSizeError);
const activeAudioWorkletNodeInputsStore = new WeakMap();
const getActiveAudioWorkletNodeInputs = _getActiveAudioWorkletNodeInputs.createGetActiveAudioWorkletNodeInputs(activeAudioWorkletNodeInputsStore, _getValueForKey.getValueForKey);
const createNativeAudioWorkletNodeFaker = _nativeAudioWorkletNodeFakerFactory.createNativeAudioWorkletNodeFakerFactory(connectMultipleOutputs, _indexSizeError.createIndexSizeError, _invalidStateError.createInvalidStateError, createNativeChannelMergerNode, _nativeChannelSplitterNode.createNativeChannelSplitterNode, createNativeConstantSourceNode, _nativeGainNode.createNativeGainNode, _nativeScriptProcessorNode.createNativeScriptProcessorNode, _notSupportedError.createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections);
const createNativeAudioWorkletNode = _nativeAudioWorkletNodeFactory.createNativeAudioWorkletNodeFactory(_invalidStateError.createInvalidStateError, createNativeAudioWorkletNodeFaker, _nativeGainNode.createNativeGainNode, _notSupportedError.createNotSupportedError, monitorConnections);
const createAudioWorkletNodeRenderer = _audioWorkletNodeRendererFactory.createAudioWorkletNodeRendererFactory(connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, _nativeChannelSplitterNode.createNativeChannelSplitterNode, createNativeConstantSourceNode, _nativeGainNode.createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, _getNativeAudioNode.getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext);
const getBackupOfflineAudioContext = _getBackupOfflineAudioContext.createGetBackupOfflineAudioContext(backupOfflineAudioContextStore);
const setActiveAudioWorkletNodeInputs = _setActiveAudioWorkletNodeInputs.createSetActiveAudioWorkletNodeInputs(activeAudioWorkletNodeInputsStore);
// The AudioWorkletNode constructor is only available in a SecureContext.
const audioWorkletNodeConstructor = isSecureContext ? _audioWorkletNodeConstructor.createAudioWorkletNodeConstructor(addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, _getAudioNodeConnections.getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, _sanitizeAudioWorkletNodeOptions.sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, _testAudioWorkletNodeOptionsClonability.testAudioWorkletNodeOptionsClonability, _wrapEventListener.wrapEventListener) : undefined;
const minimalAudioContextConstructor = _minimalAudioContextConstructor.createMinimalAudioContextConstructor(_invalidStateError.createInvalidStateError, _notSupportedError.createNotSupportedError, _unknownError.createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor);
const createNativeOfflineAudioContext = _createNativeOfflineAudioContext.createCreateNativeOfflineAudioContext(_notSupportedError.createNotSupportedError, nativeOfflineAudioContextConstructor);
const startRendering = _startRendering.createStartRendering(audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, _testAudioBufferCopyChannelMethodsOutOfBoundsSupport.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds);
const minimalOfflineAudioContextConstructor = _minimalOfflineAudioContextConstructor.createMinimalOfflineAudioContextConstructor(cacheTestResult, _invalidStateError.createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering);
const offlineAudioContextConstructor = _offlineAudioContextConstructor.createOfflineAudioContextConstructor(baseAudioContextConstructor, cacheTestResult, _invalidStateError.createInvalidStateError, createNativeOfflineAudioContext, startRendering);
const isAnyAudioContext = _isAnyAudioContext.createIsAnyAudioContext(_globals.CONTEXT_STORE, isNativeAudioContext);
const isAnyAudioNode = _isAnyAudioNode.createIsAnyAudioNode(_globals.AUDIO_NODE_STORE, isNativeAudioNode);
const isAnyAudioParam = _isAnyAudioParam.createIsAnyAudioParam(_globals.AUDIO_PARAM_STORE, isNativeAudioParam);
const isAnyOfflineAudioContext = _isAnyOfflineAudioContext.createIsAnyOfflineAudioContext(_globals.CONTEXT_STORE, isNativeOfflineAudioContext);
const isSupported = ()=>_isSupportedPromise.createIsSupportedPromise(cacheTestResult, _testAudioBufferCopyChannelMethodsSubarraySupport.createTestAudioBufferCopyChannelMethodsSubarraySupport(nativeOfflineAudioContextConstructor), _testAudioContextCloseMethodSupport.createTestAudioContextCloseMethodSupport(nativeAudioContextConstructor), _testAudioContextDecodeAudioDataMethodTypeErrorSupport.createTestAudioContextDecodeAudioDataMethodTypeErrorSupport(nativeOfflineAudioContextConstructor), _testAudioContextOptionsSupport.createTestAudioContextOptionsSupport(nativeAudioContextConstructor), _testAudioNodeConnectMethodSupport.createTestAudioNodeConnectMethodSupport(nativeOfflineAudioContextConstructor), _testAudioWorkletProcessorNoOutputsSupport.createTestAudioWorkletProcessorNoOutputsSupport(nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor), _testChannelMergerNodeChannelCountSupport.createTestChannelMergerNodeChannelCountSupport(nativeOfflineAudioContextConstructor), _testConstantSourceNodeAccurateSchedulingSupport.createTestConstantSourceNodeAccurateSchedulingSupport(nativeOfflineAudioContextConstructor), _testConvolverNodeBufferReassignabilitySupport.createTestConvolverNodeBufferReassignabilitySupport(nativeOfflineAudioContextConstructor), _testConvolverNodeChannelCountSupport.createTestConvolverNodeChannelCountSupport(nativeOfflineAudioContextConstructor), _testDomExceptionConstructorSupport.testDomExceptionConstructorSupport, _testIsSecureContextSupport.createTestIsSecureContextSupport(window), _testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport.createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport(nativeAudioContextConstructor), _testStereoPannerNodeDefaultValueSupport.createTestStereoPannerNodeDefaultValueSupport(nativeOfflineAudioContextConstructor), _testTransferablesSupport.testTransferablesSupport)
;

},{"automation-events":"hP2Jr","./factories/abort-error":"gcQNB","./factories/add-active-input-connection-to-audio-node":"ktW36","./factories/add-audio-node-connections":"6uyL2","./factories/add-audio-param-connections":"fNrio","./factories/add-audio-worklet-module":"i734y","./factories/add-connection-to-audio-node":"cLQHj","./factories/add-passive-input-connection-to-audio-node":"i68wf","./factories/add-silent-connection":"YYbtB","./factories/add-unrendered-audio-worklet-node":"fZfR9","./factories/analyser-node-constructor":"fjwCz","./factories/analyser-node-renderer-factory":"lt2g3","./factories/audio-buffer-constructor":"5aodM","./factories/audio-buffer-source-node-constructor":"in3ti","./factories/audio-buffer-source-node-renderer-factory":"gmYEM","./factories/audio-context-constructor":"fHpei","./factories/audio-destination-node-constructor":"bFUCJ","./factories/audio-destination-node-renderer-factory":"cX5aF","./factories/audio-listener-factory":"lRosi","./factories/audio-node-constructor":"7YZZi","./factories/audio-param-factory":"buC3m","./factories/audio-param-renderer":"hiyLY","./factories/audio-worklet-node-constructor":"1TBsi","./factories/audio-worklet-node-renderer-factory":"1xnlD","./factories/base-audio-context-constructor":"gYnX5","./factories/biquad-filter-node-constructor":"12rCH","./factories/biquad-filter-node-renderer-factory":"5gXPH","./factories/cache-test-result":"jxh1a","./factories/channel-merger-node-constructor":"9F55c","./factories/channel-merger-node-renderer-factory":"3dPqu","./factories/channel-splitter-node-constructor":"2Jv1p","./factories/channel-splitter-node-renderer-factory":"cQs9X","./factories/connect-audio-param":"ffceE","./factories/connect-multiple-outputs":"k2tjb","./factories/connected-native-audio-buffer-source-node-factory":"knghE","./factories/constant-source-node-constructor":"gDaEY","./factories/constant-source-node-renderer-factory":"eXWDG","./factories/convert-number-to-unsigned-long":"gHJdq","./factories/convolver-node-constructor":"huigM","./factories/convolver-node-renderer-factory":"cCbtq","./factories/create-native-offline-audio-context":"5vuLC","./factories/data-clone-error":"hpGSA","./factories/decode-audio-data":"e0wCw","./factories/decrement-cycle-counter":"gqBHS","./factories/delay-node-constructor":"1kjKK","./factories/delay-node-renderer-factory":"e9Hhp","./factories/delete-active-input-connection-to-audio-node":"1sYav","./factories/delete-unrendered-audio-worklet-node":"7Sd6K","./factories/detect-cycles":"cbYj2","./factories/disconnect-multiple-outputs":"2vAzP","./factories/dynamics-compressor-node-constructor":"aOjun","./factories/dynamics-compressor-node-renderer-factory":"ijyoV","./factories/encoding-error":"ayhFC","./factories/evaluate-source":"lAWbH","./factories/event-target-constructor":"22mxx","./factories/expose-current-frame-and-current-time":"fhD5Q","./factories/fetch-source":"9Fmtn","./factories/gain-node-constructor":"4ccFC","./factories/gain-node-renderer-factory":"eB9zs","./factories/get-active-audio-worklet-node-inputs":"7u5Wl","./factories/get-audio-node-renderer":"5d8tK","./factories/get-audio-node-tail-time":"kxrG8","./factories/get-audio-param-renderer":"e5iAn","./factories/get-backup-offline-audio-context":"7WKwq","./factories/get-native-context":"a5g0D","./factories/get-or-create-backup-offline-audio-context":"3BEPC","./factories/get-unrendered-audio-worklet-nodes":"bef04","./factories/iir-filter-node-constructor":"7XCZ8","./factories/iir-filter-node-renderer-factory":"coeG5","./factories/increment-cycle-counter-factory":"jOaj9","./factories/index-size-error":"jFao7","./factories/invalid-access-error":"irzR7","./factories/invalid-state-error":"kvntE","./factories/is-any-audio-context":"77CuE","./factories/is-any-audio-node":"46fQP","./factories/is-any-audio-param":"7duKE","./factories/is-any-offline-audio-context":"7lqyw","./factories/is-native-audio-context":"cf0YV","./factories/is-native-audio-node":"jkhov","./factories/is-native-audio-param":"bDZUl","./factories/is-native-context":"sk4ws","./factories/is-native-offline-audio-context":"ed9HY","./factories/is-secure-context":"8H0Db","./factories/is-supported-promise":"1cpZE","./factories/media-element-audio-source-node-constructor":"iZbh0","./factories/media-stream-audio-destination-node-constructor":"66Na4","./factories/media-stream-audio-source-node-constructor":"3GcMB","./factories/media-stream-track-audio-source-node-constructor":"87CyX","./factories/minimal-audio-context-constructor":"42jSk","./factories/minimal-base-audio-context-constructor":"7EGmO","./factories/minimal-offline-audio-context-constructor":"3oO6X","./factories/monitor-connections":"8PkhL","./factories/native-analyser-node-factory":"aVma8","./factories/native-audio-buffer-constructor":"k70lf","./factories/native-audio-buffer-source-node-factory":"eXNh0","./factories/native-audio-context-constructor":"7CcBH","./factories/native-audio-destination-node":"eiD7E","./factories/native-audio-worklet-node-constructor":"4LdwE","./factories/native-audio-worklet-node-factory":"kwJGf","./factories/native-audio-worklet-node-faker-factory":"9qlJs","./factories/native-biquad-filter-node":"gZ7jY","./factories/native-channel-merger-node-factory":"hjRzD","./factories/native-channel-splitter-node":"1l37J","./factories/native-constant-source-node-factory":"cNqnP","./factories/native-constant-source-node-faker-factory":"6XrrD","./factories/native-convolver-node-factory":"7ax0y","./factories/native-delay-node":"2bykR","./factories/native-dynamics-compressor-node-factory":"6sRUo","./factories/native-gain-node":"dLDco","./factories/native-iir-filter-node-factory":"aUNPS","./factories/native-iir-filter-node-faker-factory":"f6Clz","./factories/native-media-element-audio-source-node":"9P3cG","./factories/native-media-stream-audio-destination-node":"51GnX","./factories/native-media-stream-audio-source-node":"ajOzY","./factories/native-media-stream-track-audio-source-node-factory":"hB0YW","./factories/native-offline-audio-context-constructor":"4ywUg","./factories/native-oscillator-node-factory":"dJ9Ae","./factories/native-panner-node-factory":"2MBWa","./factories/native-panner-node-faker-factory":"3CT8l","./factories/native-periodic-wave-factory":"5jjiX","./factories/native-script-processor-node":"fRr7m","./factories/native-stereo-panner-node-factory":"fqEid","./factories/native-stereo-panner-node-faker-factory":"4RkM7","./factories/native-wave-shaper-node-factory":"fhU38","./factories/native-wave-shaper-node-faker-factory":"cl7SO","./factories/not-supported-error":"l51fO","./factories/offline-audio-context-constructor":"kAkwN","./factories/oscillator-node-constructor":"fgXfo","./factories/oscillator-node-renderer-factory":"kgvGW","./factories/panner-node-constructor":"3fegt","./factories/panner-node-renderer-factory":"82fmB","./factories/periodic-wave-constructor":"3dENA","./factories/render-automation":"kGzLE","./factories/render-inputs-of-audio-node":"dLSj7","./factories/render-inputs-of-audio-param":"4Xi7v","./factories/render-native-offline-audio-context":"4XZx3","./factories/set-active-audio-worklet-node-inputs":"kakVM","./factories/set-audio-node-tail-time":"fEtVG","./factories/start-rendering":"hcf4W","./factories/stereo-panner-node-constructor":"3yTkS","./factories/stereo-panner-node-renderer-factory":"gmiKt","./factories/test-audio-buffer-constructor-support":"7WVWw","./factories/test-audio-buffer-copy-channel-methods-subarray-support":"f4OgP","./factories/test-audio-context-close-method-support":"emL8l","./factories/test-audio-context-decode-audio-data-method-type-error-support":"kTCKa","./factories/test-audio-context-options-support":"06jf9","./factories/test-audio-node-connect-method-support":"j0dao","./factories/test-audio-worklet-processor-no-outputs-support":"kY07I","./factories/test-audio-worklet-processor-post-message-support":"32UqD","./factories/test-channel-merger-node-channel-count-support":"jUYFB","./factories/test-constant-source-node-accurate-scheduling-support":"4jSSH","./factories/test-convolver-node-buffer-reassignability-support":"et056","./factories/test-convolver-node-channel-count-support":"lWUKb","./factories/test-is-secure-context-support":"1rfsb","./factories/test-media-stream-audio-source-node-media-stream-without-audio-track-support":"6mP0O","./factories/test-offline-audio-context-current-time-support":"1SZjr","./factories/test-stereo-panner-node-default-value-support":"eE2QO","./factories/unknown-error":"hTeWs","./factories/wave-shaper-node-constructor":"8YqhL","./factories/wave-shaper-node-renderer-factory":"1DUt3","./factories/window":"4q4HM","./factories/wrap-audio-buffer-copy-channel-methods":"5kCLR","./factories/wrap-audio-buffer-copy-channel-methods-out-of-bounds":"lvdcn","./factories/wrap-audio-buffer-source-node-stop-method-nullified-buffer":"101CU","./factories/wrap-channel-merger-node":"fFaQP","./globals":"80KZG","./helpers/connect-native-audio-node-to-native-audio-node":"1r52J","./helpers/disconnect-native-audio-node-from-native-audio-node":"3V2hA","./helpers/get-audio-node-connections":"b9slo","./helpers/get-audio-param-connections":"elnXq","./helpers/get-event-listeners-of-audio-node":"5ePnU","./helpers/get-first-sample":"idIDB","./helpers/get-native-audio-node":"5vfeq","./helpers/get-native-audio-param":"d3w1J","./helpers/get-value-for-key":"ktCVX","./helpers/insert-element-in-set":"lF3LX","./helpers/is-active-audio-node":"3g5Fl","./helpers/is-dc-curve":"ikasp","./helpers/is-part-of-a-cycle":"AboZ8","./helpers/is-passive-audio-node":"aaSth","./helpers/overwrite-accessors":"jifeM","./helpers/pick-element-from-set":"hKh0z","./helpers/sanitize-audio-worklet-node-options":"WVucX","./helpers/sanitize-channel-splitter-options":"9Pzxt","./helpers/sanitize-periodic-wave-options":"19pUc","./helpers/set-value-at-time-until-possible":"iYruz","./helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support":"jisnd","./helpers/test-audio-buffer-source-node-start-method-consecutive-calls-support":"kZBYK","./helpers/test-audio-buffer-source-node-start-method-offset-clamping-support":"jeSkh","./helpers/test-audio-buffer-source-node-stop-method-nullified-buffer-support":"5PZwx","./helpers/test-audio-scheduled-source-node-start-method-negative-parameters-support":"7zejX","./helpers/test-audio-scheduled-source-node-stop-method-consecutive-calls-support":"ebWz3","./helpers/test-audio-scheduled-source-node-stop-method-negative-parameters-support":"gpV16","./helpers/test-audio-worklet-node-options-clonability":"rJW54","./helpers/test-dom-exception-constructor-support":"boinr","./helpers/test-promise-support":"bcKJv","./helpers/test-transferables-support":"6xhFt","./helpers/wrap-audio-buffer-source-node-start-method-offset-clamping":"1gYCo","./helpers/wrap-audio-scheduled-source-node-stop-method-consecutive-calls":"fBU4X","./helpers/wrap-event-listener":"1G08j","./interfaces/index":"go3d9","./types/index":"2sOgk","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hP2Jr":[function(require,module,exports) {
(function(global, factory) {
    typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('@babel/runtime/helpers/slicedToArray'), require('@babel/runtime/helpers/classCallCheck'), require('@babel/runtime/helpers/createClass')) : typeof define === 'function' && define.amd ? define([
        'exports',
        '@babel/runtime/helpers/slicedToArray',
        '@babel/runtime/helpers/classCallCheck',
        '@babel/runtime/helpers/createClass'
    ], factory) : (global = typeof globalThis !== 'undefined' ? globalThis : global || self, factory(global.automationEvents = {
    }, global._slicedToArray, global._classCallCheck, global._createClass));
})(this, function(exports, _slicedToArray, _classCallCheck, _createClass) {
    'use strict';
    function _interopDefaultLegacy(e) {
        return e && typeof e === 'object' && 'default' in e ? e : {
            'default': e
        };
    }
    var _slicedToArray__default = /*#__PURE__*/ _interopDefaultLegacy(_slicedToArray);
    var _classCallCheck__default = /*#__PURE__*/ _interopDefaultLegacy(_classCallCheck);
    var _createClass__default = /*#__PURE__*/ _interopDefaultLegacy(_createClass);
    var createExtendedExponentialRampToValueAutomationEvent = function createExtendedExponentialRampToValueAutomationEvent1(value, endTime, insertTime) {
        return {
            endTime: endTime,
            insertTime: insertTime,
            type: 'exponentialRampToValue',
            value: value
        };
    };
    var createExtendedLinearRampToValueAutomationEvent = function createExtendedLinearRampToValueAutomationEvent1(value, endTime, insertTime) {
        return {
            endTime: endTime,
            insertTime: insertTime,
            type: 'linearRampToValue',
            value: value
        };
    };
    var createSetValueAutomationEvent = function createSetValueAutomationEvent1(value, startTime) {
        return {
            startTime: startTime,
            type: 'setValue',
            value: value
        };
    };
    var createSetValueCurveAutomationEvent = function createSetValueCurveAutomationEvent1(values, startTime, duration) {
        return {
            duration: duration,
            startTime: startTime,
            type: 'setValueCurve',
            values: values
        };
    };
    var getTargetValueAtTime = function getTargetValueAtTime1(time, valueAtStartTime, _ref) {
        var startTime = _ref.startTime, target = _ref.target, timeConstant = _ref.timeConstant;
        return target + (valueAtStartTime - target) * Math.exp((startTime - time) / timeConstant);
    };
    var isExponentialRampToValueAutomationEvent = function isExponentialRampToValueAutomationEvent1(automationEvent) {
        return automationEvent.type === 'exponentialRampToValue';
    };
    var isLinearRampToValueAutomationEvent = function isLinearRampToValueAutomationEvent1(automationEvent) {
        return automationEvent.type === 'linearRampToValue';
    };
    var isAnyRampToValueAutomationEvent = function isAnyRampToValueAutomationEvent1(automationEvent) {
        return isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent);
    };
    var isSetValueAutomationEvent = function isSetValueAutomationEvent1(automationEvent) {
        return automationEvent.type === 'setValue';
    };
    var isSetValueCurveAutomationEvent = function isSetValueCurveAutomationEvent1(automationEvent) {
        return automationEvent.type === 'setValueCurve';
    };
    var getValueOfAutomationEventAtIndexAtTime = function getValueOfAutomationEventAtIndexAtTime1(automationEvents, index, time, defaultValue) {
        var automationEvent = automationEvents[index];
        return automationEvent === undefined ? defaultValue : isAnyRampToValueAutomationEvent(automationEvent) || isSetValueAutomationEvent(automationEvent) ? automationEvent.value : isSetValueCurveAutomationEvent(automationEvent) ? automationEvent.values[automationEvent.values.length - 1] : getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime1(automationEvents, index - 1, automationEvent.startTime, defaultValue), automationEvent);
    };
    var getEndTimeAndValueOfPreviousAutomationEvent = function getEndTimeAndValueOfPreviousAutomationEvent1(automationEvents, index, currentAutomationEvent, nextAutomationEvent, defaultValue) {
        return currentAutomationEvent === undefined ? [
            nextAutomationEvent.insertTime,
            defaultValue
        ] : isAnyRampToValueAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.endTime,
            currentAutomationEvent.value
        ] : isSetValueAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.startTime,
            currentAutomationEvent.value
        ] : isSetValueCurveAutomationEvent(currentAutomationEvent) ? [
            currentAutomationEvent.startTime + currentAutomationEvent.duration,
            currentAutomationEvent.values[currentAutomationEvent.values.length - 1]
        ] : [
            currentAutomationEvent.startTime,
            getValueOfAutomationEventAtIndexAtTime(automationEvents, index - 1, currentAutomationEvent.startTime, defaultValue)
        ];
    };
    var isCancelAndHoldAutomationEvent = function isCancelAndHoldAutomationEvent1(automationEvent) {
        return automationEvent.type === 'cancelAndHold';
    };
    var isCancelScheduledValuesAutomationEvent = function isCancelScheduledValuesAutomationEvent1(automationEvent) {
        return automationEvent.type === 'cancelScheduledValues';
    };
    var getEventTime = function getEventTime1(automationEvent) {
        if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) return automationEvent.cancelTime;
        if (isExponentialRampToValueAutomationEvent(automationEvent) || isLinearRampToValueAutomationEvent(automationEvent)) return automationEvent.endTime;
        return automationEvent.startTime;
    };
    var getExponentialRampValueAtTime = function getExponentialRampValueAtTime1(time, startTime, valueAtStartTime, _ref) {
        var endTime = _ref.endTime, value = _ref.value;
        if (valueAtStartTime === value) return value;
        if (0 < valueAtStartTime && 0 < value || valueAtStartTime < 0 && value < 0) return valueAtStartTime * Math.pow(value / valueAtStartTime, (time - startTime) / (endTime - startTime));
        return 0;
    };
    var getLinearRampValueAtTime = function getLinearRampValueAtTime1(time, startTime, valueAtStartTime, _ref) {
        var endTime = _ref.endTime, value = _ref.value;
        return valueAtStartTime + (time - startTime) / (endTime - startTime) * (value - valueAtStartTime);
    };
    var interpolateValue = function interpolateValue1(values, theoreticIndex) {
        var lowerIndex = Math.floor(theoreticIndex);
        var upperIndex = Math.ceil(theoreticIndex);
        if (lowerIndex === upperIndex) return values[lowerIndex];
        return (1 - (theoreticIndex - lowerIndex)) * values[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * values[upperIndex];
    };
    var getValueCurveValueAtTime = function getValueCurveValueAtTime1(time, _ref) {
        var duration = _ref.duration, startTime = _ref.startTime, values = _ref.values;
        var theoreticIndex = (time - startTime) / duration * (values.length - 1);
        return interpolateValue(values, theoreticIndex);
    };
    var isSetTargetAutomationEvent = function isSetTargetAutomationEvent1(automationEvent) {
        return automationEvent.type === 'setTarget';
    };
    var AutomationEventList = /*#__PURE__*/ function(_Symbol$iterator) {
        function AutomationEventList1(defaultValue) {
            _classCallCheck__default['default'](this, AutomationEventList1);
            this._automationEvents = [];
            this._currenTime = 0;
            this._defaultValue = defaultValue;
        }
        _createClass__default['default'](AutomationEventList1, [
            {
                key: _Symbol$iterator,
                value: function value() {
                    return this._automationEvents[Symbol.iterator]();
                }
            },
            {
                key: "add",
                value: function add(automationEvent) {
                    var eventTime = getEventTime(automationEvent);
                    if (isCancelAndHoldAutomationEvent(automationEvent) || isCancelScheduledValuesAutomationEvent(automationEvent)) {
                        var index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                            if (isCancelScheduledValuesAutomationEvent(automationEvent) && isSetValueCurveAutomationEvent(currentAutomationEvent)) return currentAutomationEvent.startTime + currentAutomationEvent.duration >= eventTime;
                            return getEventTime(currentAutomationEvent) >= eventTime;
                        });
                        var removedAutomationEvent = this._automationEvents[index];
                        if (index !== -1) this._automationEvents = this._automationEvents.slice(0, index);
                        if (isCancelAndHoldAutomationEvent(automationEvent)) {
                            var lastAutomationEvent = this._automationEvents[this._automationEvents.length - 1];
                            if (removedAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(removedAutomationEvent)) {
                                if (isSetTargetAutomationEvent(lastAutomationEvent)) throw new Error('The internal list is malformed.');
                                var startTime = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.startTime + lastAutomationEvent.duration : getEventTime(lastAutomationEvent);
                                var startValue = isSetValueCurveAutomationEvent(lastAutomationEvent) ? lastAutomationEvent.values[lastAutomationEvent.values.length - 1] : lastAutomationEvent.value;
                                var value = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? getExponentialRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent) : getLinearRampValueAtTime(eventTime, startTime, startValue, removedAutomationEvent);
                                var truncatedAutomationEvent = isExponentialRampToValueAutomationEvent(removedAutomationEvent) ? createExtendedExponentialRampToValueAutomationEvent(value, eventTime, this._currenTime) : createExtendedLinearRampToValueAutomationEvent(value, eventTime, this._currenTime);
                                this._automationEvents.push(truncatedAutomationEvent);
                            }
                            if (lastAutomationEvent !== undefined && isSetTargetAutomationEvent(lastAutomationEvent)) this._automationEvents.push(createSetValueAutomationEvent(this.getValue(eventTime), eventTime));
                            if (lastAutomationEvent !== undefined && isSetValueCurveAutomationEvent(lastAutomationEvent) && lastAutomationEvent.startTime + lastAutomationEvent.duration > eventTime) this._automationEvents[this._automationEvents.length - 1] = createSetValueCurveAutomationEvent(new Float32Array([
                                6,
                                7
                            ]), lastAutomationEvent.startTime, eventTime - lastAutomationEvent.startTime);
                        }
                    } else {
                        var _index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                            return getEventTime(currentAutomationEvent) > eventTime;
                        });
                        var previousAutomationEvent = _index === -1 ? this._automationEvents[this._automationEvents.length - 1] : this._automationEvents[_index - 1];
                        if (previousAutomationEvent !== undefined && isSetValueCurveAutomationEvent(previousAutomationEvent) && getEventTime(previousAutomationEvent) + previousAutomationEvent.duration > eventTime) return false;
                        var persistentAutomationEvent = isExponentialRampToValueAutomationEvent(automationEvent) ? createExtendedExponentialRampToValueAutomationEvent(automationEvent.value, automationEvent.endTime, this._currenTime) : isLinearRampToValueAutomationEvent(automationEvent) ? createExtendedLinearRampToValueAutomationEvent(automationEvent.value, eventTime, this._currenTime) : automationEvent;
                        if (_index === -1) this._automationEvents.push(persistentAutomationEvent);
                        else {
                            if (isSetValueCurveAutomationEvent(automationEvent) && eventTime + automationEvent.duration > getEventTime(this._automationEvents[_index])) return false;
                            this._automationEvents.splice(_index, 0, persistentAutomationEvent);
                        }
                    }
                    return true;
                }
            },
            {
                key: "flush",
                value: function flush(time) {
                    var index = this._automationEvents.findIndex(function(currentAutomationEvent) {
                        return getEventTime(currentAutomationEvent) > time;
                    });
                    if (index > 1) {
                        var remainingAutomationEvents = this._automationEvents.slice(index - 1);
                        var firstRemainingAutomationEvent = remainingAutomationEvents[0];
                        if (isSetTargetAutomationEvent(firstRemainingAutomationEvent)) remainingAutomationEvents.unshift(createSetValueAutomationEvent(getValueOfAutomationEventAtIndexAtTime(this._automationEvents, index - 2, firstRemainingAutomationEvent.startTime, this._defaultValue), firstRemainingAutomationEvent.startTime));
                        this._automationEvents = remainingAutomationEvents;
                    }
                }
            },
            {
                key: "getValue",
                value: function getValue(time) {
                    if (this._automationEvents.length === 0) return this._defaultValue;
                    var indexOfNextEvent = this._automationEvents.findIndex(function(automationEvent) {
                        return getEventTime(automationEvent) > time;
                    });
                    var nextAutomationEvent = this._automationEvents[indexOfNextEvent];
                    var indexOfCurrentEvent = (indexOfNextEvent === -1 ? this._automationEvents.length : indexOfNextEvent) - 1;
                    var currentAutomationEvent = this._automationEvents[indexOfCurrentEvent];
                    if (currentAutomationEvent !== undefined && isSetTargetAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || nextAutomationEvent.insertTime > time)) return getTargetValueAtTime(time, getValueOfAutomationEventAtIndexAtTime(this._automationEvents, indexOfCurrentEvent - 1, currentAutomationEvent.startTime, this._defaultValue), currentAutomationEvent);
                    if (currentAutomationEvent !== undefined && isSetValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) return currentAutomationEvent.value;
                    if (currentAutomationEvent !== undefined && isSetValueCurveAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent) || currentAutomationEvent.startTime + currentAutomationEvent.duration > time)) {
                        if (time < currentAutomationEvent.startTime + currentAutomationEvent.duration) return getValueCurveValueAtTime(time, currentAutomationEvent);
                        return currentAutomationEvent.values[currentAutomationEvent.values.length - 1];
                    }
                    if (currentAutomationEvent !== undefined && isAnyRampToValueAutomationEvent(currentAutomationEvent) && (nextAutomationEvent === undefined || !isAnyRampToValueAutomationEvent(nextAutomationEvent))) return currentAutomationEvent.value;
                    if (nextAutomationEvent !== undefined && isExponentialRampToValueAutomationEvent(nextAutomationEvent)) {
                        var _getEndTimeAndValueOf = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue), _getEndTimeAndValueOf2 = _slicedToArray__default['default'](_getEndTimeAndValueOf, 2), startTime = _getEndTimeAndValueOf2[0], value = _getEndTimeAndValueOf2[1];
                        return getExponentialRampValueAtTime(time, startTime, value, nextAutomationEvent);
                    }
                    if (nextAutomationEvent !== undefined && isLinearRampToValueAutomationEvent(nextAutomationEvent)) {
                        var _getEndTimeAndValueOf3 = getEndTimeAndValueOfPreviousAutomationEvent(this._automationEvents, indexOfCurrentEvent, currentAutomationEvent, nextAutomationEvent, this._defaultValue), _getEndTimeAndValueOf4 = _slicedToArray__default['default'](_getEndTimeAndValueOf3, 2), _startTime = _getEndTimeAndValueOf4[0], _value = _getEndTimeAndValueOf4[1];
                        return getLinearRampValueAtTime(time, _startTime, _value, nextAutomationEvent);
                    }
                    return this._defaultValue;
                }
            }
        ]);
        return AutomationEventList1;
    }(Symbol.iterator);
    var createCancelAndHoldAutomationEvent = function createCancelAndHoldAutomationEvent1(cancelTime) {
        return {
            cancelTime: cancelTime,
            type: 'cancelAndHold'
        };
    };
    var createCancelScheduledValuesAutomationEvent = function createCancelScheduledValuesAutomationEvent1(cancelTime) {
        return {
            cancelTime: cancelTime,
            type: 'cancelScheduledValues'
        };
    };
    var createExponentialRampToValueAutomationEvent = function createExponentialRampToValueAutomationEvent1(value, endTime) {
        return {
            endTime: endTime,
            type: 'exponentialRampToValue',
            value: value
        };
    };
    var createLinearRampToValueAutomationEvent = function createLinearRampToValueAutomationEvent1(value, endTime) {
        return {
            endTime: endTime,
            type: 'linearRampToValue',
            value: value
        };
    };
    var createSetTargetAutomationEvent = function createSetTargetAutomationEvent1(target, startTime, timeConstant) {
        return {
            startTime: startTime,
            target: target,
            timeConstant: timeConstant,
            type: 'setTarget'
        };
    };
    exports.AutomationEventList = AutomationEventList;
    exports.createCancelAndHoldAutomationEvent = createCancelAndHoldAutomationEvent;
    exports.createCancelScheduledValuesAutomationEvent = createCancelScheduledValuesAutomationEvent;
    exports.createExponentialRampToValueAutomationEvent = createExponentialRampToValueAutomationEvent;
    exports.createLinearRampToValueAutomationEvent = createLinearRampToValueAutomationEvent;
    exports.createSetTargetAutomationEvent = createSetTargetAutomationEvent;
    exports.createSetValueAutomationEvent = createSetValueAutomationEvent;
    exports.createSetValueCurveAutomationEvent = createSetValueCurveAutomationEvent;
    Object.defineProperty(exports, '__esModule', {
        value: true
    });
});

},{"@babel/runtime/helpers/slicedToArray":"ePN39","@babel/runtime/helpers/classCallCheck":"fIqcI","@babel/runtime/helpers/createClass":"eFNXV"}],"ePN39":[function(require,module,exports) {
var arrayWithHoles = require("./arrayWithHoles.js");
var iterableToArrayLimit = require("./iterableToArrayLimit.js");
var unsupportedIterableToArray = require("./unsupportedIterableToArray.js");
var nonIterableRest = require("./nonIterableRest.js");
function _slicedToArray(arr, i) {
    return arrayWithHoles(arr) || iterableToArrayLimit(arr, i) || unsupportedIterableToArray(arr, i) || nonIterableRest();
}
module.exports = _slicedToArray;
module.exports["default"] = module.exports, module.exports.__esModule = true;

},{"./arrayWithHoles.js":"aME12","./iterableToArrayLimit.js":"jaFvf","./unsupportedIterableToArray.js":"78KDe","./nonIterableRest.js":"afIId"}],"aME12":[function(require,module,exports) {
function _arrayWithHoles(arr) {
    if (Array.isArray(arr)) return arr;
}
module.exports = _arrayWithHoles;
module.exports["default"] = module.exports, module.exports.__esModule = true;

},{}],"jaFvf":[function(require,module,exports) {
function _iterableToArrayLimit(arr, i) {
    var _i = arr == null ? null : typeof Symbol !== "undefined" && arr[Symbol.iterator] || arr["@@iterator"];
    if (_i == null) return;
    var _arr = [];
    var _n = true;
    var _d = false;
    var _s, _e;
    try {
        for(_i = _i.call(arr); !(_n = (_s = _i.next()).done); _n = true){
            _arr.push(_s.value);
            if (i && _arr.length === i) break;
        }
    } catch (err) {
        _d = true;
        _e = err;
    } finally{
        try {
            if (!_n && _i["return"] != null) _i["return"]();
        } finally{
            if (_d) throw _e;
        }
    }
    return _arr;
}
module.exports = _iterableToArrayLimit;
module.exports["default"] = module.exports, module.exports.__esModule = true;

},{}],"78KDe":[function(require,module,exports) {
var arrayLikeToArray = require("./arrayLikeToArray.js");
function _unsupportedIterableToArray(o, minLen) {
    if (!o) return;
    if (typeof o === "string") return arrayLikeToArray(o, minLen);
    var n = Object.prototype.toString.call(o).slice(8, -1);
    if (n === "Object" && o.constructor) n = o.constructor.name;
    if (n === "Map" || n === "Set") return Array.from(o);
    if (n === "Arguments" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return arrayLikeToArray(o, minLen);
}
module.exports = _unsupportedIterableToArray;
module.exports["default"] = module.exports, module.exports.__esModule = true;

},{"./arrayLikeToArray.js":"cF1Zj"}],"cF1Zj":[function(require,module,exports) {
function _arrayLikeToArray(arr, len) {
    if (len == null || len > arr.length) len = arr.length;
    for(var i = 0, arr2 = new Array(len); i < len; i++)arr2[i] = arr[i];
    return arr2;
}
module.exports = _arrayLikeToArray;
module.exports["default"] = module.exports, module.exports.__esModule = true;

},{}],"afIId":[function(require,module,exports) {
function _nonIterableRest() {
    throw new TypeError("Invalid attempt to destructure non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.");
}
module.exports = _nonIterableRest;
module.exports["default"] = module.exports, module.exports.__esModule = true;

},{}],"fIqcI":[function(require,module,exports) {
function _classCallCheck(instance, Constructor) {
    if (!(instance instanceof Constructor)) throw new TypeError("Cannot call a class as a function");
}
module.exports = _classCallCheck;
module.exports["default"] = module.exports, module.exports.__esModule = true;

},{}],"eFNXV":[function(require,module,exports) {
function _defineProperties(target, props) {
    for(var i = 0; i < props.length; i++){
        var descriptor = props[i];
        descriptor.enumerable = descriptor.enumerable || false;
        descriptor.configurable = true;
        if ("value" in descriptor) descriptor.writable = true;
        Object.defineProperty(target, descriptor.key, descriptor);
    }
}
function _createClass(Constructor, protoProps, staticProps) {
    if (protoProps) _defineProperties(Constructor.prototype, protoProps);
    if (staticProps) _defineProperties(Constructor, staticProps);
    return Constructor;
}
module.exports = _createClass;
module.exports["default"] = module.exports, module.exports.__esModule = true;

},{}],"gcQNB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAbortError", ()=>createAbortError
);
const createAbortError = ()=>new DOMException('', 'AbortError')
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ktW36":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddActiveInputConnectionToAudioNode", ()=>createAddActiveInputConnectionToAudioNode
);
const createAddActiveInputConnectionToAudioNode = (insertElementInSet)=>{
    return (activeInputs, source, [output, input, eventListener], ignoreDuplicates)=>{
        insertElementInSet(activeInputs[input], [
            source,
            output,
            eventListener
        ], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output
        , ignoreDuplicates);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6uyL2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddAudioNodeConnections", ()=>createAddAudioNodeConnections
);
const createAddAudioNodeConnections = (audioNodeConnectionsStore)=>{
    return (audioNode, audioNodeRenderer, nativeAudioNode)=>{
        const activeInputs = [];
        for(let i = 0; i < nativeAudioNode.numberOfInputs; i += 1)activeInputs.push(new Set());
        audioNodeConnectionsStore.set(audioNode, {
            activeInputs,
            outputs: new Set(),
            passiveInputs: new WeakMap(),
            renderer: audioNodeRenderer
        });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fNrio":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddAudioParamConnections", ()=>createAddAudioParamConnections
);
const createAddAudioParamConnections = (audioParamConnectionsStore)=>{
    return (audioParam, audioParamRenderer)=>{
        audioParamConnectionsStore.set(audioParam, {
            activeInputs: new Set(),
            passiveInputs: new WeakMap(),
            renderer: audioParamRenderer
        });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"i734y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddAudioWorkletModule", ()=>createAddAudioWorkletModule
);
var _globals = require("../globals");
var _isConstructible = require("../helpers/is-constructible");
var _splitImportStatements = require("../helpers/split-import-statements");
const verifyParameterDescriptors = (parameterDescriptors)=>{
    if (parameterDescriptors !== undefined && !Array.isArray(parameterDescriptors)) throw new TypeError('The parameterDescriptors property of given value for processorCtor is not an array.');
};
const verifyProcessorCtor = (processorCtor)=>{
    if (!_isConstructible.isConstructible(processorCtor)) throw new TypeError('The given value for processorCtor should be a constructor.');
    if (processorCtor.prototype === null || typeof processorCtor.prototype !== 'object') throw new TypeError('The given value for processorCtor should have a prototype.');
};
const createAddAudioWorkletModule = (cacheTestResult, createNotSupportedError, evaluateSource, exposeCurrentFrameAndCurrentTime, fetchSource, getNativeContext, getOrCreateBackupOfflineAudioContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, ongoingRequests, resolvedRequests, testAudioWorkletProcessorPostMessageSupport, window)=>{
    let index = 0;
    return (context, moduleURL, options = {
        credentials: 'omit'
    })=>{
        const resolvedRequestsOfContext = resolvedRequests.get(context);
        if (resolvedRequestsOfContext !== undefined && resolvedRequestsOfContext.has(moduleURL)) return Promise.resolve();
        const ongoingRequestsOfContext = ongoingRequests.get(context);
        if (ongoingRequestsOfContext !== undefined) {
            const promiseOfOngoingRequest = ongoingRequestsOfContext.get(moduleURL);
            if (promiseOfOngoingRequest !== undefined) return promiseOfOngoingRequest;
        }
        const nativeContext = getNativeContext(context);
        // Bug #59: Safari does not implement the audioWorklet property.
        const promise = nativeContext.audioWorklet === undefined ? fetchSource(moduleURL).then(([source, absoluteUrl])=>{
            const [importStatements, sourceWithoutImportStatements] = _splitImportStatements.splitImportStatements(source, absoluteUrl);
            /*
                 * This is the unminified version of the code used below:
                 *
                 * ```js
                 * ${ importStatements };
                 * ((a, b) => {
                 *     (a[b] = a[b] || [ ]).push(
                 *         (AudioWorkletProcessor, global, registerProcessor, sampleRate, self, window) => {
                 *             ${ sourceWithoutImportStatements }
                 *         }
                 *     );
                 * })(window, '_AWGS');
                 * ```
                 */ // tslint:disable-next-line:max-line-length
            const wrappedSource = `${importStatements};((a,b)=>{(a[b]=a[b]||[]).push((AudioWorkletProcessor,global,registerProcessor,sampleRate,self,window)=>{${sourceWithoutImportStatements}\n})})(window,'_AWGS')`;
            // @todo Evaluating the given source code is a possible security problem.
            return evaluateSource(wrappedSource);
        }).then(()=>{
            const evaluateAudioWorkletGlobalScope = window._AWGS.pop();
            if (evaluateAudioWorkletGlobalScope === undefined) // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
            throw new SyntaxError();
            exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, ()=>evaluateAudioWorkletGlobalScope(class AudioWorkletProcessor1 {
                }, undefined, (name, processorCtor)=>{
                    if (name.trim() === '') throw createNotSupportedError();
                    const nodeNameToProcessorConstructorMap = _globals.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);
                    if (nodeNameToProcessorConstructorMap !== undefined) {
                        if (nodeNameToProcessorConstructorMap.has(name)) throw createNotSupportedError();
                        verifyProcessorCtor(processorCtor);
                        verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        nodeNameToProcessorConstructorMap.set(name, processorCtor);
                    } else {
                        verifyProcessorCtor(processorCtor);
                        verifyParameterDescriptors(processorCtor.parameterDescriptors);
                        _globals.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.set(nativeContext, new Map([
                            [
                                name,
                                processorCtor
                            ]
                        ]));
                    }
                }, nativeContext.sampleRate, undefined, undefined)
            );
        }) : Promise.all([
            fetchSource(moduleURL),
            Promise.resolve(cacheTestResult(testAudioWorkletProcessorPostMessageSupport, testAudioWorkletProcessorPostMessageSupport))
        ]).then(([[source, absoluteUrl], isSupportingPostMessage])=>{
            const currentIndex = index + 1;
            index = currentIndex;
            const [importStatements, sourceWithoutImportStatements] = _splitImportStatements.splitImportStatements(source, absoluteUrl);
            /*
                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
                 *
                 * This is the unminified version of the code used below.
                 *
                 * ```js
                 * class extends AudioWorkletProcessor {
                 *
                 *     __buffers = new WeakSet();
                 *
                 *     constructor () {
                 *         super();
                 *
                 *         this.port.postMessage = ((postMessage) => {
                 *             return (message, transferables) => {
                 *                 const filteredTransferables = (transferables)
                 *                     ? transferables.filter((transferable) => !this.__buffers.has(transferable))
                 *                     : transferables;
                 *
                 *                 return postMessage.call(this.port, message, filteredTransferables);
                 *              };
                 *         })(this.port.postMessage);
                 *     }
                 * }
                 * ```
                 */ const patchedAudioWorkletProcessor = isSupportingPostMessage ? 'AudioWorkletProcessor' : 'class extends AudioWorkletProcessor {__b=new WeakSet();constructor(){super();(p=>p.postMessage=(q=>(m,t)=>q.call(p,m,t?t.filter(u=>!this.__b.has(u)):t))(p.postMessage))(this.port)}}';
            /*
                 * Bug #170: Chrome and Edge do call process() with an array with empty channelData for each input if no input is connected.
                 *
                 * Bug #179: Firefox does not allow to transfer any buffer which has been passed to the process() method as an argument.
                 *
                 * Bug #190: Safari doesn't throw an error when loading an unparsable module.
                 *
                 * This is the unminified version of the code used below:
                 *
                 * ```js
                 * `${ importStatements };
                 * ((AudioWorkletProcessor, registerProcessor) => {${ sourceWithoutImportStatements }
                 * })(
                 *     ${ patchedAudioWorkletProcessor },
                 *     (name, processorCtor) => registerProcessor(name, class extends processorCtor {
                 *
                 *         __collectBuffers = (array) => {
                 *             array.forEach((element) => this.__buffers.add(element.buffer));
                 *         };
                 *
                 *         process (inputs, outputs, parameters) {
                 *             inputs.forEach(this.__collectBuffers);
                 *             outputs.forEach(this.__collectBuffers);
                 *             this.__collectBuffers(Object.values(parameters));
                 *
                 *             return super.process(
                 *                 (inputs.map((input) => input.some((channelData) => channelData.length === 0)) ? [ ] : input),
                 *                 outputs,
                 *                 parameters
                 *             );
                 *         }
                 *
                 *     })
                 * );
                 *
                 * registerProcessor(`__sac${currentIndex}`, class extends AudioWorkletProcessor{
                 *
                 *     process () {
                 *         return false;
                 *     }
                 *
                 * })`
                 * ```
                 */ const memberDefinition = isSupportingPostMessage ? '' : '__c = (a) => a.forEach(e=>this.__b.add(e.buffer));';
            const bufferRegistration = isSupportingPostMessage ? '' : 'i.forEach(this.__c);o.forEach(this.__c);this.__c(Object.values(p));';
            const wrappedSource = `${importStatements};((AudioWorkletProcessor,registerProcessor)=>{${sourceWithoutImportStatements}\n})(${patchedAudioWorkletProcessor},(n,p)=>registerProcessor(n,class extends p{${memberDefinition}process(i,o,p){${bufferRegistration}return super.process(i.map(j=>j.some(k=>k.length===0)?[]:j),o,p)}}));registerProcessor('__sac${currentIndex}',class extends AudioWorkletProcessor{process(){return !1}})`;
            const blob = new Blob([
                wrappedSource
            ], {
                type: 'application/javascript; charset=utf-8'
            });
            const url = URL.createObjectURL(blob);
            return nativeContext.audioWorklet.addModule(url, options).then(()=>{
                if (isNativeOfflineAudioContext(nativeContext)) return nativeContext;
                // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.
                const backupOfflineAudioContext = getOrCreateBackupOfflineAudioContext(nativeContext);
                return backupOfflineAudioContext.audioWorklet.addModule(url, options).then(()=>backupOfflineAudioContext
                );
            }).then((nativeContextOrBackupOfflineAudioContext)=>{
                if (nativeAudioWorkletNodeConstructor === null) throw new SyntaxError();
                try {
                    // Bug #190: Safari doesn't throw an error when loading an unparsable module.
                    new nativeAudioWorkletNodeConstructor(nativeContextOrBackupOfflineAudioContext, `__sac${currentIndex}`); // tslint:disable-line:no-unused-expression
                } catch  {
                    throw new SyntaxError();
                }
            }).finally(()=>URL.revokeObjectURL(url)
            );
        });
        if (ongoingRequestsOfContext === undefined) ongoingRequests.set(context, new Map([
            [
                moduleURL,
                promise
            ]
        ]));
        else ongoingRequestsOfContext.set(moduleURL, promise);
        promise.then(()=>{
            const updatedResolvedRequestsOfContext = resolvedRequests.get(context);
            if (updatedResolvedRequestsOfContext === undefined) resolvedRequests.set(context, new Set([
                moduleURL
            ]));
            else updatedResolvedRequestsOfContext.add(moduleURL);
        }).finally(()=>{
            const updatedOngoingRequestsOfContext = ongoingRequests.get(context);
            if (updatedOngoingRequestsOfContext !== undefined) updatedOngoingRequestsOfContext.delete(moduleURL);
        });
        return promise;
    };
};

},{"../globals":"80KZG","../helpers/is-constructible":"iJWGZ","../helpers/split-import-statements":"gU2ra","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"80KZG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ACTIVE_AUDIO_NODE_STORE", ()=>ACTIVE_AUDIO_NODE_STORE
);
parcelHelpers.export(exports, "AUDIO_NODE_CONNECTIONS_STORE", ()=>AUDIO_NODE_CONNECTIONS_STORE
);
parcelHelpers.export(exports, "AUDIO_NODE_STORE", ()=>AUDIO_NODE_STORE
);
parcelHelpers.export(exports, "AUDIO_PARAM_CONNECTIONS_STORE", ()=>AUDIO_PARAM_CONNECTIONS_STORE
);
parcelHelpers.export(exports, "AUDIO_PARAM_STORE", ()=>AUDIO_PARAM_STORE
);
parcelHelpers.export(exports, "CONTEXT_STORE", ()=>CONTEXT_STORE
);
parcelHelpers.export(exports, "EVENT_LISTENERS", ()=>EVENT_LISTENERS
);
parcelHelpers.export(exports, "CYCLE_COUNTERS", ()=>CYCLE_COUNTERS
);
parcelHelpers.export(exports, "NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS", ()=>NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS
);
parcelHelpers.export(exports, "NODE_TO_PROCESSOR_MAPS", ()=>NODE_TO_PROCESSOR_MAPS
);
const ACTIVE_AUDIO_NODE_STORE = new WeakSet();
const AUDIO_NODE_CONNECTIONS_STORE = new WeakMap();
const AUDIO_NODE_STORE = new WeakMap();
const AUDIO_PARAM_CONNECTIONS_STORE = new WeakMap();
const AUDIO_PARAM_STORE = new WeakMap();
const CONTEXT_STORE = new WeakMap();
const EVENT_LISTENERS = new WeakMap();
const CYCLE_COUNTERS = new WeakMap();
const NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS = new WeakMap();
const NODE_TO_PROCESSOR_MAPS = new WeakMap();

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iJWGZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isConstructible", ()=>isConstructible
);
const handler = {
    construct () {
        return handler;
    }
};
const isConstructible = (constructible)=>{
    try {
        const proxy = new Proxy(constructible, handler);
        new proxy(); // tslint:disable-line:no-unused-expression
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gU2ra":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "splitImportStatements", ()=>splitImportStatements
);
/*
 * This massive regex tries to cover all the following cases.
 *
 * import './path';
 * import defaultImport from './path';
 * import { namedImport } from './path';
 * import { namedImport as renamendImport } from './path';
 * import * as namespaceImport from './path';
 * import defaultImport, { namedImport } from './path';
 * import defaultImport, { namedImport as renamendImport } from './path';
 * import defaultImport, * as namespaceImport from './path';
 */ const IMPORT_STATEMENT_REGEX = /^import(?:(?:[\s]+[\w]+|(?:[\s]+[\w]+[\s]*,)?[\s]*\{[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?(?:[\s]*,[\s]*[\w]+(?:[\s]+as[\s]+[\w]+)?)*[\s]*}|(?:[\s]+[\w]+[\s]*,)?[\s]*\*[\s]+as[\s]+[\w]+)[\s]+from)?(?:[\s]*)("([^"\\]|\\.)+"|'([^'\\]|\\.)+')(?:[\s]*);?/; // tslint:disable-line:max-line-length
const splitImportStatements = (source, url)=>{
    const importStatements = [];
    let sourceWithoutImportStatements = source.replace(/^[\s]+/, '');
    let result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);
    while(result !== null){
        const unresolvedUrl = result[1].slice(1, -1);
        const importStatementWithResolvedUrl = result[0].replace(/([\s]+)?;?$/, '').replace(unresolvedUrl, new URL(unresolvedUrl, url).toString());
        importStatements.push(importStatementWithResolvedUrl);
        sourceWithoutImportStatements = sourceWithoutImportStatements.slice(result[0].length).replace(/^[\s]+/, '');
        result = sourceWithoutImportStatements.match(IMPORT_STATEMENT_REGEX);
    }
    return [
        importStatements.join(';'),
        sourceWithoutImportStatements
    ];
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cLQHj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddConnectionToAudioNode", ()=>createAddConnectionToAudioNode
);
var _deletePassiveInputConnectionToAudioNode = require("../helpers/delete-passive-input-connection-to-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassiveWhenNecessary = require("../helpers/set-internal-state-to-passive-when-necessary");
const createAddConnectionToAudioNode = (addActiveInputConnectionToAudioNode, addPassiveInputConnectionToAudioNode, connectNativeAudioNodeToNativeAudioNode, deleteActiveInputConnectionToAudioNode, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getAudioNodeTailTime, getEventListenersOfAudioNode, getNativeAudioNode, insertElementInSet, isActiveAudioNode, isPartOfACycle, isPassiveAudioNode)=>{
    const tailTimeTimeoutIds = new WeakMap();
    return (source, destination, output, input, isOffline)=>{
        const { activeInputs , passiveInputs  } = getAudioNodeConnections(destination);
        const { outputs  } = getAudioNodeConnections(source);
        const eventListeners = getEventListenersOfAudioNode(source);
        const eventListener = (isActive)=>{
            const nativeDestinationAudioNode = getNativeAudioNode(destination);
            const nativeSourceAudioNode = getNativeAudioNode(source);
            if (isActive) {
                const partialConnection = _deletePassiveInputConnectionToAudioNode.deletePassiveInputConnectionToAudioNode(passiveInputs, source, output, input);
                addActiveInputConnectionToAudioNode(activeInputs, source, partialConnection, false);
                if (!isOffline && !isPartOfACycle(source)) connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);
                if (isPassiveAudioNode(destination)) _setInternalStateToActive.setInternalStateToActive(destination);
            } else {
                const partialConnection = deleteActiveInputConnectionToAudioNode(activeInputs, source, output, input);
                addPassiveInputConnectionToAudioNode(passiveInputs, input, partialConnection, false);
                if (!isOffline && !isPartOfACycle(source)) disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output, input);
                const tailTime = getAudioNodeTailTime(destination);
                if (tailTime === 0) {
                    if (isActiveAudioNode(destination)) _setInternalStateToPassiveWhenNecessary.setInternalStateToPassiveWhenNecessary(destination, activeInputs);
                } else {
                    const tailTimeTimeoutId = tailTimeTimeoutIds.get(destination);
                    if (tailTimeTimeoutId !== undefined) clearTimeout(tailTimeTimeoutId);
                    tailTimeTimeoutIds.set(destination, setTimeout(()=>{
                        if (isActiveAudioNode(destination)) _setInternalStateToPassiveWhenNecessary.setInternalStateToPassiveWhenNecessary(destination, activeInputs);
                    }, tailTime * 1000));
                }
            }
        };
        if (insertElementInSet(outputs, [
            destination,
            output,
            input
        ], (outputConnection)=>outputConnection[0] === destination && outputConnection[1] === output && outputConnection[2] === input
        , true)) {
            eventListeners.add(eventListener);
            if (isActiveAudioNode(source)) addActiveInputConnectionToAudioNode(activeInputs, source, [
                output,
                input,
                eventListener
            ], true);
            else addPassiveInputConnectionToAudioNode(passiveInputs, input, [
                source,
                output,
                eventListener
            ], true);
            return true;
        }
        return false;
    };
};

},{"../helpers/delete-passive-input-connection-to-audio-node":"doPzE","../helpers/set-internal-state-to-active":"21L0g","../helpers/set-internal-state-to-passive-when-necessary":"i6w3c","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"doPzE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deletePassiveInputConnectionToAudioNode", ()=>deletePassiveInputConnectionToAudioNode
);
var _getValueForKey = require("./get-value-for-key");
var _pickElementFromSet = require("./pick-element-from-set");
const deletePassiveInputConnectionToAudioNode = (passiveInputs, source, output, input)=>{
    const passiveInputConnections = _getValueForKey.getValueForKey(passiveInputs, source);
    const matchingConnection = _pickElementFromSet.pickElementFromSet(passiveInputConnections, (passiveInputConnection)=>passiveInputConnection[0] === output && passiveInputConnection[1] === input
    );
    if (passiveInputConnections.size === 0) passiveInputs.delete(source);
    return matchingConnection;
};

},{"./get-value-for-key":"ktCVX","./pick-element-from-set":"hKh0z","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ktCVX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getValueForKey", ()=>getValueForKey
);
const getValueForKey = (map, key)=>{
    const value = map.get(key);
    if (value === undefined) throw new Error('A value with the given key could not be found.');
    return value;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hKh0z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "pickElementFromSet", ()=>pickElementFromSet
);
const pickElementFromSet = (set, predicate)=>{
    const matchingElements = Array.from(set).filter(predicate);
    if (matchingElements.length > 1) throw Error('More than one element was found.');
    if (matchingElements.length === 0) throw Error('No element was found.');
    const [matchingElement] = matchingElements;
    set.delete(matchingElement);
    return matchingElement;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"21L0g":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setInternalStateToActive", ()=>setInternalStateToActive
);
var _globals = require("../globals");
var _getEventListenersOfAudioNode = require("./get-event-listeners-of-audio-node");
const setInternalStateToActive = (audioNode)=>{
    if (_globals.ACTIVE_AUDIO_NODE_STORE.has(audioNode)) throw new Error('The AudioNode is already stored.');
    _globals.ACTIVE_AUDIO_NODE_STORE.add(audioNode);
    _getEventListenersOfAudioNode.getEventListenersOfAudioNode(audioNode).forEach((eventListener)=>eventListener(true)
    );
};

},{"../globals":"80KZG","./get-event-listeners-of-audio-node":"5ePnU","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5ePnU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getEventListenersOfAudioNode", ()=>getEventListenersOfAudioNode
);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getEventListenersOfAudioNode = (audioNode)=>{
    return _getValueForKey.getValueForKey(_globals.EVENT_LISTENERS, audioNode);
};

},{"../globals":"80KZG","./get-value-for-key":"ktCVX","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"i6w3c":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setInternalStateToPassiveWhenNecessary", ()=>setInternalStateToPassiveWhenNecessary
);
var _audioWorkletNode = require("../guards/audio-worklet-node");
var _setInternalStateToPassive = require("./set-internal-state-to-passive");
const setInternalStateToPassiveWhenNecessary = (audioNode, activeInputs)=>{
    if (!_audioWorkletNode.isAudioWorkletNode(audioNode) && activeInputs.every((connections)=>connections.size === 0
    )) _setInternalStateToPassive.setInternalStateToPassive(audioNode);
};

},{"../guards/audio-worklet-node":"5Lz30","./set-internal-state-to-passive":"37J9v","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5Lz30":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isAudioWorkletNode", ()=>isAudioWorkletNode
);
const isAudioWorkletNode = (audioNode)=>{
    return 'port' in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"37J9v":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setInternalStateToPassive", ()=>setInternalStateToPassive
);
var _globals = require("../globals");
var _getEventListenersOfAudioNode = require("./get-event-listeners-of-audio-node");
const setInternalStateToPassive = (audioNode)=>{
    if (!_globals.ACTIVE_AUDIO_NODE_STORE.has(audioNode)) throw new Error('The AudioNode is not stored.');
    _globals.ACTIVE_AUDIO_NODE_STORE.delete(audioNode);
    _getEventListenersOfAudioNode.getEventListenersOfAudioNode(audioNode).forEach((eventListener)=>eventListener(false)
    );
};

},{"../globals":"80KZG","./get-event-listeners-of-audio-node":"5ePnU","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"i68wf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddPassiveInputConnectionToAudioNode", ()=>createAddPassiveInputConnectionToAudioNode
);
const createAddPassiveInputConnectionToAudioNode = (insertElementInSet)=>{
    return (passiveInputs, input, [source, output, eventListener], ignoreDuplicates)=>{
        const passiveInputConnections = passiveInputs.get(source);
        if (passiveInputConnections === undefined) passiveInputs.set(source, new Set([
            [
                output,
                input,
                eventListener
            ]
        ]));
        else insertElementInSet(passiveInputConnections, [
            output,
            input,
            eventListener
        ], (passiveInputConnection)=>passiveInputConnection[0] === output && passiveInputConnection[1] === input
        , ignoreDuplicates);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"YYbtB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddSilentConnection", ()=>createAddSilentConnection
);
const createAddSilentConnection = (createNativeGainNode)=>{
    return (nativeContext, nativeAudioScheduledSourceNode)=>{
        const nativeGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: 'explicit',
            channelInterpretation: 'discrete',
            gain: 0
        });
        nativeAudioScheduledSourceNode.connect(nativeGainNode).connect(nativeContext.destination);
        const disconnect = ()=>{
            nativeAudioScheduledSourceNode.removeEventListener('ended', disconnect);
            nativeAudioScheduledSourceNode.disconnect(nativeGainNode);
            nativeGainNode.disconnect();
        };
        nativeAudioScheduledSourceNode.addEventListener('ended', disconnect);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fZfR9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAddUnrenderedAudioWorkletNode", ()=>createAddUnrenderedAudioWorkletNode
);
const createAddUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes)=>{
    return (nativeContext, audioWorkletNode)=>{
        getUnrenderedAudioWorkletNodes(nativeContext).add(audioWorkletNode);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fjwCz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAnalyserNodeConstructor", ()=>createAnalyserNodeConstructor
);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers',
    fftSize: 2048,
    maxDecibels: -30,
    minDecibels: -100,
    smoothingTimeConstant: 0.8
};
const createAnalyserNodeConstructor = (audionNodeConstructor, createAnalyserNodeRenderer, createIndexSizeError, createNativeAnalyserNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class AnalyserNode1 extends audionNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeAnalyserNode = createNativeAnalyserNode(nativeContext, mergedOptions);
            const analyserNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createAnalyserNodeRenderer() : null;
            super(context, false, nativeAnalyserNode, analyserNodeRenderer);
            this._nativeAnalyserNode = nativeAnalyserNode;
        }
        get fftSize() {
            return this._nativeAnalyserNode.fftSize;
        }
        set fftSize(value) {
            this._nativeAnalyserNode.fftSize = value;
        }
        get frequencyBinCount() {
            return this._nativeAnalyserNode.frequencyBinCount;
        }
        get maxDecibels() {
            return this._nativeAnalyserNode.maxDecibels;
        }
        set maxDecibels(value) {
            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
            const maxDecibels = this._nativeAnalyserNode.maxDecibels;
            this._nativeAnalyserNode.maxDecibels = value;
            if (!(value > this._nativeAnalyserNode.minDecibels)) {
                this._nativeAnalyserNode.maxDecibels = maxDecibels;
                throw createIndexSizeError();
            }
        }
        get minDecibels() {
            return this._nativeAnalyserNode.minDecibels;
        }
        set minDecibels(value) {
            // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
            const minDecibels = this._nativeAnalyserNode.minDecibels;
            this._nativeAnalyserNode.minDecibels = value;
            if (!(this._nativeAnalyserNode.maxDecibels > value)) {
                this._nativeAnalyserNode.minDecibels = minDecibels;
                throw createIndexSizeError();
            }
        }
        get smoothingTimeConstant() {
            return this._nativeAnalyserNode.smoothingTimeConstant;
        }
        set smoothingTimeConstant(value) {
            this._nativeAnalyserNode.smoothingTimeConstant = value;
        }
        getByteFrequencyData(array) {
            this._nativeAnalyserNode.getByteFrequencyData(array);
        }
        getByteTimeDomainData(array) {
            this._nativeAnalyserNode.getByteTimeDomainData(array);
        }
        getFloatFrequencyData(array) {
            this._nativeAnalyserNode.getFloatFrequencyData(array);
        }
        getFloatTimeDomainData(array) {
            this._nativeAnalyserNode.getFloatTimeDomainData(array);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lt2g3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAnalyserNodeRendererFactory", ()=>createAnalyserNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createAnalyserNodeRendererFactory = (createNativeAnalyserNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAnalyserNodes = new WeakMap();
        const createAnalyserNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeAnalyserNode = getNativeAudioNode(proxy);
            // If the initially used nativeAnalyserNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAnalyserNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeAnalyserNode, nativeOfflineAudioContext);
            if (!nativeAnalyserNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAnalyserNode.channelCount,
                    channelCountMode: nativeAnalyserNode.channelCountMode,
                    channelInterpretation: nativeAnalyserNode.channelInterpretation,
                    fftSize: nativeAnalyserNode.fftSize,
                    maxDecibels: nativeAnalyserNode.maxDecibels,
                    minDecibels: nativeAnalyserNode.minDecibels,
                    smoothingTimeConstant: nativeAnalyserNode.smoothingTimeConstant
                };
                nativeAnalyserNode = createNativeAnalyserNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAnalyserNodes.set(nativeOfflineAudioContext, nativeAnalyserNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAnalyserNode, trace);
            return nativeAnalyserNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeAnalyserNode = renderedNativeAnalyserNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAnalyserNode !== undefined) return Promise.resolve(renderedNativeAnalyserNode);
                return createAnalyserNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fFON4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isOwnedByContext", ()=>isOwnedByContext
);
const isOwnedByContext = (nativeAudioNode, nativeContext)=>{
    return nativeAudioNode.context === nativeContext;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5aodM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioBufferConstructor", ()=>createAudioBufferConstructor
);
var _testAudioBufferCopyChannelMethodsOutOfBoundsSupport = require("../helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support");
var _wrapAudioBufferGetChannelDataMethod = require("../helpers/wrap-audio-buffer-get-channel-data-method");
const DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const createAudioBufferConstructor = (audioBufferStore, cacheTestResult, createNotSupportedError, nativeAudioBufferConstructor, nativeOfflineAudioContextConstructor, testNativeAudioBufferConstructorSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    let nativeOfflineAudioContext = null;
    return class AudioBuffer1 {
        constructor(options){
            if (nativeOfflineAudioContextConstructor === null) throw new Error('Missing the native OfflineAudioContext constructor.');
            const { length , numberOfChannels , sampleRate  } = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            if (nativeOfflineAudioContext === null) nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
            /*
             * Bug #99: Firefox does not throw a NotSupportedError when the numberOfChannels is zero. But it only does it when using the
             * factory function. But since Firefox also supports the constructor everything should be fine.
             */ const audioBuffer = nativeAudioBufferConstructor !== null && cacheTestResult(testNativeAudioBufferConstructorSupport, testNativeAudioBufferConstructorSupport) ? new nativeAudioBufferConstructor({
                length,
                numberOfChannels,
                sampleRate
            }) : nativeOfflineAudioContext.createBuffer(numberOfChannels, length, sampleRate);
            // Bug #99: Safari does not throw an error when the numberOfChannels is zero.
            if (audioBuffer.numberOfChannels === 0) throw createNotSupportedError();
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
            if (typeof audioBuffer.copyFromChannel !== 'function') {
                wrapAudioBufferCopyChannelMethods(audioBuffer);
                _wrapAudioBufferGetChannelDataMethod.wrapAudioBufferGetChannelDataMethod(audioBuffer);
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            } else if (!cacheTestResult(_testAudioBufferCopyChannelMethodsOutOfBoundsSupport.testAudioBufferCopyChannelMethodsOutOfBoundsSupport, ()=>_testAudioBufferCopyChannelMethodsOutOfBoundsSupport.testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer)
            )) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            /*
             * This does violate all good pratices but it is necessary to allow this AudioBuffer to be used with native
             * (Offline)AudioContexts.
             */ return audioBuffer;
        }
        static [Symbol.hasInstance](instance) {
            return instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === AudioBuffer1.prototype || audioBufferStore.has(instance);
        }
    };
};

},{"../helpers/test-audio-buffer-copy-channel-methods-out-of-bounds-support":"jisnd","../helpers/wrap-audio-buffer-get-channel-data-method":"cHHc4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jisnd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioBufferCopyChannelMethodsOutOfBoundsSupport", ()=>testAudioBufferCopyChannelMethodsOutOfBoundsSupport
);
const testAudioBufferCopyChannelMethodsOutOfBoundsSupport = (nativeAudioBuffer)=>{
    try {
        nativeAudioBuffer.copyToChannel(new Float32Array(1), 0, -1);
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cHHc4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioBufferGetChannelDataMethod", ()=>wrapAudioBufferGetChannelDataMethod
);
var _indexSizeError = require("../factories/index-size-error");
const wrapAudioBufferGetChannelDataMethod = (audioBuffer)=>{
    audioBuffer.getChannelData = ((getChannelData)=>{
        return (channel)=>{
            try {
                return getChannelData.call(audioBuffer, channel);
            } catch (err) {
                if (err.code === 12) throw _indexSizeError.createIndexSizeError();
                throw err;
            }
        };
    })(audioBuffer.getChannelData);
};

},{"../factories/index-size-error":"jFao7","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jFao7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIndexSizeError", ()=>createIndexSizeError
);
const createIndexSizeError = ()=>new DOMException('', 'IndexSizeError')
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"in3ti":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioBufferSourceNodeConstructor", ()=>createAudioBufferSourceNodeConstructor
);
var _constants = require("../constants");
var _isActiveAudioNode = require("../helpers/is-active-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassive = require("../helpers/set-internal-state-to-passive");
const DEFAULT_OPTIONS = {
    buffer: null,
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers',
    // Bug #149: Safari does not yet support the detune AudioParam.
    loop: false,
    loopEnd: 0,
    loopStart: 0,
    playbackRate: 1
};
const createAudioBufferSourceNodeConstructor = (audioNodeConstructor, createAudioBufferSourceNodeRenderer, createAudioParam, createInvalidStateError, createNativeAudioBufferSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class AudioBufferSourceNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const audioBufferSourceNodeRenderer = isOffline ? createAudioBufferSourceNodeRenderer() : null;
            super(context, false, nativeAudioBufferSourceNode, audioBufferSourceNodeRenderer);
            this._audioBufferSourceNodeRenderer = audioBufferSourceNodeRenderer;
            this._isBufferNullified = false;
            this._isBufferSet = mergedOptions.buffer !== null;
            this._nativeAudioBufferSourceNode = nativeAudioBufferSourceNode;
            this._onended = null;
            // Bug #73: Safari does not export the correct values for maxValue and minValue.
            this._playbackRate = createAudioParam(this, isOffline, nativeAudioBufferSourceNode.playbackRate, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
        }
        get buffer() {
            if (this._isBufferNullified) return null;
            return this._nativeAudioBufferSourceNode.buffer;
        }
        set buffer(value) {
            this._nativeAudioBufferSourceNode.buffer = value;
            // Bug #72: Only Chrome, Edge & Opera do not allow to reassign the buffer yet.
            if (value !== null) {
                if (this._isBufferSet) throw createInvalidStateError();
                this._isBufferSet = true;
            }
        }
        get loop() {
            return this._nativeAudioBufferSourceNode.loop;
        }
        set loop(value) {
            this._nativeAudioBufferSourceNode.loop = value;
        }
        get loopEnd() {
            return this._nativeAudioBufferSourceNode.loopEnd;
        }
        set loopEnd(value) {
            this._nativeAudioBufferSourceNode.loopEnd = value;
        }
        get loopStart() {
            return this._nativeAudioBufferSourceNode.loopStart;
        }
        set loopStart(value) {
            this._nativeAudioBufferSourceNode.loopStart = value;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
            this._nativeAudioBufferSourceNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeAudioBufferSourceNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        get playbackRate() {
            return this._playbackRate;
        }
        start(when = 0, offset = 0, duration) {
            this._nativeAudioBufferSourceNode.start(when, offset, duration);
            if (this._audioBufferSourceNodeRenderer !== null) this._audioBufferSourceNodeRenderer.start = duration === undefined ? [
                when,
                offset
            ] : [
                when,
                offset,
                duration
            ];
            if (this.context.state !== 'closed') {
                _setInternalStateToActive.setInternalStateToActive(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeAudioBufferSourceNode.removeEventListener('ended', resetInternalStateToPassive);
                    if (_isActiveAudioNode.isActiveAudioNode(this)) _setInternalStateToPassive.setInternalStateToPassive(this);
                };
                this._nativeAudioBufferSourceNode.addEventListener('ended', resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeAudioBufferSourceNode.stop(when);
            if (this._audioBufferSourceNodeRenderer !== null) this._audioBufferSourceNodeRenderer.stop = when;
        }
    };
};

},{"../constants":"dG3Pl","../helpers/is-active-audio-node":"3g5Fl","../helpers/set-internal-state-to-active":"21L0g","../helpers/set-internal-state-to-passive":"37J9v","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dG3Pl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "MOST_NEGATIVE_SINGLE_FLOAT", ()=>MOST_NEGATIVE_SINGLE_FLOAT
);
parcelHelpers.export(exports, "MOST_POSITIVE_SINGLE_FLOAT", ()=>MOST_POSITIVE_SINGLE_FLOAT
);
const MOST_NEGATIVE_SINGLE_FLOAT = -340282346638528860000000000000000000000;
const MOST_POSITIVE_SINGLE_FLOAT = -MOST_NEGATIVE_SINGLE_FLOAT;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3g5Fl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isActiveAudioNode", ()=>isActiveAudioNode
);
var _globals = require("../globals");
const isActiveAudioNode = (audioNode)=>_globals.ACTIVE_AUDIO_NODE_STORE.has(audioNode)
;

},{"../globals":"80KZG","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gmYEM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioBufferSourceNodeRendererFactory", ()=>createAudioBufferSourceNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createAudioBufferSourceNodeRendererFactory = (connectAudioParam, createNativeAudioBufferSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioBufferSourceNodes = new WeakMap();
        let start = null;
        let stop = null;
        const createAudioBufferSourceNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeAudioBufferSourceNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeAudioBufferSourceNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeAudioBufferSourceNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeAudioBufferSourceNode, nativeOfflineAudioContext);
            if (!nativeAudioBufferSourceNodeIsOwnedByContext) {
                const options = {
                    buffer: nativeAudioBufferSourceNode.buffer,
                    channelCount: nativeAudioBufferSourceNode.channelCount,
                    channelCountMode: nativeAudioBufferSourceNode.channelCountMode,
                    channelInterpretation: nativeAudioBufferSourceNode.channelInterpretation,
                    // Bug #149: Safari does not yet support the detune AudioParam.
                    loop: nativeAudioBufferSourceNode.loop,
                    loopEnd: nativeAudioBufferSourceNode.loopEnd,
                    loopStart: nativeAudioBufferSourceNode.loopStart,
                    playbackRate: nativeAudioBufferSourceNode.playbackRate.value
                };
                nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeAudioBufferSourceNode.start(...start);
                if (stop !== null) nativeAudioBufferSourceNode.stop(stop);
            }
            renderedNativeAudioBufferSourceNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode);
            if (!nativeAudioBufferSourceNodeIsOwnedByContext) // Bug #149: Safari does not yet support the detune AudioParam.
            await renderAutomation(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate, trace);
            else // Bug #149: Safari does not yet support the detune AudioParam.
            await connectAudioParam(nativeOfflineAudioContext, proxy.playbackRate, nativeAudioBufferSourceNode.playbackRate, trace);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioBufferSourceNode, trace);
            return nativeAudioBufferSourceNode;
        };
        return {
            set start (value){
                start = value;
            },
            set stop (value1){
                stop = value1;
            },
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeAudioBufferSourceNode = renderedNativeAudioBufferSourceNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioBufferSourceNode !== undefined) return Promise.resolve(renderedNativeAudioBufferSourceNode);
                return createAudioBufferSourceNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fHpei":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioContextConstructor", ()=>createAudioContextConstructor
);
var _deactivateAudioGraph = require("../helpers/deactivate-audio-graph");
var _isValidLatencyHint = require("../helpers/is-valid-latency-hint");
const createAudioContextConstructor = (baseAudioContextConstructor, createInvalidStateError, createNotSupportedError, createUnknownError, mediaElementAudioSourceNodeConstructor, mediaStreamAudioDestinationNodeConstructor, mediaStreamAudioSourceNodeConstructor, mediaStreamTrackAudioSourceNodeConstructor, nativeAudioContextConstructor)=>{
    return class AudioContext1 extends baseAudioContextConstructor {
        constructor(options = {
        }){
            if (nativeAudioContextConstructor === null) throw new Error('Missing the native AudioContext constructor.');
            let nativeAudioContext;
            try {
                nativeAudioContext = new nativeAudioContextConstructor(options);
            } catch (err) {
                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.
                if (err.code === 12 && err.message === 'sampleRate is not in range') throw createNotSupportedError();
                throw err;
            }
            // Bug #131 Safari returns null when there are four other AudioContexts running already.
            if (nativeAudioContext === null) throw createUnknownError();
            // Bug #51 Only Chrome, Edge and Opera throw an error if the given latencyHint is invalid.
            if (!_isValidLatencyHint.isValidLatencyHint(options.latencyHint)) throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);
            // Bug #150 Safari does not support setting the sampleRate.
            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) throw createNotSupportedError();
            super(nativeAudioContext, 2);
            const { latencyHint  } = options;
            const { sampleRate  } = nativeAudioContext;
            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.
            this._baseLatency = typeof nativeAudioContext.baseLatency === 'number' ? nativeAudioContext.baseLatency : latencyHint === 'balanced' ? 512 / sampleRate : latencyHint === 'interactive' || latencyHint === undefined ? 256 / sampleRate : latencyHint === 'playback' ? 1024 / sampleRate : /*
                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a
                                   * ScriptProcessorNode.
                                   */ Math.max(2, Math.min(128, Math.round(latencyHint * sampleRate / 128))) * 128 / sampleRate;
            this._nativeAudioContext = nativeAudioContext;
            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.
            if (nativeAudioContextConstructor.name === 'webkitAudioContext') {
                this._nativeGainNode = nativeAudioContext.createGain();
                this._nativeOscillatorNode = nativeAudioContext.createOscillator();
                this._nativeGainNode.gain.value = 0.0000000000000000000000000000000000001;
                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);
                this._nativeOscillatorNode.start();
            } else {
                this._nativeGainNode = null;
                this._nativeOscillatorNode = null;
            }
            this._state = null;
            /*
             * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually
             * changes to 'running'.
             */ if (nativeAudioContext.state === 'running') {
                this._state = 'suspended';
                const revokeState = ()=>{
                    if (this._state === 'suspended') this._state = null;
                    nativeAudioContext.removeEventListener('statechange', revokeState);
                };
                nativeAudioContext.addEventListener('statechange', revokeState);
            }
        }
        get baseLatency() {
            return this._baseLatency;
        }
        get state() {
            return this._state !== null ? this._state : this._nativeAudioContext.state;
        }
        close() {
            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
            if (this.state === 'closed') return this._nativeAudioContext.close().then(()=>{
                throw createInvalidStateError();
            });
            // Bug #34: If the state was set to suspended before it should be revoked now.
            if (this._state === 'suspended') this._state = null;
            return this._nativeAudioContext.close().then(()=>{
                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {
                    this._nativeOscillatorNode.stop();
                    this._nativeGainNode.disconnect();
                    this._nativeOscillatorNode.disconnect();
                }
                _deactivateAudioGraph.deactivateAudioGraph(this);
            });
        }
        createMediaElementSource(mediaElement) {
            return new mediaElementAudioSourceNodeConstructor(this, {
                mediaElement
            });
        }
        createMediaStreamDestination() {
            return new mediaStreamAudioDestinationNodeConstructor(this);
        }
        createMediaStreamSource(mediaStream) {
            return new mediaStreamAudioSourceNodeConstructor(this, {
                mediaStream
            });
        }
        createMediaStreamTrackSource(mediaStreamTrack) {
            return new mediaStreamTrackAudioSourceNodeConstructor(this, {
                mediaStreamTrack
            });
        }
        resume() {
            if (this._state === 'suspended') return new Promise((resolve, reject)=>{
                const resolvePromise = ()=>{
                    this._nativeAudioContext.removeEventListener('statechange', resolvePromise);
                    if (this._nativeAudioContext.state === 'running') resolve();
                    else this.resume().then(resolve, reject);
                };
                this._nativeAudioContext.addEventListener('statechange', resolvePromise);
            });
            return this._nativeAudioContext.resume().catch((err)=>{
                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined || err.code === 15) throw createInvalidStateError();
                throw err;
            });
        }
        suspend() {
            return this._nativeAudioContext.suspend().catch((err)=>{
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined) throw createInvalidStateError();
                throw err;
            });
        }
    };
};

},{"../helpers/deactivate-audio-graph":"kkyz8","../helpers/is-valid-latency-hint":"laOam","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kkyz8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deactivateAudioGraph", ()=>deactivateAudioGraph
);
var _deactivateActiveAudioNodeInputConnections = require("./deactivate-active-audio-node-input-connections");
const deactivateAudioGraph = (context)=>{
    _deactivateActiveAudioNodeInputConnections.deactivateActiveAudioNodeInputConnections(context.destination, []);
};

},{"./deactivate-active-audio-node-input-connections":"8NUHo","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8NUHo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deactivateActiveAudioNodeInputConnections", ()=>deactivateActiveAudioNodeInputConnections
);
var _audioBufferSourceNode = require("../guards/audio-buffer-source-node");
var _audioWorkletNode = require("../guards/audio-worklet-node");
var _biquadFilterNode = require("../guards/biquad-filter-node");
var _constantSourceNode = require("../guards/constant-source-node");
var _gainNode = require("../guards/gain-node");
var _oscillatorNode = require("../guards/oscillator-node");
var _stereoPannerNode = require("../guards/stereo-panner-node");
var _getAudioNodeConnections = require("./get-audio-node-connections");
var _getAudioParamConnections = require("./get-audio-param-connections");
var _isActiveAudioNode = require("./is-active-audio-node");
var _setInternalStateToPassive = require("./set-internal-state-to-passive");
const deactivateActiveAudioNodeInputConnections = (audioNode, trace)=>{
    const { activeInputs  } = _getAudioNodeConnections.getAudioNodeConnections(audioNode);
    activeInputs.forEach((connections)=>connections.forEach(([source])=>{
            if (!trace.includes(audioNode)) deactivateActiveAudioNodeInputConnections(source, [
                ...trace,
                audioNode
            ]);
        })
    );
    const audioParams = _audioBufferSourceNode.isAudioBufferSourceNode(audioNode) ? [
        // Bug #149: Safari does not yet support the detune AudioParam.
        audioNode.playbackRate
    ] : _audioWorkletNode.isAudioWorkletNode(audioNode) ? Array.from(audioNode.parameters.values()) : _biquadFilterNode.isBiquadFilterNode(audioNode) ? [
        audioNode.Q,
        audioNode.detune,
        audioNode.frequency,
        audioNode.gain
    ] : _constantSourceNode.isConstantSourceNode(audioNode) ? [
        audioNode.offset
    ] : _gainNode.isGainNode(audioNode) ? [
        audioNode.gain
    ] : _oscillatorNode.isOscillatorNode(audioNode) ? [
        audioNode.detune,
        audioNode.frequency
    ] : _stereoPannerNode.isStereoPannerNode(audioNode) ? [
        audioNode.pan
    ] : [];
    for (const audioParam of audioParams){
        const audioParamConnections = _getAudioParamConnections.getAudioParamConnections(audioParam);
        if (audioParamConnections !== undefined) audioParamConnections.activeInputs.forEach(([source])=>deactivateActiveAudioNodeInputConnections(source, trace)
        );
    }
    if (_isActiveAudioNode.isActiveAudioNode(audioNode)) _setInternalStateToPassive.setInternalStateToPassive(audioNode);
};

},{"../guards/audio-buffer-source-node":"b4KMX","../guards/audio-worklet-node":"5Lz30","../guards/biquad-filter-node":"9eEIa","../guards/constant-source-node":"99WNr","../guards/gain-node":"376wC","../guards/oscillator-node":"4QH2J","../guards/stereo-panner-node":"8JPzv","./get-audio-node-connections":"b9slo","./get-audio-param-connections":"elnXq","./is-active-audio-node":"3g5Fl","./set-internal-state-to-passive":"37J9v","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b4KMX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isAudioBufferSourceNode", ()=>isAudioBufferSourceNode
);
const isAudioBufferSourceNode = (audioNode)=>{
    return 'playbackRate' in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9eEIa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isBiquadFilterNode", ()=>isBiquadFilterNode
);
const isBiquadFilterNode = (audioNode)=>{
    return 'frequency' in audioNode && 'gain' in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"99WNr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isConstantSourceNode", ()=>isConstantSourceNode
);
const isConstantSourceNode = (audioNode)=>{
    return 'offset' in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"376wC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isGainNode", ()=>isGainNode
);
const isGainNode = (audioNode)=>{
    return !('frequency' in audioNode) && 'gain' in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4QH2J":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isOscillatorNode", ()=>isOscillatorNode
);
const isOscillatorNode = (audioNode)=>{
    return 'detune' in audioNode && 'frequency' in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8JPzv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isStereoPannerNode", ()=>isStereoPannerNode
);
const isStereoPannerNode = (audioNode)=>{
    return 'pan' in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b9slo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getAudioNodeConnections", ()=>getAudioNodeConnections
);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getAudioNodeConnections = (audioNode)=>{
    return _getValueForKey.getValueForKey(_globals.AUDIO_NODE_CONNECTIONS_STORE, audioNode);
};

},{"../globals":"80KZG","./get-value-for-key":"ktCVX","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"elnXq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getAudioParamConnections", ()=>getAudioParamConnections
);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getAudioParamConnections = (audioParam)=>{
    return _getValueForKey.getValueForKey(_globals.AUDIO_PARAM_CONNECTIONS_STORE, audioParam);
};

},{"../globals":"80KZG","./get-value-for-key":"ktCVX","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"laOam":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isValidLatencyHint", ()=>isValidLatencyHint
);
const isValidLatencyHint = (latencyHint)=>{
    return latencyHint === undefined || typeof latencyHint === 'number' || typeof latencyHint === 'string' && (latencyHint === 'balanced' || latencyHint === 'interactive' || latencyHint === 'playback');
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bFUCJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioDestinationNodeConstructor", ()=>createAudioDestinationNodeConstructor
);
const createAudioDestinationNodeConstructor = (audioNodeConstructor, createAudioDestinationNodeRenderer, createIndexSizeError, createInvalidStateError, createNativeAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext, renderInputsOfAudioNode)=>{
    return class AudioDestinationNode1 extends audioNodeConstructor {
        constructor(context, channelCount){
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const nativeAudioDestinationNode = createNativeAudioDestinationNode(nativeContext, channelCount, isOffline);
            const audioDestinationNodeRenderer = isOffline ? createAudioDestinationNodeRenderer(renderInputsOfAudioNode) : null;
            super(context, false, nativeAudioDestinationNode, audioDestinationNodeRenderer);
            this._isNodeOfNativeOfflineAudioContext = isOffline;
            this._nativeAudioDestinationNode = nativeAudioDestinationNode;
        }
        get channelCount() {
            return this._nativeAudioDestinationNode.channelCount;
        }
        set channelCount(value) {
            // Bug #52: Chrome, Edge, Opera & Safari do not throw an exception at all.
            // Bug #54: Firefox does throw an IndexSizeError.
            if (this._isNodeOfNativeOfflineAudioContext) throw createInvalidStateError();
            // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.
            if (value > this._nativeAudioDestinationNode.maxChannelCount) throw createIndexSizeError();
            this._nativeAudioDestinationNode.channelCount = value;
        }
        get channelCountMode() {
            return this._nativeAudioDestinationNode.channelCountMode;
        }
        set channelCountMode(value) {
            // Bug #53: No browser does throw an exception yet.
            if (this._isNodeOfNativeOfflineAudioContext) throw createInvalidStateError();
            this._nativeAudioDestinationNode.channelCountMode = value;
        }
        get maxChannelCount() {
            return this._nativeAudioDestinationNode.maxChannelCount;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cX5aF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioDestinationNodeRenderer", ()=>createAudioDestinationNodeRenderer
);
const createAudioDestinationNodeRenderer = (renderInputsOfAudioNode)=>{
    let nativeAudioDestinationNodePromise = null;
    const createAudioDestinationNode = async (proxy, nativeOfflineAudioContext, trace)=>{
        const nativeAudioDestinationNode = nativeOfflineAudioContext.destination;
        await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioDestinationNode, trace);
        return nativeAudioDestinationNode;
    };
    return {
        render (proxy, nativeOfflineAudioContext, trace) {
            if (nativeAudioDestinationNodePromise === null) nativeAudioDestinationNodePromise = createAudioDestinationNode(proxy, nativeOfflineAudioContext, trace);
            return nativeAudioDestinationNodePromise;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lRosi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioListenerFactory", ()=>createAudioListenerFactory
);
var _constants = require("../constants");
const createAudioListenerFactory = (createAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeScriptProcessorNode, createNotSupportedError, getFirstSample, isNativeOfflineAudioContext, overwriteAccessors)=>{
    return (context, nativeContext)=>{
        const nativeListener = nativeContext.listener;
        // Bug #117: Only Chrome, Edge & Opera support the new interface already.
        const createFakeAudioParams = ()=>{
            const buffer = new Float32Array(1);
            const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'speakers',
                numberOfInputs: 9
            });
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            let isScriptProcessorNodeCreated = false;
            let lastOrientation = [
                0,
                0,
                -1,
                0,
                1,
                0
            ];
            let lastPosition = [
                0,
                0,
                0
            ];
            const createScriptProcessorNode = ()=>{
                if (isScriptProcessorNodeCreated) return;
                isScriptProcessorNodeCreated = true;
                const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 9, 0);
                // tslint:disable-next-line:deprecation
                scriptProcessorNode.onaudioprocess = ({ inputBuffer  })=>{
                    const orientation = [
                        getFirstSample(inputBuffer, buffer, 0),
                        getFirstSample(inputBuffer, buffer, 1),
                        getFirstSample(inputBuffer, buffer, 2),
                        getFirstSample(inputBuffer, buffer, 3),
                        getFirstSample(inputBuffer, buffer, 4),
                        getFirstSample(inputBuffer, buffer, 5)
                    ];
                    if (orientation.some((value, index)=>value !== lastOrientation[index]
                    )) {
                        nativeListener.setOrientation(...orientation); // tslint:disable-line:deprecation
                        lastOrientation = orientation;
                    }
                    const positon = [
                        getFirstSample(inputBuffer, buffer, 6),
                        getFirstSample(inputBuffer, buffer, 7),
                        getFirstSample(inputBuffer, buffer, 8)
                    ];
                    if (positon.some((value, index)=>value !== lastPosition[index]
                    )) {
                        nativeListener.setPosition(...positon); // tslint:disable-line:deprecation
                        lastPosition = positon;
                    }
                };
                channelMergerNode.connect(scriptProcessorNode);
            };
            const createSetOrientation = (index)=>(value)=>{
                    if (value !== lastOrientation[index]) {
                        lastOrientation[index] = value;
                        nativeListener.setOrientation(...lastOrientation); // tslint:disable-line:deprecation
                    }
                }
            ;
            const createSetPosition = (index)=>(value)=>{
                    if (value !== lastPosition[index]) {
                        lastPosition[index] = value;
                        nativeListener.setPosition(...lastPosition); // tslint:disable-line:deprecation
                    }
                }
            ;
            const createFakeAudioParam = (input, initialValue, setValue)=>{
                const constantSourceNode = createNativeConstantSourceNode(nativeContext, {
                    channelCount: 1,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'discrete',
                    offset: initialValue
                });
                constantSourceNode.connect(channelMergerNode, 0, input);
                // @todo This should be stopped when the context is closed.
                constantSourceNode.start();
                Object.defineProperty(constantSourceNode.offset, 'defaultValue', {
                    get () {
                        return initialValue;
                    }
                });
                /*
                 * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and
                 * minValue for GainNodes.
                 */ const audioParam = createAudioParam({
                    context
                }, isOffline, constantSourceNode.offset, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
                overwriteAccessors(audioParam, 'value', (get)=>()=>get.call(audioParam)
                , (set)=>(value)=>{
                        try {
                            set.call(audioParam, value);
                        } catch (err) {
                            if (err.code !== 9) throw err;
                        }
                        createScriptProcessorNode();
                        if (isOffline) // Bug #117: Using setOrientation() and setPosition() doesn't work with an OfflineAudioContext.
                        setValue(value);
                    }
                );
                audioParam.cancelAndHoldAtTime = ((cancelAndHoldAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = cancelAndHoldAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.cancelAndHoldAtTime);
                audioParam.cancelScheduledValues = ((cancelScheduledValues)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = cancelScheduledValues.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.cancelScheduledValues);
                audioParam.exponentialRampToValueAtTime = ((exponentialRampToValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = exponentialRampToValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.exponentialRampToValueAtTime);
                audioParam.linearRampToValueAtTime = ((linearRampToValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = linearRampToValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.linearRampToValueAtTime);
                audioParam.setTargetAtTime = ((setTargetAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setTargetAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setTargetAtTime);
                audioParam.setValueAtTime = ((setValueAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setValueAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setValueAtTime);
                audioParam.setValueCurveAtTime = ((setValueCurveAtTime)=>{
                    if (isOffline) return ()=>{
                        throw createNotSupportedError();
                    };
                    return (...args)=>{
                        const value = setValueCurveAtTime.apply(audioParam, args);
                        createScriptProcessorNode();
                        return value;
                    };
                })(audioParam.setValueCurveAtTime);
                return audioParam;
            };
            return {
                forwardX: createFakeAudioParam(0, 0, createSetOrientation(0)),
                forwardY: createFakeAudioParam(1, 0, createSetOrientation(1)),
                forwardZ: createFakeAudioParam(2, -1, createSetOrientation(2)),
                positionX: createFakeAudioParam(6, 0, createSetPosition(0)),
                positionY: createFakeAudioParam(7, 0, createSetPosition(1)),
                positionZ: createFakeAudioParam(8, 0, createSetPosition(2)),
                upX: createFakeAudioParam(3, 0, createSetOrientation(3)),
                upY: createFakeAudioParam(4, 1, createSetOrientation(4)),
                upZ: createFakeAudioParam(5, 0, createSetOrientation(5))
            };
        };
        const { forwardX , forwardY , forwardZ , positionX , positionY , positionZ , upX , upY , upZ  } = nativeListener.forwardX === undefined ? createFakeAudioParams() : nativeListener;
        return {
            get forwardX () {
                return forwardX;
            },
            get forwardY () {
                return forwardY;
            },
            get forwardZ () {
                return forwardZ;
            },
            get positionX () {
                return positionX;
            },
            get positionY () {
                return positionY;
            },
            get positionZ () {
                return positionZ;
            },
            get upX () {
                return upX;
            },
            get upY () {
                return upY;
            },
            get upZ () {
                return upZ;
            }
        };
    };
};

},{"../constants":"dG3Pl","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7YZZi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioNodeConstructor", ()=>createAudioNodeConstructor
);
var _globals = require("../globals");
var _audioNode = require("../guards/audio-node");
var _audioNodeOutputConnection = require("../guards/audio-node-output-connection");
var _addActiveInputConnectionToAudioParam = require("../helpers/add-active-input-connection-to-audio-param");
var _addPassiveInputConnectionToAudioParam = require("../helpers/add-passive-input-connection-to-audio-param");
var _connectNativeAudioNodeToNativeAudioNode = require("../helpers/connect-native-audio-node-to-native-audio-node");
var _deleteActiveInputConnection = require("../helpers/delete-active-input-connection");
var _deleteActiveInputConnectionToAudioParam = require("../helpers/delete-active-input-connection-to-audio-param");
var _deleteEventListenersOfAudioNode = require("../helpers/delete-event-listeners-of-audio-node");
var _deletePassiveInputConnectionToAudioNode = require("../helpers/delete-passive-input-connection-to-audio-node");
var _deletePassiveInputConnectionToAudioParam = require("../helpers/delete-passive-input-connection-to-audio-param");
var _disconnectNativeAudioNodeFromNativeAudioNode = require("../helpers/disconnect-native-audio-node-from-native-audio-node");
var _getAudioNodeConnections = require("../helpers/get-audio-node-connections");
var _getAudioParamConnections = require("../helpers/get-audio-param-connections");
var _getEventListenersOfAudioNode = require("../helpers/get-event-listeners-of-audio-node");
var _getNativeAudioNode = require("../helpers/get-native-audio-node");
var _getNativeAudioParam = require("../helpers/get-native-audio-param");
var _insertElementInSet = require("../helpers/insert-element-in-set");
var _isActiveAudioNode = require("../helpers/is-active-audio-node");
var _isPartOfACycle = require("../helpers/is-part-of-a-cycle");
var _isPassiveAudioNode = require("../helpers/is-passive-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassiveWhenNecessary = require("../helpers/set-internal-state-to-passive-when-necessary");
var _testAudioNodeDisconnectMethodSupport = require("../helpers/test-audio-node-disconnect-method-support");
var _visitEachAudioNodeOnce = require("../helpers/visit-each-audio-node-once");
var _wrapAudioNodeDisconnectMethod = require("../helpers/wrap-audio-node-disconnect-method");
const addConnectionToAudioParamOfAudioContext = (source, destination, output, isOffline)=>{
    const { activeInputs , passiveInputs  } = _getAudioParamConnections.getAudioParamConnections(destination);
    const { outputs  } = _getAudioNodeConnections.getAudioNodeConnections(source);
    const eventListeners = _getEventListenersOfAudioNode.getEventListenersOfAudioNode(source);
    const eventListener = (isActive)=>{
        const nativeAudioNode = _getNativeAudioNode.getNativeAudioNode(source);
        const nativeAudioParam = _getNativeAudioParam.getNativeAudioParam(destination);
        if (isActive) {
            const partialConnection = _deletePassiveInputConnectionToAudioParam.deletePassiveInputConnectionToAudioParam(passiveInputs, source, output);
            _addActiveInputConnectionToAudioParam.addActiveInputConnectionToAudioParam(activeInputs, source, partialConnection, false);
            if (!isOffline && !_isPartOfACycle.isPartOfACycle(source)) nativeAudioNode.connect(nativeAudioParam, output);
        } else {
            const partialConnection = _deleteActiveInputConnectionToAudioParam.deleteActiveInputConnectionToAudioParam(activeInputs, source, output);
            _addPassiveInputConnectionToAudioParam.addPassiveInputConnectionToAudioParam(passiveInputs, partialConnection, false);
            if (!isOffline && !_isPartOfACycle.isPartOfACycle(source)) nativeAudioNode.disconnect(nativeAudioParam, output);
        }
    };
    if (_insertElementInSet.insertElementInSet(outputs, [
        destination,
        output
    ], (outputConnection)=>outputConnection[0] === destination && outputConnection[1] === output
    , true)) {
        eventListeners.add(eventListener);
        if (_isActiveAudioNode.isActiveAudioNode(source)) _addActiveInputConnectionToAudioParam.addActiveInputConnectionToAudioParam(activeInputs, source, [
            output,
            eventListener
        ], true);
        else _addPassiveInputConnectionToAudioParam.addPassiveInputConnectionToAudioParam(passiveInputs, [
            source,
            output,
            eventListener
        ], true);
        return true;
    }
    return false;
};
const deleteInputConnectionOfAudioNode = (source, destination, output, input)=>{
    const { activeInputs , passiveInputs  } = _getAudioNodeConnections.getAudioNodeConnections(destination);
    const activeInputConnection = _deleteActiveInputConnection.deleteActiveInputConnection(activeInputs[input], source, output);
    if (activeInputConnection === null) {
        const passiveInputConnection = _deletePassiveInputConnectionToAudioNode.deletePassiveInputConnectionToAudioNode(passiveInputs, source, output, input);
        return [
            passiveInputConnection[2],
            false
        ];
    }
    return [
        activeInputConnection[2],
        true
    ];
};
const deleteInputConnectionOfAudioParam = (source, destination, output)=>{
    const { activeInputs , passiveInputs  } = _getAudioParamConnections.getAudioParamConnections(destination);
    const activeInputConnection = _deleteActiveInputConnection.deleteActiveInputConnection(activeInputs, source, output);
    if (activeInputConnection === null) {
        const passiveInputConnection = _deletePassiveInputConnectionToAudioParam.deletePassiveInputConnectionToAudioParam(passiveInputs, source, output);
        return [
            passiveInputConnection[1],
            false
        ];
    }
    return [
        activeInputConnection[2],
        true
    ];
};
const deleteInputsOfAudioNode = (source, isOffline, destination, output, input)=>{
    const [listener, isActive] = deleteInputConnectionOfAudioNode(source, destination, output, input);
    if (listener !== null) {
        _deleteEventListenersOfAudioNode.deleteEventListenerOfAudioNode(source, listener);
        if (isActive && !isOffline && !_isPartOfACycle.isPartOfACycle(source)) _disconnectNativeAudioNodeFromNativeAudioNode.disconnectNativeAudioNodeFromNativeAudioNode(_getNativeAudioNode.getNativeAudioNode(source), _getNativeAudioNode.getNativeAudioNode(destination), output, input);
    }
    if (_isActiveAudioNode.isActiveAudioNode(destination)) {
        const { activeInputs  } = _getAudioNodeConnections.getAudioNodeConnections(destination);
        _setInternalStateToPassiveWhenNecessary.setInternalStateToPassiveWhenNecessary(destination, activeInputs);
    }
};
const deleteInputsOfAudioParam = (source, isOffline, destination, output)=>{
    const [listener, isActive] = deleteInputConnectionOfAudioParam(source, destination, output);
    if (listener !== null) {
        _deleteEventListenersOfAudioNode.deleteEventListenerOfAudioNode(source, listener);
        if (isActive && !isOffline && !_isPartOfACycle.isPartOfACycle(source)) _getNativeAudioNode.getNativeAudioNode(source).disconnect(_getNativeAudioParam.getNativeAudioParam(destination), output);
    }
};
const deleteAnyConnection = (source, isOffline)=>{
    const audioNodeConnectionsOfSource = _getAudioNodeConnections.getAudioNodeConnections(source);
    const destinations = [];
    for (const outputConnection of audioNodeConnectionsOfSource.outputs){
        if (_audioNodeOutputConnection.isAudioNodeOutputConnection(outputConnection)) deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        destinations.push(outputConnection[0]);
    }
    audioNodeConnectionsOfSource.outputs.clear();
    return destinations;
};
const deleteConnectionAtOutput = (source, isOffline, output)=>{
    const audioNodeConnectionsOfSource = _getAudioNodeConnections.getAudioNodeConnections(source);
    const destinations = [];
    for (const outputConnection of audioNodeConnectionsOfSource.outputs)if (outputConnection[1] === output) {
        if (_audioNodeOutputConnection.isAudioNodeOutputConnection(outputConnection)) deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        destinations.push(outputConnection[0]);
        audioNodeConnectionsOfSource.outputs.delete(outputConnection);
    }
    return destinations;
};
const deleteConnectionToDestination = (source, isOffline, destination, output, input)=>{
    const audioNodeConnectionsOfSource = _getAudioNodeConnections.getAudioNodeConnections(source);
    return Array.from(audioNodeConnectionsOfSource.outputs).filter((outputConnection)=>outputConnection[0] === destination && (output === undefined || outputConnection[1] === output) && (input === undefined || outputConnection[2] === input)
    ).map((outputConnection)=>{
        if (_audioNodeOutputConnection.isAudioNodeOutputConnection(outputConnection)) deleteInputsOfAudioNode(source, isOffline, ...outputConnection);
        else deleteInputsOfAudioParam(source, isOffline, ...outputConnection);
        audioNodeConnectionsOfSource.outputs.delete(outputConnection);
        return outputConnection[0];
    });
};
const createAudioNodeConstructor = (addAudioNodeConnections, addConnectionToAudioNode, cacheTestResult, createIncrementCycleCounter, createIndexSizeError, createInvalidAccessError, createNotSupportedError, decrementCycleCounter, detectCycles, eventTargetConstructor, getNativeContext, isNativeAudioContext, isNativeAudioNode, isNativeAudioParam, isNativeOfflineAudioContext)=>{
    return class AudioNode1 extends eventTargetConstructor {
        constructor(context, isActive, nativeAudioNode, audioNodeRenderer){
            super(nativeAudioNode);
            this._context = context;
            this._nativeAudioNode = nativeAudioNode;
            const nativeContext = getNativeContext(context);
            // Bug #12: Safari does not support to disconnect a specific destination.
            if (isNativeAudioContext(nativeContext) && true !== cacheTestResult(_testAudioNodeDisconnectMethodSupport.testAudioNodeDisconnectMethodSupport, ()=>{
                return _testAudioNodeDisconnectMethodSupport.testAudioNodeDisconnectMethodSupport(nativeContext);
            })) _wrapAudioNodeDisconnectMethod.wrapAudioNodeDisconnectMethod(nativeAudioNode);
            _globals.AUDIO_NODE_STORE.set(this, nativeAudioNode);
            _globals.EVENT_LISTENERS.set(this, new Set());
            if (context.state !== 'closed' && isActive) _setInternalStateToActive.setInternalStateToActive(this);
            addAudioNodeConnections(this, audioNodeRenderer, nativeAudioNode);
        }
        get channelCount() {
            return this._nativeAudioNode.channelCount;
        }
        set channelCount(value) {
            this._nativeAudioNode.channelCount = value;
        }
        get channelCountMode() {
            return this._nativeAudioNode.channelCountMode;
        }
        set channelCountMode(value) {
            this._nativeAudioNode.channelCountMode = value;
        }
        get channelInterpretation() {
            return this._nativeAudioNode.channelInterpretation;
        }
        set channelInterpretation(value) {
            this._nativeAudioNode.channelInterpretation = value;
        }
        get context() {
            return this._context;
        }
        get numberOfInputs() {
            return this._nativeAudioNode.numberOfInputs;
        }
        get numberOfOutputs() {
            return this._nativeAudioNode.numberOfOutputs;
        }
        // tslint:disable-next-line:invalid-void
        connect(destination, output = 0, input = 0) {
            // Bug #174: Safari does expose a wrong numberOfOutputs for MediaStreamAudioDestinationNodes.
            if (output < 0 || output >= this._nativeAudioNode.numberOfOutputs) throw createIndexSizeError();
            const nativeContext1 = getNativeContext(this._context);
            const isOffline = isNativeOfflineAudioContext(nativeContext1);
            if (isNativeAudioNode(destination) || isNativeAudioParam(destination)) throw createInvalidAccessError();
            if (_audioNode.isAudioNode(destination)) {
                const nativeDestinationAudioNode = _getNativeAudioNode.getNativeAudioNode(destination);
                try {
                    const connection = _connectNativeAudioNodeToNativeAudioNode.connectNativeAudioNodeToNativeAudioNode(this._nativeAudioNode, nativeDestinationAudioNode, output, input);
                    const isPassive = _isPassiveAudioNode.isPassiveAudioNode(this);
                    if (isOffline || isPassive) this._nativeAudioNode.disconnect(...connection);
                    if (this.context.state !== 'closed' && !isPassive && _isPassiveAudioNode.isPassiveAudioNode(destination)) _setInternalStateToActive.setInternalStateToActive(destination);
                } catch (err) {
                    // Bug #41: Safari does not throw the correct exception so far.
                    if (err.code === 12) throw createInvalidAccessError();
                    throw err;
                }
                const isNewConnectionToAudioNode = addConnectionToAudioNode(this, destination, output, input, isOffline);
                // Bug #164: Only Firefox detects cycles so far.
                if (isNewConnectionToAudioNode) {
                    const cycles = detectCycles([
                        this
                    ], destination);
                    _visitEachAudioNodeOnce.visitEachAudioNodeOnce(cycles, createIncrementCycleCounter(isOffline));
                }
                return destination;
            }
            const nativeAudioParam = _getNativeAudioParam.getNativeAudioParam(destination);
            /*
             * Bug #73, #147 & #153: Safari does not support to connect an input signal to the playbackRate AudioParam of an
             * AudioBufferSourceNode. This can't be easily detected and that's why the outdated name property is used here to identify
             * Safari. In addition to that the maxValue property is used to only detect the affected versions below v14.0.2.
             */ if (nativeAudioParam.name === 'playbackRate' && nativeAudioParam.maxValue === 1024) throw createNotSupportedError();
            try {
                this._nativeAudioNode.connect(nativeAudioParam, output);
                if (isOffline || _isPassiveAudioNode.isPassiveAudioNode(this)) this._nativeAudioNode.disconnect(nativeAudioParam, output);
            } catch (err) {
                // Bug #58: Only Firefox does throw an InvalidAccessError yet.
                if (err.code === 12) throw createInvalidAccessError();
                throw err;
            }
            const isNewConnectionToAudioParam = addConnectionToAudioParamOfAudioContext(this, destination, output, isOffline);
            // Bug #164: Only Firefox detects cycles so far.
            if (isNewConnectionToAudioParam) {
                const cycles = detectCycles([
                    this
                ], destination);
                _visitEachAudioNodeOnce.visitEachAudioNodeOnce(cycles, createIncrementCycleCounter(isOffline));
            }
        }
        disconnect(destinationOrOutput, output, input) {
            let destinations;
            const nativeContext1 = getNativeContext(this._context);
            const isOffline = isNativeOfflineAudioContext(nativeContext1);
            if (destinationOrOutput === undefined) destinations = deleteAnyConnection(this, isOffline);
            else if (typeof destinationOrOutput === 'number') {
                if (destinationOrOutput < 0 || destinationOrOutput >= this.numberOfOutputs) throw createIndexSizeError();
                destinations = deleteConnectionAtOutput(this, isOffline, destinationOrOutput);
            } else {
                if (output !== undefined && (output < 0 || output >= this.numberOfOutputs)) throw createIndexSizeError();
                if (_audioNode.isAudioNode(destinationOrOutput) && input !== undefined && (input < 0 || input >= destinationOrOutput.numberOfInputs)) throw createIndexSizeError();
                destinations = deleteConnectionToDestination(this, isOffline, destinationOrOutput, output, input);
                if (destinations.length === 0) throw createInvalidAccessError();
            }
            // Bug #164: Only Firefox detects cycles so far.
            for (const destination of destinations){
                const cycles = detectCycles([
                    this
                ], destination);
                _visitEachAudioNodeOnce.visitEachAudioNodeOnce(cycles, decrementCycleCounter);
            }
        }
    };
};

},{"../globals":"80KZG","../guards/audio-node":"4NFmA","../guards/audio-node-output-connection":"3Drf7","../helpers/add-active-input-connection-to-audio-param":"lvIjN","../helpers/add-passive-input-connection-to-audio-param":"iLkkM","../helpers/connect-native-audio-node-to-native-audio-node":"1r52J","../helpers/delete-active-input-connection":"4Exsi","../helpers/delete-active-input-connection-to-audio-param":"1iUzI","../helpers/delete-event-listeners-of-audio-node":"33h3Q","../helpers/delete-passive-input-connection-to-audio-node":"doPzE","../helpers/delete-passive-input-connection-to-audio-param":"hnjbz","../helpers/disconnect-native-audio-node-from-native-audio-node":"3V2hA","../helpers/get-audio-node-connections":"b9slo","../helpers/get-audio-param-connections":"elnXq","../helpers/get-event-listeners-of-audio-node":"5ePnU","../helpers/get-native-audio-node":"5vfeq","../helpers/get-native-audio-param":"d3w1J","../helpers/insert-element-in-set":"lF3LX","../helpers/is-active-audio-node":"3g5Fl","../helpers/is-part-of-a-cycle":"AboZ8","../helpers/is-passive-audio-node":"aaSth","../helpers/set-internal-state-to-active":"21L0g","../helpers/set-internal-state-to-passive-when-necessary":"i6w3c","../helpers/test-audio-node-disconnect-method-support":"biUDI","../helpers/visit-each-audio-node-once":"6cvGD","../helpers/wrap-audio-node-disconnect-method":"j2cWF","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4NFmA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isAudioNode", ()=>isAudioNode
);
const isAudioNode = (audioNodeOrAudioParam)=>{
    return 'context' in audioNodeOrAudioParam;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3Drf7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isAudioNodeOutputConnection", ()=>isAudioNodeOutputConnection
);
var _audioNode = require("./audio-node");
const isAudioNodeOutputConnection = (outputConnection)=>{
    return _audioNode.isAudioNode(outputConnection[0]);
};

},{"./audio-node":"4NFmA","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lvIjN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "addActiveInputConnectionToAudioParam", ()=>addActiveInputConnectionToAudioParam
);
var _insertElementInSet = require("./insert-element-in-set");
const addActiveInputConnectionToAudioParam = (activeInputs, source, [output, eventListener], ignoreDuplicates)=>{
    _insertElementInSet.insertElementInSet(activeInputs, [
        source,
        output,
        eventListener
    ], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output
    , ignoreDuplicates);
};

},{"./insert-element-in-set":"lF3LX","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lF3LX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "insertElementInSet", ()=>insertElementInSet
);
const insertElementInSet = (set, element, predicate, ignoreDuplicates)=>{
    for (const lmnt of set)if (predicate(lmnt)) {
        if (ignoreDuplicates) return false;
        throw Error('The set contains at least one similar element.');
    }
    set.add(element);
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iLkkM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "addPassiveInputConnectionToAudioParam", ()=>addPassiveInputConnectionToAudioParam
);
var _insertElementInSet = require("./insert-element-in-set");
const addPassiveInputConnectionToAudioParam = (passiveInputs, [source, output, eventListener], ignoreDuplicates)=>{
    const passiveInputConnections = passiveInputs.get(source);
    if (passiveInputConnections === undefined) passiveInputs.set(source, new Set([
        [
            output,
            eventListener
        ]
    ]));
    else _insertElementInSet.insertElementInSet(passiveInputConnections, [
        output,
        eventListener
    ], (passiveInputConnection)=>passiveInputConnection[0] === output
    , ignoreDuplicates);
};

},{"./insert-element-in-set":"lF3LX","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1r52J":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "connectNativeAudioNodeToNativeAudioNode", ()=>connectNativeAudioNodeToNativeAudioNode
);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
const connectNativeAudioNodeToNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input)=>{
    if (_nativeAudioNodeFaker.isNativeAudioNodeFaker(nativeDestinationAudioNode)) {
        const fakeNativeDestinationAudioNode = nativeDestinationAudioNode.inputs[input];
        nativeSourceAudioNode.connect(fakeNativeDestinationAudioNode, output, 0);
        return [
            fakeNativeDestinationAudioNode,
            output,
            0
        ];
    }
    nativeSourceAudioNode.connect(nativeDestinationAudioNode, output, input);
    return [
        nativeDestinationAudioNode,
        output,
        input
    ];
};

},{"../guards/native-audio-node-faker":"9mpuK","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9mpuK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isNativeAudioNodeFaker", ()=>isNativeAudioNodeFaker
);
const isNativeAudioNodeFaker = (nativeAudioNodeOrNativeAudioNodeFaker)=>{
    return 'inputs' in nativeAudioNodeOrNativeAudioNodeFaker;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4Exsi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deleteActiveInputConnection", ()=>deleteActiveInputConnection
);
const deleteActiveInputConnection = (activeInputConnections, source, output)=>{
    for (const activeInputConnection of activeInputConnections)if (activeInputConnection[0] === source && activeInputConnection[1] === output) {
        activeInputConnections.delete(activeInputConnection);
        return activeInputConnection;
    }
    return null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1iUzI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deleteActiveInputConnectionToAudioParam", ()=>deleteActiveInputConnectionToAudioParam
);
var _pickElementFromSet = require("./pick-element-from-set");
const deleteActiveInputConnectionToAudioParam = (activeInputs, source, output)=>{
    return _pickElementFromSet.pickElementFromSet(activeInputs, (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output
    );
};

},{"./pick-element-from-set":"hKh0z","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"33h3Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deleteEventListenerOfAudioNode", ()=>deleteEventListenerOfAudioNode
);
var _getEventListenersOfAudioNode = require("./get-event-listeners-of-audio-node");
const deleteEventListenerOfAudioNode = (audioNode, eventListener)=>{
    const eventListeners = _getEventListenersOfAudioNode.getEventListenersOfAudioNode(audioNode);
    if (!eventListeners.delete(eventListener)) throw new Error('Missing the expected event listener.');
};

},{"./get-event-listeners-of-audio-node":"5ePnU","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hnjbz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deletePassiveInputConnectionToAudioParam", ()=>deletePassiveInputConnectionToAudioParam
);
var _getValueForKey = require("./get-value-for-key");
var _pickElementFromSet = require("./pick-element-from-set");
const deletePassiveInputConnectionToAudioParam = (passiveInputs, source, output)=>{
    const passiveInputConnections = _getValueForKey.getValueForKey(passiveInputs, source);
    const matchingConnection = _pickElementFromSet.pickElementFromSet(passiveInputConnections, (passiveInputConnection)=>passiveInputConnection[0] === output
    );
    if (passiveInputConnections.size === 0) passiveInputs.delete(source);
    return matchingConnection;
};

},{"./get-value-for-key":"ktCVX","./pick-element-from-set":"hKh0z","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3V2hA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "disconnectNativeAudioNodeFromNativeAudioNode", ()=>disconnectNativeAudioNodeFromNativeAudioNode
);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
const disconnectNativeAudioNodeFromNativeAudioNode = (nativeSourceAudioNode, nativeDestinationAudioNode, output, input)=>{
    if (_nativeAudioNodeFaker.isNativeAudioNodeFaker(nativeDestinationAudioNode)) nativeSourceAudioNode.disconnect(nativeDestinationAudioNode.inputs[input], output, 0);
    else nativeSourceAudioNode.disconnect(nativeDestinationAudioNode, output, input);
};

},{"../guards/native-audio-node-faker":"9mpuK","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5vfeq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getNativeAudioNode", ()=>getNativeAudioNode
);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getNativeAudioNode = (audioNode)=>{
    return _getValueForKey.getValueForKey(_globals.AUDIO_NODE_STORE, audioNode);
};

},{"../globals":"80KZG","./get-value-for-key":"ktCVX","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d3w1J":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getNativeAudioParam", ()=>getNativeAudioParam
);
var _globals = require("../globals");
var _getValueForKey = require("./get-value-for-key");
const getNativeAudioParam = (audioParam)=>{
    return _getValueForKey.getValueForKey(_globals.AUDIO_PARAM_STORE, audioParam);
};

},{"../globals":"80KZG","./get-value-for-key":"ktCVX","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"AboZ8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isPartOfACycle", ()=>isPartOfACycle
);
var _globals = require("../globals");
const isPartOfACycle = (audioNode)=>{
    return _globals.CYCLE_COUNTERS.has(audioNode);
};

},{"../globals":"80KZG","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aaSth":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isPassiveAudioNode", ()=>isPassiveAudioNode
);
var _globals = require("../globals");
const isPassiveAudioNode = (audioNode)=>{
    return !_globals.ACTIVE_AUDIO_NODE_STORE.has(audioNode);
};

},{"../globals":"80KZG","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"biUDI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioNodeDisconnectMethodSupport", ()=>testAudioNodeDisconnectMethodSupport
);
const testAudioNodeDisconnectMethodSupport = (nativeAudioContext)=>{
    return new Promise((resolve)=>{
        const analyzer = nativeAudioContext.createScriptProcessor(256, 1, 1); // tslint:disable-line deprecation
        const dummy = nativeAudioContext.createGain();
        // Bug #95: Safari does not play one sample buffers.
        const ones = nativeAudioContext.createBuffer(1, 2, 44100);
        const channelData = ones.getChannelData(0);
        channelData[0] = 1;
        channelData[1] = 1;
        const source = nativeAudioContext.createBufferSource();
        source.buffer = ones;
        source.loop = true;
        source.connect(analyzer).connect(nativeAudioContext.destination);
        source.connect(dummy);
        source.disconnect(dummy);
        // tslint:disable-next-line:deprecation
        analyzer.onaudioprocess = (event)=>{
            const chnnlDt = event.inputBuffer.getChannelData(0); // tslint:disable-line deprecation
            if (Array.prototype.some.call(chnnlDt, (sample)=>sample === 1
            )) resolve(true);
            else resolve(false);
            source.stop();
            analyzer.onaudioprocess = null; // tslint:disable-line:deprecation
            source.disconnect(analyzer);
            analyzer.disconnect(nativeAudioContext.destination);
        };
        source.start();
    });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6cvGD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "visitEachAudioNodeOnce", ()=>visitEachAudioNodeOnce
);
const visitEachAudioNodeOnce = (cycles, visitor)=>{
    const counts = new Map();
    for (const cycle of cycles)for (const audioNode of cycle){
        const count = counts.get(audioNode);
        counts.set(audioNode, count === undefined ? 1 : count + 1);
    }
    counts.forEach((count, audioNode1)=>visitor(audioNode1, count)
    );
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j2cWF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioNodeDisconnectMethod", ()=>wrapAudioNodeDisconnectMethod
);
var _nativeAudioNode = require("../guards/native-audio-node");
const wrapAudioNodeDisconnectMethod = (nativeAudioNode)=>{
    const connections = new Map();
    nativeAudioNode.connect = ((connect)=>{
        // tslint:disable-next-line:invalid-void
        return (destination, output = 0, input = 0)=>{
            const returnValue = _nativeAudioNode.isNativeAudioNode(destination) ? connect(destination, output, input) : connect(destination, output);
            // Save the new connection only if the calls to connect above didn't throw an error.
            const connectionsToDestination = connections.get(destination);
            if (connectionsToDestination === undefined) connections.set(destination, [
                {
                    input,
                    output
                }
            ]);
            else if (connectionsToDestination.every((connection)=>connection.input !== input || connection.output !== output
            )) connectionsToDestination.push({
                input,
                output
            });
            return returnValue;
        };
    })(nativeAudioNode.connect.bind(nativeAudioNode));
    nativeAudioNode.disconnect = ((disconnect)=>{
        return (destinationOrOutput, output, input)=>{
            disconnect.apply(nativeAudioNode);
            if (destinationOrOutput === undefined) connections.clear();
            else if (typeof destinationOrOutput === 'number') for (const [destination, connectionsToDestination] of connections){
                const filteredConnections = connectionsToDestination.filter((connection)=>connection.output !== destinationOrOutput
                );
                if (filteredConnections.length === 0) connections.delete(destination);
                else connections.set(destination, filteredConnections);
            }
            else if (connections.has(destinationOrOutput)) {
                if (output === undefined) connections.delete(destinationOrOutput);
                else {
                    const connectionsToDestination1 = connections.get(destinationOrOutput);
                    if (connectionsToDestination1 !== undefined) {
                        const filteredConnections = connectionsToDestination1.filter((connection)=>connection.output !== output && (connection.input !== input || input === undefined)
                        );
                        if (filteredConnections.length === 0) connections.delete(destinationOrOutput);
                        else connections.set(destinationOrOutput, filteredConnections);
                    }
                }
            }
            for (const [destination1, connectionsToDestination1] of connections)connectionsToDestination1.forEach((connection)=>{
                if (_nativeAudioNode.isNativeAudioNode(destination1)) nativeAudioNode.connect(destination1, connection.output, connection.input);
                else nativeAudioNode.connect(destination1, connection.output);
            });
        };
    })(nativeAudioNode.disconnect);
};

},{"../guards/native-audio-node":"bDooh","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bDooh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isNativeAudioNode", ()=>isNativeAudioNode
);
const isNativeAudioNode = (nativeAudioNodeOrAudioParam)=>{
    return 'context' in nativeAudioNodeOrAudioParam;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"buC3m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioParamFactory", ()=>createAudioParamFactory
);
var _automationEvents = require("automation-events");
const createAudioParamFactory = (addAudioParamConnections, audioParamAudioNodeStore, audioParamStore, createAudioParamRenderer, createCancelAndHoldAutomationEvent, createCancelScheduledValuesAutomationEvent, createExponentialRampToValueAutomationEvent, createLinearRampToValueAutomationEvent, createSetTargetAutomationEvent, createSetValueAutomationEvent, createSetValueCurveAutomationEvent, nativeAudioContextConstructor, setValueAtTimeUntilPossible)=>{
    return (audioNode, isAudioParamOfOfflineAudioContext, nativeAudioParam, maxValue = null, minValue = null)=>{
        const automationEventList = new _automationEvents.AutomationEventList(nativeAudioParam.defaultValue);
        const audioParamRenderer = isAudioParamOfOfflineAudioContext ? createAudioParamRenderer(automationEventList) : null;
        const audioParam = {
            get defaultValue () {
                return nativeAudioParam.defaultValue;
            },
            get maxValue () {
                return maxValue === null ? nativeAudioParam.maxValue : maxValue;
            },
            get minValue () {
                return minValue === null ? nativeAudioParam.minValue : minValue;
            },
            get value () {
                return nativeAudioParam.value;
            },
            set value (value1){
                nativeAudioParam.value = value1;
                // Bug #98: Firefox & Safari do not yet treat the value setter like a call to setValueAtTime().
                audioParam.setValueAtTime(value1, audioNode.context.currentTime);
            },
            cancelAndHoldAtTime (cancelTime) {
                // Bug #28: Firefox & Safari do not yet implement cancelAndHoldAtTime().
                if (typeof nativeAudioParam.cancelAndHoldAtTime === 'function') {
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));
                    nativeAudioParam.cancelAndHoldAtTime(cancelTime);
                } else {
                    const previousLastEvent = Array.from(automationEventList).pop();
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createCancelAndHoldAutomationEvent(cancelTime));
                    const currentLastEvent = Array.from(automationEventList).pop();
                    nativeAudioParam.cancelScheduledValues(cancelTime);
                    if (previousLastEvent !== currentLastEvent && currentLastEvent !== undefined) {
                        if (currentLastEvent.type === 'exponentialRampToValue') nativeAudioParam.exponentialRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);
                        else if (currentLastEvent.type === 'linearRampToValue') nativeAudioParam.linearRampToValueAtTime(currentLastEvent.value, currentLastEvent.endTime);
                        else if (currentLastEvent.type === 'setValue') nativeAudioParam.setValueAtTime(currentLastEvent.value, currentLastEvent.startTime);
                        else if (currentLastEvent.type === 'setValueCurve') nativeAudioParam.setValueCurveAtTime(currentLastEvent.values, currentLastEvent.startTime, currentLastEvent.duration);
                    }
                }
                return audioParam;
            },
            cancelScheduledValues (cancelTime) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createCancelScheduledValuesAutomationEvent(cancelTime));
                nativeAudioParam.cancelScheduledValues(cancelTime);
                return audioParam;
            },
            exponentialRampToValueAtTime (value, endTime) {
                // Bug #45: Safari does not throw an error yet.
                if (value === 0) throw new RangeError();
                // Bug #187: Safari does not throw an error yet.
                if (!Number.isFinite(endTime) || endTime < 0) throw new RangeError();
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createExponentialRampToValueAutomationEvent(value, endTime));
                nativeAudioParam.exponentialRampToValueAtTime(value, endTime);
                return audioParam;
            },
            linearRampToValueAtTime (value, endTime) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createLinearRampToValueAutomationEvent(value, endTime));
                nativeAudioParam.linearRampToValueAtTime(value, endTime);
                return audioParam;
            },
            setTargetAtTime (target, startTime, timeConstant) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createSetTargetAutomationEvent(target, startTime, timeConstant));
                nativeAudioParam.setTargetAtTime(target, startTime, timeConstant);
                return audioParam;
            },
            setValueAtTime (value, startTime) {
                if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                automationEventList.add(createSetValueAutomationEvent(value, startTime));
                nativeAudioParam.setValueAtTime(value, startTime);
                return audioParam;
            },
            setValueCurveAtTime (values, startTime, duration) {
                // Bug 183: Safari only accepts a Float32Array.
                const convertedValues = values instanceof Float32Array ? values : new Float32Array(values);
                /*
                 * Bug #152: Safari does not correctly interpolate the values of the curve.
                 * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the
                 * existence of the webkitAudioContext is used as a workaround here.
                 */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') {
                    const endTime = startTime + duration;
                    const sampleRate = audioNode.context.sampleRate;
                    const firstSample = Math.ceil(startTime * sampleRate);
                    const lastSample = Math.floor(endTime * sampleRate);
                    const numberOfInterpolatedValues = lastSample - firstSample;
                    const interpolatedValues = new Float32Array(numberOfInterpolatedValues);
                    for(let i = 0; i < numberOfInterpolatedValues; i += 1){
                        const theoreticIndex = (convertedValues.length - 1) / duration * ((firstSample + i) / sampleRate - startTime);
                        const lowerIndex = Math.floor(theoreticIndex);
                        const upperIndex = Math.ceil(theoreticIndex);
                        interpolatedValues[i] = lowerIndex === upperIndex ? convertedValues[lowerIndex] : (1 - (theoreticIndex - lowerIndex)) * convertedValues[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * convertedValues[upperIndex];
                    }
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createSetValueCurveAutomationEvent(interpolatedValues, startTime, duration));
                    nativeAudioParam.setValueCurveAtTime(interpolatedValues, startTime, duration);
                    const timeOfLastSample = lastSample / sampleRate;
                    if (timeOfLastSample < endTime) setValueAtTimeUntilPossible(audioParam, interpolatedValues[interpolatedValues.length - 1], timeOfLastSample);
                    setValueAtTimeUntilPossible(audioParam, convertedValues[convertedValues.length - 1], endTime);
                } else {
                    if (audioParamRenderer === null) automationEventList.flush(audioNode.context.currentTime);
                    automationEventList.add(createSetValueCurveAutomationEvent(convertedValues, startTime, duration));
                    nativeAudioParam.setValueCurveAtTime(convertedValues, startTime, duration);
                }
                return audioParam;
            }
        };
        audioParamStore.set(audioParam, nativeAudioParam);
        audioParamAudioNodeStore.set(audioParam, audioNode);
        addAudioParamConnections(audioParam, audioParamRenderer);
        return audioParam;
    };
};

},{"automation-events":"hP2Jr","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hiyLY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioParamRenderer", ()=>createAudioParamRenderer
);
const createAudioParamRenderer = (automationEventList)=>{
    return {
        replay (audioParam) {
            for (const automationEvent of automationEventList){
                if (automationEvent.type === 'exponentialRampToValue') {
                    const { endTime , value  } = automationEvent;
                    audioParam.exponentialRampToValueAtTime(value, endTime);
                } else if (automationEvent.type === 'linearRampToValue') {
                    const { endTime , value  } = automationEvent;
                    audioParam.linearRampToValueAtTime(value, endTime);
                } else if (automationEvent.type === 'setTarget') {
                    const { startTime , target , timeConstant  } = automationEvent;
                    audioParam.setTargetAtTime(target, startTime, timeConstant);
                } else if (automationEvent.type === 'setValue') {
                    const { startTime , value  } = automationEvent;
                    audioParam.setValueAtTime(value, startTime);
                } else if (automationEvent.type === 'setValueCurve') {
                    const { duration , startTime , values  } = automationEvent;
                    audioParam.setValueCurveAtTime(values, startTime, duration);
                } else throw new Error("Can't apply an unknown automation.");
            }
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1TBsi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioWorkletNodeConstructor", ()=>createAudioWorkletNodeConstructor
);
var _globals = require("../globals");
var _readOnlyMap = require("../read-only-map");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    // Bug #61: The channelCountMode should be 'max' according to the spec but is set to 'explicit' to achieve consistent behavior.
    channelCountMode: 'explicit',
    channelInterpretation: 'speakers',
    numberOfInputs: 1,
    numberOfOutputs: 1,
    parameterData: {
    },
    processorOptions: {
    }
};
const createAudioWorkletNodeConstructor = (addUnrenderedAudioWorkletNode, audioNodeConstructor, createAudioParam, createAudioWorkletNodeRenderer, createNativeAudioWorkletNode, getAudioNodeConnections, getBackupOfflineAudioContext, getNativeContext, isNativeOfflineAudioContext, nativeAudioWorkletNodeConstructor, sanitizeAudioWorkletNodeOptions, setActiveAudioWorkletNodeInputs, testAudioWorkletNodeOptionsClonability, wrapEventListener)=>{
    return class AudioWorkletNode1 extends audioNodeConstructor {
        constructor(context, name, options){
            var _a;
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const mergedOptions = sanitizeAudioWorkletNodeOptions({
                ...DEFAULT_OPTIONS,
                ...options
            });
            // Bug #191: Safari doesn't throw an error if the options aren't clonable.
            testAudioWorkletNodeOptionsClonability(mergedOptions);
            const nodeNameToProcessorConstructorMap = _globals.NODE_NAME_TO_PROCESSOR_CONSTRUCTOR_MAPS.get(nativeContext);
            const processorConstructor = nodeNameToProcessorConstructorMap === null || nodeNameToProcessorConstructorMap === void 0 ? void 0 : nodeNameToProcessorConstructorMap.get(name);
            // Bug #186: Chrome, Edge and Opera do not allow to create an AudioWorkletNode on a closed AudioContext.
            const nativeContextOrBackupOfflineAudioContext = isOffline || nativeContext.state !== 'closed' ? nativeContext : (_a = getBackupOfflineAudioContext(nativeContext)) !== null && _a !== void 0 ? _a : nativeContext;
            const nativeAudioWorkletNode = createNativeAudioWorkletNode(nativeContextOrBackupOfflineAudioContext, isOffline ? null : context.baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, mergedOptions);
            const audioWorkletNodeRenderer = isOffline ? createAudioWorkletNodeRenderer(name, mergedOptions, processorConstructor) : null;
            /*
             * @todo Add a mechanism to switch an AudioWorkletNode to passive once the process() function of the AudioWorkletProcessor
             * returns false.
             */ super(context, true, nativeAudioWorkletNode, audioWorkletNodeRenderer);
            const parameters = [];
            nativeAudioWorkletNode.parameters.forEach((nativeAudioParam, nm)=>{
                const audioParam = createAudioParam(this, isOffline, nativeAudioParam);
                parameters.push([
                    nm,
                    audioParam
                ]);
            });
            this._nativeAudioWorkletNode = nativeAudioWorkletNode;
            this._onprocessorerror = null;
            this._parameters = new _readOnlyMap.ReadOnlyMap(parameters);
            /*
             * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to
             * the destination.
             */ if (isOffline) addUnrenderedAudioWorkletNode(nativeContext, this);
            const { activeInputs  } = getAudioNodeConnections(this);
            setActiveAudioWorkletNodeInputs(nativeAudioWorkletNode, activeInputs);
        }
        get onprocessorerror() {
            return this._onprocessorerror;
        }
        set onprocessorerror(value) {
            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
            this._nativeAudioWorkletNode.onprocessorerror = wrappedListener;
            const nativeOnProcessorError = this._nativeAudioWorkletNode.onprocessorerror;
            this._onprocessorerror = nativeOnProcessorError !== null && nativeOnProcessorError === wrappedListener ? value : nativeOnProcessorError;
        }
        get parameters() {
            if (this._parameters === null) // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            return this._nativeAudioWorkletNode.parameters;
            return this._parameters;
        }
        get port() {
            return this._nativeAudioWorkletNode.port;
        }
    };
};

},{"../globals":"80KZG","../read-only-map":"1p3Tl","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1p3Tl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ReadOnlyMap", ()=>ReadOnlyMap
);
class ReadOnlyMap {
    constructor(parameters){
        this._map = new Map(parameters);
    }
    get size() {
        return this._map.size;
    }
    entries() {
        return this._map.entries();
    }
    forEach(callback, thisArg = null) {
        return this._map.forEach((value, key)=>callback.call(thisArg, value, key, this)
        );
    }
    get(name) {
        return this._map.get(name);
    }
    has(name) {
        return this._map.has(name);
    }
    keys() {
        return this._map.keys();
    }
    values() {
        return this._map.values();
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1xnlD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioWorkletNodeRendererFactory", ()=>createAudioWorkletNodeRendererFactory
);
var _copyFromChannel = require("../helpers/copy-from-channel");
var _copyToChannel = require("../helpers/copy-to-channel");
var _createNestedArrays = require("../helpers/create-nested-arrays");
var _getAudioNodeConnections = require("../helpers/get-audio-node-connections");
var _getAudioWorkletProcessor = require("../helpers/get-audio-worklet-processor");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const processBuffer = async (proxy, renderedBuffer, nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime)=>{
    // Ceil the length to the next full render quantum.
    // Bug #17: Safari does not yet expose the length.
    const length = renderedBuffer === null ? Math.ceil(proxy.context.length / 128) * 128 : renderedBuffer.length;
    const numberOfInputChannels = options.channelCount * options.numberOfInputs;
    const numberOfOutputChannels = outputChannelCount.reduce((sum, value)=>sum + value
    , 0);
    const processedBuffer = numberOfOutputChannels === 0 ? null : nativeOfflineAudioContext.createBuffer(numberOfOutputChannels, length, nativeOfflineAudioContext.sampleRate);
    if (processorConstructor === undefined) throw new Error('Missing the processor constructor.');
    const audioNodeConnections = _getAudioNodeConnections.getAudioNodeConnections(proxy);
    const audioWorkletProcessor = await _getAudioWorkletProcessor.getAudioWorkletProcessor(nativeOfflineAudioContext, proxy);
    const inputs = _createNestedArrays.createNestedArrays(options.numberOfInputs, options.channelCount);
    const outputs = _createNestedArrays.createNestedArrays(options.numberOfOutputs, outputChannelCount);
    const parameters = Array.from(proxy.parameters.keys()).reduce((prmtrs, name)=>({
            ...prmtrs,
            [name]: new Float32Array(128)
        })
    , {
    });
    for(let i = 0; i < length; i += 128){
        if (options.numberOfInputs > 0 && renderedBuffer !== null) {
            for(let j = 0; j < options.numberOfInputs; j += 1)for(let k = 0; k < options.channelCount; k += 1)_copyFromChannel.copyFromChannel(renderedBuffer, inputs[j], k, k, i);
        }
        if (processorConstructor.parameterDescriptors !== undefined && renderedBuffer !== null) processorConstructor.parameterDescriptors.forEach(({ name  }, index)=>{
            _copyFromChannel.copyFromChannel(renderedBuffer, parameters, name, numberOfInputChannels + index, i);
        });
        for(let j = 0; j < options.numberOfInputs; j += 1){
            for(let k = 0; k < outputChannelCount[j]; k += 1)// The byteLength will be 0 when the ArrayBuffer was transferred.
            if (outputs[j][k].byteLength === 0) outputs[j][k] = new Float32Array(128);
        }
        try {
            const potentiallyEmptyInputs = inputs.map((input, index)=>{
                if (audioNodeConnections.activeInputs[index].size === 0) return [];
                return input;
            });
            const activeSourceFlag = exposeCurrentFrameAndCurrentTime(i / nativeOfflineAudioContext.sampleRate, nativeOfflineAudioContext.sampleRate, ()=>audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters)
            );
            if (processedBuffer !== null) for(let j1 = 0, outputChannelSplitterNodeOutput = 0; j1 < options.numberOfOutputs; j1 += 1){
                for(let k = 0; k < outputChannelCount[j1]; k += 1)_copyToChannel.copyToChannel(processedBuffer, outputs[j1], k, outputChannelSplitterNodeOutput + k, i);
                outputChannelSplitterNodeOutput += outputChannelCount[j1];
            }
            if (!activeSourceFlag) break;
        } catch (error) {
            proxy.dispatchEvent(new ErrorEvent('processorerror', {
                colno: error.colno,
                filename: error.filename,
                lineno: error.lineno,
                message: error.message
            }));
            break;
        }
    }
    return processedBuffer;
};
const createAudioWorkletNodeRendererFactory = (connectAudioParam, connectMultipleOutputs, createNativeAudioBufferSourceNode, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, deleteUnrenderedAudioWorkletNode, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getNativeAudioNode, nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return (name, options, processorConstructor)=>{
        const renderedNativeAudioNodes = new WeakMap();
        let processedBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeAudioWorkletNode = getNativeAudioNode(proxy);
            let nativeOutputNodes = null;
            const nativeAudioWorkletNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeAudioWorkletNode, nativeOfflineAudioContext);
            const outputChannelCount = Array.isArray(options.outputChannelCount) ? options.outputChannelCount : Array.from(options.outputChannelCount);
            // Bug #61: Only Chrome, Edge, Firefox & Opera have an implementation of the AudioWorkletNode yet.
            if (nativeAudioWorkletNodeConstructor === null) {
                const numberOfOutputChannels = outputChannelCount.reduce((sum, value)=>sum + value
                , 0);
                const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, {
                    channelCount: Math.max(1, numberOfOutputChannels),
                    channelCountMode: 'explicit',
                    channelInterpretation: 'discrete',
                    numberOfOutputs: Math.max(1, numberOfOutputChannels)
                });
                const outputChannelMergerNodes = [];
                for(let i = 0; i < proxy.numberOfOutputs; i += 1)outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeOfflineAudioContext, {
                    channelCount: 1,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'speakers',
                    numberOfInputs: outputChannelCount[i]
                }));
                const outputGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    channelCount: options.channelCount,
                    channelCountMode: options.channelCountMode,
                    channelInterpretation: options.channelInterpretation,
                    gain: 1
                });
                outputGainNode.connect = connectMultipleOutputs.bind(null, outputChannelMergerNodes);
                outputGainNode.disconnect = disconnectMultipleOutputs.bind(null, outputChannelMergerNodes);
                nativeOutputNodes = [
                    outputChannelSplitterNode,
                    outputChannelMergerNodes,
                    outputGainNode
                ];
            } else if (!nativeAudioWorkletNodeIsOwnedByContext) nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeOfflineAudioContext, name);
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeOutputNodes === null ? nativeAudioWorkletNode : nativeOutputNodes[2]);
            if (nativeOutputNodes !== null) {
                if (processedBufferPromise === null) {
                    if (processorConstructor === undefined) throw new Error('Missing the processor constructor.');
                    if (nativeOfflineAudioContextConstructor === null) throw new Error('Missing the native OfflineAudioContext constructor.');
                    // Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.
                    const numberOfInputChannels = proxy.channelCount * proxy.numberOfInputs;
                    const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;
                    const numberOfChannels = numberOfInputChannels + numberOfParameters;
                    const renderBuffer = async ()=>{
                        const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(numberOfChannels, // Ceil the length to the next full render quantum.
                        // Bug #17: Safari does not yet expose the length.
                        Math.ceil(proxy.context.length / 128) * 128, nativeOfflineAudioContext.sampleRate);
                        const gainNodes = [];
                        const inputChannelSplitterNodes = [];
                        for(let i = 0; i < options.numberOfInputs; i += 1){
                            gainNodes.push(createNativeGainNode(partialOfflineAudioContext, {
                                channelCount: options.channelCount,
                                channelCountMode: options.channelCountMode,
                                channelInterpretation: options.channelInterpretation,
                                gain: 1
                            }));
                            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(partialOfflineAudioContext, {
                                channelCount: options.channelCount,
                                channelCountMode: 'explicit',
                                channelInterpretation: 'discrete',
                                numberOfOutputs: options.channelCount
                            }));
                        }
                        const constantSourceNodes = await Promise.all(Array.from(proxy.parameters.values()).map(async (audioParam)=>{
                            const constantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                channelCount: 1,
                                channelCountMode: 'explicit',
                                channelInterpretation: 'discrete',
                                offset: audioParam.value
                            });
                            await renderAutomation(partialOfflineAudioContext, audioParam, constantSourceNode.offset, trace);
                            return constantSourceNode;
                        }));
                        const inputChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                            channelCount: 1,
                            channelCountMode: 'explicit',
                            channelInterpretation: 'speakers',
                            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
                        });
                        for(let i1 = 0; i1 < options.numberOfInputs; i1 += 1){
                            gainNodes[i1].connect(inputChannelSplitterNodes[i1]);
                            for(let j = 0; j < options.channelCount; j += 1)inputChannelSplitterNodes[i1].connect(inputChannelMergerNode, j, i1 * options.channelCount + j);
                        }
                        for (const [index, constantSourceNode] of constantSourceNodes.entries()){
                            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
                            constantSourceNode.start(0);
                        }
                        inputChannelMergerNode.connect(partialOfflineAudioContext.destination);
                        await Promise.all(gainNodes.map((gainNode)=>renderInputsOfAudioNode(proxy, partialOfflineAudioContext, gainNode, trace)
                        ));
                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                    };
                    processedBufferPromise = processBuffer(proxy, numberOfChannels === 0 ? null : await renderBuffer(), nativeOfflineAudioContext, options, outputChannelCount, processorConstructor, exposeCurrentFrameAndCurrentTime);
                }
                const processedBuffer = await processedBufferPromise;
                const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {
                    buffer: null,
                    channelCount: 2,
                    channelCountMode: 'max',
                    channelInterpretation: 'speakers',
                    loop: false,
                    loopEnd: 0,
                    loopStart: 0,
                    playbackRate: 1
                });
                const [outputChannelSplitterNode, outputChannelMergerNodes, outputGainNode] = nativeOutputNodes;
                if (processedBuffer !== null) {
                    audioBufferSourceNode.buffer = processedBuffer;
                    audioBufferSourceNode.start(0);
                }
                audioBufferSourceNode.connect(outputChannelSplitterNode);
                for(let i = 0, outputChannelSplitterNodeOutput = 0; i < proxy.numberOfOutputs; i += 1){
                    const outputChannelMergerNode = outputChannelMergerNodes[i];
                    for(let j = 0; j < outputChannelCount[i]; j += 1)outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                    outputChannelSplitterNodeOutput += outputChannelCount[i];
                }
                return outputGainNode;
            }
            if (!nativeAudioWorkletNodeIsOwnedByContext) for (const [nm, audioParam] of proxy.parameters.entries())await renderAutomation(nativeOfflineAudioContext, audioParam, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            nativeAudioWorkletNode.parameters.get(nm), trace);
            else for (const [nm1, audioParam1] of proxy.parameters.entries())await connectAudioParam(nativeOfflineAudioContext, audioParam1, // @todo The definition that TypeScript uses of the AudioParamMap is lacking many methods.
            nativeAudioWorkletNode.parameters.get(nm1), trace);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioWorkletNode, trace);
            return nativeAudioWorkletNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                deleteUnrenderedAudioWorkletNode(nativeOfflineAudioContext, proxy);
                const renderedNativeAudioWorkletNodeOrGainNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioWorkletNodeOrGainNode !== undefined) return Promise.resolve(renderedNativeAudioWorkletNodeOrGainNode);
                return createAudioNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/copy-from-channel":"D6Pec","../helpers/copy-to-channel":"islV9","../helpers/create-nested-arrays":"5Wso6","../helpers/get-audio-node-connections":"b9slo","../helpers/get-audio-worklet-processor":"jgF0h","../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"D6Pec":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "copyFromChannel", ()=>copyFromChannel
);
function copyFromChannel(audioBuffer, // @todo There is currently no way to define something like { [ key: number | string ]: Float32Array }
parent, key, channelNumber, bufferOffset) {
    if (typeof audioBuffer.copyFromChannel === 'function') {
        // The byteLength will be 0 when the ArrayBuffer was transferred.
        if (parent[key].byteLength === 0) parent[key] = new Float32Array(128);
        audioBuffer.copyFromChannel(parent[key], channelNumber, bufferOffset);
    // Bug #5: Safari does not support copyFromChannel().
    } else {
        const channelData = audioBuffer.getChannelData(channelNumber);
        // The byteLength will be 0 when the ArrayBuffer was transferred.
        if (parent[key].byteLength === 0) parent[key] = channelData.slice(bufferOffset, bufferOffset + 128);
        else {
            const slicedInput = new Float32Array(channelData.buffer, bufferOffset * Float32Array.BYTES_PER_ELEMENT, 128);
            parent[key].set(slicedInput);
        }
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"islV9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "copyToChannel", ()=>copyToChannel
);
const copyToChannel = (audioBuffer, parent, key, channelNumber, bufferOffset)=>{
    if (typeof audioBuffer.copyToChannel === 'function') // The byteLength will be 0 when the ArrayBuffer was transferred.
    {
        if (parent[key].byteLength !== 0) audioBuffer.copyToChannel(parent[key], channelNumber, bufferOffset);
    } else // The byteLength will be 0 when the ArrayBuffer was transferred.
    if (parent[key].byteLength !== 0) audioBuffer.getChannelData(channelNumber).set(parent[key], bufferOffset);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5Wso6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNestedArrays", ()=>createNestedArrays
);
const createNestedArrays = (x, y)=>{
    const arrays = [];
    for(let i = 0; i < x; i += 1){
        const array = [];
        const length = typeof y === 'number' ? y : y[i];
        for(let j = 0; j < length; j += 1)array.push(new Float32Array(128));
        arrays.push(array);
    }
    return arrays;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jgF0h":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getAudioWorkletProcessor", ()=>getAudioWorkletProcessor
);
var _globals = require("../globals");
var _getNativeAudioNode = require("./get-native-audio-node");
var _getValueForKey = require("./get-value-for-key");
const getAudioWorkletProcessor = (nativeOfflineAudioContext, proxy)=>{
    const nodeToProcessorMap = _getValueForKey.getValueForKey(_globals.NODE_TO_PROCESSOR_MAPS, nativeOfflineAudioContext);
    const nativeAudioWorkletNode = _getNativeAudioNode.getNativeAudioNode(proxy);
    return _getValueForKey.getValueForKey(nodeToProcessorMap, nativeAudioWorkletNode);
};

},{"../globals":"80KZG","./get-native-audio-node":"5vfeq","./get-value-for-key":"ktCVX","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gYnX5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createBaseAudioContextConstructor", ()=>createBaseAudioContextConstructor
);
const createBaseAudioContextConstructor = (addAudioWorkletModule, analyserNodeConstructor, audioBufferConstructor, audioBufferSourceNodeConstructor, biquadFilterNodeConstructor, channelMergerNodeConstructor, channelSplitterNodeConstructor, constantSourceNodeConstructor, convolverNodeConstructor, decodeAudioData, delayNodeConstructor, dynamicsCompressorNodeConstructor, gainNodeConstructor, iIRFilterNodeConstructor, minimalBaseAudioContextConstructor, oscillatorNodeConstructor, pannerNodeConstructor, periodicWaveConstructor, stereoPannerNodeConstructor, waveShaperNodeConstructor)=>{
    return class BaseAudioContext1 extends minimalBaseAudioContextConstructor {
        constructor(_nativeContext, numberOfChannels1){
            super(_nativeContext, numberOfChannels1);
            this._nativeContext = _nativeContext;
            this._audioWorklet = addAudioWorkletModule === undefined ? undefined : {
                addModule: (moduleURL, options)=>{
                    return addAudioWorkletModule(this, moduleURL, options);
                }
            };
        }
        get audioWorklet() {
            return this._audioWorklet;
        }
        createAnalyser() {
            return new analyserNodeConstructor(this);
        }
        createBiquadFilter() {
            return new biquadFilterNodeConstructor(this);
        }
        createBuffer(numberOfChannels, length, sampleRate) {
            return new audioBufferConstructor({
                length,
                numberOfChannels,
                sampleRate
            });
        }
        createBufferSource() {
            return new audioBufferSourceNodeConstructor(this);
        }
        createChannelMerger(numberOfInputs = 6) {
            return new channelMergerNodeConstructor(this, {
                numberOfInputs
            });
        }
        createChannelSplitter(numberOfOutputs = 6) {
            return new channelSplitterNodeConstructor(this, {
                numberOfOutputs
            });
        }
        createConstantSource() {
            return new constantSourceNodeConstructor(this);
        }
        createConvolver() {
            return new convolverNodeConstructor(this);
        }
        createDelay(maxDelayTime = 1) {
            return new delayNodeConstructor(this, {
                maxDelayTime
            });
        }
        createDynamicsCompressor() {
            return new dynamicsCompressorNodeConstructor(this);
        }
        createGain() {
            return new gainNodeConstructor(this);
        }
        createIIRFilter(feedforward, feedback) {
            return new iIRFilterNodeConstructor(this, {
                feedback,
                feedforward
            });
        }
        createOscillator() {
            return new oscillatorNodeConstructor(this);
        }
        createPanner() {
            return new pannerNodeConstructor(this);
        }
        createPeriodicWave(real, imag, constraints = {
            disableNormalization: false
        }) {
            return new periodicWaveConstructor(this, {
                ...constraints,
                imag,
                real
            });
        }
        createStereoPanner() {
            return new stereoPannerNodeConstructor(this);
        }
        createWaveShaper() {
            return new waveShaperNodeConstructor(this);
        }
        decodeAudioData(audioData, successCallback, errorCallback) {
            return decodeAudioData(this._nativeContext, audioData).then((audioBuffer)=>{
                if (typeof successCallback === 'function') successCallback(audioBuffer);
                return audioBuffer;
            }, (err)=>{
                if (typeof errorCallback === 'function') errorCallback(err);
                throw err;
            });
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"12rCH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createBiquadFilterNodeConstructor", ()=>createBiquadFilterNodeConstructor
);
var _constants = require("../constants");
const DEFAULT_OPTIONS = {
    Q: 1,
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers',
    detune: 0,
    frequency: 350,
    gain: 0,
    type: 'lowpass'
};
const createBiquadFilterNodeConstructor = (audioNodeConstructor, createAudioParam, createBiquadFilterNodeRenderer, createInvalidAccessError, createNativeBiquadFilterNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class BiquadFilterNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const biquadFilterNodeRenderer = isOffline ? createBiquadFilterNodeRenderer() : null;
            super(context, false, nativeBiquadFilterNode, biquadFilterNodeRenderer);
            // Bug #80: Safari does not export the correct values for maxValue and minValue.
            this._Q = createAudioParam(this, isOffline, nativeBiquadFilterNode.Q, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            // Bug #78: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._detune = createAudioParam(this, isOffline, nativeBiquadFilterNode.detune, 1200 * Math.log2(_constants.MOST_POSITIVE_SINGLE_FLOAT), -1200 * Math.log2(_constants.MOST_POSITIVE_SINGLE_FLOAT));
            // Bug #77: Firefox & Safari do not export the correct value for minValue.
            this._frequency = createAudioParam(this, isOffline, nativeBiquadFilterNode.frequency, context.sampleRate / 2, 0);
            // Bug #79: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._gain = createAudioParam(this, isOffline, nativeBiquadFilterNode.gain, 40 * Math.log10(_constants.MOST_POSITIVE_SINGLE_FLOAT), _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            this._nativeBiquadFilterNode = nativeBiquadFilterNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get detune() {
            return this._detune;
        }
        get frequency() {
            return this._frequency;
        }
        get gain() {
            return this._gain;
        }
        get Q() {
            return this._Q;
        }
        get type() {
            return this._nativeBiquadFilterNode.type;
        }
        set type(value) {
            this._nativeBiquadFilterNode.type = value;
        }
        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
            // Bug #189: Safari does throw an InvalidStateError.
            try {
                this._nativeBiquadFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
            } catch (err) {
                if (err.code === 11) throw createInvalidAccessError();
                throw err;
            }
            // Bug #68: Safari does not throw an error if the parameters differ in their length.
            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw createInvalidAccessError();
        }
    };
};

},{"../constants":"dG3Pl","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5gXPH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createBiquadFilterNodeRendererFactory", ()=>createBiquadFilterNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createBiquadFilterNodeRendererFactory = (connectAudioParam, createNativeBiquadFilterNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeBiquadFilterNodes = new WeakMap();
        const createBiquadFilterNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeBiquadFilterNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeBiquadFilterNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeBiquadFilterNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeBiquadFilterNode, nativeOfflineAudioContext);
            if (!nativeBiquadFilterNodeIsOwnedByContext) {
                const options = {
                    Q: nativeBiquadFilterNode.Q.value,
                    channelCount: nativeBiquadFilterNode.channelCount,
                    channelCountMode: nativeBiquadFilterNode.channelCountMode,
                    channelInterpretation: nativeBiquadFilterNode.channelInterpretation,
                    detune: nativeBiquadFilterNode.detune.value,
                    frequency: nativeBiquadFilterNode.frequency.value,
                    gain: nativeBiquadFilterNode.gain.value,
                    type: nativeBiquadFilterNode.type
                };
                nativeBiquadFilterNode = createNativeBiquadFilterNode(nativeOfflineAudioContext, options);
            }
            renderedNativeBiquadFilterNodes.set(nativeOfflineAudioContext, nativeBiquadFilterNode);
            if (!nativeBiquadFilterNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain, trace);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.Q, nativeBiquadFilterNode.Q, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeBiquadFilterNode.detune, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeBiquadFilterNode.frequency, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeBiquadFilterNode.gain, trace);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeBiquadFilterNode, trace);
            return nativeBiquadFilterNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeBiquadFilterNode = renderedNativeBiquadFilterNodes.get(nativeOfflineAudioContext);
                if (renderedNativeBiquadFilterNode !== undefined) return Promise.resolve(renderedNativeBiquadFilterNode);
                return createBiquadFilterNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jxh1a":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createCacheTestResult", ()=>createCacheTestResult
);
const createCacheTestResult = (ongoingTests, testResults)=>{
    return (tester, test)=>{
        const cachedTestResult = testResults.get(tester);
        if (cachedTestResult !== undefined) return cachedTestResult;
        const ongoingTest = ongoingTests.get(tester);
        if (ongoingTest !== undefined) return ongoingTest;
        try {
            const synchronousTestResult = test();
            if (synchronousTestResult instanceof Promise) {
                ongoingTests.set(tester, synchronousTestResult);
                return synchronousTestResult.catch(()=>false
                ).then((finalTestResult)=>{
                    ongoingTests.delete(tester);
                    testResults.set(tester, finalTestResult);
                    return finalTestResult;
                });
            }
            testResults.set(tester, synchronousTestResult);
            return synchronousTestResult;
        } catch  {
            testResults.set(tester, false);
            return false;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9F55c":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createChannelMergerNodeConstructor", ()=>createChannelMergerNodeConstructor
);
const DEFAULT_OPTIONS = {
    channelCount: 1,
    channelCountMode: 'explicit',
    channelInterpretation: 'speakers',
    numberOfInputs: 6
};
const createChannelMergerNodeConstructor = (audioNodeConstructor, createChannelMergerNodeRenderer, createNativeChannelMergerNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class ChannelMergerNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeChannelMergerNode = createNativeChannelMergerNode(nativeContext, mergedOptions);
            const channelMergerNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createChannelMergerNodeRenderer() : null;
            super(context, false, nativeChannelMergerNode, channelMergerNodeRenderer);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3dPqu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createChannelMergerNodeRendererFactory", ()=>createChannelMergerNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createChannelMergerNodeRendererFactory = (createNativeChannelMergerNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeAudioNode = getNativeAudioNode(proxy);
            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAudioNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext);
            if (!nativeAudioNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAudioNode.channelCount,
                    channelCountMode: nativeAudioNode.channelCountMode,
                    channelInterpretation: nativeAudioNode.channelInterpretation,
                    numberOfInputs: nativeAudioNode.numberOfInputs
                };
                nativeAudioNode = createNativeChannelMergerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode, trace);
            return nativeAudioNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2Jv1p":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createChannelSplitterNodeConstructor", ()=>createChannelSplitterNodeConstructor
);
const DEFAULT_OPTIONS = {
    channelCount: 6,
    channelCountMode: 'explicit',
    channelInterpretation: 'discrete',
    numberOfOutputs: 6
};
const createChannelSplitterNodeConstructor = (audioNodeConstructor, createChannelSplitterNodeRenderer, createNativeChannelSplitterNode, getNativeContext, isNativeOfflineAudioContext, sanitizeChannelSplitterOptions)=>{
    return class ChannelSplitterNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = sanitizeChannelSplitterOptions({
                ...DEFAULT_OPTIONS,
                ...options
            });
            const nativeChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, mergedOptions);
            const channelSplitterNodeRenderer = isNativeOfflineAudioContext(nativeContext) ? createChannelSplitterNodeRenderer() : null;
            super(context, false, nativeChannelSplitterNode, channelSplitterNodeRenderer);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cQs9X":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createChannelSplitterNodeRendererFactory", ()=>createChannelSplitterNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createChannelSplitterNodeRendererFactory = (createNativeChannelSplitterNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeAudioNode = getNativeAudioNode(proxy);
            // If the initially used nativeAudioNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeAudioNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeAudioNode, nativeOfflineAudioContext);
            if (!nativeAudioNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeAudioNode.channelCount,
                    channelCountMode: nativeAudioNode.channelCountMode,
                    channelInterpretation: nativeAudioNode.channelInterpretation,
                    numberOfOutputs: nativeAudioNode.numberOfOutputs
                };
                nativeAudioNode = createNativeChannelSplitterNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioNode);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeAudioNode, trace);
            return nativeAudioNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ffceE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConnectAudioParam", ()=>createConnectAudioParam
);
const createConnectAudioParam = (renderInputsOfAudioParam)=>{
    return (nativeOfflineAudioContext, audioParam, nativeAudioParam, trace)=>{
        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam, trace);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"k2tjb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConnectMultipleOutputs", ()=>createConnectMultipleOutputs
);
var _nativeAudioNode = require("../guards/native-audio-node");
const createConnectMultipleOutputs = (createIndexSizeError)=>{
    return (outputAudioNodes, destination, output = 0, input = 0)=>{
        const outputAudioNode = outputAudioNodes[output];
        if (outputAudioNode === undefined) throw createIndexSizeError();
        if (_nativeAudioNode.isNativeAudioNode(destination)) return outputAudioNode.connect(destination, 0, input);
        return outputAudioNode.connect(destination, 0);
    };
};

},{"../guards/native-audio-node":"bDooh","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"knghE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConnectedNativeAudioBufferSourceNodeFactory", ()=>createConnectedNativeAudioBufferSourceNodeFactory
);
const createConnectedNativeAudioBufferSourceNodeFactory = (createNativeAudioBufferSourceNode)=>{
    return (nativeContext, nativeAudioNode)=>{
        const nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {
            buffer: null,
            channelCount: 2,
            channelCountMode: 'max',
            channelInterpretation: 'speakers',
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            playbackRate: 1
        });
        const nativeAudioBuffer = nativeContext.createBuffer(1, 2, 44100);
        nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
        nativeAudioBufferSourceNode.loop = true;
        nativeAudioBufferSourceNode.connect(nativeAudioNode);
        nativeAudioBufferSourceNode.start();
        return ()=>{
            nativeAudioBufferSourceNode.stop();
            nativeAudioBufferSourceNode.disconnect(nativeAudioNode);
        };
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gDaEY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConstantSourceNodeConstructor", ()=>createConstantSourceNodeConstructor
);
var _constants = require("../constants");
var _isActiveAudioNode = require("../helpers/is-active-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassive = require("../helpers/set-internal-state-to-passive");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers',
    offset: 1
};
const createConstantSourceNodeConstructor = (audioNodeConstructor, createAudioParam, createConstantSourceNodeRendererFactory, createNativeConstantSourceNode, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class ConstantSourceNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeConstantSourceNode = createNativeConstantSourceNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const constantSourceNodeRenderer = isOffline ? createConstantSourceNodeRendererFactory() : null;
            super(context, false, nativeConstantSourceNode, constantSourceNodeRenderer);
            this._constantSourceNodeRenderer = constantSourceNodeRenderer;
            this._nativeConstantSourceNode = nativeConstantSourceNode;
            /*
             * Bug #62 & #74: Safari does not support ConstantSourceNodes and does not export the correct values for maxValue and minValue
             * for GainNodes.
             */ this._offset = createAudioParam(this, isOffline, nativeConstantSourceNode.offset, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            this._onended = null;
        }
        get offset() {
            return this._offset;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
            this._nativeConstantSourceNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeConstantSourceNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        start(when = 0) {
            this._nativeConstantSourceNode.start(when);
            if (this._constantSourceNodeRenderer !== null) this._constantSourceNodeRenderer.start = when;
            if (this.context.state !== 'closed') {
                _setInternalStateToActive.setInternalStateToActive(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeConstantSourceNode.removeEventListener('ended', resetInternalStateToPassive);
                    if (_isActiveAudioNode.isActiveAudioNode(this)) _setInternalStateToPassive.setInternalStateToPassive(this);
                };
                this._nativeConstantSourceNode.addEventListener('ended', resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeConstantSourceNode.stop(when);
            if (this._constantSourceNodeRenderer !== null) this._constantSourceNodeRenderer.stop = when;
        }
    };
};

},{"../constants":"dG3Pl","../helpers/is-active-audio-node":"3g5Fl","../helpers/set-internal-state-to-active":"21L0g","../helpers/set-internal-state-to-passive":"37J9v","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eXWDG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConstantSourceNodeRendererFactory", ()=>createConstantSourceNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createConstantSourceNodeRendererFactory = (connectAudioParam, createNativeConstantSourceNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeConstantSourceNodes = new WeakMap();
        let start = null;
        let stop = null;
        const createConstantSourceNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeConstantSourceNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeConstantSourceNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeConstantSourceNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeConstantSourceNode, nativeOfflineAudioContext);
            if (!nativeConstantSourceNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeConstantSourceNode.channelCount,
                    channelCountMode: nativeConstantSourceNode.channelCountMode,
                    channelInterpretation: nativeConstantSourceNode.channelInterpretation,
                    offset: nativeConstantSourceNode.offset.value
                };
                nativeConstantSourceNode = createNativeConstantSourceNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeConstantSourceNode.start(start);
                if (stop !== null) nativeConstantSourceNode.stop(stop);
            }
            renderedNativeConstantSourceNodes.set(nativeOfflineAudioContext, nativeConstantSourceNode);
            if (!nativeConstantSourceNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset, trace);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.offset, nativeConstantSourceNode.offset, trace);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConstantSourceNode, trace);
            return nativeConstantSourceNode;
        };
        return {
            set start (value){
                start = value;
            },
            set stop (value1){
                stop = value1;
            },
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeConstantSourceNode = renderedNativeConstantSourceNodes.get(nativeOfflineAudioContext);
                if (renderedNativeConstantSourceNode !== undefined) return Promise.resolve(renderedNativeConstantSourceNode);
                return createConstantSourceNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gHJdq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConvertNumberToUnsignedLong", ()=>createConvertNumberToUnsignedLong
);
const createConvertNumberToUnsignedLong = (unit32Array)=>{
    return (value)=>{
        unit32Array[0] = value;
        return unit32Array[0];
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"huigM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConvolverNodeConstructor", ()=>createConvolverNodeConstructor
);
const DEFAULT_OPTIONS = {
    buffer: null,
    channelCount: 2,
    channelCountMode: 'clamped-max',
    channelInterpretation: 'speakers',
    disableNormalization: false
};
const createConvolverNodeConstructor = (audioNodeConstructor, createConvolverNodeRenderer, createNativeConvolverNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class ConvolverNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeConvolverNode = createNativeConvolverNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const convolverNodeRenderer = isOffline ? createConvolverNodeRenderer() : null;
            super(context, false, nativeConvolverNode, convolverNodeRenderer);
            this._isBufferNullified = false;
            this._nativeConvolverNode = nativeConvolverNode;
            if (mergedOptions.buffer !== null) setAudioNodeTailTime(this, mergedOptions.buffer.duration);
        }
        get buffer() {
            if (this._isBufferNullified) return null;
            return this._nativeConvolverNode.buffer;
        }
        set buffer(value) {
            this._nativeConvolverNode.buffer = value;
            // Bug #115: Safari does not allow to set the buffer to null.
            if (value === null && this._nativeConvolverNode.buffer !== null) {
                const nativeContext1 = this._nativeConvolverNode.context;
                this._nativeConvolverNode.buffer = nativeContext1.createBuffer(1, 1, 44100);
                this._isBufferNullified = true;
                setAudioNodeTailTime(this, 0);
            } else {
                this._isBufferNullified = false;
                setAudioNodeTailTime(this, this._nativeConvolverNode.buffer === null ? 0 : this._nativeConvolverNode.buffer.duration);
            }
        }
        get normalize() {
            return this._nativeConvolverNode.normalize;
        }
        set normalize(value) {
            this._nativeConvolverNode.normalize = value;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cCbtq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createConvolverNodeRendererFactory", ()=>createConvolverNodeRendererFactory
);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createConvolverNodeRendererFactory = (createNativeConvolverNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeConvolverNodes = new WeakMap();
        const createConvolverNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeConvolverNode = getNativeAudioNode(proxy);
            // If the initially used nativeConvolverNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeConvolverNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeConvolverNode, nativeOfflineAudioContext);
            if (!nativeConvolverNodeIsOwnedByContext) {
                const options = {
                    buffer: nativeConvolverNode.buffer,
                    channelCount: nativeConvolverNode.channelCount,
                    channelCountMode: nativeConvolverNode.channelCountMode,
                    channelInterpretation: nativeConvolverNode.channelInterpretation,
                    disableNormalization: !nativeConvolverNode.normalize
                };
                nativeConvolverNode = createNativeConvolverNode(nativeOfflineAudioContext, options);
            }
            renderedNativeConvolverNodes.set(nativeOfflineAudioContext, nativeConvolverNode);
            if (_nativeAudioNodeFaker.isNativeAudioNodeFaker(nativeConvolverNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode.inputs[0], trace);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeConvolverNode, trace);
            return nativeConvolverNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeConvolverNode = renderedNativeConvolverNodes.get(nativeOfflineAudioContext);
                if (renderedNativeConvolverNode !== undefined) return Promise.resolve(renderedNativeConvolverNode);
                return createConvolverNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../guards/native-audio-node-faker":"9mpuK","../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5vuLC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createCreateNativeOfflineAudioContext", ()=>createCreateNativeOfflineAudioContext
);
const createCreateNativeOfflineAudioContext = (createNotSupportedError, nativeOfflineAudioContextConstructor)=>{
    return (numberOfChannels, length, sampleRate)=>{
        if (nativeOfflineAudioContextConstructor === null) throw new Error('Missing the native OfflineAudioContext constructor.');
        try {
            return new nativeOfflineAudioContextConstructor(numberOfChannels, length, sampleRate);
        } catch (err) {
            // Bug #143, #144 & #146: Safari throws a SyntaxError when numberOfChannels, length or sampleRate are invalid.
            if (err.name === 'SyntaxError') throw createNotSupportedError();
            throw err;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hpGSA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDataCloneError", ()=>createDataCloneError
);
const createDataCloneError = ()=>new DOMException('', 'DataCloneError')
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e0wCw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDecodeAudioData", ()=>createDecodeAudioData
);
var _detachArrayBuffer = require("../helpers/detach-array-buffer");
var _wrapAudioBufferGetChannelDataMethod = require("../helpers/wrap-audio-buffer-get-channel-data-method");
const createDecodeAudioData = (audioBufferStore, cacheTestResult, createDataCloneError, createEncodingError, detachedArrayBuffers, getNativeContext, isNativeContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, testPromiseSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    return (anyContext, audioData)=>{
        const nativeContext = isNativeContext(anyContext) ? anyContext : getNativeContext(anyContext);
        // Bug #43: Only Chrome, Edge and Opera do throw a DataCloneError.
        if (detachedArrayBuffers.has(audioData)) {
            const err = createDataCloneError();
            return Promise.reject(err);
        }
        // The audioData parameter maybe of a type which can't be added to a WeakSet.
        try {
            detachedArrayBuffers.add(audioData);
        } catch  {
        // Ignore errors.
        }
        // Bug #21: Safari does not support promises yet.
        if (cacheTestResult(testPromiseSupport, ()=>testPromiseSupport(nativeContext)
        )) return nativeContext.decodeAudioData(audioData).then((audioBuffer)=>{
            // Bug #133: Safari does neuter the ArrayBuffer.
            _detachArrayBuffer.detachArrayBuffer(audioData).catch(()=>{
            // Ignore errors.
            });
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, ()=>testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer)
            )) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            return audioBuffer;
        });
        // Bug #21: Safari does not return a Promise yet.
        return new Promise((resolve, reject)=>{
            const complete = async ()=>{
                // Bug #133: Safari does neuter the ArrayBuffer.
                try {
                    await _detachArrayBuffer.detachArrayBuffer(audioData);
                } catch  {
                // Ignore errors.
                }
            };
            const fail = (err)=>{
                reject(err);
                complete();
            };
            // Bug #26: Safari throws a synchronous error.
            try {
                // Bug #1: Safari requires a successCallback.
                nativeContext.decodeAudioData(audioData, (audioBuffer)=>{
                    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
                    // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
                    if (typeof audioBuffer.copyFromChannel !== 'function') {
                        wrapAudioBufferCopyChannelMethods(audioBuffer);
                        _wrapAudioBufferGetChannelDataMethod.wrapAudioBufferGetChannelDataMethod(audioBuffer);
                    }
                    audioBufferStore.add(audioBuffer);
                    complete().then(()=>resolve(audioBuffer)
                    );
                }, (err)=>{
                    // Bug #4: Safari returns null instead of an error.
                    if (err === null) fail(createEncodingError());
                    else fail(err);
                });
            } catch (err) {
                fail(err);
            }
        });
    };
};

},{"../helpers/detach-array-buffer":"gdVP0","../helpers/wrap-audio-buffer-get-channel-data-method":"cHHc4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gdVP0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "detachArrayBuffer", ()=>detachArrayBuffer
);
const detachArrayBuffer = (arrayBuffer)=>{
    const { port1 , port2  } = new MessageChannel();
    return new Promise((resolve)=>{
        const closeAndResolve = ()=>{
            port2.onmessage = null;
            port1.close();
            port2.close();
            resolve();
        };
        port2.onmessage = ()=>closeAndResolve()
        ;
        try {
            port1.postMessage(arrayBuffer, [
                arrayBuffer
            ]);
        } finally{
            closeAndResolve();
        }
    });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gqBHS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDecrementCycleCounter", ()=>createDecrementCycleCounter
);
var _audioNodeOutputConnection = require("../guards/audio-node-output-connection");
const createDecrementCycleCounter = (connectNativeAudioNodeToNativeAudioNode, cycleCounters, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, getNativeContext, isActiveAudioNode, isNativeOfflineAudioContext)=>{
    return (audioNode, count)=>{
        const cycleCounter = cycleCounters.get(audioNode);
        if (cycleCounter === undefined) throw new Error('Missing the expected cycle count.');
        const nativeContext = getNativeContext(audioNode.context);
        const isOffline = isNativeOfflineAudioContext(nativeContext);
        if (cycleCounter === count) {
            cycleCounters.delete(audioNode);
            if (!isOffline && isActiveAudioNode(audioNode)) {
                const nativeSourceAudioNode = getNativeAudioNode(audioNode);
                const { outputs  } = getAudioNodeConnections(audioNode);
                for (const output of outputs)if (_audioNodeOutputConnection.isAudioNodeOutputConnection(output)) {
                    const nativeDestinationAudioNode = getNativeAudioNode(output[0]);
                    connectNativeAudioNodeToNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);
                } else {
                    const nativeDestinationAudioParam = getNativeAudioParam(output[0]);
                    nativeSourceAudioNode.connect(nativeDestinationAudioParam, output[1]);
                }
            }
        } else cycleCounters.set(audioNode, cycleCounter - count);
    };
};

},{"../guards/audio-node-output-connection":"3Drf7","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1kjKK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDelayNodeConstructor", ()=>createDelayNodeConstructor
);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers',
    delayTime: 0,
    maxDelayTime: 1
};
const createDelayNodeConstructor = (audioNodeConstructor, createAudioParam, createDelayNodeRenderer, createNativeDelayNode, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class DelayNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeDelayNode = createNativeDelayNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const delayNodeRenderer = isOffline ? createDelayNodeRenderer(mergedOptions.maxDelayTime) : null;
            super(context, false, nativeDelayNode, delayNodeRenderer);
            this._delayTime = createAudioParam(this, isOffline, nativeDelayNode.delayTime);
            setAudioNodeTailTime(this, mergedOptions.maxDelayTime);
        }
        get delayTime() {
            return this._delayTime;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e9Hhp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDelayNodeRendererFactory", ()=>createDelayNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createDelayNodeRendererFactory = (connectAudioParam, createNativeDelayNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return (maxDelayTime)=>{
        const renderedNativeDelayNodes = new WeakMap();
        const createDelayNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeDelayNode = getNativeAudioNode(proxy);
            // If the initially used nativeDelayNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeDelayNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeDelayNode, nativeOfflineAudioContext);
            if (!nativeDelayNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeDelayNode.channelCount,
                    channelCountMode: nativeDelayNode.channelCountMode,
                    channelInterpretation: nativeDelayNode.channelInterpretation,
                    delayTime: nativeDelayNode.delayTime.value,
                    maxDelayTime
                };
                nativeDelayNode = createNativeDelayNode(nativeOfflineAudioContext, options);
            }
            renderedNativeDelayNodes.set(nativeOfflineAudioContext, nativeDelayNode);
            if (!nativeDelayNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime, trace);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.delayTime, nativeDelayNode.delayTime, trace);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDelayNode, trace);
            return nativeDelayNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeDelayNode = renderedNativeDelayNodes.get(nativeOfflineAudioContext);
                if (renderedNativeDelayNode !== undefined) return Promise.resolve(renderedNativeDelayNode);
                return createDelayNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1sYav":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDeleteActiveInputConnectionToAudioNode", ()=>createDeleteActiveInputConnectionToAudioNode
);
const createDeleteActiveInputConnectionToAudioNode = (pickElementFromSet)=>{
    return (activeInputs, source, output, input)=>{
        return pickElementFromSet(activeInputs[input], (activeInputConnection)=>activeInputConnection[0] === source && activeInputConnection[1] === output
        );
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7Sd6K":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDeleteUnrenderedAudioWorkletNode", ()=>createDeleteUnrenderedAudioWorkletNode
);
const createDeleteUnrenderedAudioWorkletNode = (getUnrenderedAudioWorkletNodes)=>{
    return (nativeContext, audioWorkletNode)=>{
        getUnrenderedAudioWorkletNodes(nativeContext).delete(audioWorkletNode);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cbYj2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDetectCycles", ()=>createDetectCycles
);
var _audioNode = require("../guards/audio-node");
var _delayNode = require("../guards/delay-node");
const createDetectCycles = (audioParamAudioNodeStore, getAudioNodeConnections, getValueForKey)=>{
    return function detectCycles(chain, nextLink) {
        const audioNode = _audioNode.isAudioNode(nextLink) ? nextLink : getValueForKey(audioParamAudioNodeStore, nextLink);
        if (_delayNode.isDelayNode(audioNode)) return [];
        if (chain[0] === audioNode) return [
            chain
        ];
        if (chain.includes(audioNode)) return [];
        const { outputs  } = getAudioNodeConnections(audioNode);
        return Array.from(outputs).map((outputConnection)=>detectCycles([
                ...chain,
                audioNode
            ], outputConnection[0])
        ).reduce((mergedCycles, nestedCycles)=>mergedCycles.concat(nestedCycles)
        , []);
    };
};

},{"../guards/audio-node":"4NFmA","../guards/delay-node":"siRPd","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"siRPd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isDelayNode", ()=>isDelayNode
);
const isDelayNode = (audioNode)=>{
    return 'delayTime' in audioNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2vAzP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDisconnectMultipleOutputs", ()=>createDisconnectMultipleOutputs
);
var _nativeAudioNode = require("../guards/native-audio-node");
const getOutputAudioNodeAtIndex = (createIndexSizeError, outputAudioNodes, output)=>{
    const outputAudioNode = outputAudioNodes[output];
    if (outputAudioNode === undefined) throw createIndexSizeError();
    return outputAudioNode;
};
const createDisconnectMultipleOutputs = (createIndexSizeError)=>{
    return (outputAudioNodes, destinationOrOutput, output, input = 0)=>{
        if (destinationOrOutput === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect()
        );
        if (typeof destinationOrOutput === 'number') return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, destinationOrOutput).disconnect();
        if (_nativeAudioNode.isNativeAudioNode(destinationOrOutput)) {
            if (output === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect(destinationOrOutput)
            );
            if (input === undefined) return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);
            return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0, input);
        }
        if (output === undefined) return outputAudioNodes.forEach((outputAudioNode)=>outputAudioNode.disconnect(destinationOrOutput)
        );
        return getOutputAudioNodeAtIndex(createIndexSizeError, outputAudioNodes, output).disconnect(destinationOrOutput, 0);
    };
};

},{"../guards/native-audio-node":"bDooh","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aOjun":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDynamicsCompressorNodeConstructor", ()=>createDynamicsCompressorNodeConstructor
);
const DEFAULT_OPTIONS = {
    attack: 0.003,
    channelCount: 2,
    channelCountMode: 'clamped-max',
    channelInterpretation: 'speakers',
    knee: 30,
    ratio: 12,
    release: 0.25,
    threshold: -24
};
const createDynamicsCompressorNodeConstructor = (audioNodeConstructor, createAudioParam, createDynamicsCompressorNodeRenderer, createNativeDynamicsCompressorNode, createNotSupportedError, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class DynamicsCompressorNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const dynamicsCompressorNodeRenderer = isOffline ? createDynamicsCompressorNodeRenderer() : null;
            super(context, false, nativeDynamicsCompressorNode, dynamicsCompressorNodeRenderer);
            this._attack = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.attack);
            this._knee = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.knee);
            this._nativeDynamicsCompressorNode = nativeDynamicsCompressorNode;
            this._ratio = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.ratio);
            this._release = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.release);
            this._threshold = createAudioParam(this, isOffline, nativeDynamicsCompressorNode.threshold);
            setAudioNodeTailTime(this, 0.006);
        }
        get attack() {
            return this._attack;
        }
        // Bug #108: Safari allows a channelCount of three and above which is why the getter and setter needs to be overwritten here.
        get channelCount() {
            return this._nativeDynamicsCompressorNode.channelCount;
        }
        set channelCount(value) {
            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCount;
            this._nativeDynamicsCompressorNode.channelCount = value;
            if (value > 2) {
                this._nativeDynamicsCompressorNode.channelCount = previousChannelCount;
                throw createNotSupportedError();
            }
        }
        /*
         * Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max' yet which is why the getter and setter needs to be
         * overwritten here.
         */ get channelCountMode() {
            return this._nativeDynamicsCompressorNode.channelCountMode;
        }
        set channelCountMode(value) {
            const previousChannelCount = this._nativeDynamicsCompressorNode.channelCountMode;
            this._nativeDynamicsCompressorNode.channelCountMode = value;
            if (value === 'max') {
                this._nativeDynamicsCompressorNode.channelCountMode = previousChannelCount;
                throw createNotSupportedError();
            }
        }
        get knee() {
            return this._knee;
        }
        get ratio() {
            return this._ratio;
        }
        get reduction() {
            // Bug #111: Safari returns an AudioParam instead of a number.
            if (typeof this._nativeDynamicsCompressorNode.reduction.value === 'number') return this._nativeDynamicsCompressorNode.reduction.value;
            return this._nativeDynamicsCompressorNode.reduction;
        }
        get release() {
            return this._release;
        }
        get threshold() {
            return this._threshold;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ijyoV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createDynamicsCompressorNodeRendererFactory", ()=>createDynamicsCompressorNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createDynamicsCompressorNodeRendererFactory = (connectAudioParam, createNativeDynamicsCompressorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeDynamicsCompressorNodes = new WeakMap();
        const createDynamicsCompressorNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeDynamicsCompressorNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeDynamicsCompressorNode was not constructed on the same OfflineAudioContext it needs to be
             * created again.
             */ const nativeDynamicsCompressorNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeDynamicsCompressorNode, nativeOfflineAudioContext);
            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {
                const options = {
                    attack: nativeDynamicsCompressorNode.attack.value,
                    channelCount: nativeDynamicsCompressorNode.channelCount,
                    channelCountMode: nativeDynamicsCompressorNode.channelCountMode,
                    channelInterpretation: nativeDynamicsCompressorNode.channelInterpretation,
                    knee: nativeDynamicsCompressorNode.knee.value,
                    ratio: nativeDynamicsCompressorNode.ratio.value,
                    release: nativeDynamicsCompressorNode.release.value,
                    threshold: nativeDynamicsCompressorNode.threshold.value
                };
                nativeDynamicsCompressorNode = createNativeDynamicsCompressorNode(nativeOfflineAudioContext, options);
            }
            renderedNativeDynamicsCompressorNodes.set(nativeOfflineAudioContext, nativeDynamicsCompressorNode);
            if (!nativeDynamicsCompressorNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold, trace);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.attack, nativeDynamicsCompressorNode.attack, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.knee, nativeDynamicsCompressorNode.knee, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.ratio, nativeDynamicsCompressorNode.ratio, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.release, nativeDynamicsCompressorNode.release, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.threshold, nativeDynamicsCompressorNode.threshold, trace);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeDynamicsCompressorNode, trace);
            return nativeDynamicsCompressorNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeDynamicsCompressorNode = renderedNativeDynamicsCompressorNodes.get(nativeOfflineAudioContext);
                if (renderedNativeDynamicsCompressorNode !== undefined) return Promise.resolve(renderedNativeDynamicsCompressorNode);
                return createDynamicsCompressorNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ayhFC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createEncodingError", ()=>createEncodingError
);
const createEncodingError = ()=>new DOMException('', 'EncodingError')
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lAWbH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createEvaluateSource", ()=>createEvaluateSource
);
const createEvaluateSource = (window)=>{
    return (source)=>new Promise((resolve, reject)=>{
            if (window === null) {
                // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
                reject(new SyntaxError());
                return;
            }
            const head = window.document.head;
            if (head === null) // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
            reject(new SyntaxError());
            else {
                const script = window.document.createElement('script');
                // @todo Safari doesn't like URLs with a type of 'application/javascript; charset=utf-8'.
                const blob = new Blob([
                    source
                ], {
                    type: 'application/javascript'
                });
                const url = URL.createObjectURL(blob);
                const originalOnErrorHandler = window.onerror;
                const removeErrorEventListenerAndRevokeUrl = ()=>{
                    window.onerror = originalOnErrorHandler;
                    URL.revokeObjectURL(url);
                };
                window.onerror = (message, src, lineno, colno, error)=>{
                    // @todo Edge thinks the source is the one of the html document.
                    if (src === url || src === window.location.href && lineno === 1 && colno === 1) {
                        removeErrorEventListenerAndRevokeUrl();
                        reject(error);
                        return false;
                    }
                    if (originalOnErrorHandler !== null) return originalOnErrorHandler(message, src, lineno, colno, error);
                };
                script.onerror = ()=>{
                    removeErrorEventListenerAndRevokeUrl();
                    // Bug #182 Chrome, Edge and Opera do throw an instance of a SyntaxError instead of a DOMException.
                    reject(new SyntaxError());
                };
                script.onload = ()=>{
                    removeErrorEventListenerAndRevokeUrl();
                    resolve();
                };
                script.src = url;
                script.type = 'module';
                head.appendChild(script);
            }
        })
    ;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"22mxx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createEventTargetConstructor", ()=>createEventTargetConstructor
);
const createEventTargetConstructor = (wrapEventListener)=>{
    return class EventTarget1 {
        constructor(_nativeEventTarget){
            this._nativeEventTarget = _nativeEventTarget;
            this._listeners = new WeakMap();
        }
        addEventListener(type, listener, options) {
            if (listener !== null) {
                let wrappedEventListener = this._listeners.get(listener);
                if (wrappedEventListener === undefined) {
                    wrappedEventListener = wrapEventListener(this, listener);
                    if (typeof listener === 'function') this._listeners.set(listener, wrappedEventListener);
                }
                this._nativeEventTarget.addEventListener(type, wrappedEventListener, options);
            }
        }
        dispatchEvent(event) {
            return this._nativeEventTarget.dispatchEvent(event);
        }
        removeEventListener(type, listener, options) {
            const wrappedEventListener = listener === null ? undefined : this._listeners.get(listener);
            this._nativeEventTarget.removeEventListener(type, wrappedEventListener === undefined ? null : wrappedEventListener, options);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fhD5Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createExposeCurrentFrameAndCurrentTime", ()=>createExposeCurrentFrameAndCurrentTime
);
const createExposeCurrentFrameAndCurrentTime = (window)=>{
    return (currentTime, sampleRate, fn)=>{
        Object.defineProperties(window, {
            currentFrame: {
                configurable: true,
                get () {
                    return Math.round(currentTime * sampleRate);
                }
            },
            currentTime: {
                configurable: true,
                get () {
                    return currentTime;
                }
            }
        });
        try {
            return fn();
        } finally{
            if (window !== null) {
                delete window.currentFrame;
                delete window.currentTime;
            }
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9Fmtn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createFetchSource", ()=>createFetchSource
);
const createFetchSource = (createAbortError)=>{
    return async (url)=>{
        try {
            const response = await fetch(url);
            if (response.ok) return [
                await response.text(),
                response.url
            ];
        } catch  {
        // Ignore errors.
        } // tslint:disable-line:no-empty
        throw createAbortError();
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4ccFC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGainNodeConstructor", ()=>createGainNodeConstructor
);
var _constants = require("../constants");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers',
    gain: 1
};
const createGainNodeConstructor = (audioNodeConstructor, createAudioParam, createGainNodeRenderer, createNativeGainNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class GainNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeGainNode = createNativeGainNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const gainNodeRenderer = isOffline ? createGainNodeRenderer() : null;
            super(context, false, nativeGainNode, gainNodeRenderer);
            // Bug #74: Safari does not export the correct values for maxValue and minValue.
            this._gain = createAudioParam(this, isOffline, nativeGainNode.gain, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
        }
        get gain() {
            return this._gain;
        }
    };
};

},{"../constants":"dG3Pl","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eB9zs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGainNodeRendererFactory", ()=>createGainNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createGainNodeRendererFactory = (connectAudioParam, createNativeGainNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeGainNodes = new WeakMap();
        const createGainNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeGainNode = getNativeAudioNode(proxy);
            // If the initially used nativeGainNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeGainNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeGainNode, nativeOfflineAudioContext);
            if (!nativeGainNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeGainNode.channelCount,
                    channelCountMode: nativeGainNode.channelCountMode,
                    channelInterpretation: nativeGainNode.channelInterpretation,
                    gain: nativeGainNode.gain.value
                };
                nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, options);
            }
            renderedNativeGainNodes.set(nativeOfflineAudioContext, nativeGainNode);
            if (!nativeGainNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain, trace);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.gain, nativeGainNode.gain, trace);
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeGainNode, trace);
            return nativeGainNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeGainNode = renderedNativeGainNodes.get(nativeOfflineAudioContext);
                if (renderedNativeGainNode !== undefined) return Promise.resolve(renderedNativeGainNode);
                return createGainNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7u5Wl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetActiveAudioWorkletNodeInputs", ()=>createGetActiveAudioWorkletNodeInputs
);
const createGetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore, getValueForKey)=>{
    return (nativeAudioWorkletNode)=>getValueForKey(activeAudioWorkletNodeInputsStore, nativeAudioWorkletNode)
    ;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5d8tK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetAudioNodeRenderer", ()=>createGetAudioNodeRenderer
);
const createGetAudioNodeRenderer = (getAudioNodeConnections)=>{
    return (audioNode)=>{
        const audioNodeConnections = getAudioNodeConnections(audioNode);
        if (audioNodeConnections.renderer === null) throw new Error('Missing the renderer of the given AudioNode in the audio graph.');
        return audioNodeConnections.renderer;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kxrG8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetAudioNodeTailTime", ()=>createGetAudioNodeTailTime
);
const createGetAudioNodeTailTime = (audioNodeTailTimeStore)=>{
    return (audioNode)=>{
        var _a;
        return (_a = audioNodeTailTimeStore.get(audioNode)) !== null && _a !== void 0 ? _a : 0;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e5iAn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetAudioParamRenderer", ()=>createGetAudioParamRenderer
);
const createGetAudioParamRenderer = (getAudioParamConnections)=>{
    return (audioParam)=>{
        const audioParamConnections = getAudioParamConnections(audioParam);
        if (audioParamConnections.renderer === null) throw new Error('Missing the renderer of the given AudioParam in the audio graph.');
        return audioParamConnections.renderer;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7WKwq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetBackupOfflineAudioContext", ()=>createGetBackupOfflineAudioContext
);
const createGetBackupOfflineAudioContext = (backupOfflineAudioContextStore)=>{
    return (nativeContext)=>{
        return backupOfflineAudioContextStore.get(nativeContext);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"a5g0D":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetNativeContext", ()=>createGetNativeContext
);
var _invalidStateError = require("./invalid-state-error");
const createGetNativeContext = (contextStore)=>{
    return (context)=>{
        const nativeContext = contextStore.get(context);
        if (nativeContext === undefined) throw _invalidStateError.createInvalidStateError();
        return nativeContext;
    };
};

},{"./invalid-state-error":"kvntE","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kvntE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createInvalidStateError", ()=>createInvalidStateError
);
const createInvalidStateError = ()=>new DOMException('', 'InvalidStateError')
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3BEPC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetOrCreateBackupOfflineAudioContext", ()=>createGetOrCreateBackupOfflineAudioContext
);
const createGetOrCreateBackupOfflineAudioContext = (backupOfflineAudioContextStore, nativeOfflineAudioContextConstructor)=>{
    return (nativeContext)=>{
        let backupOfflineAudioContext = backupOfflineAudioContextStore.get(nativeContext);
        if (backupOfflineAudioContext !== undefined) return backupOfflineAudioContext;
        if (nativeOfflineAudioContextConstructor === null) throw new Error('Missing the native OfflineAudioContext constructor.');
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        backupOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        backupOfflineAudioContextStore.set(nativeContext, backupOfflineAudioContext);
        return backupOfflineAudioContext;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bef04":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createGetUnrenderedAudioWorkletNodes", ()=>createGetUnrenderedAudioWorkletNodes
);
const createGetUnrenderedAudioWorkletNodes = (unrenderedAudioWorkletNodeStore)=>{
    return (nativeContext)=>{
        const unrenderedAudioWorkletNodes = unrenderedAudioWorkletNodeStore.get(nativeContext);
        if (unrenderedAudioWorkletNodes === undefined) throw new Error('The context has no set of AudioWorkletNodes.');
        return unrenderedAudioWorkletNodes;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7XCZ8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIIRFilterNodeConstructor", ()=>createIIRFilterNodeConstructor
);
var _wrapIirFilterNodeGetFrequencyResponseMethod = require("../helpers/wrap-iir-filter-node-get-frequency-response-method");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers'
};
const createIIRFilterNodeConstructor = (audioNodeConstructor, createNativeIIRFilterNode, createIIRFilterNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class IIRFilterNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeIIRFilterNode = createNativeIIRFilterNode(nativeContext, isOffline ? null : context.baseLatency, mergedOptions);
            const iirFilterNodeRenderer = isOffline ? createIIRFilterNodeRenderer(mergedOptions.feedback, mergedOptions.feedforward) : null;
            super(context, false, nativeIIRFilterNode, iirFilterNodeRenderer);
            // Bug #23 & #24: FirefoxDeveloper does not throw an InvalidAccessError.
            // @todo Write a test which allows other browsers to remain unpatched.
            _wrapIirFilterNodeGetFrequencyResponseMethod.wrapIIRFilterNodeGetFrequencyResponseMethod(nativeIIRFilterNode);
            this._nativeIIRFilterNode = nativeIIRFilterNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        getFrequencyResponse(frequencyHz, magResponse, phaseResponse) {
            return this._nativeIIRFilterNode.getFrequencyResponse(frequencyHz, magResponse, phaseResponse);
        }
    };
};

},{"../helpers/wrap-iir-filter-node-get-frequency-response-method":"7FgW0","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7FgW0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapIIRFilterNodeGetFrequencyResponseMethod", ()=>wrapIIRFilterNodeGetFrequencyResponseMethod
);
var _invalidAccessError = require("../factories/invalid-access-error");
const wrapIIRFilterNodeGetFrequencyResponseMethod = (nativeIIRFilterNode)=>{
    nativeIIRFilterNode.getFrequencyResponse = ((getFrequencyResponse)=>{
        return (frequencyHz, magResponse, phaseResponse)=>{
            if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw _invalidAccessError.createInvalidAccessError();
            return getFrequencyResponse.call(nativeIIRFilterNode, frequencyHz, magResponse, phaseResponse);
        };
    })(nativeIIRFilterNode.getFrequencyResponse);
};

},{"../factories/invalid-access-error":"irzR7","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"irzR7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createInvalidAccessError", ()=>createInvalidAccessError
);
const createInvalidAccessError = ()=>new DOMException('', 'InvalidAccessError')
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"coeG5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIIRFilterNodeRendererFactory", ()=>createIIRFilterNodeRendererFactory
);
var _filterBuffer = require("../helpers/filter-buffer");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const filterFullBuffer = (renderedBuffer, nativeOfflineAudioContext, feedback, feedforward)=>{
    const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);
    const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);
    const feedbackLength = convertedFeedback.length;
    const feedforwardLength = convertedFeedforward.length;
    const minLength = Math.min(feedbackLength, feedforwardLength);
    if (convertedFeedback[0] !== 1) {
        for(let i = 0; i < feedbackLength; i += 1)convertedFeedforward[i] /= convertedFeedback[0];
        for(let i1 = 1; i1 < feedforwardLength; i1 += 1)convertedFeedback[i1] /= convertedFeedback[0];
    }
    const bufferLength = 32;
    const xBuffer = new Float32Array(bufferLength);
    const yBuffer = new Float32Array(bufferLength);
    const filteredBuffer = nativeOfflineAudioContext.createBuffer(renderedBuffer.numberOfChannels, renderedBuffer.length, renderedBuffer.sampleRate);
    const numberOfChannels = renderedBuffer.numberOfChannels;
    for(let i = 0; i < numberOfChannels; i += 1){
        const input = renderedBuffer.getChannelData(i);
        const output = filteredBuffer.getChannelData(i);
        xBuffer.fill(0);
        yBuffer.fill(0);
        _filterBuffer.filterBuffer(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffer, yBuffer, 0, bufferLength, input, output);
    }
    return filteredBuffer;
};
const createIIRFilterNodeRendererFactory = (createNativeAudioBufferSourceNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return (feedback, feedforward)=>{
        const renderedNativeAudioNodes = new WeakMap();
        let filteredBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeAudioBufferSourceNode = null;
            let nativeIIRFilterNode = getNativeAudioNode(proxy);
            // If the initially used nativeIIRFilterNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeIIRFilterNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeIIRFilterNode, nativeOfflineAudioContext);
            // Bug #9: Safari does not support IIRFilterNodes.
            if (nativeOfflineAudioContext.createIIRFilter === undefined) nativeAudioBufferSourceNode = createNativeAudioBufferSourceNode(nativeOfflineAudioContext, {
                buffer: null,
                channelCount: 2,
                channelCountMode: 'max',
                channelInterpretation: 'speakers',
                loop: false,
                loopEnd: 0,
                loopStart: 0,
                playbackRate: 1
            });
            else if (!nativeIIRFilterNodeIsOwnedByContext) // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.
            nativeIIRFilterNode = nativeOfflineAudioContext.createIIRFilter(feedforward, feedback);
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeAudioBufferSourceNode === null ? nativeIIRFilterNode : nativeAudioBufferSourceNode);
            if (nativeAudioBufferSourceNode !== null) {
                if (filteredBufferPromise === null) {
                    if (nativeOfflineAudioContextConstructor === null) throw new Error('Missing the native OfflineAudioContext constructor.');
                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(// Bug #47: The AudioDestinationNode in Safari gets not initialized correctly.
                    proxy.context.destination.channelCount, // Bug #17: Safari does not yet expose the length.
                    proxy.context.length, nativeOfflineAudioContext.sampleRate);
                    filteredBufferPromise = (async ()=>{
                        await renderInputsOfAudioNode(proxy, partialOfflineAudioContext, partialOfflineAudioContext.destination, trace);
                        const renderedBuffer = await renderNativeOfflineAudioContext(partialOfflineAudioContext);
                        return filterFullBuffer(renderedBuffer, nativeOfflineAudioContext, feedback, feedforward);
                    })();
                }
                const filteredBuffer = await filteredBufferPromise;
                nativeAudioBufferSourceNode.buffer = filteredBuffer;
                nativeAudioBufferSourceNode.start(0);
                return nativeAudioBufferSourceNode;
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeIIRFilterNode, trace);
            return nativeIIRFilterNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeAudioNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeAudioNode !== undefined) return Promise.resolve(renderedNativeAudioNode);
                return createAudioNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/filter-buffer":"gpqLm","../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gpqLm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "filterBuffer", ()=>filterBuffer
);
const filterBuffer = (feedback, feedbackLength, feedforward, feedforwardLength, minLength, xBuffer, yBuffer, bufferIndex, bufferLength, input, output)=>{
    const inputLength = input.length;
    let i = bufferIndex;
    for(let j = 0; j < inputLength; j += 1){
        let y = feedforward[0] * input[j];
        for(let k = 1; k < minLength; k += 1){
            const x = i - k & bufferLength - 1; // tslint:disable-line:no-bitwise
            y += feedforward[k] * xBuffer[x];
            y -= feedback[k] * yBuffer[x];
        }
        for(let k1 = minLength; k1 < feedforwardLength; k1 += 1)y += feedforward[k1] * xBuffer[i - k1 & bufferLength - 1]; // tslint:disable-line:no-bitwise
        for(let k2 = minLength; k2 < feedbackLength; k2 += 1)y -= feedback[k2] * yBuffer[i - k2 & bufferLength - 1]; // tslint:disable-line:no-bitwise
        xBuffer[i] = input[j];
        yBuffer[i] = y;
        i = i + 1 & bufferLength - 1; // tslint:disable-line:no-bitwise
        output[j] = y;
    }
    return i;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jOaj9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIncrementCycleCounterFactory", ()=>createIncrementCycleCounterFactory
);
var _audioNodeOutputConnection = require("../guards/audio-node-output-connection");
const createIncrementCycleCounterFactory = (cycleCounters, disconnectNativeAudioNodeFromNativeAudioNode, getAudioNodeConnections, getNativeAudioNode, getNativeAudioParam, isActiveAudioNode)=>{
    return (isOffline)=>{
        return (audioNode, count)=>{
            const cycleCounter = cycleCounters.get(audioNode);
            if (cycleCounter === undefined) {
                if (!isOffline && isActiveAudioNode(audioNode)) {
                    const nativeSourceAudioNode = getNativeAudioNode(audioNode);
                    const { outputs  } = getAudioNodeConnections(audioNode);
                    for (const output of outputs)if (_audioNodeOutputConnection.isAudioNodeOutputConnection(output)) {
                        const nativeDestinationAudioNode = getNativeAudioNode(output[0]);
                        disconnectNativeAudioNodeFromNativeAudioNode(nativeSourceAudioNode, nativeDestinationAudioNode, output[1], output[2]);
                    } else {
                        const nativeDestinationAudioParam = getNativeAudioParam(output[0]);
                        nativeSourceAudioNode.disconnect(nativeDestinationAudioParam, output[1]);
                    }
                }
                cycleCounters.set(audioNode, count);
            } else cycleCounters.set(audioNode, cycleCounter + count);
        };
    };
};

},{"../guards/audio-node-output-connection":"3Drf7","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"77CuE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsAnyAudioContext", ()=>createIsAnyAudioContext
);
const createIsAnyAudioContext = (contextStore, isNativeAudioContext)=>{
    return (anything)=>{
        const nativeContext = contextStore.get(anything);
        return isNativeAudioContext(nativeContext) || isNativeAudioContext(anything);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"46fQP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsAnyAudioNode", ()=>createIsAnyAudioNode
);
const createIsAnyAudioNode = (audioNodeStore, isNativeAudioNode)=>{
    return (anything)=>audioNodeStore.has(anything) || isNativeAudioNode(anything)
    ;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7duKE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsAnyAudioParam", ()=>createIsAnyAudioParam
);
const createIsAnyAudioParam = (audioParamStore, isNativeAudioParam)=>{
    return (anything)=>audioParamStore.has(anything) || isNativeAudioParam(anything)
    ;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7lqyw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsAnyOfflineAudioContext", ()=>createIsAnyOfflineAudioContext
);
const createIsAnyOfflineAudioContext = (contextStore, isNativeOfflineAudioContext)=>{
    return (anything)=>{
        const nativeContext = contextStore.get(anything);
        return isNativeOfflineAudioContext(nativeContext) || isNativeOfflineAudioContext(anything);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cf0YV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeAudioContext", ()=>createIsNativeAudioContext
);
const createIsNativeAudioContext = (nativeAudioContextConstructor)=>{
    return (anything)=>{
        return nativeAudioContextConstructor !== null && anything instanceof nativeAudioContextConstructor;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jkhov":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeAudioNode", ()=>createIsNativeAudioNode
);
const createIsNativeAudioNode = (window)=>{
    return (anything)=>{
        return window !== null && typeof window.AudioNode === 'function' && anything instanceof window.AudioNode;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bDZUl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeAudioParam", ()=>createIsNativeAudioParam
);
const createIsNativeAudioParam = (window)=>{
    return (anything)=>{
        return window !== null && typeof window.AudioParam === 'function' && anything instanceof window.AudioParam;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"sk4ws":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeContext", ()=>createIsNativeContext
);
const createIsNativeContext = (isNativeAudioContext, isNativeOfflineAudioContext)=>{
    return (anything)=>{
        return isNativeAudioContext(anything) || isNativeOfflineAudioContext(anything);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ed9HY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsNativeOfflineAudioContext", ()=>createIsNativeOfflineAudioContext
);
const createIsNativeOfflineAudioContext = (nativeOfflineAudioContextConstructor)=>{
    return (anything)=>{
        return nativeOfflineAudioContextConstructor !== null && anything instanceof nativeOfflineAudioContextConstructor;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8H0Db":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsSecureContext", ()=>createIsSecureContext
);
const createIsSecureContext = (window)=>window !== null && window.isSecureContext
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1cpZE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createIsSupportedPromise", ()=>createIsSupportedPromise
);
const createIsSupportedPromise = async (cacheTestResult, testAudioBufferCopyChannelMethodsSubarraySupport, testAudioContextCloseMethodSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextOptionsSupport, testAudioNodeConnectMethodSupport, testAudioWorkletProcessorNoOutputsSupport, testChannelMergerNodeChannelCountSupport, testConstantSourceNodeAccurateSchedulingSupport, testConvolverNodeBufferReassignabilitySupport, testConvolverNodeChannelCountSupport, testDomExceptionContrucorSupport, testIsSecureContextSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testStereoPannerNodeDefaultValueSupport, testTransferablesSupport)=>{
    if (cacheTestResult(testAudioBufferCopyChannelMethodsSubarraySupport, testAudioBufferCopyChannelMethodsSubarraySupport) && cacheTestResult(testAudioContextCloseMethodSupport, testAudioContextCloseMethodSupport) && cacheTestResult(testAudioContextOptionsSupport, testAudioContextOptionsSupport) && cacheTestResult(testAudioNodeConnectMethodSupport, testAudioNodeConnectMethodSupport) && cacheTestResult(testChannelMergerNodeChannelCountSupport, testChannelMergerNodeChannelCountSupport) && cacheTestResult(testConstantSourceNodeAccurateSchedulingSupport, testConstantSourceNodeAccurateSchedulingSupport) && cacheTestResult(testConvolverNodeBufferReassignabilitySupport, testConvolverNodeBufferReassignabilitySupport) && cacheTestResult(testConvolverNodeChannelCountSupport, testConvolverNodeChannelCountSupport) && cacheTestResult(testDomExceptionContrucorSupport, testDomExceptionContrucorSupport) && cacheTestResult(testIsSecureContextSupport, testIsSecureContextSupport) && cacheTestResult(testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport)) {
        const results = await Promise.all([
            cacheTestResult(testAudioContextDecodeAudioDataMethodTypeErrorSupport, testAudioContextDecodeAudioDataMethodTypeErrorSupport),
            cacheTestResult(testAudioWorkletProcessorNoOutputsSupport, testAudioWorkletProcessorNoOutputsSupport),
            cacheTestResult(testStereoPannerNodeDefaultValueSupport, testStereoPannerNodeDefaultValueSupport),
            cacheTestResult(testTransferablesSupport, testTransferablesSupport)
        ]);
        return results.every((result)=>result
        );
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iZbh0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMediaElementAudioSourceNodeConstructor", ()=>createMediaElementAudioSourceNodeConstructor
);
const createMediaElementAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaElementAudioSourceNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaElementAudioSourceNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaElementAudioSourceNode = createNativeMediaElementAudioSourceNode(nativeContext, options);
            // Bug #171: Safari allows to create a MediaElementAudioSourceNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw TypeError();
            super(context, true, nativeMediaElementAudioSourceNode, null);
            this._nativeMediaElementAudioSourceNode = nativeMediaElementAudioSourceNode;
        }
        get mediaElement() {
            return this._nativeMediaElementAudioSourceNode.mediaElement;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"66Na4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMediaStreamAudioDestinationNodeConstructor", ()=>createMediaStreamAudioDestinationNodeConstructor
);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'explicit',
    channelInterpretation: 'speakers'
};
const createMediaStreamAudioDestinationNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioDestinationNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaStreamAudioDestinationNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            // Bug #173: Safari allows to create a MediaStreamAudioDestinationNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw new TypeError();
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeMediaStreamAudioDestinationNode = createNativeMediaStreamAudioDestinationNode(nativeContext, mergedOptions);
            super(context, false, nativeMediaStreamAudioDestinationNode, null);
            this._nativeMediaStreamAudioDestinationNode = nativeMediaStreamAudioDestinationNode;
        }
        get stream() {
            return this._nativeMediaStreamAudioDestinationNode.stream;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3GcMB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMediaStreamAudioSourceNodeConstructor", ()=>createMediaStreamAudioSourceNodeConstructor
);
const createMediaStreamAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamAudioSourceNode, getNativeContext, isNativeOfflineAudioContext)=>{
    return class MediaStreamAudioSourceNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaStreamAudioSourceNode = createNativeMediaStreamAudioSourceNode(nativeContext, options);
            // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.
            if (isNativeOfflineAudioContext(nativeContext)) throw new TypeError();
            super(context, true, nativeMediaStreamAudioSourceNode, null);
            this._nativeMediaStreamAudioSourceNode = nativeMediaStreamAudioSourceNode;
        }
        get mediaStream() {
            return this._nativeMediaStreamAudioSourceNode.mediaStream;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"87CyX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMediaStreamTrackAudioSourceNodeConstructor", ()=>createMediaStreamTrackAudioSourceNodeConstructor
);
const createMediaStreamTrackAudioSourceNodeConstructor = (audioNodeConstructor, createNativeMediaStreamTrackAudioSourceNode, getNativeContext)=>{
    return class MediaStreamTrackAudioSourceNode extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const nativeMediaStreamTrackAudioSourceNode = createNativeMediaStreamTrackAudioSourceNode(nativeContext, options);
            super(context, true, nativeMediaStreamTrackAudioSourceNode, null);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"42jSk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMinimalAudioContextConstructor", ()=>createMinimalAudioContextConstructor
);
var _deactivateAudioGraph = require("../helpers/deactivate-audio-graph");
var _isValidLatencyHint = require("../helpers/is-valid-latency-hint");
const createMinimalAudioContextConstructor = (createInvalidStateError, createNotSupportedError, createUnknownError, minimalBaseAudioContextConstructor, nativeAudioContextConstructor)=>{
    return class MinimalAudioContext extends minimalBaseAudioContextConstructor {
        constructor(options = {
        }){
            if (nativeAudioContextConstructor === null) throw new Error('Missing the native AudioContext constructor.');
            let nativeAudioContext;
            try {
                nativeAudioContext = new nativeAudioContextConstructor(options);
            } catch (err) {
                // Bug #192 Safari does throw a SyntaxError if the sampleRate is not supported.
                if (err.code === 12 && err.message === 'sampleRate is not in range') throw createNotSupportedError();
                throw err;
            }
            // Bug #131 Safari returns null when there are four other AudioContexts running already.
            if (nativeAudioContext === null) throw createUnknownError();
            // Bug #51 Only Chrome Edge, and Opera throw an error if the given latencyHint is invalid.
            if (!_isValidLatencyHint.isValidLatencyHint(options.latencyHint)) throw new TypeError(`The provided value '${options.latencyHint}' is not a valid enum value of type AudioContextLatencyCategory.`);
            // Bug #150 Safari does not support setting the sampleRate.
            if (options.sampleRate !== undefined && nativeAudioContext.sampleRate !== options.sampleRate) throw createNotSupportedError();
            super(nativeAudioContext, 2);
            const { latencyHint  } = options;
            const { sampleRate  } = nativeAudioContext;
            // @todo The values for 'balanced', 'interactive' and 'playback' are just copied from Chrome's implementation.
            this._baseLatency = typeof nativeAudioContext.baseLatency === 'number' ? nativeAudioContext.baseLatency : latencyHint === 'balanced' ? 512 / sampleRate : latencyHint === 'interactive' || latencyHint === undefined ? 256 / sampleRate : latencyHint === 'playback' ? 1024 / sampleRate : /*
                                   * @todo The min (256) and max (16384) values are taken from the allowed bufferSize values of a
                                   * ScriptProcessorNode.
                                   */ Math.max(2, Math.min(128, Math.round(latencyHint * sampleRate / 128))) * 128 / sampleRate;
            this._nativeAudioContext = nativeAudioContext;
            // Bug #188: Safari will set the context's state to 'interrupted' in case the user switches tabs.
            if (nativeAudioContextConstructor.name === 'webkitAudioContext') {
                this._nativeGainNode = nativeAudioContext.createGain();
                this._nativeOscillatorNode = nativeAudioContext.createOscillator();
                this._nativeGainNode.gain.value = 0.0000000000000000000000000000000000001;
                this._nativeOscillatorNode.connect(this._nativeGainNode).connect(nativeAudioContext.destination);
                this._nativeOscillatorNode.start();
            } else {
                this._nativeGainNode = null;
                this._nativeOscillatorNode = null;
            }
            this._state = null;
            /*
             * Bug #34: Chrome, Edge and Opera pretend to be running right away, but fire an onstatechange event when the state actually
             * changes to 'running'.
             */ if (nativeAudioContext.state === 'running') {
                this._state = 'suspended';
                const revokeState = ()=>{
                    if (this._state === 'suspended') this._state = null;
                    nativeAudioContext.removeEventListener('statechange', revokeState);
                };
                nativeAudioContext.addEventListener('statechange', revokeState);
            }
        }
        get baseLatency() {
            return this._baseLatency;
        }
        get state() {
            return this._state !== null ? this._state : this._nativeAudioContext.state;
        }
        close() {
            // Bug #35: Firefox does not throw an error if the AudioContext was closed before.
            if (this.state === 'closed') return this._nativeAudioContext.close().then(()=>{
                throw createInvalidStateError();
            });
            // Bug #34: If the state was set to suspended before it should be revoked now.
            if (this._state === 'suspended') this._state = null;
            return this._nativeAudioContext.close().then(()=>{
                if (this._nativeGainNode !== null && this._nativeOscillatorNode !== null) {
                    this._nativeOscillatorNode.stop();
                    this._nativeGainNode.disconnect();
                    this._nativeOscillatorNode.disconnect();
                }
                _deactivateAudioGraph.deactivateAudioGraph(this);
            });
        }
        resume() {
            if (this._state === 'suspended') return new Promise((resolve, reject)=>{
                const resolvePromise = ()=>{
                    this._nativeAudioContext.removeEventListener('statechange', resolvePromise);
                    if (this._nativeAudioContext.state === 'running') resolve();
                    else this.resume().then(resolve, reject);
                };
                this._nativeAudioContext.addEventListener('statechange', resolvePromise);
            });
            return this._nativeAudioContext.resume().catch((err)=>{
                // Bug #55: Chrome, Edge and Opera do throw an InvalidAccessError instead of an InvalidStateError.
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined || err.code === 15) throw createInvalidStateError();
                throw err;
            });
        }
        suspend() {
            return this._nativeAudioContext.suspend().catch((err)=>{
                // Bug #56: Safari invokes the catch handler but without an error.
                if (err === undefined) throw createInvalidStateError();
                throw err;
            });
        }
    };
};

},{"../helpers/deactivate-audio-graph":"kkyz8","../helpers/is-valid-latency-hint":"laOam","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7EGmO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMinimalBaseAudioContextConstructor", ()=>createMinimalBaseAudioContextConstructor
);
var _globals = require("../globals");
const createMinimalBaseAudioContextConstructor = (audioDestinationNodeConstructor, createAudioListener, eventTargetConstructor, isNativeOfflineAudioContext, unrenderedAudioWorkletNodeStore, wrapEventListener)=>{
    return class MinimalBaseAudioContext extends eventTargetConstructor {
        constructor(_nativeContext, numberOfChannels){
            super(_nativeContext);
            this._nativeContext = _nativeContext;
            _globals.CONTEXT_STORE.set(this, _nativeContext);
            if (isNativeOfflineAudioContext(_nativeContext)) unrenderedAudioWorkletNodeStore.set(_nativeContext, new Set());
            this._destination = new audioDestinationNodeConstructor(this, numberOfChannels);
            this._listener = createAudioListener(this, _nativeContext);
            this._onstatechange = null;
        }
        get currentTime() {
            return this._nativeContext.currentTime;
        }
        get destination() {
            return this._destination;
        }
        get listener() {
            return this._listener;
        }
        get onstatechange() {
            return this._onstatechange;
        }
        set onstatechange(value) {
            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
            this._nativeContext.onstatechange = wrappedListener;
            const nativeOnStateChange = this._nativeContext.onstatechange;
            this._onstatechange = nativeOnStateChange !== null && nativeOnStateChange === wrappedListener ? value : nativeOnStateChange;
        }
        get sampleRate() {
            return this._nativeContext.sampleRate;
        }
        get state() {
            return this._nativeContext.state;
        }
    };
};

},{"../globals":"80KZG","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3oO6X":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMinimalOfflineAudioContextConstructor", ()=>createMinimalOfflineAudioContextConstructor
);
var _deactivateAudioGraph = require("../helpers/deactivate-audio-graph");
var _testPromiseSupport = require("../helpers/test-promise-support");
const DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const createMinimalOfflineAudioContextConstructor = (cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, minimalBaseAudioContextConstructor, startRendering)=>{
    return class MinimalOfflineAudioContext extends minimalBaseAudioContextConstructor {
        constructor(options){
            const { length , numberOfChannels , sampleRate  } = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);
            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
            if (!cacheTestResult(_testPromiseSupport.testPromiseSupport, ()=>_testPromiseSupport.testPromiseSupport(nativeOfflineAudioContext)
            )) nativeOfflineAudioContext.addEventListener('statechange', (()=>{
                let i = 0;
                const delayStateChangeEvent = (event)=>{
                    if (this._state === 'running') {
                        if (i > 0) {
                            nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);
                            event.stopImmediatePropagation();
                            this._waitForThePromiseToSettle(event);
                        } else i += 1;
                    }
                };
                return delayStateChangeEvent;
            })());
            super(nativeOfflineAudioContext, numberOfChannels);
            this._length = length;
            this._nativeOfflineAudioContext = nativeOfflineAudioContext;
            this._state = null;
        }
        get length() {
            // Bug #17: Safari does not yet expose the length.
            if (this._nativeOfflineAudioContext.length === undefined) return this._length;
            return this._nativeOfflineAudioContext.length;
        }
        get state() {
            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
        }
        startRendering() {
            /*
             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
             * the state of the nativeOfflineAudioContext might no transition to running immediately.
             */ if (this._state === 'running') return Promise.reject(createInvalidStateError());
            this._state = 'running';
            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(()=>{
                this._state = null;
                _deactivateAudioGraph.deactivateAudioGraph(this);
            });
        }
        _waitForThePromiseToSettle(event) {
            if (this._state === null) this._nativeOfflineAudioContext.dispatchEvent(event);
            else setTimeout(()=>this._waitForThePromiseToSettle(event)
            );
        }
    };
};

},{"../helpers/deactivate-audio-graph":"kkyz8","../helpers/test-promise-support":"bcKJv","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bcKJv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testPromiseSupport", ()=>testPromiseSupport
);
const testPromiseSupport = (nativeContext)=>{
    // This 12 numbers represent the 48 bytes of an empty WAVE file with a single sample.
    const uint32Array = new Uint32Array([
        1179011410,
        40,
        1163280727,
        544501094,
        16,
        131073,
        44100,
        176400,
        1048580,
        1635017060,
        4,
        0
    ]);
    try {
        // Bug #1: Safari requires a successCallback.
        const promise = nativeContext.decodeAudioData(uint32Array.buffer, ()=>{
        // Ignore the success callback.
        });
        if (promise === undefined) return false;
        promise.catch(()=>{
        // Ignore rejected errors.
        });
        return true;
    } catch  {
    // Ignore errors.
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8PkhL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createMonitorConnections", ()=>createMonitorConnections
);
const createMonitorConnections = (insertElementInSet, isNativeAudioNode)=>{
    return (nativeAudioNode, whenConnected, whenDisconnected)=>{
        const connections = new Set();
        nativeAudioNode.connect = ((connect)=>{
            // tslint:disable-next-line:invalid-void
            return (destination, output = 0, input = 0)=>{
                const wasDisconnected = connections.size === 0;
                if (isNativeAudioNode(destination)) {
                    // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                    connect.call(nativeAudioNode, destination, output, input);
                    insertElementInSet(connections, [
                        destination,
                        output,
                        input
                    ], (connection)=>connection[0] === destination && connection[1] === output && connection[2] === input
                    , true);
                    if (wasDisconnected) whenConnected();
                    return destination;
                }
                connect.call(nativeAudioNode, destination, output);
                insertElementInSet(connections, [
                    destination,
                    output
                ], (connection)=>connection[0] === destination && connection[1] === output
                , true);
                if (wasDisconnected) whenConnected();
                return;
            };
        })(nativeAudioNode.connect);
        nativeAudioNode.disconnect = ((disconnect)=>{
            return (destinationOrOutput, output, input)=>{
                const wasConnected = connections.size > 0;
                if (destinationOrOutput === undefined) {
                    disconnect.apply(nativeAudioNode);
                    connections.clear();
                } else if (typeof destinationOrOutput === 'number') {
                    // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput);
                    for (const connection of connections)if (connection[1] === destinationOrOutput) connections.delete(connection);
                } else {
                    if (isNativeAudioNode(destinationOrOutput)) // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput, output, input);
                    else // @todo TypeScript cannot infer the overloaded signature with 2 arguments yet.
                    disconnect.call(nativeAudioNode, destinationOrOutput, output);
                    for (const connection of connections)if (connection[0] === destinationOrOutput && (output === undefined || connection[1] === output) && (input === undefined || connection[2] === input)) connections.delete(connection);
                }
                const isDisconnected = connections.size === 0;
                if (wasConnected && isDisconnected) whenDisconnected();
            };
        })(nativeAudioNode.disconnect);
        return nativeAudioNode;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aVma8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAnalyserNodeFactory", ()=>createNativeAnalyserNodeFactory
);
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _testAnalyserNodeGetFloatTimeDomainDataMethodSupport = require("../helpers/test-analyser-node-get-float-time-domain-data-method-support");
var _wrapAnalyserNodeGetFloatTimeDomainDataMethod = require("../helpers/wrap-analyser-node-get-float-time-domain-data-method");
const createNativeAnalyserNodeFactory = (cacheTestResult, createIndexSizeError)=>{
    return (nativeContext, options)=>{
        const nativeAnalyserNode = nativeContext.createAnalyser();
        // Bug #37: Firefox does not create an AnalyserNode with the default properties.
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeAnalyserNode, options);
        // Bug #118: Safari does not throw an error if maxDecibels is not more than minDecibels.
        if (!(options.maxDecibels > options.minDecibels)) throw createIndexSizeError();
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAnalyserNode, options, 'fftSize');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAnalyserNode, options, 'maxDecibels');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAnalyserNode, options, 'minDecibels');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAnalyserNode, options, 'smoothingTimeConstant');
        // Bug #36: Safari does not support getFloatTimeDomainData() yet.
        if (!cacheTestResult(_testAnalyserNodeGetFloatTimeDomainDataMethodSupport.testAnalyserNodeGetFloatTimeDomainDataMethodSupport, ()=>_testAnalyserNodeGetFloatTimeDomainDataMethodSupport.testAnalyserNodeGetFloatTimeDomainDataMethodSupport(nativeAnalyserNode)
        )) _wrapAnalyserNodeGetFloatTimeDomainDataMethod.wrapAnalyserNodeGetFloatTimeDomainDataMethod(nativeAnalyserNode);
        return nativeAnalyserNode;
    };
};

},{"../helpers/assign-native-audio-node-option":"2lkZy","../helpers/assign-native-audio-node-options":"2pMvb","../helpers/test-analyser-node-get-float-time-domain-data-method-support":"f6LoT","../helpers/wrap-analyser-node-get-float-time-domain-data-method":"OaNXK","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2lkZy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "assignNativeAudioNodeOption", ()=>assignNativeAudioNodeOption
);
const assignNativeAudioNodeOption = (nativeAudioNode, options, option)=>{
    const value = options[option];
    if (value !== undefined && value !== nativeAudioNode[option]) nativeAudioNode[option] = value;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2pMvb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "assignNativeAudioNodeOptions", ()=>assignNativeAudioNodeOptions
);
var _assignNativeAudioNodeOption = require("./assign-native-audio-node-option");
const assignNativeAudioNodeOptions = (nativeAudioNode, options)=>{
    _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAudioNode, options, 'channelCount');
    _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAudioNode, options, 'channelCountMode');
    _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAudioNode, options, 'channelInterpretation');
};

},{"./assign-native-audio-node-option":"2lkZy","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"f6LoT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAnalyserNodeGetFloatTimeDomainDataMethodSupport", ()=>testAnalyserNodeGetFloatTimeDomainDataMethodSupport
);
const testAnalyserNodeGetFloatTimeDomainDataMethodSupport = (nativeAnalyserNode)=>{
    return typeof nativeAnalyserNode.getFloatTimeDomainData === 'function';
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"OaNXK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAnalyserNodeGetFloatTimeDomainDataMethod", ()=>wrapAnalyserNodeGetFloatTimeDomainDataMethod
);
const wrapAnalyserNodeGetFloatTimeDomainDataMethod = (nativeAnalyserNode)=>{
    nativeAnalyserNode.getFloatTimeDomainData = (array)=>{
        const byteTimeDomainData = new Uint8Array(array.length);
        nativeAnalyserNode.getByteTimeDomainData(byteTimeDomainData);
        const length = Math.max(byteTimeDomainData.length, nativeAnalyserNode.fftSize);
        for(let i = 0; i < length; i += 1)array[i] = (byteTimeDomainData[i] - 128) * 0.0078125;
        return array;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"k70lf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioBufferConstructor", ()=>createNativeAudioBufferConstructor
);
const createNativeAudioBufferConstructor = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty('AudioBuffer')) return window.AudioBuffer;
    return null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eXNh0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioBufferSourceNodeFactory", ()=>createNativeAudioBufferSourceNodeFactory
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = require("../helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls");
var _wrapAudioScheduledSourceNodeStartMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters");
var _wrapAudioScheduledSourceNodeStopMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters");
const createNativeAudioBufferSourceNodeFactory = (addSilentConnection, cacheTestResult, testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, testAudioBufferSourceNodeStartMethodOffsetClampingSupport, testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioBufferSourceNodeStartMethodOffsetClampling, wrapAudioBufferSourceNodeStopMethodNullifiedBuffer, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls)=>{
    return (nativeContext, options)=>{
        const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeAudioBufferSourceNode, options);
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeAudioBufferSourceNode, options, 'playbackRate');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'buffer');
        // Bug #149: Safari does not yet support the detune AudioParam.
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loop');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loopEnd');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeAudioBufferSourceNode, options, 'loopStart');
        // Bug #69: Safari does allow calls to start() of an already scheduled AudioBufferSourceNode.
        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport, ()=>testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport(nativeContext)
        )) _wrapAudioBufferSourceNodeStartMethodConsecutiveCalls.wrapAudioBufferSourceNodeStartMethodConsecutiveCalls(nativeAudioBufferSourceNode);
        // Bug #154 & #155: Safari does not handle offsets which are equal to or greater than the duration of the buffer.
        if (!cacheTestResult(testAudioBufferSourceNodeStartMethodOffsetClampingSupport, ()=>testAudioBufferSourceNodeStartMethodOffsetClampingSupport(nativeContext)
        )) wrapAudioBufferSourceNodeStartMethodOffsetClampling(nativeAudioBufferSourceNode);
        // Bug #162: Safari does throw an error when stop() is called on an AudioBufferSourceNode which has no buffer assigned to it.
        if (!cacheTestResult(testAudioBufferSourceNodeStopMethodNullifiedBufferSupport, ()=>testAudioBufferSourceNodeStopMethodNullifiedBufferSupport(nativeContext)
        )) wrapAudioBufferSourceNodeStopMethodNullifiedBuffer(nativeAudioBufferSourceNode, nativeContext);
        // Bug #44: Safari does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext)
        )) _wrapAudioScheduledSourceNodeStartMethodNegativeParameters.wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeAudioBufferSourceNode);
        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, ()=>testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext)
        )) wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeAudioBufferSourceNode, nativeContext);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext)
        )) _wrapAudioScheduledSourceNodeStopMethodNegativeParameters.wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeAudioBufferSourceNode);
        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.
        addSilentConnection(nativeContext, nativeAudioBufferSourceNode);
        return nativeAudioBufferSourceNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-option":"2lkZy","../helpers/assign-native-audio-node-options":"2pMvb","../helpers/wrap-audio-buffer-source-node-start-method-consecutive-calls":"6qFmL","../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters":"kHOSr","../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters":"fqZi5","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jOVEo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "assignNativeAudioNodeAudioParamValue", ()=>assignNativeAudioNodeAudioParamValue
);
const assignNativeAudioNodeAudioParamValue = (nativeAudioNode, options, audioParam)=>{
    const value = options[audioParam];
    if (value !== undefined && value !== nativeAudioNode[audioParam].value) nativeAudioNode[audioParam].value = value;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6qFmL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioBufferSourceNodeStartMethodConsecutiveCalls", ()=>wrapAudioBufferSourceNodeStartMethodConsecutiveCalls
);
var _invalidStateError = require("../factories/invalid-state-error");
const wrapAudioBufferSourceNodeStartMethodConsecutiveCalls = (nativeAudioBufferSourceNode)=>{
    nativeAudioBufferSourceNode.start = ((start)=>{
        let isScheduled = false;
        return (when = 0, offset = 0, duration)=>{
            if (isScheduled) throw _invalidStateError.createInvalidStateError();
            start.call(nativeAudioBufferSourceNode, when, offset, duration);
            isScheduled = true;
        };
    })(nativeAudioBufferSourceNode.start);
};

},{"../factories/invalid-state-error":"kvntE","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kHOSr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioScheduledSourceNodeStartMethodNegativeParameters", ()=>wrapAudioScheduledSourceNodeStartMethodNegativeParameters
);
const wrapAudioScheduledSourceNodeStartMethodNegativeParameters = (nativeAudioScheduledSourceNode)=>{
    nativeAudioScheduledSourceNode.start = ((start)=>{
        return (when = 0, offset = 0, duration)=>{
            if (typeof duration === 'number' && duration < 0 || offset < 0 || when < 0) throw new RangeError("The parameters can't be negative.");
            // @todo TypeScript cannot infer the overloaded signature with 3 arguments yet.
            start.call(nativeAudioScheduledSourceNode, when, offset, duration);
        };
    })(nativeAudioScheduledSourceNode.start);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fqZi5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioScheduledSourceNodeStopMethodNegativeParameters", ()=>wrapAudioScheduledSourceNodeStopMethodNegativeParameters
);
const wrapAudioScheduledSourceNodeStopMethodNegativeParameters = (nativeAudioScheduledSourceNode)=>{
    nativeAudioScheduledSourceNode.stop = ((stop)=>{
        return (when = 0)=>{
            if (when < 0) throw new RangeError("The parameter can't be negative.");
            stop.call(nativeAudioScheduledSourceNode, when);
        };
    })(nativeAudioScheduledSourceNode.stop);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7CcBH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioContextConstructor", ()=>createNativeAudioContextConstructor
);
const createNativeAudioContextConstructor = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty('AudioContext')) return window.AudioContext;
    return window.hasOwnProperty('webkitAudioContext') ? window.webkitAudioContext : null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eiD7E":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioDestinationNodeFactory", ()=>createNativeAudioDestinationNodeFactory
);
const createNativeAudioDestinationNodeFactory = (createNativeGainNode, overwriteAccessors)=>{
    return (nativeContext, channelCount, isNodeOfNativeOfflineAudioContext)=>{
        const nativeAudioDestinationNode = nativeContext.destination;
        // Bug #132: Safari does not have the correct channelCount.
        if (nativeAudioDestinationNode.channelCount !== channelCount) try {
            nativeAudioDestinationNode.channelCount = channelCount;
        } catch  {
        // Bug #169: Safari throws an error on each attempt to change the channelCount.
        }
        // Bug #83: Safari does not have the correct channelCountMode.
        if (isNodeOfNativeOfflineAudioContext && nativeAudioDestinationNode.channelCountMode !== 'explicit') nativeAudioDestinationNode.channelCountMode = 'explicit';
        // Bug #47: The AudioDestinationNode in Safari does not initialize the maxChannelCount property correctly.
        if (nativeAudioDestinationNode.maxChannelCount === 0) Object.defineProperty(nativeAudioDestinationNode, 'maxChannelCount', {
            value: channelCount
        });
        // Bug #168: No browser does yet have an AudioDestinationNode with an output.
        const gainNode = createNativeGainNode(nativeContext, {
            channelCount,
            channelCountMode: nativeAudioDestinationNode.channelCountMode,
            channelInterpretation: nativeAudioDestinationNode.channelInterpretation,
            gain: 1
        });
        overwriteAccessors(gainNode, 'channelCount', (get)=>()=>get.call(gainNode)
        , (set)=>(value)=>{
                set.call(gainNode, value);
                try {
                    nativeAudioDestinationNode.channelCount = value;
                } catch (err) {
                    // Bug #169: Safari throws an error on each attempt to change the channelCount.
                    if (value > nativeAudioDestinationNode.maxChannelCount) throw err;
                }
            }
        );
        overwriteAccessors(gainNode, 'channelCountMode', (get)=>()=>get.call(gainNode)
        , (set)=>(value)=>{
                set.call(gainNode, value);
                nativeAudioDestinationNode.channelCountMode = value;
            }
        );
        overwriteAccessors(gainNode, 'channelInterpretation', (get)=>()=>get.call(gainNode)
        , (set)=>(value)=>{
                set.call(gainNode, value);
                nativeAudioDestinationNode.channelInterpretation = value;
            }
        );
        Object.defineProperty(gainNode, 'maxChannelCount', {
            get: ()=>nativeAudioDestinationNode.maxChannelCount
        });
        // @todo This should be disconnected when the context is closed.
        gainNode.connect(nativeAudioDestinationNode);
        return gainNode;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4LdwE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioWorkletNodeConstructor", ()=>createNativeAudioWorkletNodeConstructor
);
const createNativeAudioWorkletNodeConstructor = (window)=>{
    if (window === null) return null;
    return window.hasOwnProperty('AudioWorkletNode') ? window.AudioWorkletNode : null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kwJGf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioWorkletNodeFactory", ()=>createNativeAudioWorkletNodeFactory
);
var _testClonabilityOfAudioWorkletNodeOptions = require("../helpers/test-clonability-of-audio-worklet-node-options");
const createNativeAudioWorkletNodeFactory = (createInvalidStateError, createNativeAudioWorkletNodeFaker, createNativeGainNode, createNotSupportedError, monitorConnections)=>{
    return (nativeContext, baseLatency, nativeAudioWorkletNodeConstructor, name, processorConstructor, options)=>{
        if (nativeAudioWorkletNodeConstructor !== null) try {
            const nativeAudioWorkletNode = new nativeAudioWorkletNodeConstructor(nativeContext, name, options);
            const patchedEventListeners = new Map();
            let onprocessorerror = null;
            Object.defineProperties(nativeAudioWorkletNode, {
                /*
                     * Bug #61: Overwriting the property accessors for channelCount and channelCountMode is necessary as long as some
                     * browsers have no native implementation to achieve a consistent behavior.
                     */ channelCount: {
                    get: ()=>options.channelCount
                    ,
                    set: ()=>{
                        throw createInvalidStateError();
                    }
                },
                channelCountMode: {
                    get: ()=>'explicit'
                    ,
                    set: ()=>{
                        throw createInvalidStateError();
                    }
                },
                // Bug #156: Chrome and Edge do not yet fire an ErrorEvent.
                onprocessorerror: {
                    get: ()=>onprocessorerror
                    ,
                    set: (value)=>{
                        if (typeof onprocessorerror === 'function') nativeAudioWorkletNode.removeEventListener('processorerror', onprocessorerror);
                        onprocessorerror = typeof value === 'function' ? value : null;
                        if (typeof onprocessorerror === 'function') nativeAudioWorkletNode.addEventListener('processorerror', onprocessorerror);
                    }
                }
            });
            nativeAudioWorkletNode.addEventListener = ((addEventListener)=>{
                return (...args)=>{
                    if (args[0] === 'processorerror') {
                        const unpatchedEventListener = typeof args[1] === 'function' ? args[1] : typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function' ? args[1].handleEvent : null;
                        if (unpatchedEventListener !== null) {
                            const patchedEventListener = patchedEventListeners.get(args[1]);
                            if (patchedEventListener !== undefined) args[1] = patchedEventListener;
                            else {
                                args[1] = (event)=>{
                                    // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                                    if (event.type === 'error') {
                                        Object.defineProperties(event, {
                                            type: {
                                                value: 'processorerror'
                                            }
                                        });
                                        unpatchedEventListener(event);
                                    } else unpatchedEventListener(new ErrorEvent(args[0], {
                                        ...event
                                    }));
                                };
                                patchedEventListeners.set(unpatchedEventListener, args[1]);
                            }
                        }
                    }
                    // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                    addEventListener.call(nativeAudioWorkletNode, 'error', args[1], args[2]);
                    return addEventListener.call(nativeAudioWorkletNode, ...args);
                };
            })(nativeAudioWorkletNode.addEventListener);
            nativeAudioWorkletNode.removeEventListener = ((removeEventListener)=>{
                return (...args)=>{
                    if (args[0] === 'processorerror') {
                        const patchedEventListener = patchedEventListeners.get(args[1]);
                        if (patchedEventListener !== undefined) {
                            patchedEventListeners.delete(args[1]);
                            args[1] = patchedEventListener;
                        }
                    }
                    // Bug #178: Chrome, Edge and Opera do fire an event of type error.
                    removeEventListener.call(nativeAudioWorkletNode, 'error', args[1], args[2]);
                    return removeEventListener.call(nativeAudioWorkletNode, args[0], args[1], args[2]);
                };
            })(nativeAudioWorkletNode.removeEventListener);
            /*
                 * Bug #86: Chrome and Edge do not invoke the process() function if the corresponding AudioWorkletNode is unconnected but
                 * has an output.
                 */ if (options.numberOfOutputs !== 0) {
                const nativeGainNode = createNativeGainNode(nativeContext, {
                    channelCount: 1,
                    channelCountMode: 'explicit',
                    channelInterpretation: 'discrete',
                    gain: 0
                });
                nativeAudioWorkletNode.connect(nativeGainNode).connect(nativeContext.destination);
                const whenConnected = ()=>nativeGainNode.disconnect()
                ;
                const whenDisconnected = ()=>nativeGainNode.connect(nativeContext.destination)
                ;
                // @todo Disconnect the connection when the process() function of the AudioWorkletNode returns false.
                return monitorConnections(nativeAudioWorkletNode, whenConnected, whenDisconnected);
            }
            return nativeAudioWorkletNode;
        } catch (err) {
            // Bug #60: Chrome, Edge & Opera throw an InvalidStateError instead of a NotSupportedError.
            if (err.code === 11) throw createNotSupportedError();
            throw err;
        }
        // Bug #61: Only Chrome & Opera have an implementation of the AudioWorkletNode yet.
        if (processorConstructor === undefined) throw createNotSupportedError();
        _testClonabilityOfAudioWorkletNodeOptions.testClonabilityOfAudioWorkletNodeOptions(options);
        return createNativeAudioWorkletNodeFaker(nativeContext, baseLatency, processorConstructor, options);
    };
};

},{"../helpers/test-clonability-of-audio-worklet-node-options":"fgmkV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fgmkV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testClonabilityOfAudioWorkletNodeOptions", ()=>testClonabilityOfAudioWorkletNodeOptions
);
const testClonabilityOfAudioWorkletNodeOptions = (audioWorkletNodeOptions)=>{
    const { port1  } = new MessageChannel();
    try {
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port1.postMessage(audioWorkletNodeOptions);
    } finally{
        port1.close();
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9qlJs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeAudioWorkletNodeFakerFactory", ()=>createNativeAudioWorkletNodeFakerFactory
);
var _constants = require("../constants");
var _computeBufferSize = require("../helpers/compute-buffer-size");
var _copyFromChannel = require("../helpers/copy-from-channel");
var _copyToChannel = require("../helpers/copy-to-channel");
var _createAudioWorkletProcessor = require("../helpers/create-audio-worklet-processor");
var _createNestedArrays = require("../helpers/create-nested-arrays");
var _readOnlyMap = require("../read-only-map");
const createNativeAudioWorkletNodeFakerFactory = (connectMultipleOutputs, createIndexSizeError, createInvalidStateError, createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeConstantSourceNode, createNativeGainNode, createNativeScriptProcessorNode, createNotSupportedError, disconnectMultipleOutputs, exposeCurrentFrameAndCurrentTime, getActiveAudioWorkletNodeInputs, monitorConnections)=>{
    return (nativeContext, baseLatency, processorConstructor, options)=>{
        if (options.numberOfInputs === 0 && options.numberOfOutputs === 0) throw createNotSupportedError();
        const outputChannelCount = Array.isArray(options.outputChannelCount) ? options.outputChannelCount : Array.from(options.outputChannelCount);
        // @todo Check if any of the channelCount values is greater than the implementation's maximum number of channels.
        if (outputChannelCount.some((channelCount)=>channelCount < 1
        )) throw createNotSupportedError();
        if (outputChannelCount.length !== options.numberOfOutputs) throw createIndexSizeError();
        // Bug #61: This is not part of the standard but required for the faker to work.
        if (options.channelCountMode !== 'explicit') throw createNotSupportedError();
        const numberOfInputChannels = options.channelCount * options.numberOfInputs;
        const numberOfOutputChannels = outputChannelCount.reduce((sum, value)=>sum + value
        , 0);
        const numberOfParameters = processorConstructor.parameterDescriptors === undefined ? 0 : processorConstructor.parameterDescriptors.length;
        // Bug #61: This is not part of the standard but required for the faker to work.
        if (numberOfInputChannels + numberOfParameters > 6 || numberOfOutputChannels > 6) throw createNotSupportedError();
        const messageChannel = new MessageChannel();
        const gainNodes = [];
        const inputChannelSplitterNodes = [];
        for(let i = 0; i < options.numberOfInputs; i += 1){
            gainNodes.push(createNativeGainNode(nativeContext, {
                channelCount: options.channelCount,
                channelCountMode: options.channelCountMode,
                channelInterpretation: options.channelInterpretation,
                gain: 1
            }));
            inputChannelSplitterNodes.push(createNativeChannelSplitterNode(nativeContext, {
                channelCount: options.channelCount,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                numberOfOutputs: options.channelCount
            }));
        }
        const constantSourceNodes = [];
        if (processorConstructor.parameterDescriptors !== undefined) for (const { defaultValue , maxValue , minValue , name  } of processorConstructor.parameterDescriptors){
            const constantSourceNode = createNativeConstantSourceNode(nativeContext, {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                offset: options.parameterData[name] !== undefined ? options.parameterData[name] : defaultValue === undefined ? 0 : defaultValue
            });
            Object.defineProperties(constantSourceNode.offset, {
                defaultValue: {
                    get: ()=>defaultValue === undefined ? 0 : defaultValue
                },
                maxValue: {
                    get: ()=>maxValue === undefined ? _constants.MOST_POSITIVE_SINGLE_FLOAT : maxValue
                },
                minValue: {
                    get: ()=>minValue === undefined ? _constants.MOST_NEGATIVE_SINGLE_FLOAT : minValue
                }
            });
            constantSourceNodes.push(constantSourceNode);
        }
        const inputChannelMergerNode = createNativeChannelMergerNode(nativeContext, {
            channelCount: 1,
            channelCountMode: 'explicit',
            channelInterpretation: 'speakers',
            numberOfInputs: Math.max(1, numberOfInputChannels + numberOfParameters)
        });
        const bufferSize = _computeBufferSize.computeBufferSize(baseLatency, nativeContext.sampleRate);
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, numberOfInputChannels + numberOfParameters, // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
        Math.max(1, numberOfOutputChannels));
        const outputChannelSplitterNode = createNativeChannelSplitterNode(nativeContext, {
            channelCount: Math.max(1, numberOfOutputChannels),
            channelCountMode: 'explicit',
            channelInterpretation: 'discrete',
            numberOfOutputs: Math.max(1, numberOfOutputChannels)
        });
        const outputChannelMergerNodes = [];
        for(let i1 = 0; i1 < options.numberOfOutputs; i1 += 1)outputChannelMergerNodes.push(createNativeChannelMergerNode(nativeContext, {
            channelCount: 1,
            channelCountMode: 'explicit',
            channelInterpretation: 'speakers',
            numberOfInputs: outputChannelCount[i1]
        }));
        for(let i2 = 0; i2 < options.numberOfInputs; i2 += 1){
            gainNodes[i2].connect(inputChannelSplitterNodes[i2]);
            for(let j = 0; j < options.channelCount; j += 1)inputChannelSplitterNodes[i2].connect(inputChannelMergerNode, j, i2 * options.channelCount + j);
        }
        const parameterMap = new _readOnlyMap.ReadOnlyMap(processorConstructor.parameterDescriptors === undefined ? [] : processorConstructor.parameterDescriptors.map(({ name: name1  }, index)=>{
            const constantSourceNode = constantSourceNodes[index];
            constantSourceNode.connect(inputChannelMergerNode, 0, numberOfInputChannels + index);
            constantSourceNode.start(0);
            return [
                name1,
                constantSourceNode.offset
            ];
        }));
        inputChannelMergerNode.connect(scriptProcessorNode);
        let channelInterpretation = options.channelInterpretation;
        let onprocessorerror = null;
        // Bug #87: Expose at least one output to make this node connectable.
        const outputAudioNodes = options.numberOfOutputs === 0 ? [
            scriptProcessorNode
        ] : outputChannelMergerNodes;
        const nativeAudioWorkletNodeFaker = {
            get bufferSize () {
                return bufferSize;
            },
            get channelCount () {
                return options.channelCount;
            },
            set channelCount (_){
                // Bug #61: This is not part of the standard but required for the faker to work.
                throw createInvalidStateError();
            },
            get channelCountMode () {
                return options.channelCountMode;
            },
            set channelCountMode (_1){
                // Bug #61: This is not part of the standard but required for the faker to work.
                throw createInvalidStateError();
            },
            get channelInterpretation () {
                return channelInterpretation;
            },
            set channelInterpretation (value){
                for (const gainNode of gainNodes)gainNode.channelInterpretation = value;
                channelInterpretation = value;
            },
            get context () {
                return scriptProcessorNode.context;
            },
            get inputs () {
                return gainNodes;
            },
            get numberOfInputs () {
                return options.numberOfInputs;
            },
            get numberOfOutputs () {
                return options.numberOfOutputs;
            },
            get onprocessorerror () {
                return onprocessorerror;
            },
            set onprocessorerror (value1){
                if (typeof onprocessorerror === 'function') nativeAudioWorkletNodeFaker.removeEventListener('processorerror', onprocessorerror);
                onprocessorerror = typeof value1 === 'function' ? value1 : null;
                if (typeof onprocessorerror === 'function') nativeAudioWorkletNodeFaker.addEventListener('processorerror', onprocessorerror);
            },
            get parameters () {
                return parameterMap;
            },
            get port () {
                return messageChannel.port2;
            },
            addEventListener (...args) {
                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);
            },
            connect: connectMultipleOutputs.bind(null, outputAudioNodes),
            disconnect: disconnectMultipleOutputs.bind(null, outputAudioNodes),
            dispatchEvent (...args) {
                return scriptProcessorNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        const patchedEventListeners = new Map();
        messageChannel.port1.addEventListener = ((addEventListener)=>{
            return (...args)=>{
                if (args[0] === 'message') {
                    const unpatchedEventListener = typeof args[1] === 'function' ? args[1] : typeof args[1] === 'object' && args[1] !== null && typeof args[1].handleEvent === 'function' ? args[1].handleEvent : null;
                    if (unpatchedEventListener !== null) {
                        const patchedEventListener = patchedEventListeners.get(args[1]);
                        if (patchedEventListener !== undefined) args[1] = patchedEventListener;
                        else {
                            args[1] = (event)=>{
                                exposeCurrentFrameAndCurrentTime(nativeContext.currentTime, nativeContext.sampleRate, ()=>unpatchedEventListener(event)
                                );
                            };
                            patchedEventListeners.set(unpatchedEventListener, args[1]);
                        }
                    }
                }
                return addEventListener.call(messageChannel.port1, args[0], args[1], args[2]);
            };
        })(messageChannel.port1.addEventListener);
        messageChannel.port1.removeEventListener = ((removeEventListener)=>{
            return (...args)=>{
                if (args[0] === 'message') {
                    const patchedEventListener = patchedEventListeners.get(args[1]);
                    if (patchedEventListener !== undefined) {
                        patchedEventListeners.delete(args[1]);
                        args[1] = patchedEventListener;
                    }
                }
                return removeEventListener.call(messageChannel.port1, args[0], args[1], args[2]);
            };
        })(messageChannel.port1.removeEventListener);
        let onmessage = null;
        Object.defineProperty(messageChannel.port1, 'onmessage', {
            get: ()=>onmessage
            ,
            set: (value)=>{
                if (typeof onmessage === 'function') messageChannel.port1.removeEventListener('message', onmessage);
                onmessage = typeof value === 'function' ? value : null;
                if (typeof onmessage === 'function') {
                    messageChannel.port1.addEventListener('message', onmessage);
                    messageChannel.port1.start();
                }
            }
        });
        processorConstructor.prototype.port = messageChannel.port1;
        let audioWorkletProcessor = null;
        const audioWorkletProcessorPromise = _createAudioWorkletProcessor.createAudioWorkletProcessor(nativeContext, nativeAudioWorkletNodeFaker, processorConstructor, options);
        audioWorkletProcessorPromise.then((dWrkltPrcssr)=>audioWorkletProcessor = dWrkltPrcssr
        );
        const inputs = _createNestedArrays.createNestedArrays(options.numberOfInputs, options.channelCount);
        const outputs = _createNestedArrays.createNestedArrays(options.numberOfOutputs, outputChannelCount);
        const parameters = processorConstructor.parameterDescriptors === undefined ? [] : processorConstructor.parameterDescriptors.reduce((prmtrs, { name: name1  })=>({
                ...prmtrs,
                [name1]: new Float32Array(128)
            })
        , {
        });
        let isActive = true;
        const disconnectOutputsGraph = ()=>{
            if (options.numberOfOutputs > 0) scriptProcessorNode.disconnect(outputChannelSplitterNode);
            for(let i3 = 0, outputChannelSplitterNodeOutput = 0; i3 < options.numberOfOutputs; i3 += 1){
                const outputChannelMergerNode = outputChannelMergerNodes[i3];
                for(let j = 0; j < outputChannelCount[i3]; j += 1)outputChannelSplitterNode.disconnect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                outputChannelSplitterNodeOutput += outputChannelCount[i3];
            }
        };
        const activeInputIndexes = new Map();
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = ({ inputBuffer , outputBuffer  })=>{
            if (audioWorkletProcessor !== null) {
                const activeInputs = getActiveAudioWorkletNodeInputs(nativeAudioWorkletNodeFaker);
                for(let i3 = 0; i3 < bufferSize; i3 += 128){
                    for(let j = 0; j < options.numberOfInputs; j += 1)for(let k = 0; k < options.channelCount; k += 1)_copyFromChannel.copyFromChannel(inputBuffer, inputs[j], k, k, i3);
                    if (processorConstructor.parameterDescriptors !== undefined) processorConstructor.parameterDescriptors.forEach(({ name: name1  }, index)=>{
                        _copyFromChannel.copyFromChannel(inputBuffer, parameters, name1, numberOfInputChannels + index, i3);
                    });
                    for(let j1 = 0; j1 < options.numberOfInputs; j1 += 1){
                        for(let k1 = 0; k1 < outputChannelCount[j1]; k1 += 1)// The byteLength will be 0 when the ArrayBuffer was transferred.
                        if (outputs[j1][k1].byteLength === 0) outputs[j1][k1] = new Float32Array(128);
                    }
                    try {
                        const potentiallyEmptyInputs = inputs.map((input, index)=>{
                            const activeInput = activeInputs[index];
                            if (activeInput.size > 0) {
                                activeInputIndexes.set(index, bufferSize / 128);
                                return input;
                            }
                            const count = activeInputIndexes.get(index);
                            if (count === undefined) return [];
                            if (input.every((channelData)=>channelData.every((sample)=>sample === 0
                                )
                            )) {
                                if (count === 1) activeInputIndexes.delete(index);
                                else activeInputIndexes.set(index, count - 1);
                            }
                            return input;
                        });
                        const activeSourceFlag = exposeCurrentFrameAndCurrentTime(nativeContext.currentTime + i3 / nativeContext.sampleRate, nativeContext.sampleRate, ()=>audioWorkletProcessor.process(potentiallyEmptyInputs, outputs, parameters)
                        );
                        isActive = activeSourceFlag;
                        for(let j2 = 0, outputChannelSplitterNodeOutput = 0; j2 < options.numberOfOutputs; j2 += 1){
                            for(let k1 = 0; k1 < outputChannelCount[j2]; k1 += 1)_copyToChannel.copyToChannel(outputBuffer, outputs[j2], k1, outputChannelSplitterNodeOutput + k1, i3);
                            outputChannelSplitterNodeOutput += outputChannelCount[j2];
                        }
                    } catch (error) {
                        isActive = false;
                        nativeAudioWorkletNodeFaker.dispatchEvent(new ErrorEvent('processorerror', {
                            colno: error.colno,
                            filename: error.filename,
                            lineno: error.lineno,
                            message: error.message
                        }));
                    }
                    if (!isActive) {
                        for(let j3 = 0; j3 < options.numberOfInputs; j3 += 1){
                            gainNodes[j3].disconnect(inputChannelSplitterNodes[j3]);
                            for(let k1 = 0; k1 < options.channelCount; k1 += 1)inputChannelSplitterNodes[i3].disconnect(inputChannelMergerNode, k1, j3 * options.channelCount + k1);
                        }
                        if (processorConstructor.parameterDescriptors !== undefined) {
                            const length = processorConstructor.parameterDescriptors.length;
                            for(let j4 = 0; j4 < length; j4 += 1){
                                const constantSourceNode = constantSourceNodes[j4];
                                constantSourceNode.disconnect(inputChannelMergerNode, 0, numberOfInputChannels + j4);
                                constantSourceNode.stop();
                            }
                        }
                        inputChannelMergerNode.disconnect(scriptProcessorNode);
                        scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation
                        if (isConnected) disconnectOutputsGraph();
                        else disconnectFakeGraph();
                        break;
                    }
                }
            }
        };
        let isConnected = false;
        // Bug #87: Only Firefox will fire an AudioProcessingEvent if there is no connected output.
        const nativeGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: 'explicit',
            channelInterpretation: 'discrete',
            gain: 0
        });
        const connectFakeGraph = ()=>scriptProcessorNode.connect(nativeGainNode).connect(nativeContext.destination)
        ;
        const disconnectFakeGraph = ()=>{
            scriptProcessorNode.disconnect(nativeGainNode);
            nativeGainNode.disconnect();
        };
        const whenConnected = ()=>{
            if (isActive) {
                disconnectFakeGraph();
                if (options.numberOfOutputs > 0) scriptProcessorNode.connect(outputChannelSplitterNode);
                for(let i3 = 0, outputChannelSplitterNodeOutput = 0; i3 < options.numberOfOutputs; i3 += 1){
                    const outputChannelMergerNode = outputChannelMergerNodes[i3];
                    for(let j = 0; j < outputChannelCount[i3]; j += 1)outputChannelSplitterNode.connect(outputChannelMergerNode, outputChannelSplitterNodeOutput + j, j);
                    outputChannelSplitterNodeOutput += outputChannelCount[i3];
                }
            }
            isConnected = true;
        };
        const whenDisconnected = ()=>{
            if (isActive) {
                connectFakeGraph();
                disconnectOutputsGraph();
            }
            isConnected = false;
        };
        connectFakeGraph();
        return monitorConnections(nativeAudioWorkletNodeFaker, whenConnected, whenDisconnected);
    };
};

},{"../constants":"dG3Pl","../helpers/compute-buffer-size":"12UGn","../helpers/copy-from-channel":"D6Pec","../helpers/copy-to-channel":"islV9","../helpers/create-audio-worklet-processor":"bFjkx","../helpers/create-nested-arrays":"5Wso6","../read-only-map":"1p3Tl","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"12UGn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "computeBufferSize", ()=>computeBufferSize
);
const computeBufferSize = (baseLatency, sampleRate)=>{
    if (baseLatency === null) return 512;
    return Math.max(512, Math.min(16384, Math.pow(2, Math.round(Math.log2(baseLatency * sampleRate)))));
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bFjkx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioWorkletProcessor", ()=>createAudioWorkletProcessor
);
var _globals = require("../globals");
var _createAudioWorkletProcessorPromise = require("./create-audio-worklet-processor-promise");
const createAudioWorkletProcessor = (nativeContext, nativeAudioWorkletNode, processorConstructor, audioWorkletNodeOptions)=>{
    let nodeToProcessorMap = _globals.NODE_TO_PROCESSOR_MAPS.get(nativeContext);
    if (nodeToProcessorMap === undefined) {
        nodeToProcessorMap = new WeakMap();
        _globals.NODE_TO_PROCESSOR_MAPS.set(nativeContext, nodeToProcessorMap);
    }
    const audioWorkletProcessorPromise = _createAudioWorkletProcessorPromise.createAudioWorkletProcessorPromise(processorConstructor, audioWorkletNodeOptions);
    nodeToProcessorMap.set(nativeAudioWorkletNode, audioWorkletProcessorPromise);
    return audioWorkletProcessorPromise;
};

},{"../globals":"80KZG","./create-audio-worklet-processor-promise":"61j32","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"61j32":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createAudioWorkletProcessorPromise", ()=>createAudioWorkletProcessorPromise
);
var _cloneAudioWorkletNodeOptions = require("./clone-audio-worklet-node-options");
const createAudioWorkletProcessorPromise = async (processorConstructor, audioWorkletNodeOptions)=>{
    const clonedAudioWorkletNodeOptions = await _cloneAudioWorkletNodeOptions.cloneAudioWorkletNodeOptions(audioWorkletNodeOptions);
    return new processorConstructor(clonedAudioWorkletNodeOptions);
};

},{"./clone-audio-worklet-node-options":"jwWV5","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jwWV5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "cloneAudioWorkletNodeOptions", ()=>cloneAudioWorkletNodeOptions
);
const cloneAudioWorkletNodeOptions = (audioWorkletNodeOptions)=>{
    return new Promise((resolve, reject)=>{
        const { port1 , port2  } = new MessageChannel();
        port1.onmessage = ({ data  })=>{
            port1.close();
            port2.close();
            resolve(data);
        };
        port1.onmessageerror = ({ data  })=>{
            port1.close();
            port2.close();
            reject(data);
        };
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port2.postMessage(audioWorkletNodeOptions);
    });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gZ7jY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeBiquadFilterNode", ()=>createNativeBiquadFilterNode
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeBiquadFilterNode = (nativeContext, options)=>{
    const nativeBiquadFilterNode = nativeContext.createBiquadFilter();
    _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeBiquadFilterNode, options);
    _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'Q');
    _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'detune');
    _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'frequency');
    _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeBiquadFilterNode, options, 'gain');
    _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeBiquadFilterNode, options, 'type');
    return nativeBiquadFilterNode;
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-option":"2lkZy","../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hjRzD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeChannelMergerNodeFactory", ()=>createNativeChannelMergerNodeFactory
);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeChannelMergerNodeFactory = (nativeAudioContextConstructor, wrapChannelMergerNode)=>{
    return (nativeContext, options)=>{
        const nativeChannelMergerNode = nativeContext.createChannelMerger(options.numberOfInputs);
        /*
         * Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of
         * the webkitAudioContext is used as a workaround here.
         */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext') wrapChannelMergerNode(nativeContext, nativeChannelMergerNode);
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeChannelMergerNode, options);
        return nativeChannelMergerNode;
    };
};

},{"../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1l37J":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeChannelSplitterNode", ()=>createNativeChannelSplitterNode
);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _wrapChannelSplitterNode = require("../helpers/wrap-channel-splitter-node");
const createNativeChannelSplitterNode = (nativeContext, options)=>{
    const nativeChannelSplitterNode = nativeContext.createChannelSplitter(options.numberOfOutputs);
    // Bug #96: Safari does not have the correct channelCount.
    // Bug #29: Safari does not have the correct channelCountMode.
    // Bug #31: Safari does not have the correct channelInterpretation.
    _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeChannelSplitterNode, options);
    // Bug #29, #30, #31, #32, #96 & #97: Only Chrome, Edge, Firefox & Opera partially support the spec yet.
    _wrapChannelSplitterNode.wrapChannelSplitterNode(nativeChannelSplitterNode);
    return nativeChannelSplitterNode;
};

},{"../helpers/assign-native-audio-node-options":"2pMvb","../helpers/wrap-channel-splitter-node":"ena4K","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ena4K":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapChannelSplitterNode", ()=>wrapChannelSplitterNode
);
var _invalidStateError = require("../factories/invalid-state-error");
const wrapChannelSplitterNode = (channelSplitterNode)=>{
    const channelCount = channelSplitterNode.numberOfOutputs;
    // Bug #97: Safari does not throw an error when attempting to change the channelCount to something other than its initial value.
    Object.defineProperty(channelSplitterNode, 'channelCount', {
        get: ()=>channelCount
        ,
        set: (value)=>{
            if (value !== channelCount) throw _invalidStateError.createInvalidStateError();
        }
    });
    // Bug #30: Safari does not throw an error when attempting to change the channelCountMode to something other than explicit.
    Object.defineProperty(channelSplitterNode, 'channelCountMode', {
        get: ()=>'explicit'
        ,
        set: (value)=>{
            if (value !== 'explicit') throw _invalidStateError.createInvalidStateError();
        }
    });
    // Bug #32: Safari does not throw an error when attempting to change the channelInterpretation to something other than discrete.
    Object.defineProperty(channelSplitterNode, 'channelInterpretation', {
        get: ()=>'discrete'
        ,
        set: (value)=>{
            if (value !== 'discrete') throw _invalidStateError.createInvalidStateError();
        }
    });
};

},{"../factories/invalid-state-error":"kvntE","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cNqnP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeConstantSourceNodeFactory", ()=>createNativeConstantSourceNodeFactory
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _wrapAudioScheduledSourceNodeStartMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters");
var _wrapAudioScheduledSourceNodeStopMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters");
const createNativeConstantSourceNodeFactory = (addSilentConnection, cacheTestResult, createNativeConstantSourceNodeFaker, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport)=>{
    return (nativeContext, options)=>{
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeContext.createConstantSource === undefined) return createNativeConstantSourceNodeFaker(nativeContext, options);
        const nativeConstantSourceNode = nativeContext.createConstantSource();
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeConstantSourceNode, options);
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeConstantSourceNode, options, 'offset');
        // Bug #44: Safari does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext)
        )) _wrapAudioScheduledSourceNodeStartMethodNegativeParameters.wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeConstantSourceNode);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext)
        )) _wrapAudioScheduledSourceNodeStopMethodNegativeParameters.wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeConstantSourceNode);
        // Bug #175: Safari will not fire an ended event if the ConstantSourceNode is unconnected.
        addSilentConnection(nativeContext, nativeConstantSourceNode);
        return nativeConstantSourceNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-options":"2pMvb","../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters":"kHOSr","../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters":"fqZi5","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6XrrD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeConstantSourceNodeFakerFactory", ()=>createNativeConstantSourceNodeFakerFactory
);
var _interceptConnections = require("../helpers/intercept-connections");
const createNativeConstantSourceNodeFakerFactory = (addSilentConnection, createNativeAudioBufferSourceNode, createNativeGainNode, monitorConnections)=>{
    return (nativeContext, { offset , ...audioNodeOptions })=>{
        const audioBuffer = nativeContext.createBuffer(1, 2, 44100);
        const audioBufferSourceNode = createNativeAudioBufferSourceNode(nativeContext, {
            buffer: null,
            channelCount: 2,
            channelCountMode: 'max',
            channelInterpretation: 'speakers',
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            playbackRate: 1
        });
        const gainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: offset
        });
        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
        const channelData = audioBuffer.getChannelData(0);
        // Bug #95: Safari does not play or loop one sample buffers.
        channelData[0] = 1;
        channelData[1] = 1;
        audioBufferSourceNode.buffer = audioBuffer;
        audioBufferSourceNode.loop = true;
        const nativeConstantSourceNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return gainNode.channelCount;
            },
            set channelCount (value){
                gainNode.channelCount = value;
            },
            get channelCountMode () {
                return gainNode.channelCountMode;
            },
            set channelCountMode (value1){
                gainNode.channelCountMode = value1;
            },
            get channelInterpretation () {
                return gainNode.channelInterpretation;
            },
            set channelInterpretation (value2){
                gainNode.channelInterpretation = value2;
            },
            get context () {
                return gainNode.context;
            },
            get inputs () {
                return [];
            },
            get numberOfInputs () {
                return audioBufferSourceNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return gainNode.numberOfOutputs;
            },
            get offset () {
                return gainNode.gain;
            },
            get onended () {
                return audioBufferSourceNode.onended;
            },
            set onended (value3){
                audioBufferSourceNode.onended = value3;
            },
            addEventListener (...args) {
                return audioBufferSourceNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return audioBufferSourceNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return audioBufferSourceNode.removeEventListener(args[0], args[1], args[2]);
            },
            start (when = 0) {
                audioBufferSourceNode.start.call(audioBufferSourceNode, when);
            },
            stop (when = 0) {
                audioBufferSourceNode.stop.call(audioBufferSourceNode, when);
            }
        };
        const whenConnected = ()=>audioBufferSourceNode.connect(gainNode)
        ;
        const whenDisconnected = ()=>audioBufferSourceNode.disconnect(gainNode)
        ;
        // Bug #175: Safari will not fire an ended event if the AudioBufferSourceNode is unconnected.
        addSilentConnection(nativeContext, audioBufferSourceNode);
        return monitorConnections(_interceptConnections.interceptConnections(nativeConstantSourceNodeFaker, gainNode), whenConnected, whenDisconnected);
    };
};

},{"../helpers/intercept-connections":"7vk0h","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7vk0h":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "interceptConnections", ()=>interceptConnections
);
const interceptConnections = (original, interceptor)=>{
    original.connect = interceptor.connect.bind(interceptor);
    original.disconnect = interceptor.disconnect.bind(interceptor);
    return original;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7ax0y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeConvolverNodeFactory", ()=>createNativeConvolverNodeFactory
);
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeConvolverNodeFactory = (createNotSupportedError, overwriteAccessors)=>{
    return (nativeContext, options)=>{
        const nativeConvolverNode = nativeContext.createConvolver();
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeConvolverNode, options);
        // The normalize property needs to be set before setting the buffer.
        if (options.disableNormalization === nativeConvolverNode.normalize) nativeConvolverNode.normalize = !options.disableNormalization;
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeConvolverNode, options, 'buffer');
        // Bug #113: Safari does allow to set the channelCount to a value larger than 2.
        if (options.channelCount > 2) throw createNotSupportedError();
        overwriteAccessors(nativeConvolverNode, 'channelCount', (get)=>()=>get.call(nativeConvolverNode)
        , (set)=>(value)=>{
                if (value > 2) throw createNotSupportedError();
                return set.call(nativeConvolverNode, value);
            }
        );
        // Bug #114: Safari allows to set the channelCountMode to 'max'.
        if (options.channelCountMode === 'max') throw createNotSupportedError();
        overwriteAccessors(nativeConvolverNode, 'channelCountMode', (get)=>()=>get.call(nativeConvolverNode)
        , (set)=>(value)=>{
                if (value === 'max') throw createNotSupportedError();
                return set.call(nativeConvolverNode, value);
            }
        );
        return nativeConvolverNode;
    };
};

},{"../helpers/assign-native-audio-node-option":"2lkZy","../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2bykR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeDelayNode", ()=>createNativeDelayNode
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeDelayNode = (nativeContext, options)=>{
    const nativeDelayNode = nativeContext.createDelay(options.maxDelayTime);
    _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeDelayNode, options);
    _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeDelayNode, options, 'delayTime');
    return nativeDelayNode;
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6sRUo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeDynamicsCompressorNodeFactory", ()=>createNativeDynamicsCompressorNodeFactory
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeDynamicsCompressorNodeFactory = (createNotSupportedError)=>{
    return (nativeContext, options)=>{
        const nativeDynamicsCompressorNode = nativeContext.createDynamicsCompressor();
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeDynamicsCompressorNode, options);
        // Bug #108: Safari allows a channelCount of three and above.
        if (options.channelCount > 2) throw createNotSupportedError();
        // Bug #109: Only Chrome, Firefox and Opera disallow a channelCountMode of 'max'.
        if (options.channelCountMode === 'max') throw createNotSupportedError();
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'attack');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'knee');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'ratio');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'release');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeDynamicsCompressorNode, options, 'threshold');
        return nativeDynamicsCompressorNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dLDco":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeGainNode", ()=>createNativeGainNode
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeGainNode = (nativeContext, options)=>{
    const nativeGainNode = nativeContext.createGain();
    _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeGainNode, options);
    _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeGainNode, options, 'gain');
    return nativeGainNode;
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aUNPS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeIIRFilterNodeFactory", ()=>createNativeIIRFilterNodeFactory
);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeIIRFilterNodeFactory = (createNativeIIRFilterNodeFaker)=>{
    return (nativeContext, baseLatency, options)=>{
        // Bug #9: Safari does not support IIRFilterNodes.
        if (nativeContext.createIIRFilter === undefined) return createNativeIIRFilterNodeFaker(nativeContext, baseLatency, options);
        // @todo TypeScript defines the parameters of createIIRFilter() as arrays of numbers.
        const nativeIIRFilterNode = nativeContext.createIIRFilter(options.feedforward, options.feedback);
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeIIRFilterNode, options);
        return nativeIIRFilterNode;
    };
};

},{"../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"f6Clz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeIIRFilterNodeFakerFactory", ()=>createNativeIIRFilterNodeFakerFactory
);
var _computeBufferSize = require("../helpers/compute-buffer-size");
var _filterBuffer = require("../helpers/filter-buffer");
var _interceptConnections = require("../helpers/intercept-connections");
function divide(a, b) {
    const denominator = b[0] * b[0] + b[1] * b[1];
    return [
        (a[0] * b[0] + a[1] * b[1]) / denominator,
        (a[1] * b[0] - a[0] * b[1]) / denominator
    ];
}
function multiply(a, b) {
    return [
        a[0] * b[0] - a[1] * b[1],
        a[0] * b[1] + a[1] * b[0]
    ];
}
function evaluatePolynomial(coefficient, z) {
    let result = [
        0,
        0
    ];
    for(let i = coefficient.length - 1; i >= 0; i -= 1){
        result = multiply(result, z);
        result[0] += coefficient[i];
    }
    return result;
}
const createNativeIIRFilterNodeFakerFactory = (createInvalidAccessError, createInvalidStateError, createNativeScriptProcessorNode, createNotSupportedError)=>{
    return (nativeContext, baseLatency, { channelCount , channelCountMode , channelInterpretation , feedback , feedforward  })=>{
        const bufferSize = _computeBufferSize.computeBufferSize(baseLatency, nativeContext.sampleRate);
        const convertedFeedback = feedback instanceof Float64Array ? feedback : new Float64Array(feedback);
        const convertedFeedforward = feedforward instanceof Float64Array ? feedforward : new Float64Array(feedforward);
        const feedbackLength = convertedFeedback.length;
        const feedforwardLength = convertedFeedforward.length;
        const minLength = Math.min(feedbackLength, feedforwardLength);
        if (feedbackLength === 0 || feedbackLength > 20) throw createNotSupportedError();
        if (convertedFeedback[0] === 0) throw createInvalidStateError();
        if (feedforwardLength === 0 || feedforwardLength > 20) throw createNotSupportedError();
        if (convertedFeedforward[0] === 0) throw createInvalidStateError();
        if (convertedFeedback[0] !== 1) {
            for(let i = 0; i < feedforwardLength; i += 1)convertedFeedforward[i] /= convertedFeedback[0];
            for(let i1 = 1; i1 < feedbackLength; i1 += 1)convertedFeedback[i1] /= convertedFeedback[0];
        }
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, bufferSize, channelCount, channelCount);
        scriptProcessorNode.channelCount = channelCount;
        scriptProcessorNode.channelCountMode = channelCountMode;
        scriptProcessorNode.channelInterpretation = channelInterpretation;
        const bufferLength = 32;
        const bufferIndexes = [];
        const xBuffers = [];
        const yBuffers = [];
        for(let i = 0; i < channelCount; i += 1){
            bufferIndexes.push(0);
            const xBuffer = new Float32Array(bufferLength);
            const yBuffer = new Float32Array(bufferLength);
            xBuffer.fill(0);
            yBuffer.fill(0);
            xBuffers.push(xBuffer);
            yBuffers.push(yBuffer);
        }
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = (event)=>{
            const inputBuffer = event.inputBuffer;
            const outputBuffer = event.outputBuffer;
            const numberOfChannels = inputBuffer.numberOfChannels;
            for(let i1 = 0; i1 < numberOfChannels; i1 += 1){
                const input = inputBuffer.getChannelData(i1);
                const output = outputBuffer.getChannelData(i1);
                bufferIndexes[i1] = _filterBuffer.filterBuffer(convertedFeedback, feedbackLength, convertedFeedforward, feedforwardLength, minLength, xBuffers[i1], yBuffers[i1], bufferIndexes[i1], bufferLength, input, output);
            }
        };
        const nyquist = nativeContext.sampleRate / 2;
        const nativeIIRFilterNodeFaker = {
            get bufferSize () {
                return bufferSize;
            },
            get channelCount () {
                return scriptProcessorNode.channelCount;
            },
            set channelCount (value){
                scriptProcessorNode.channelCount = value;
            },
            get channelCountMode () {
                return scriptProcessorNode.channelCountMode;
            },
            set channelCountMode (value1){
                scriptProcessorNode.channelCountMode = value1;
            },
            get channelInterpretation () {
                return scriptProcessorNode.channelInterpretation;
            },
            set channelInterpretation (value2){
                scriptProcessorNode.channelInterpretation = value2;
            },
            get context () {
                return scriptProcessorNode.context;
            },
            get inputs () {
                return [
                    scriptProcessorNode
                ];
            },
            get numberOfInputs () {
                return scriptProcessorNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return scriptProcessorNode.numberOfOutputs;
            },
            addEventListener (...args) {
                // @todo Dissallow adding an audioprocess listener.
                return scriptProcessorNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return scriptProcessorNode.dispatchEvent(args[0]);
            },
            getFrequencyResponse (frequencyHz, magResponse, phaseResponse) {
                if (frequencyHz.length !== magResponse.length || magResponse.length !== phaseResponse.length) throw createInvalidAccessError();
                const length = frequencyHz.length;
                for(let i1 = 0; i1 < length; i1 += 1){
                    const omega = -Math.PI * (frequencyHz[i1] / nyquist);
                    const z = [
                        Math.cos(omega),
                        Math.sin(omega)
                    ];
                    const numerator = evaluatePolynomial(convertedFeedforward, z);
                    const denominator = evaluatePolynomial(convertedFeedback, z);
                    const response = divide(numerator, denominator);
                    magResponse[i1] = Math.sqrt(response[0] * response[0] + response[1] * response[1]);
                    phaseResponse[i1] = Math.atan2(response[1], response[0]);
                }
            },
            removeEventListener (...args) {
                return scriptProcessorNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        return _interceptConnections.interceptConnections(nativeIIRFilterNodeFaker, scriptProcessorNode);
    };
};

},{"../helpers/compute-buffer-size":"12UGn","../helpers/filter-buffer":"gpqLm","../helpers/intercept-connections":"7vk0h","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9P3cG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeMediaElementAudioSourceNode", ()=>createNativeMediaElementAudioSourceNode
);
const createNativeMediaElementAudioSourceNode = (nativeAudioContext, options)=>{
    return nativeAudioContext.createMediaElementSource(options.mediaElement);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"51GnX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeMediaStreamAudioDestinationNode", ()=>createNativeMediaStreamAudioDestinationNode
);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeMediaStreamAudioDestinationNode = (nativeAudioContext, options)=>{
    const nativeMediaStreamAudioDestinationNode = nativeAudioContext.createMediaStreamDestination();
    _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeMediaStreamAudioDestinationNode, options);
    // Bug #174: Safari does expose a wrong numberOfOutputs.
    if (nativeMediaStreamAudioDestinationNode.numberOfOutputs === 1) Object.defineProperty(nativeMediaStreamAudioDestinationNode, 'numberOfOutputs', {
        get: ()=>0
    });
    return nativeMediaStreamAudioDestinationNode;
};

},{"../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ajOzY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeMediaStreamAudioSourceNode", ()=>createNativeMediaStreamAudioSourceNode
);
const createNativeMediaStreamAudioSourceNode = (nativeAudioContext, { mediaStream  })=>{
    const audioStreamTracks = mediaStream.getAudioTracks();
    /*
     * Bug #151: Safari does not use the audio track as input anymore if it gets removed from the mediaStream after construction.
     * Bug #159: Safari picks the first audio track if the MediaStream has more than one audio track.
     */ audioStreamTracks.sort((a, b)=>a.id < b.id ? -1 : a.id > b.id ? 1 : 0
    );
    const filteredAudioStreamTracks = audioStreamTracks.slice(0, 1);
    const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(new MediaStream(filteredAudioStreamTracks));
    /*
     * Bug #151 & #159: The given mediaStream gets reconstructed before it gets passed to the native node which is why the accessor needs
     * to be overwritten as it would otherwise expose the reconstructed version.
     */ Object.defineProperty(nativeMediaStreamAudioSourceNode, 'mediaStream', {
        value: mediaStream
    });
    return nativeMediaStreamAudioSourceNode;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hB0YW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeMediaStreamTrackAudioSourceNodeFactory", ()=>createNativeMediaStreamTrackAudioSourceNodeFactory
);
const createNativeMediaStreamTrackAudioSourceNodeFactory = (createInvalidStateError, isNativeOfflineAudioContext)=>{
    return (nativeAudioContext, { mediaStreamTrack  })=>{
        // Bug #121: Only Firefox does yet support the MediaStreamTrackAudioSourceNode.
        if (typeof nativeAudioContext.createMediaStreamTrackSource === 'function') return nativeAudioContext.createMediaStreamTrackSource(mediaStreamTrack);
        const mediaStream = new MediaStream([
            mediaStreamTrack
        ]);
        const nativeMediaStreamAudioSourceNode = nativeAudioContext.createMediaStreamSource(mediaStream);
        // Bug #120: Firefox does not throw an error if the mediaStream has no audio track.
        if (mediaStreamTrack.kind !== 'audio') throw createInvalidStateError();
        // Bug #172: Safari allows to create a MediaStreamAudioSourceNode with an OfflineAudioContext.
        if (isNativeOfflineAudioContext(nativeAudioContext)) throw new TypeError();
        return nativeMediaStreamAudioSourceNode;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4ywUg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeOfflineAudioContextConstructor", ()=>createNativeOfflineAudioContextConstructor
);
const createNativeOfflineAudioContextConstructor = (window)=>{
    if (window === null) return null;
    if (window.hasOwnProperty('OfflineAudioContext')) return window.OfflineAudioContext;
    return window.hasOwnProperty('webkitOfflineAudioContext') ? window.webkitOfflineAudioContext : null;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dJ9Ae":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeOscillatorNodeFactory", ()=>createNativeOscillatorNodeFactory
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _wrapAudioScheduledSourceNodeStartMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters");
var _wrapAudioScheduledSourceNodeStopMethodNegativeParameters = require("../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters");
const createNativeOscillatorNodeFactory = (addSilentConnection, cacheTestResult, testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls)=>{
    return (nativeContext, options)=>{
        const nativeOscillatorNode = nativeContext.createOscillator();
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeOscillatorNode, options);
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeOscillatorNode, options, 'detune');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeOscillatorNode, options, 'frequency');
        if (options.periodicWave !== undefined) nativeOscillatorNode.setPeriodicWave(options.periodicWave);
        else _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeOscillatorNode, options, 'type');
        // Bug #44: Only Chrome, Edge & Opera throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStartMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport(nativeContext)
        )) _wrapAudioScheduledSourceNodeStartMethodNegativeParameters.wrapAudioScheduledSourceNodeStartMethodNegativeParameters(nativeOscillatorNode);
        // Bug #19: Safari does not ignore calls to stop() of an already stopped AudioBufferSourceNode.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport, ()=>testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport(nativeContext)
        )) wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls(nativeOscillatorNode, nativeContext);
        // Bug #44: Only Firefox does not throw a RangeError yet.
        if (!cacheTestResult(testAudioScheduledSourceNodeStopMethodNegativeParametersSupport, ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport(nativeContext)
        )) _wrapAudioScheduledSourceNodeStopMethodNegativeParameters.wrapAudioScheduledSourceNodeStopMethodNegativeParameters(nativeOscillatorNode);
        // Bug #175: Safari will not fire an ended event if the OscillatorNode is unconnected.
        addSilentConnection(nativeContext, nativeOscillatorNode);
        return nativeOscillatorNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-option":"2lkZy","../helpers/assign-native-audio-node-options":"2pMvb","../helpers/wrap-audio-scheduled-source-node-start-method-negative-parameters":"kHOSr","../helpers/wrap-audio-scheduled-source-node-stop-method-negative-parameters":"fqZi5","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2MBWa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativePannerNodeFactory", ()=>createNativePannerNodeFactory
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativePannerNodeFactory = (createNativePannerNodeFaker)=>{
    return (nativeContext, options)=>{
        const nativePannerNode = nativeContext.createPanner();
        // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.
        if (nativePannerNode.orientationX === undefined) return createNativePannerNodeFaker(nativeContext, options);
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativePannerNode, options);
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationX');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationY');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'orientationZ');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionX');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionY');
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativePannerNode, options, 'positionZ');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativePannerNode, options, 'coneInnerAngle');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativePannerNode, options, 'coneOuterAngle');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativePannerNode, options, 'coneOuterGain');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativePannerNode, options, 'distanceModel');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativePannerNode, options, 'maxDistance');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativePannerNode, options, 'panningModel');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativePannerNode, options, 'refDistance');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativePannerNode, options, 'rolloffFactor');
        return nativePannerNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-option":"2lkZy","../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3CT8l":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativePannerNodeFakerFactory", ()=>createNativePannerNodeFakerFactory
);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _interceptConnections = require("../helpers/intercept-connections");
const createNativePannerNodeFakerFactory = (connectNativeAudioNodeToNativeAudioNode, createInvalidStateError, createNativeChannelMergerNode, createNativeGainNode, createNativeScriptProcessorNode, createNativeWaveShaperNode, createNotSupportedError, disconnectNativeAudioNodeFromNativeAudioNode, getFirstSample, monitorConnections)=>{
    return (nativeContext, { coneInnerAngle , coneOuterAngle , coneOuterGain , distanceModel , maxDistance , orientationX , orientationY , orientationZ , panningModel , positionX , positionY , positionZ , refDistance , rolloffFactor , ...audioNodeOptions })=>{
        const pannerNode = nativeContext.createPanner();
        // Bug #125: Safari does not throw an error yet.
        if (audioNodeOptions.channelCount > 2) throw createNotSupportedError();
        // Bug #126: Safari does not throw an error yet.
        if (audioNodeOptions.channelCountMode === 'max') throw createNotSupportedError();
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(pannerNode, audioNodeOptions);
        const SINGLE_CHANNEL_OPTIONS = {
            channelCount: 1,
            channelCountMode: 'explicit',
            channelInterpretation: 'discrete'
        };
        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            channelInterpretation: 'speakers',
            numberOfInputs: 6
        });
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const orientationXGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 1
        });
        const orientationYGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const orientationZGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionXGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionYGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const positionZGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        const scriptProcessorNode = createNativeScriptProcessorNode(nativeContext, 256, 6, 1);
        const waveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            curve: new Float32Array([
                1,
                1
            ]),
            oversample: 'none'
        });
        let lastOrientation = [
            orientationX,
            orientationY,
            orientationZ
        ];
        let lastPosition = [
            positionX,
            positionY,
            positionZ
        ];
        const buffer = new Float32Array(1);
        // tslint:disable-next-line:deprecation
        scriptProcessorNode.onaudioprocess = ({ inputBuffer  })=>{
            const orientation = [
                getFirstSample(inputBuffer, buffer, 0),
                getFirstSample(inputBuffer, buffer, 1),
                getFirstSample(inputBuffer, buffer, 2)
            ];
            if (orientation.some((value, index)=>value !== lastOrientation[index]
            )) {
                pannerNode.setOrientation(...orientation); // tslint:disable-line:deprecation
                lastOrientation = orientation;
            }
            const positon = [
                getFirstSample(inputBuffer, buffer, 3),
                getFirstSample(inputBuffer, buffer, 4),
                getFirstSample(inputBuffer, buffer, 5)
            ];
            if (positon.some((value, index)=>value !== lastPosition[index]
            )) {
                pannerNode.setPosition(...positon); // tslint:disable-line:deprecation
                lastPosition = positon;
            }
        };
        Object.defineProperty(orientationYGainNode.gain, 'defaultValue', {
            get: ()=>0
        });
        Object.defineProperty(orientationZGainNode.gain, 'defaultValue', {
            get: ()=>0
        });
        Object.defineProperty(positionXGainNode.gain, 'defaultValue', {
            get: ()=>0
        });
        Object.defineProperty(positionYGainNode.gain, 'defaultValue', {
            get: ()=>0
        });
        Object.defineProperty(positionZGainNode.gain, 'defaultValue', {
            get: ()=>0
        });
        const nativePannerNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return pannerNode.channelCount;
            },
            set channelCount (value){
                // Bug #125: Safari does not throw an error yet.
                if (value > 2) throw createNotSupportedError();
                inputGainNode.channelCount = value;
                pannerNode.channelCount = value;
            },
            get channelCountMode () {
                return pannerNode.channelCountMode;
            },
            set channelCountMode (value1){
                // Bug #126: Safari does not throw an error yet.
                if (value1 === 'max') throw createNotSupportedError();
                inputGainNode.channelCountMode = value1;
                pannerNode.channelCountMode = value1;
            },
            get channelInterpretation () {
                return pannerNode.channelInterpretation;
            },
            set channelInterpretation (value2){
                inputGainNode.channelInterpretation = value2;
                pannerNode.channelInterpretation = value2;
            },
            get coneInnerAngle () {
                return pannerNode.coneInnerAngle;
            },
            set coneInnerAngle (value3){
                pannerNode.coneInnerAngle = value3;
            },
            get coneOuterAngle () {
                return pannerNode.coneOuterAngle;
            },
            set coneOuterAngle (value4){
                pannerNode.coneOuterAngle = value4;
            },
            get coneOuterGain () {
                return pannerNode.coneOuterGain;
            },
            set coneOuterGain (value5){
                // Bug #127: Safari does not throw an InvalidStateError yet.
                if (value5 < 0 || value5 > 1) throw createInvalidStateError();
                pannerNode.coneOuterGain = value5;
            },
            get context () {
                return pannerNode.context;
            },
            get distanceModel () {
                return pannerNode.distanceModel;
            },
            set distanceModel (value6){
                pannerNode.distanceModel = value6;
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get maxDistance () {
                return pannerNode.maxDistance;
            },
            set maxDistance (value7){
                // Bug #128: Safari does not throw an error yet.
                if (value7 < 0) throw new RangeError();
                pannerNode.maxDistance = value7;
            },
            get numberOfInputs () {
                return pannerNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return pannerNode.numberOfOutputs;
            },
            get orientationX () {
                return orientationXGainNode.gain;
            },
            get orientationY () {
                return orientationYGainNode.gain;
            },
            get orientationZ () {
                return orientationZGainNode.gain;
            },
            get panningModel () {
                return pannerNode.panningModel;
            },
            set panningModel (value8){
                pannerNode.panningModel = value8;
            },
            get positionX () {
                return positionXGainNode.gain;
            },
            get positionY () {
                return positionYGainNode.gain;
            },
            get positionZ () {
                return positionZGainNode.gain;
            },
            get refDistance () {
                return pannerNode.refDistance;
            },
            set refDistance (value9){
                // Bug #129: Safari does not throw an error yet.
                if (value9 < 0) throw new RangeError();
                pannerNode.refDistance = value9;
            },
            get rolloffFactor () {
                return pannerNode.rolloffFactor;
            },
            set rolloffFactor (value10){
                // Bug #130: Safari does not throw an error yet.
                if (value10 < 0) throw new RangeError();
                pannerNode.rolloffFactor = value10;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        if (coneInnerAngle !== nativePannerNodeFaker.coneInnerAngle) nativePannerNodeFaker.coneInnerAngle = coneInnerAngle;
        if (coneOuterAngle !== nativePannerNodeFaker.coneOuterAngle) nativePannerNodeFaker.coneOuterAngle = coneOuterAngle;
        if (coneOuterGain !== nativePannerNodeFaker.coneOuterGain) nativePannerNodeFaker.coneOuterGain = coneOuterGain;
        if (distanceModel !== nativePannerNodeFaker.distanceModel) nativePannerNodeFaker.distanceModel = distanceModel;
        if (maxDistance !== nativePannerNodeFaker.maxDistance) nativePannerNodeFaker.maxDistance = maxDistance;
        if (orientationX !== nativePannerNodeFaker.orientationX.value) nativePannerNodeFaker.orientationX.value = orientationX;
        if (orientationY !== nativePannerNodeFaker.orientationY.value) nativePannerNodeFaker.orientationY.value = orientationY;
        if (orientationZ !== nativePannerNodeFaker.orientationZ.value) nativePannerNodeFaker.orientationZ.value = orientationZ;
        if (panningModel !== nativePannerNodeFaker.panningModel) nativePannerNodeFaker.panningModel = panningModel;
        if (positionX !== nativePannerNodeFaker.positionX.value) nativePannerNodeFaker.positionX.value = positionX;
        if (positionY !== nativePannerNodeFaker.positionY.value) nativePannerNodeFaker.positionY.value = positionY;
        if (positionZ !== nativePannerNodeFaker.positionZ.value) nativePannerNodeFaker.positionZ.value = positionZ;
        if (refDistance !== nativePannerNodeFaker.refDistance) nativePannerNodeFaker.refDistance = refDistance;
        if (rolloffFactor !== nativePannerNodeFaker.rolloffFactor) nativePannerNodeFaker.rolloffFactor = rolloffFactor;
        if (lastOrientation[0] !== 1 || lastOrientation[1] !== 0 || lastOrientation[2] !== 0) pannerNode.setOrientation(...lastOrientation); // tslint:disable-line:deprecation
        if (lastPosition[0] !== 0 || lastPosition[1] !== 0 || lastPosition[2] !== 0) pannerNode.setPosition(...lastPosition); // tslint:disable-line:deprecation
        const whenConnected = ()=>{
            inputGainNode.connect(pannerNode);
            // Bug #119: Safari does not fully support the WaveShaperNode.
            connectNativeAudioNodeToNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);
            waveShaperNode.connect(orientationXGainNode).connect(channelMergerNode, 0, 0);
            waveShaperNode.connect(orientationYGainNode).connect(channelMergerNode, 0, 1);
            waveShaperNode.connect(orientationZGainNode).connect(channelMergerNode, 0, 2);
            waveShaperNode.connect(positionXGainNode).connect(channelMergerNode, 0, 3);
            waveShaperNode.connect(positionYGainNode).connect(channelMergerNode, 0, 4);
            waveShaperNode.connect(positionZGainNode).connect(channelMergerNode, 0, 5);
            channelMergerNode.connect(scriptProcessorNode).connect(nativeContext.destination);
        };
        const whenDisconnected = ()=>{
            inputGainNode.disconnect(pannerNode);
            // Bug #119: Safari does not fully support the WaveShaperNode.
            disconnectNativeAudioNodeFromNativeAudioNode(inputGainNode, waveShaperNode, 0, 0);
            waveShaperNode.disconnect(orientationXGainNode);
            orientationXGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(orientationYGainNode);
            orientationYGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(orientationZGainNode);
            orientationZGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionXGainNode);
            positionXGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionYGainNode);
            positionYGainNode.disconnect(channelMergerNode);
            waveShaperNode.disconnect(positionZGainNode);
            positionZGainNode.disconnect(channelMergerNode);
            channelMergerNode.disconnect(scriptProcessorNode);
            scriptProcessorNode.disconnect(nativeContext.destination);
        };
        return monitorConnections(_interceptConnections.interceptConnections(nativePannerNodeFaker, pannerNode), whenConnected, whenDisconnected);
    };
};

},{"../helpers/assign-native-audio-node-options":"2pMvb","../helpers/intercept-connections":"7vk0h","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5jjiX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativePeriodicWaveFactory", ()=>createNativePeriodicWaveFactory
);
const createNativePeriodicWaveFactory = (createIndexSizeError)=>{
    return (nativeContext, { disableNormalization , imag , real  })=>{
        // Bug #180: Safari does not allow to use ordinary arrays.
        const convertedImag = imag instanceof Float32Array ? imag : new Float32Array(imag);
        const convertedReal = real instanceof Float32Array ? real : new Float32Array(real);
        const nativePeriodicWave = nativeContext.createPeriodicWave(convertedReal, convertedImag, {
            disableNormalization
        });
        // Bug #181: Safari does not throw an IndexSizeError so far if the given arrays have less than two values.
        if (Array.from(imag).length < 2) throw createIndexSizeError();
        return nativePeriodicWave;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fRr7m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeScriptProcessorNode", ()=>createNativeScriptProcessorNode
);
const createNativeScriptProcessorNode = (nativeContext, bufferSize, numberOfInputChannels, numberOfOutputChannels)=>{
    return nativeContext.createScriptProcessor(bufferSize, numberOfInputChannels, numberOfOutputChannels); // tslint:disable-line deprecation
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fqEid":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeStereoPannerNodeFactory", ()=>createNativeStereoPannerNodeFactory
);
var _assignNativeAudioNodeAudioParamValue = require("../helpers/assign-native-audio-node-audio-param-value");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeStereoPannerNodeFactory = (createNativeStereoPannerNodeFaker, createNotSupportedError)=>{
    return (nativeContext, options)=>{
        const channelCountMode = options.channelCountMode;
        /*
         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari
         * which supports it and therefore it can't be supported at all.
         */ if (channelCountMode === 'clamped-max') throw createNotSupportedError();
        // Bug #105: Safari does not support the StereoPannerNode.
        if (nativeContext.createStereoPanner === undefined) return createNativeStereoPannerNodeFaker(nativeContext, options);
        const nativeStereoPannerNode = nativeContext.createStereoPanner();
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeStereoPannerNode, options);
        _assignNativeAudioNodeAudioParamValue.assignNativeAudioNodeAudioParamValue(nativeStereoPannerNode, options, 'pan');
        /*
         * Bug #105: The channelCountMode of 'clamped-max' should be supported. However it is not possible to write a polyfill for Safari
         * which supports it and therefore it can't be supported at all.
         */ Object.defineProperty(nativeStereoPannerNode, 'channelCountMode', {
            get: ()=>channelCountMode
            ,
            set: (value)=>{
                if (value !== channelCountMode) throw createNotSupportedError();
            }
        });
        return nativeStereoPannerNode;
    };
};

},{"../helpers/assign-native-audio-node-audio-param-value":"jOVEo","../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4RkM7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeStereoPannerNodeFakerFactory", ()=>createNativeStereoPannerNodeFakerFactory
);
var _interceptConnections = require("../helpers/intercept-connections");
const createNativeStereoPannerNodeFakerFactory = (createNativeChannelMergerNode, createNativeChannelSplitterNode, createNativeGainNode, createNativeWaveShaperNode, createNotSupportedError, monitorConnections)=>{
    // The curve has a size of 14bit plus 1 value to have an exact representation for zero. This value has been determined experimentally.
    const CURVE_SIZE = 16385;
    const DC_CURVE = new Float32Array([
        1,
        1
    ]);
    const HALF_PI = Math.PI / 2;
    const SINGLE_CHANNEL_OPTIONS = {
        channelCount: 1,
        channelCountMode: 'explicit',
        channelInterpretation: 'discrete'
    };
    const SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS = {
        ...SINGLE_CHANNEL_OPTIONS,
        oversample: 'none'
    };
    const buildInternalGraphForMono = (nativeContext, inputGainNode, panGainNode, channelMergerNode)=>{
        const leftWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightWaveShaperCurve = new Float32Array(CURVE_SIZE);
        for(let i = 0; i < CURVE_SIZE; i += 1){
            const x = i / (CURVE_SIZE - 1) * HALF_PI;
            leftWaveShaperCurve[i] = Math.cos(x);
            rightWaveShaperCurve[i] = Math.sin(x);
        }
        const leftGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftWaveShaperCurve
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const panWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: DC_CURVE
        });
        const rightGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightWaveShaperCurve
        });
        return {
            connectGraph () {
                inputGainNode.connect(leftGainNode);
                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                inputGainNode.connect(rightGainNode);
                panWaveShaperNode.connect(panGainNode);
                panGainNode.connect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);
                panGainNode.connect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);
                leftWaveShaperNode.connect(leftGainNode.gain);
                rightWaveShaperNode.connect(rightGainNode.gain);
                leftGainNode.connect(channelMergerNode, 0, 0);
                rightGainNode.connect(channelMergerNode, 0, 1);
            },
            disconnectGraph () {
                inputGainNode.disconnect(leftGainNode);
                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                inputGainNode.disconnect(rightGainNode);
                panWaveShaperNode.disconnect(panGainNode);
                panGainNode.disconnect(leftWaveShaperNode.inputs === undefined ? leftWaveShaperNode : leftWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightWaveShaperNode.inputs === undefined ? rightWaveShaperNode : rightWaveShaperNode.inputs[0]);
                leftWaveShaperNode.disconnect(leftGainNode.gain);
                rightWaveShaperNode.disconnect(rightGainNode.gain);
                leftGainNode.disconnect(channelMergerNode, 0, 0);
                rightGainNode.disconnect(channelMergerNode, 0, 1);
            }
        };
    };
    const buildInternalGraphForStereo = (nativeContext, inputGainNode, panGainNode, channelMergerNode)=>{
        const leftInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const leftInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightInputForLeftOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const rightInputForRightOutputWaveShaperCurve = new Float32Array(CURVE_SIZE);
        const centerIndex = Math.floor(CURVE_SIZE / 2);
        for(let i = 0; i < CURVE_SIZE; i += 1)if (i > centerIndex) {
            const x = (i - centerIndex) / (CURVE_SIZE - 1 - centerIndex) * HALF_PI;
            leftInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);
            leftInputForRightOutputWaveShaperCurve[i] = Math.sin(x);
            rightInputForLeftOutputWaveShaperCurve[i] = 0;
            rightInputForRightOutputWaveShaperCurve[i] = 1;
        } else {
            const x = i / (CURVE_SIZE - 1 - centerIndex) * HALF_PI;
            leftInputForLeftOutputWaveShaperCurve[i] = 1;
            leftInputForRightOutputWaveShaperCurve[i] = 0;
            rightInputForLeftOutputWaveShaperCurve[i] = Math.cos(x);
            rightInputForRightOutputWaveShaperCurve[i] = Math.sin(x);
        }
        const channelSplitterNode = createNativeChannelSplitterNode(nativeContext, {
            channelCount: 2,
            channelCountMode: 'explicit',
            channelInterpretation: 'discrete',
            numberOfOutputs: 2
        });
        const leftInputForLeftOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftInputForLeftOutputWaveShaperCurve
        });
        const leftInputForRightOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const leftInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: leftInputForRightOutputWaveShaperCurve
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const panWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: DC_CURVE
        });
        const rightInputForLeftOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightInputForLeftOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightInputForLeftOutputWaveShaperCurve
        });
        const rightInputForRightOutputGainNode = createNativeGainNode(nativeContext, {
            ...SINGLE_CHANNEL_OPTIONS,
            gain: 0
        });
        // Bug #119: Safari does not fully support the WaveShaperNode.
        const rightInputForRightOutputWaveShaperNode = createNativeWaveShaperNode(nativeContext, {
            ...SINGLE_CHANNEL_WAVE_SHAPER_OPTIONS,
            curve: rightInputForRightOutputWaveShaperCurve
        });
        return {
            connectGraph () {
                inputGainNode.connect(channelSplitterNode);
                inputGainNode.connect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                channelSplitterNode.connect(leftInputForLeftOutputGainNode, 0);
                channelSplitterNode.connect(leftInputForRightOutputGainNode, 0);
                channelSplitterNode.connect(rightInputForLeftOutputGainNode, 1);
                channelSplitterNode.connect(rightInputForRightOutputGainNode, 1);
                panWaveShaperNode.connect(panGainNode);
                panGainNode.connect(leftInputForLeftOutputWaveShaperNode.inputs === undefined ? leftInputForLeftOutputWaveShaperNode : leftInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(leftInputForRightOutputWaveShaperNode.inputs === undefined ? leftInputForRightOutputWaveShaperNode : leftInputForRightOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(rightInputForLeftOutputWaveShaperNode.inputs === undefined ? rightInputForLeftOutputWaveShaperNode : rightInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.connect(rightInputForRightOutputWaveShaperNode.inputs === undefined ? rightInputForRightOutputWaveShaperNode : rightInputForRightOutputWaveShaperNode.inputs[0]);
                leftInputForLeftOutputWaveShaperNode.connect(leftInputForLeftOutputGainNode.gain);
                leftInputForRightOutputWaveShaperNode.connect(leftInputForRightOutputGainNode.gain);
                rightInputForLeftOutputWaveShaperNode.connect(rightInputForLeftOutputGainNode.gain);
                rightInputForRightOutputWaveShaperNode.connect(rightInputForRightOutputGainNode.gain);
                leftInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);
                rightInputForLeftOutputGainNode.connect(channelMergerNode, 0, 0);
                leftInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);
                rightInputForRightOutputGainNode.connect(channelMergerNode, 0, 1);
            },
            disconnectGraph () {
                inputGainNode.disconnect(channelSplitterNode);
                inputGainNode.disconnect(panWaveShaperNode.inputs === undefined ? panWaveShaperNode : panWaveShaperNode.inputs[0]);
                channelSplitterNode.disconnect(leftInputForLeftOutputGainNode, 0);
                channelSplitterNode.disconnect(leftInputForRightOutputGainNode, 0);
                channelSplitterNode.disconnect(rightInputForLeftOutputGainNode, 1);
                channelSplitterNode.disconnect(rightInputForRightOutputGainNode, 1);
                panWaveShaperNode.disconnect(panGainNode);
                panGainNode.disconnect(leftInputForLeftOutputWaveShaperNode.inputs === undefined ? leftInputForLeftOutputWaveShaperNode : leftInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(leftInputForRightOutputWaveShaperNode.inputs === undefined ? leftInputForRightOutputWaveShaperNode : leftInputForRightOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightInputForLeftOutputWaveShaperNode.inputs === undefined ? rightInputForLeftOutputWaveShaperNode : rightInputForLeftOutputWaveShaperNode.inputs[0]);
                panGainNode.disconnect(rightInputForRightOutputWaveShaperNode.inputs === undefined ? rightInputForRightOutputWaveShaperNode : rightInputForRightOutputWaveShaperNode.inputs[0]);
                leftInputForLeftOutputWaveShaperNode.disconnect(leftInputForLeftOutputGainNode.gain);
                leftInputForRightOutputWaveShaperNode.disconnect(leftInputForRightOutputGainNode.gain);
                rightInputForLeftOutputWaveShaperNode.disconnect(rightInputForLeftOutputGainNode.gain);
                rightInputForRightOutputWaveShaperNode.disconnect(rightInputForRightOutputGainNode.gain);
                leftInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);
                rightInputForLeftOutputGainNode.disconnect(channelMergerNode, 0, 0);
                leftInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);
                rightInputForRightOutputGainNode.disconnect(channelMergerNode, 0, 1);
            }
        };
    };
    const buildInternalGraph = (nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode)=>{
        if (channelCount === 1) return buildInternalGraphForMono(nativeContext, inputGainNode, panGainNode, channelMergerNode);
        if (channelCount === 2) return buildInternalGraphForStereo(nativeContext, inputGainNode, panGainNode, channelMergerNode);
        throw createNotSupportedError();
    };
    return (nativeContext, { channelCount , channelCountMode , pan , ...audioNodeOptions })=>{
        if (channelCountMode === 'max') throw createNotSupportedError();
        const channelMergerNode = createNativeChannelMergerNode(nativeContext, {
            ...audioNodeOptions,
            channelCount: 1,
            channelCountMode,
            numberOfInputs: 2
        });
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            channelCount,
            channelCountMode,
            gain: 1
        });
        const panGainNode = createNativeGainNode(nativeContext, {
            channelCount: 1,
            channelCountMode: 'explicit',
            channelInterpretation: 'discrete',
            gain: pan
        });
        let { connectGraph , disconnectGraph  } = buildInternalGraph(nativeContext, channelCount, inputGainNode, panGainNode, channelMergerNode);
        Object.defineProperty(panGainNode.gain, 'defaultValue', {
            get: ()=>0
        });
        Object.defineProperty(panGainNode.gain, 'maxValue', {
            get: ()=>1
        });
        Object.defineProperty(panGainNode.gain, 'minValue', {
            get: ()=>-1
        });
        const nativeStereoPannerNodeFakerFactory = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return inputGainNode.channelCount;
            },
            set channelCount (value){
                if (inputGainNode.channelCount !== value) {
                    if (isConnected) disconnectGraph();
                    ({ connectGraph , disconnectGraph  } = buildInternalGraph(nativeContext, value, inputGainNode, panGainNode, channelMergerNode));
                    if (isConnected) connectGraph();
                }
                inputGainNode.channelCount = value;
            },
            get channelCountMode () {
                return inputGainNode.channelCountMode;
            },
            set channelCountMode (value1){
                if (value1 === 'clamped-max' || value1 === 'max') throw createNotSupportedError();
                inputGainNode.channelCountMode = value1;
            },
            get channelInterpretation () {
                return inputGainNode.channelInterpretation;
            },
            set channelInterpretation (value2){
                inputGainNode.channelInterpretation = value2;
            },
            get context () {
                return inputGainNode.context;
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get numberOfInputs () {
                return inputGainNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return inputGainNode.numberOfOutputs;
            },
            get pan () {
                return panGainNode.gain;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        let isConnected = false;
        const whenConnected = ()=>{
            connectGraph();
            isConnected = true;
        };
        const whenDisconnected = ()=>{
            disconnectGraph();
            isConnected = false;
        };
        return monitorConnections(_interceptConnections.interceptConnections(nativeStereoPannerNodeFakerFactory, channelMergerNode), whenConnected, whenDisconnected);
    };
};

},{"../helpers/intercept-connections":"7vk0h","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fhU38":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeWaveShaperNodeFactory", ()=>createNativeWaveShaperNodeFactory
);
var _assignNativeAudioNodeOption = require("../helpers/assign-native-audio-node-option");
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
const createNativeWaveShaperNodeFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeWaveShaperNodeFaker, isDCCurve, monitorConnections, nativeAudioContextConstructor, overwriteAccessors)=>{
    return (nativeContext, options)=>{
        const nativeWaveShaperNode = nativeContext.createWaveShaper();
        /*
         * Bug #119: Safari does not correctly map the values.
         * @todo Unfortunately there is no way to test for this behavior in a synchronous fashion which is why testing for the existence of
         * the webkitAudioContext is used as a workaround here. Testing for the automationRate property is necessary because this workaround
         * isn't necessary anymore since v14.0.2 of Safari.
         */ if (nativeAudioContextConstructor !== null && nativeAudioContextConstructor.name === 'webkitAudioContext' && nativeContext.createGain().gain.automationRate === undefined) return createNativeWaveShaperNodeFaker(nativeContext, options);
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(nativeWaveShaperNode, options);
        const curve = options.curve === null || options.curve instanceof Float32Array ? options.curve : new Float32Array(options.curve);
        // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.
        if (curve !== null && curve.length < 2) throw createInvalidStateError();
        // Only values of type Float32Array can be assigned to the curve property.
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeWaveShaperNode, {
            curve
        }, 'curve');
        _assignNativeAudioNodeOption.assignNativeAudioNodeOption(nativeWaveShaperNode, options, 'oversample');
        let disconnectNativeAudioBufferSourceNode = null;
        let isConnected = false;
        overwriteAccessors(nativeWaveShaperNode, 'curve', (get)=>()=>get.call(nativeWaveShaperNode)
        , (set)=>(value)=>{
                set.call(nativeWaveShaperNode, value);
                if (isConnected) {
                    if (isDCCurve(value) && disconnectNativeAudioBufferSourceNode === null) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);
                    else if (!isDCCurve(value) && disconnectNativeAudioBufferSourceNode !== null) {
                        disconnectNativeAudioBufferSourceNode();
                        disconnectNativeAudioBufferSourceNode = null;
                    }
                }
                return value;
            }
        );
        const whenConnected = ()=>{
            isConnected = true;
            if (isDCCurve(nativeWaveShaperNode.curve)) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, nativeWaveShaperNode);
        };
        const whenDisconnected = ()=>{
            isConnected = false;
            if (disconnectNativeAudioBufferSourceNode !== null) {
                disconnectNativeAudioBufferSourceNode();
                disconnectNativeAudioBufferSourceNode = null;
            }
        };
        return monitorConnections(nativeWaveShaperNode, whenConnected, whenDisconnected);
    };
};

},{"../helpers/assign-native-audio-node-option":"2lkZy","../helpers/assign-native-audio-node-options":"2pMvb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cl7SO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNativeWaveShaperNodeFakerFactory", ()=>createNativeWaveShaperNodeFakerFactory
);
var _assignNativeAudioNodeOptions = require("../helpers/assign-native-audio-node-options");
var _interceptConnections = require("../helpers/intercept-connections");
const createNativeWaveShaperNodeFakerFactory = (createConnectedNativeAudioBufferSourceNode, createInvalidStateError, createNativeGainNode, isDCCurve, monitorConnections)=>{
    return (nativeContext, { curve , oversample , ...audioNodeOptions })=>{
        const negativeWaveShaperNode = nativeContext.createWaveShaper();
        const positiveWaveShaperNode = nativeContext.createWaveShaper();
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(negativeWaveShaperNode, audioNodeOptions);
        _assignNativeAudioNodeOptions.assignNativeAudioNodeOptions(positiveWaveShaperNode, audioNodeOptions);
        const inputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const invertGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: -1
        });
        const outputGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: 1
        });
        const revertGainNode = createNativeGainNode(nativeContext, {
            ...audioNodeOptions,
            gain: -1
        });
        let disconnectNativeAudioBufferSourceNode = null;
        let isConnected = false;
        let unmodifiedCurve = null;
        const nativeWaveShaperNodeFaker = {
            get bufferSize () {
                return undefined;
            },
            get channelCount () {
                return negativeWaveShaperNode.channelCount;
            },
            set channelCount (value){
                inputGainNode.channelCount = value;
                invertGainNode.channelCount = value;
                negativeWaveShaperNode.channelCount = value;
                outputGainNode.channelCount = value;
                positiveWaveShaperNode.channelCount = value;
                revertGainNode.channelCount = value;
            },
            get channelCountMode () {
                return negativeWaveShaperNode.channelCountMode;
            },
            set channelCountMode (value1){
                inputGainNode.channelCountMode = value1;
                invertGainNode.channelCountMode = value1;
                negativeWaveShaperNode.channelCountMode = value1;
                outputGainNode.channelCountMode = value1;
                positiveWaveShaperNode.channelCountMode = value1;
                revertGainNode.channelCountMode = value1;
            },
            get channelInterpretation () {
                return negativeWaveShaperNode.channelInterpretation;
            },
            set channelInterpretation (value2){
                inputGainNode.channelInterpretation = value2;
                invertGainNode.channelInterpretation = value2;
                negativeWaveShaperNode.channelInterpretation = value2;
                outputGainNode.channelInterpretation = value2;
                positiveWaveShaperNode.channelInterpretation = value2;
                revertGainNode.channelInterpretation = value2;
            },
            get context () {
                return negativeWaveShaperNode.context;
            },
            get curve () {
                return unmodifiedCurve;
            },
            set curve (value3){
                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.
                if (value3 !== null && value3.length < 2) throw createInvalidStateError();
                if (value3 === null) {
                    negativeWaveShaperNode.curve = value3;
                    positiveWaveShaperNode.curve = value3;
                } else {
                    const curveLength = value3.length;
                    const negativeCurve = new Float32Array(curveLength + 2 - curveLength % 2);
                    const positiveCurve = new Float32Array(curveLength + 2 - curveLength % 2);
                    negativeCurve[0] = value3[0];
                    positiveCurve[0] = -value3[curveLength - 1];
                    const length = Math.ceil((curveLength + 1) / 2);
                    const centerIndex = (curveLength + 1) / 2 - 1;
                    for(let i = 1; i < length; i += 1){
                        const theoreticIndex = i / length * centerIndex;
                        const lowerIndex = Math.floor(theoreticIndex);
                        const upperIndex = Math.ceil(theoreticIndex);
                        negativeCurve[i] = lowerIndex === upperIndex ? value3[lowerIndex] : (1 - (theoreticIndex - lowerIndex)) * value3[lowerIndex] + (1 - (upperIndex - theoreticIndex)) * value3[upperIndex];
                        positiveCurve[i] = lowerIndex === upperIndex ? -value3[curveLength - 1 - lowerIndex] : -((1 - (theoreticIndex - lowerIndex)) * value3[curveLength - 1 - lowerIndex]) - (1 - (upperIndex - theoreticIndex)) * value3[curveLength - 1 - upperIndex];
                    }
                    negativeCurve[length] = curveLength % 2 === 1 ? value3[length - 1] : (value3[length - 2] + value3[length - 1]) / 2;
                    negativeWaveShaperNode.curve = negativeCurve;
                    positiveWaveShaperNode.curve = positiveCurve;
                }
                unmodifiedCurve = value3;
                if (isConnected) {
                    if (isDCCurve(unmodifiedCurve) && disconnectNativeAudioBufferSourceNode === null) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);
                    else if (disconnectNativeAudioBufferSourceNode !== null) {
                        disconnectNativeAudioBufferSourceNode();
                        disconnectNativeAudioBufferSourceNode = null;
                    }
                }
            },
            get inputs () {
                return [
                    inputGainNode
                ];
            },
            get numberOfInputs () {
                return negativeWaveShaperNode.numberOfInputs;
            },
            get numberOfOutputs () {
                return negativeWaveShaperNode.numberOfOutputs;
            },
            get oversample () {
                return negativeWaveShaperNode.oversample;
            },
            set oversample (value4){
                negativeWaveShaperNode.oversample = value4;
                positiveWaveShaperNode.oversample = value4;
            },
            addEventListener (...args) {
                return inputGainNode.addEventListener(args[0], args[1], args[2]);
            },
            dispatchEvent (...args) {
                return inputGainNode.dispatchEvent(args[0]);
            },
            removeEventListener (...args) {
                return inputGainNode.removeEventListener(args[0], args[1], args[2]);
            }
        };
        if (curve !== null) // Only values of type Float32Array can be assigned to the curve property.
        nativeWaveShaperNodeFaker.curve = curve instanceof Float32Array ? curve : new Float32Array(curve);
        if (oversample !== nativeWaveShaperNodeFaker.oversample) nativeWaveShaperNodeFaker.oversample = oversample;
        const whenConnected = ()=>{
            inputGainNode.connect(negativeWaveShaperNode).connect(outputGainNode);
            inputGainNode.connect(invertGainNode).connect(positiveWaveShaperNode).connect(revertGainNode).connect(outputGainNode);
            isConnected = true;
            if (isDCCurve(unmodifiedCurve)) disconnectNativeAudioBufferSourceNode = createConnectedNativeAudioBufferSourceNode(nativeContext, inputGainNode);
        };
        const whenDisconnected = ()=>{
            inputGainNode.disconnect(negativeWaveShaperNode);
            negativeWaveShaperNode.disconnect(outputGainNode);
            inputGainNode.disconnect(invertGainNode);
            invertGainNode.disconnect(positiveWaveShaperNode);
            positiveWaveShaperNode.disconnect(revertGainNode);
            revertGainNode.disconnect(outputGainNode);
            isConnected = false;
            if (disconnectNativeAudioBufferSourceNode !== null) {
                disconnectNativeAudioBufferSourceNode();
                disconnectNativeAudioBufferSourceNode = null;
            }
        };
        return monitorConnections(_interceptConnections.interceptConnections(nativeWaveShaperNodeFaker, outputGainNode), whenConnected, whenDisconnected);
    };
};

},{"../helpers/assign-native-audio-node-options":"2pMvb","../helpers/intercept-connections":"7vk0h","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"l51fO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createNotSupportedError", ()=>createNotSupportedError
);
const createNotSupportedError = ()=>new DOMException('', 'NotSupportedError')
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kAkwN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createOfflineAudioContextConstructor", ()=>createOfflineAudioContextConstructor
);
var _deactivateAudioGraph = require("../helpers/deactivate-audio-graph");
var _testPromiseSupport = require("../helpers/test-promise-support");
const DEFAULT_OPTIONS = {
    numberOfChannels: 1
};
const createOfflineAudioContextConstructor = (baseAudioContextConstructor, cacheTestResult, createInvalidStateError, createNativeOfflineAudioContext, startRendering)=>{
    return class OfflineAudioContext1 extends baseAudioContextConstructor {
        constructor(a, b, c){
            let options;
            if (typeof a === 'number' && b !== undefined && c !== undefined) options = {
                length: b,
                numberOfChannels: a,
                sampleRate: c
            };
            else if (typeof a === 'object') options = a;
            else throw new Error('The given parameters are not valid.');
            const { length , numberOfChannels , sampleRate  } = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeOfflineAudioContext = createNativeOfflineAudioContext(numberOfChannels, length, sampleRate);
            // #21 Safari does not support promises and therefore would fire the statechange event before the promise can be resolved.
            if (!cacheTestResult(_testPromiseSupport.testPromiseSupport, ()=>_testPromiseSupport.testPromiseSupport(nativeOfflineAudioContext)
            )) nativeOfflineAudioContext.addEventListener('statechange', (()=>{
                let i = 0;
                const delayStateChangeEvent = (event)=>{
                    if (this._state === 'running') {
                        if (i > 0) {
                            nativeOfflineAudioContext.removeEventListener('statechange', delayStateChangeEvent);
                            event.stopImmediatePropagation();
                            this._waitForThePromiseToSettle(event);
                        } else i += 1;
                    }
                };
                return delayStateChangeEvent;
            })());
            super(nativeOfflineAudioContext, numberOfChannels);
            this._length = length;
            this._nativeOfflineAudioContext = nativeOfflineAudioContext;
            this._state = null;
        }
        get length() {
            // Bug #17: Safari does not yet expose the length.
            if (this._nativeOfflineAudioContext.length === undefined) return this._length;
            return this._nativeOfflineAudioContext.length;
        }
        get state() {
            return this._state === null ? this._nativeOfflineAudioContext.state : this._state;
        }
        startRendering() {
            /*
             * Bug #9 & #59: It is theoretically possible that startRendering() will first render a partialOfflineAudioContext. Therefore
             * the state of the nativeOfflineAudioContext might no transition to running immediately.
             */ if (this._state === 'running') return Promise.reject(createInvalidStateError());
            this._state = 'running';
            return startRendering(this.destination, this._nativeOfflineAudioContext).finally(()=>{
                this._state = null;
                _deactivateAudioGraph.deactivateAudioGraph(this);
            });
        }
        _waitForThePromiseToSettle(event) {
            if (this._state === null) this._nativeOfflineAudioContext.dispatchEvent(event);
            else setTimeout(()=>this._waitForThePromiseToSettle(event)
            );
        }
    };
};

},{"../helpers/deactivate-audio-graph":"kkyz8","../helpers/test-promise-support":"bcKJv","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fgXfo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createOscillatorNodeConstructor", ()=>createOscillatorNodeConstructor
);
var _isActiveAudioNode = require("../helpers/is-active-audio-node");
var _setInternalStateToActive = require("../helpers/set-internal-state-to-active");
var _setInternalStateToPassive = require("../helpers/set-internal-state-to-passive");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers',
    detune: 0,
    frequency: 440,
    periodicWave: undefined,
    type: 'sine'
};
const createOscillatorNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeOscillatorNode, createOscillatorNodeRenderer, getNativeContext, isNativeOfflineAudioContext, wrapEventListener)=>{
    return class OscillatorNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeOscillatorNode = createNativeOscillatorNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const oscillatorNodeRenderer = isOffline ? createOscillatorNodeRenderer() : null;
            const nyquist = context.sampleRate / 2;
            super(context, false, nativeOscillatorNode, oscillatorNodeRenderer);
            // Bug #81: Firefox & Safari do not export the correct values for maxValue and minValue.
            this._detune = createAudioParam(this, isOffline, nativeOscillatorNode.detune, 153600, -153600);
            // Bug #76: Safari does not export the correct values for maxValue and minValue.
            this._frequency = createAudioParam(this, isOffline, nativeOscillatorNode.frequency, nyquist, -nyquist);
            this._nativeOscillatorNode = nativeOscillatorNode;
            this._onended = null;
            this._oscillatorNodeRenderer = oscillatorNodeRenderer;
            if (this._oscillatorNodeRenderer !== null && mergedOptions.periodicWave !== undefined) this._oscillatorNodeRenderer.periodicWave = mergedOptions.periodicWave;
        }
        get detune() {
            return this._detune;
        }
        get frequency() {
            return this._frequency;
        }
        get onended() {
            return this._onended;
        }
        set onended(value) {
            const wrappedListener = typeof value === 'function' ? wrapEventListener(this, value) : null;
            this._nativeOscillatorNode.onended = wrappedListener;
            const nativeOnEnded = this._nativeOscillatorNode.onended;
            this._onended = nativeOnEnded !== null && nativeOnEnded === wrappedListener ? value : nativeOnEnded;
        }
        get type() {
            return this._nativeOscillatorNode.type;
        }
        set type(value) {
            this._nativeOscillatorNode.type = value;
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.periodicWave = null;
        }
        setPeriodicWave(periodicWave) {
            this._nativeOscillatorNode.setPeriodicWave(periodicWave);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.periodicWave = periodicWave;
        }
        start(when = 0) {
            this._nativeOscillatorNode.start(when);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.start = when;
            if (this.context.state !== 'closed') {
                _setInternalStateToActive.setInternalStateToActive(this);
                const resetInternalStateToPassive = ()=>{
                    this._nativeOscillatorNode.removeEventListener('ended', resetInternalStateToPassive);
                    if (_isActiveAudioNode.isActiveAudioNode(this)) _setInternalStateToPassive.setInternalStateToPassive(this);
                };
                this._nativeOscillatorNode.addEventListener('ended', resetInternalStateToPassive);
            }
        }
        stop(when = 0) {
            this._nativeOscillatorNode.stop(when);
            if (this._oscillatorNodeRenderer !== null) this._oscillatorNodeRenderer.stop = when;
        }
    };
};

},{"../helpers/is-active-audio-node":"3g5Fl","../helpers/set-internal-state-to-active":"21L0g","../helpers/set-internal-state-to-passive":"37J9v","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kgvGW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createOscillatorNodeRendererFactory", ()=>createOscillatorNodeRendererFactory
);
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createOscillatorNodeRendererFactory = (connectAudioParam, createNativeOscillatorNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeOscillatorNodes = new WeakMap();
        let periodicWave = null;
        let start = null;
        let stop = null;
        const createOscillatorNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeOscillatorNode = getNativeAudioNode(proxy);
            // If the initially used nativeOscillatorNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeOscillatorNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeOscillatorNode, nativeOfflineAudioContext);
            if (!nativeOscillatorNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeOscillatorNode.channelCount,
                    channelCountMode: nativeOscillatorNode.channelCountMode,
                    channelInterpretation: nativeOscillatorNode.channelInterpretation,
                    detune: nativeOscillatorNode.detune.value,
                    frequency: nativeOscillatorNode.frequency.value,
                    periodicWave: periodicWave === null ? undefined : periodicWave,
                    type: nativeOscillatorNode.type
                };
                nativeOscillatorNode = createNativeOscillatorNode(nativeOfflineAudioContext, options);
                if (start !== null) nativeOscillatorNode.start(start);
                if (stop !== null) nativeOscillatorNode.stop(stop);
            }
            renderedNativeOscillatorNodes.set(nativeOfflineAudioContext, nativeOscillatorNode);
            if (!nativeOscillatorNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency, trace);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.detune, nativeOscillatorNode.detune, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.frequency, nativeOscillatorNode.frequency, trace);
            }
            await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeOscillatorNode, trace);
            return nativeOscillatorNode;
        };
        return {
            set periodicWave (value){
                periodicWave = value;
            },
            set start (value1){
                start = value1;
            },
            set stop (value2){
                stop = value2;
            },
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeOscillatorNode = renderedNativeOscillatorNodes.get(nativeOfflineAudioContext);
                if (renderedNativeOscillatorNode !== undefined) return Promise.resolve(renderedNativeOscillatorNode);
                return createOscillatorNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3fegt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createPannerNodeConstructor", ()=>createPannerNodeConstructor
);
var _constants = require("../constants");
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'clamped-max',
    channelInterpretation: 'speakers',
    coneInnerAngle: 360,
    coneOuterAngle: 360,
    coneOuterGain: 0,
    distanceModel: 'inverse',
    maxDistance: 10000,
    orientationX: 1,
    orientationY: 0,
    orientationZ: 0,
    panningModel: 'equalpower',
    positionX: 0,
    positionY: 0,
    positionZ: 0,
    refDistance: 1,
    rolloffFactor: 1
};
const createPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativePannerNode, createPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class PannerNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativePannerNode = createNativePannerNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const pannerNodeRenderer = isOffline ? createPannerNodeRenderer() : null;
            super(context, false, nativePannerNode, pannerNodeRenderer);
            this._nativePannerNode = nativePannerNode;
            // Bug #74: Safari does not export the correct values for maxValue and minValue.
            this._orientationX = createAudioParam(this, isOffline, nativePannerNode.orientationX, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            this._orientationY = createAudioParam(this, isOffline, nativePannerNode.orientationY, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            this._orientationZ = createAudioParam(this, isOffline, nativePannerNode.orientationZ, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            this._positionX = createAudioParam(this, isOffline, nativePannerNode.positionX, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            this._positionY = createAudioParam(this, isOffline, nativePannerNode.positionY, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            this._positionZ = createAudioParam(this, isOffline, nativePannerNode.positionZ, _constants.MOST_POSITIVE_SINGLE_FLOAT, _constants.MOST_NEGATIVE_SINGLE_FLOAT);
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get coneInnerAngle() {
            return this._nativePannerNode.coneInnerAngle;
        }
        set coneInnerAngle(value) {
            this._nativePannerNode.coneInnerAngle = value;
        }
        get coneOuterAngle() {
            return this._nativePannerNode.coneOuterAngle;
        }
        set coneOuterAngle(value) {
            this._nativePannerNode.coneOuterAngle = value;
        }
        get coneOuterGain() {
            return this._nativePannerNode.coneOuterGain;
        }
        set coneOuterGain(value) {
            this._nativePannerNode.coneOuterGain = value;
        }
        get distanceModel() {
            return this._nativePannerNode.distanceModel;
        }
        set distanceModel(value) {
            this._nativePannerNode.distanceModel = value;
        }
        get maxDistance() {
            return this._nativePannerNode.maxDistance;
        }
        set maxDistance(value) {
            this._nativePannerNode.maxDistance = value;
        }
        get orientationX() {
            return this._orientationX;
        }
        get orientationY() {
            return this._orientationY;
        }
        get orientationZ() {
            return this._orientationZ;
        }
        get panningModel() {
            return this._nativePannerNode.panningModel;
        }
        set panningModel(value) {
            this._nativePannerNode.panningModel = value;
        }
        get positionX() {
            return this._positionX;
        }
        get positionY() {
            return this._positionY;
        }
        get positionZ() {
            return this._positionZ;
        }
        get refDistance() {
            return this._nativePannerNode.refDistance;
        }
        set refDistance(value) {
            this._nativePannerNode.refDistance = value;
        }
        get rolloffFactor() {
            return this._nativePannerNode.rolloffFactor;
        }
        set rolloffFactor(value) {
            this._nativePannerNode.rolloffFactor = value;
        }
    };
};

},{"../constants":"dG3Pl","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"82fmB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createPannerNodeRendererFactory", ()=>createPannerNodeRendererFactory
);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createPannerNodeRendererFactory = (connectAudioParam, createNativeChannelMergerNode, createNativeConstantSourceNode, createNativeGainNode, createNativePannerNode, getNativeAudioNode, nativeOfflineAudioContextConstructor, renderAutomation, renderInputsOfAudioNode, renderNativeOfflineAudioContext)=>{
    return ()=>{
        const renderedNativeAudioNodes = new WeakMap();
        let renderedBufferPromise = null;
        const createAudioNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeGainNode = null;
            let nativePannerNode = getNativeAudioNode(proxy);
            const commonAudioNodeOptions = {
                channelCount: nativePannerNode.channelCount,
                channelCountMode: nativePannerNode.channelCountMode,
                channelInterpretation: nativePannerNode.channelInterpretation
            };
            const commonNativePannerNodeOptions = {
                ...commonAudioNodeOptions,
                coneInnerAngle: nativePannerNode.coneInnerAngle,
                coneOuterAngle: nativePannerNode.coneOuterAngle,
                coneOuterGain: nativePannerNode.coneOuterGain,
                distanceModel: nativePannerNode.distanceModel,
                maxDistance: nativePannerNode.maxDistance,
                panningModel: nativePannerNode.panningModel,
                refDistance: nativePannerNode.refDistance,
                rolloffFactor: nativePannerNode.rolloffFactor
            };
            // If the initially used nativePannerNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativePannerNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativePannerNode, nativeOfflineAudioContext);
            // Bug #124: Safari does not support modifying the orientation and the position with AudioParams.
            if ('bufferSize' in nativePannerNode) nativeGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                ...commonAudioNodeOptions,
                gain: 1
            });
            else if (!nativePannerNodeIsOwnedByContext) {
                const options = {
                    ...commonNativePannerNodeOptions,
                    orientationX: nativePannerNode.orientationX.value,
                    orientationY: nativePannerNode.orientationY.value,
                    orientationZ: nativePannerNode.orientationZ.value,
                    positionX: nativePannerNode.positionX.value,
                    positionY: nativePannerNode.positionY.value,
                    positionZ: nativePannerNode.positionZ.value
                };
                nativePannerNode = createNativePannerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeAudioNodes.set(nativeOfflineAudioContext, nativeGainNode === null ? nativePannerNode : nativeGainNode);
            if (nativeGainNode !== null) {
                if (renderedBufferPromise === null) {
                    if (nativeOfflineAudioContextConstructor === null) throw new Error('Missing the native OfflineAudioContext constructor.');
                    const partialOfflineAudioContext = new nativeOfflineAudioContextConstructor(6, // Bug #17: Safari does not yet expose the length.
                    proxy.context.length, nativeOfflineAudioContext.sampleRate);
                    const nativeChannelMergerNode = createNativeChannelMergerNode(partialOfflineAudioContext, {
                        channelCount: 1,
                        channelCountMode: 'explicit',
                        channelInterpretation: 'speakers',
                        numberOfInputs: 6
                    });
                    nativeChannelMergerNode.connect(partialOfflineAudioContext.destination);
                    renderedBufferPromise = (async ()=>{
                        const nativeConstantSourceNodes = await Promise.all([
                            proxy.orientationX,
                            proxy.orientationY,
                            proxy.orientationZ,
                            proxy.positionX,
                            proxy.positionY,
                            proxy.positionZ
                        ].map(async (audioParam, index)=>{
                            const nativeConstantSourceNode = createNativeConstantSourceNode(partialOfflineAudioContext, {
                                channelCount: 1,
                                channelCountMode: 'explicit',
                                channelInterpretation: 'discrete',
                                offset: index === 0 ? 1 : 0
                            });
                            await renderAutomation(partialOfflineAudioContext, audioParam, nativeConstantSourceNode.offset, trace);
                            return nativeConstantSourceNode;
                        }));
                        for(let i = 0; i < 6; i += 1){
                            nativeConstantSourceNodes[i].connect(nativeChannelMergerNode, 0, i);
                            nativeConstantSourceNodes[i].start(0);
                        }
                        return renderNativeOfflineAudioContext(partialOfflineAudioContext);
                    })();
                }
                const renderedBuffer = await renderedBufferPromise;
                const inputGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    ...commonAudioNodeOptions,
                    gain: 1
                });
                await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, inputGainNode, trace);
                const channelDatas = [];
                for(let i = 0; i < renderedBuffer.numberOfChannels; i += 1)channelDatas.push(renderedBuffer.getChannelData(i));
                let lastOrientation = [
                    channelDatas[0][0],
                    channelDatas[1][0],
                    channelDatas[2][0]
                ];
                let lastPosition = [
                    channelDatas[3][0],
                    channelDatas[4][0],
                    channelDatas[5][0]
                ];
                let gateGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                    ...commonAudioNodeOptions,
                    gain: 1
                });
                let partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {
                    ...commonNativePannerNodeOptions,
                    orientationX: lastOrientation[0],
                    orientationY: lastOrientation[1],
                    orientationZ: lastOrientation[2],
                    positionX: lastPosition[0],
                    positionY: lastPosition[1],
                    positionZ: lastPosition[2]
                });
                inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);
                partialPannerNode.connect(nativeGainNode);
                for(let i1 = 128; i1 < renderedBuffer.length; i1 += 128){
                    const orientation = [
                        channelDatas[0][i1],
                        channelDatas[1][i1],
                        channelDatas[2][i1]
                    ];
                    const positon = [
                        channelDatas[3][i1],
                        channelDatas[4][i1],
                        channelDatas[5][i1]
                    ];
                    if (orientation.some((value, index)=>value !== lastOrientation[index]
                    ) || positon.some((value, index)=>value !== lastPosition[index]
                    )) {
                        lastOrientation = orientation;
                        lastPosition = positon;
                        const currentTime = i1 / nativeOfflineAudioContext.sampleRate;
                        gateGainNode.gain.setValueAtTime(0, currentTime);
                        gateGainNode = createNativeGainNode(nativeOfflineAudioContext, {
                            ...commonAudioNodeOptions,
                            gain: 0
                        });
                        partialPannerNode = createNativePannerNode(nativeOfflineAudioContext, {
                            ...commonNativePannerNodeOptions,
                            orientationX: lastOrientation[0],
                            orientationY: lastOrientation[1],
                            orientationZ: lastOrientation[2],
                            positionX: lastPosition[0],
                            positionY: lastPosition[1],
                            positionZ: lastPosition[2]
                        });
                        gateGainNode.gain.setValueAtTime(1, currentTime);
                        inputGainNode.connect(gateGainNode).connect(partialPannerNode.inputs[0]);
                        partialPannerNode.connect(nativeGainNode);
                    }
                }
                return nativeGainNode;
            }
            if (!nativePannerNodeIsOwnedByContext) {
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY, trace);
                await renderAutomation(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ, trace);
            } else {
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationX, nativePannerNode.orientationX, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationY, nativePannerNode.orientationY, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.orientationZ, nativePannerNode.orientationZ, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionX, nativePannerNode.positionX, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionY, nativePannerNode.positionY, trace);
                await connectAudioParam(nativeOfflineAudioContext, proxy.positionZ, nativePannerNode.positionZ, trace);
            }
            if (_nativeAudioNodeFaker.isNativeAudioNodeFaker(nativePannerNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode.inputs[0], trace);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativePannerNode, trace);
            return nativePannerNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeGainNodeOrNativePannerNode = renderedNativeAudioNodes.get(nativeOfflineAudioContext);
                if (renderedNativeGainNodeOrNativePannerNode !== undefined) return Promise.resolve(renderedNativeGainNodeOrNativePannerNode);
                return createAudioNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../guards/native-audio-node-faker":"9mpuK","../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3dENA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createPeriodicWaveConstructor", ()=>createPeriodicWaveConstructor
);
const DEFAULT_OPTIONS = {
    disableNormalization: false
};
const createPeriodicWaveConstructor = (createNativePeriodicWave, getNativeContext, periodicWaveStore, sanitizePeriodicWaveOptions)=>{
    return class PeriodicWave1 {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = sanitizePeriodicWaveOptions({
                ...DEFAULT_OPTIONS,
                ...options
            });
            const periodicWave = createNativePeriodicWave(nativeContext, mergedOptions);
            periodicWaveStore.add(periodicWave);
            // This does violate all good pratices but it is used here to simplify the handling of periodic waves.
            return periodicWave;
        }
        static [Symbol.hasInstance](instance) {
            return instance !== null && typeof instance === 'object' && Object.getPrototypeOf(instance) === PeriodicWave1.prototype || periodicWaveStore.has(instance);
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kGzLE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createRenderAutomation", ()=>createRenderAutomation
);
const createRenderAutomation = (getAudioParamRenderer, renderInputsOfAudioParam)=>{
    return (nativeOfflineAudioContext, audioParam, nativeAudioParam, trace)=>{
        const audioParamRenderer = getAudioParamRenderer(audioParam);
        audioParamRenderer.replay(nativeAudioParam);
        return renderInputsOfAudioParam(audioParam, nativeOfflineAudioContext, nativeAudioParam, trace);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dLSj7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createRenderInputsOfAudioNode", ()=>createRenderInputsOfAudioNode
);
const createRenderInputsOfAudioNode = (getAudioNodeConnections, getAudioNodeRenderer, isPartOfACycle)=>{
    return async (audioNode, nativeOfflineAudioContext, nativeAudioNode, trace)=>{
        const audioNodeConnections = getAudioNodeConnections(audioNode);
        const nextTrace = [
            ...trace,
            audioNode
        ];
        await Promise.all(audioNodeConnections.activeInputs.map((connections, input)=>Array.from(connections).filter(([source])=>!nextTrace.includes(source)
            ).map(async ([source, output])=>{
                const audioNodeRenderer = getAudioNodeRenderer(source);
                const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext, nextTrace);
                const destination = audioNode.context.destination;
                if (!isPartOfACycle(source) && (audioNode !== destination || !isPartOfACycle(audioNode))) renderedNativeAudioNode.connect(nativeAudioNode, output, input);
            })
        ).reduce((allRenderingPromises, renderingPromises)=>[
                ...allRenderingPromises,
                ...renderingPromises
            ]
        , []));
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4Xi7v":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createRenderInputsOfAudioParam", ()=>createRenderInputsOfAudioParam
);
const createRenderInputsOfAudioParam = (getAudioNodeRenderer, getAudioParamConnections, isPartOfACycle)=>{
    return async (audioParam, nativeOfflineAudioContext, nativeAudioParam, trace)=>{
        const audioParamConnections = getAudioParamConnections(audioParam);
        await Promise.all(Array.from(audioParamConnections.activeInputs).map(async ([source, output])=>{
            const audioNodeRenderer = getAudioNodeRenderer(source);
            const renderedNativeAudioNode = await audioNodeRenderer.render(source, nativeOfflineAudioContext, trace);
            if (!isPartOfACycle(source)) renderedNativeAudioNode.connect(nativeAudioParam, output);
        }));
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4XZx3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createRenderNativeOfflineAudioContext", ()=>createRenderNativeOfflineAudioContext
);
var _testPromiseSupport = require("../helpers/test-promise-support");
const createRenderNativeOfflineAudioContext = (cacheTestResult, createNativeGainNode, createNativeScriptProcessorNode, testOfflineAudioContextCurrentTimeSupport)=>{
    return (nativeOfflineAudioContext)=>{
        // Bug #21: Safari does not support promises yet.
        if (cacheTestResult(_testPromiseSupport.testPromiseSupport, ()=>_testPromiseSupport.testPromiseSupport(nativeOfflineAudioContext)
        )) // Bug #158: Chrome and Edge do not advance currentTime if it is not accessed while rendering the audio.
        return Promise.resolve(cacheTestResult(testOfflineAudioContextCurrentTimeSupport, testOfflineAudioContextCurrentTimeSupport)).then((isOfflineAudioContextCurrentTimeSupported)=>{
            if (!isOfflineAudioContextCurrentTimeSupported) {
                const scriptProcessorNode = createNativeScriptProcessorNode(nativeOfflineAudioContext, 512, 0, 1);
                nativeOfflineAudioContext.oncomplete = ()=>{
                    scriptProcessorNode.onaudioprocess = null; // tslint:disable-line:deprecation
                    scriptProcessorNode.disconnect();
                };
                scriptProcessorNode.onaudioprocess = ()=>nativeOfflineAudioContext.currentTime
                ; // tslint:disable-line:deprecation
                scriptProcessorNode.connect(nativeOfflineAudioContext.destination);
            }
            return nativeOfflineAudioContext.startRendering();
        });
        return new Promise((resolve)=>{
            // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
            const gainNode = createNativeGainNode(nativeOfflineAudioContext, {
                channelCount: 1,
                channelCountMode: 'explicit',
                channelInterpretation: 'discrete',
                gain: 0
            });
            nativeOfflineAudioContext.oncomplete = (event)=>{
                gainNode.disconnect();
                resolve(event.renderedBuffer);
            };
            gainNode.connect(nativeOfflineAudioContext.destination);
            nativeOfflineAudioContext.startRendering();
        });
    };
};

},{"../helpers/test-promise-support":"bcKJv","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kakVM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createSetActiveAudioWorkletNodeInputs", ()=>createSetActiveAudioWorkletNodeInputs
);
const createSetActiveAudioWorkletNodeInputs = (activeAudioWorkletNodeInputsStore)=>{
    return (nativeAudioWorkletNode, activeInputs)=>{
        activeAudioWorkletNodeInputsStore.set(nativeAudioWorkletNode, activeInputs);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fEtVG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createSetAudioNodeTailTime", ()=>createSetAudioNodeTailTime
);
const createSetAudioNodeTailTime = (audioNodeTailTimeStore)=>{
    return (audioNode, tailTime)=>audioNodeTailTimeStore.set(audioNode, tailTime)
    ;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hcf4W":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createStartRendering", ()=>createStartRendering
);
var _wrapAudioBufferGetChannelDataMethod = require("../helpers/wrap-audio-buffer-get-channel-data-method");
const createStartRendering = (audioBufferStore, cacheTestResult, getAudioNodeRenderer, getUnrenderedAudioWorkletNodes, renderNativeOfflineAudioContext, testAudioBufferCopyChannelMethodsOutOfBoundsSupport, wrapAudioBufferCopyChannelMethods, wrapAudioBufferCopyChannelMethodsOutOfBounds)=>{
    const trace = [];
    return (destination, nativeOfflineAudioContext)=>getAudioNodeRenderer(destination).render(destination, nativeOfflineAudioContext, trace)/*
         * Bug #86 & #87: Invoking the renderer of an AudioWorkletNode might be necessary if it has no direct or indirect connection to the
         * destination.
         */ .then(()=>Promise.all(Array.from(getUnrenderedAudioWorkletNodes(nativeOfflineAudioContext)).map((audioWorkletNode)=>getAudioNodeRenderer(audioWorkletNode).render(audioWorkletNode, nativeOfflineAudioContext, trace)
            ))
        ).then(()=>renderNativeOfflineAudioContext(nativeOfflineAudioContext)
        ).then((audioBuffer)=>{
            // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
            // Bug #100: Safari does throw a wrong error when calling getChannelData() with an out-of-bounds value.
            if (typeof audioBuffer.copyFromChannel !== 'function') {
                wrapAudioBufferCopyChannelMethods(audioBuffer);
                _wrapAudioBufferGetChannelDataMethod.wrapAudioBufferGetChannelDataMethod(audioBuffer);
            // Bug #157: Firefox does not allow the bufferOffset to be out-of-bounds.
            } else if (!cacheTestResult(testAudioBufferCopyChannelMethodsOutOfBoundsSupport, ()=>testAudioBufferCopyChannelMethodsOutOfBoundsSupport(audioBuffer)
            )) wrapAudioBufferCopyChannelMethodsOutOfBounds(audioBuffer);
            audioBufferStore.add(audioBuffer);
            return audioBuffer;
        })
    ;
};

},{"../helpers/wrap-audio-buffer-get-channel-data-method":"cHHc4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3yTkS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createStereoPannerNodeConstructor", ()=>createStereoPannerNodeConstructor
);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    /*
     * Bug #105: The channelCountMode should be 'clamped-max' according to the spec but is set to 'explicit' to achieve consistent
     * behavior.
     */ channelCountMode: 'explicit',
    channelInterpretation: 'speakers',
    pan: 0
};
const createStereoPannerNodeConstructor = (audioNodeConstructor, createAudioParam, createNativeStereoPannerNode, createStereoPannerNodeRenderer, getNativeContext, isNativeOfflineAudioContext)=>{
    return class StereoPannerNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeStereoPannerNode = createNativeStereoPannerNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const stereoPannerNodeRenderer = isOffline ? createStereoPannerNodeRenderer() : null;
            super(context, false, nativeStereoPannerNode, stereoPannerNodeRenderer);
            this._pan = createAudioParam(this, isOffline, nativeStereoPannerNode.pan);
        }
        get pan() {
            return this._pan;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gmiKt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createStereoPannerNodeRendererFactory", ()=>createStereoPannerNodeRendererFactory
);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createStereoPannerNodeRendererFactory = (connectAudioParam, createNativeStereoPannerNode, getNativeAudioNode, renderAutomation, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeStereoPannerNodes = new WeakMap();
        const createStereoPannerNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeStereoPannerNode = getNativeAudioNode(proxy);
            /*
             * If the initially used nativeStereoPannerNode was not constructed on the same OfflineAudioContext it needs to be created
             * again.
             */ const nativeStereoPannerNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeStereoPannerNode, nativeOfflineAudioContext);
            if (!nativeStereoPannerNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeStereoPannerNode.channelCount,
                    channelCountMode: nativeStereoPannerNode.channelCountMode,
                    channelInterpretation: nativeStereoPannerNode.channelInterpretation,
                    pan: nativeStereoPannerNode.pan.value
                };
                nativeStereoPannerNode = createNativeStereoPannerNode(nativeOfflineAudioContext, options);
            }
            renderedNativeStereoPannerNodes.set(nativeOfflineAudioContext, nativeStereoPannerNode);
            if (!nativeStereoPannerNodeIsOwnedByContext) await renderAutomation(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan, trace);
            else await connectAudioParam(nativeOfflineAudioContext, proxy.pan, nativeStereoPannerNode.pan, trace);
            if (_nativeAudioNodeFaker.isNativeAudioNodeFaker(nativeStereoPannerNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode.inputs[0], trace);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeStereoPannerNode, trace);
            return nativeStereoPannerNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeStereoPannerNode = renderedNativeStereoPannerNodes.get(nativeOfflineAudioContext);
                if (renderedNativeStereoPannerNode !== undefined) return Promise.resolve(renderedNativeStereoPannerNode);
                return createStereoPannerNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../guards/native-audio-node-faker":"9mpuK","../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7WVWw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioBufferConstructorSupport", ()=>createTestAudioBufferConstructorSupport
);
const createTestAudioBufferConstructorSupport = (nativeAudioBufferConstructor)=>{
    return ()=>{
        if (nativeAudioBufferConstructor === null) return false;
        try {
            new nativeAudioBufferConstructor({
                length: 1,
                sampleRate: 44100
            }); // tslint:disable-line:no-unused-expression
        } catch  {
            return false;
        }
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"f4OgP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioBufferCopyChannelMethodsSubarraySupport", ()=>createTestAudioBufferCopyChannelMethodsSubarraySupport
);
const createTestAudioBufferCopyChannelMethodsSubarraySupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeAudioBuffer = nativeOfflineAudioContext.createBuffer(1, 1, 44100);
        // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
        if (nativeAudioBuffer.copyToChannel === undefined) return true;
        const source = new Float32Array(2);
        try {
            nativeAudioBuffer.copyFromChannel(source, 0, 0);
        } catch  {
            return false;
        }
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"emL8l":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioContextCloseMethodSupport", ()=>createTestAudioContextCloseMethodSupport
);
const createTestAudioContextCloseMethodSupport = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        // Try to check the prototype before constructing the AudioContext.
        if (nativeAudioContextConstructor.prototype !== undefined && nativeAudioContextConstructor.prototype.close !== undefined) return true;
        const audioContext = new nativeAudioContextConstructor();
        const isAudioContextClosable = audioContext.close !== undefined;
        try {
            audioContext.close();
        } catch  {
        // Ignore errors.
        }
        return isAudioContextClosable;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kTCKa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioContextDecodeAudioDataMethodTypeErrorSupport", ()=>createTestAudioContextDecodeAudioDataMethodTypeErrorSupport
);
const createTestAudioContextDecodeAudioDataMethodTypeErrorSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #21: Safari does not support promises yet.
        return new Promise((resolve)=>{
            let isPending = true;
            const resolvePromise = (err)=>{
                if (isPending) {
                    isPending = false;
                    offlineAudioContext.startRendering();
                    resolve(err instanceof TypeError);
                }
            };
            let promise;
            // Bug #26: Safari throws a synchronous error.
            try {
                promise = offlineAudioContext// Bug #1: Safari requires a successCallback.
                .decodeAudioData(null, ()=>{
                // Ignore the success callback.
                }, resolvePromise);
            } catch (err) {
                resolvePromise(err);
            }
            // Bug #21: Safari does not support promises yet.
            if (promise !== undefined) // Bug #6: Chrome, Edge, Firefox and Opera do not call the errorCallback.
            promise.catch(resolvePromise);
        });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"06jf9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioContextOptionsSupport", ()=>createTestAudioContextOptionsSupport
);
const createTestAudioContextOptionsSupport = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        let audioContext;
        try {
            audioContext = new nativeAudioContextConstructor({
                latencyHint: 'balanced'
            });
        } catch  {
            return false;
        }
        audioContext.close();
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j0dao":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioNodeConnectMethodSupport", ()=>createTestAudioNodeConnectMethodSupport
);
const createTestAudioNodeConnectMethodSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeGainNode = nativeOfflineAudioContext.createGain();
        const isSupported = nativeGainNode.connect(nativeGainNode) === nativeGainNode;
        nativeGainNode.disconnect(nativeGainNode);
        return isSupported;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kY07I":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioWorkletProcessorNoOutputsSupport", ()=>createTestAudioWorkletProcessorNoOutputsSupport
);
const createTestAudioWorkletProcessorNoOutputsSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor)=>{
    return async ()=>{
        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.
        if (nativeAudioWorkletNodeConstructor === null) return true;
        if (nativeOfflineAudioContextConstructor === null) return false;
        const blob = new Blob([
            'let c,p;class A extends AudioWorkletProcessor{constructor(){super();this.port.onmessage=(e)=>{p=e.data;p.onmessage=()=>{p.postMessage(c);p.close()};this.port.postMessage(0)}}process(){c=1}}registerProcessor("a",A)'
        ], {
            type: 'application/javascript; charset=utf-8'
        });
        const messageChannel = new MessageChannel();
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);
        const url = URL.createObjectURL(blob);
        let isCallingProcess = false;
        try {
            await offlineAudioContext.audioWorklet.addModule(url);
            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', {
                numberOfOutputs: 0
            });
            const oscillator = offlineAudioContext.createOscillator();
            await new Promise((resolve)=>{
                audioWorkletNode.port.onmessage = ()=>resolve()
                ;
                audioWorkletNode.port.postMessage(messageChannel.port2, [
                    messageChannel.port2
                ]);
            });
            audioWorkletNode.port.onmessage = ()=>isCallingProcess = true
            ;
            oscillator.connect(audioWorkletNode);
            oscillator.start(0);
            await offlineAudioContext.startRendering();
            isCallingProcess = await new Promise((resolve)=>{
                messageChannel.port1.onmessage = ({ data  })=>resolve(data === 1)
                ;
                messageChannel.port1.postMessage(0);
            });
        } catch  {
        // Ignore errors.
        } finally{
            messageChannel.port1.close();
            URL.revokeObjectURL(url);
        }
        return isCallingProcess;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"32UqD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestAudioWorkletProcessorPostMessageSupport", ()=>createTestAudioWorkletProcessorPostMessageSupport
);
const createTestAudioWorkletProcessorPostMessageSupport = (nativeAudioWorkletNodeConstructor, nativeOfflineAudioContextConstructor)=>{
    return async ()=>{
        // Bug #61: If there is no native AudioWorkletNode it gets faked and therefore it is no problem if the it doesn't exist.
        if (nativeAudioWorkletNodeConstructor === null) return true;
        if (nativeOfflineAudioContextConstructor === null) return false;
        const blob = new Blob([
            'class A extends AudioWorkletProcessor{process(i){this.port.postMessage(i,[i[0][0].buffer])}}registerProcessor("a",A)'
        ], {
            type: 'application/javascript; charset=utf-8'
        });
        // Bug #141: Safari does not support creating an OfflineAudioContext with less than 44100 Hz.
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 128, 44100);
        const url = URL.createObjectURL(blob);
        let isEmittingMessageEvents = false;
        let isEmittingProcessorErrorEvents = false;
        try {
            await offlineAudioContext.audioWorklet.addModule(url);
            const audioWorkletNode = new nativeAudioWorkletNodeConstructor(offlineAudioContext, 'a', {
                numberOfOutputs: 0
            });
            const oscillator = offlineAudioContext.createOscillator();
            audioWorkletNode.port.onmessage = ()=>isEmittingMessageEvents = true
            ;
            audioWorkletNode.onprocessorerror = ()=>isEmittingProcessorErrorEvents = true
            ;
            oscillator.connect(audioWorkletNode);
            oscillator.start(0);
            await offlineAudioContext.startRendering();
        } catch  {
        // Ignore errors.
        } finally{
            URL.revokeObjectURL(url);
        }
        return isEmittingMessageEvents && !isEmittingProcessorErrorEvents;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jUYFB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestChannelMergerNodeChannelCountSupport", ()=>createTestChannelMergerNodeChannelCountSupport
);
const createTestChannelMergerNodeChannelCountSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeChannelMergerNode = offlineAudioContext.createChannelMerger();
        /**
         * Bug #15: Safari does not return the default properties. It still needs to be patched. This test is supposed to test the support
         * in other browsers.
         */ if (nativeChannelMergerNode.channelCountMode === 'max') return true;
        try {
            nativeChannelMergerNode.channelCount = 2;
        } catch  {
            return true;
        }
        return false;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4jSSH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestConstantSourceNodeAccurateSchedulingSupport", ()=>createTestConstantSourceNodeAccurateSchedulingSupport
);
const createTestConstantSourceNodeAccurateSchedulingSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeOfflineAudioContext.createConstantSource === undefined) return true;
        const nativeConstantSourceNode = nativeOfflineAudioContext.createConstantSource();
        /*
         * @todo This is using bug #75 to detect bug #70. That works because both bugs were unique to
         * the implementation of Firefox right now, but it could probably be done in a better way.
         */ return nativeConstantSourceNode.offset.maxValue !== Number.POSITIVE_INFINITY;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"et056":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestConvolverNodeBufferReassignabilitySupport", ()=>createTestConvolverNodeBufferReassignabilitySupport
);
const createTestConvolverNodeBufferReassignabilitySupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeConvolverNode = offlineAudioContext.createConvolver();
        nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);
        try {
            nativeConvolverNode.buffer = offlineAudioContext.createBuffer(1, 1, offlineAudioContext.sampleRate);
        } catch  {
            return false;
        }
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lWUKb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestConvolverNodeChannelCountSupport", ()=>createTestConvolverNodeChannelCountSupport
);
const createTestConvolverNodeChannelCountSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return false;
        const offlineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        const nativeConvolverNode = offlineAudioContext.createConvolver();
        try {
            nativeConvolverNode.channelCount = 1;
        } catch  {
            return false;
        }
        return true;
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1rfsb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestIsSecureContextSupport", ()=>createTestIsSecureContextSupport
);
const createTestIsSecureContextSupport = (window)=>{
    return ()=>window !== null && window.hasOwnProperty('isSecureContext')
    ;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6mP0O":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport", ()=>createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport
);
const createTestMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = (nativeAudioContextConstructor)=>{
    return ()=>{
        if (nativeAudioContextConstructor === null) return false;
        const audioContext = new nativeAudioContextConstructor();
        try {
            audioContext.createMediaStreamSource(new MediaStream());
            return false;
        } catch (err) {
            return true;
        } finally{
            audioContext.close();
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1SZjr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestOfflineAudioContextCurrentTimeSupport", ()=>createTestOfflineAudioContextCurrentTimeSupport
);
const createTestOfflineAudioContextCurrentTimeSupport = (createNativeGainNode, nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        // Bug #48: Safari does not render an OfflineAudioContext without any connected node.
        const gainNode = createNativeGainNode(nativeOfflineAudioContext, {
            channelCount: 1,
            channelCountMode: 'explicit',
            channelInterpretation: 'discrete',
            gain: 0
        });
        // Bug #21: Safari does not support promises yet.
        return new Promise((resolve)=>{
            nativeOfflineAudioContext.oncomplete = ()=>{
                gainNode.disconnect();
                resolve(nativeOfflineAudioContext.currentTime !== 0);
            };
            nativeOfflineAudioContext.startRendering();
        });
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eE2QO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createTestStereoPannerNodeDefaultValueSupport", ()=>createTestStereoPannerNodeDefaultValueSupport
);
const createTestStereoPannerNodeDefaultValueSupport = (nativeOfflineAudioContextConstructor)=>{
    return ()=>{
        if (nativeOfflineAudioContextConstructor === null) return Promise.resolve(false);
        const nativeOfflineAudioContext = new nativeOfflineAudioContextConstructor(1, 1, 44100);
        /*
         * Bug #105: Safari does not support the StereoPannerNode. Therefore the returned value should normally be false but the faker does
         * support the tested behaviour.
         */ if (nativeOfflineAudioContext.createStereoPanner === undefined) return Promise.resolve(true);
        // Bug #62: Safari does not support ConstantSourceNodes.
        if (nativeOfflineAudioContext.createConstantSource === undefined) return Promise.resolve(true);
        const constantSourceNode = nativeOfflineAudioContext.createConstantSource();
        const stereoPanner = nativeOfflineAudioContext.createStereoPanner();
        constantSourceNode.channelCount = 1;
        constantSourceNode.offset.value = 1;
        stereoPanner.channelCount = 1;
        constantSourceNode.start();
        constantSourceNode.connect(stereoPanner).connect(nativeOfflineAudioContext.destination);
        return nativeOfflineAudioContext.startRendering().then((buffer)=>buffer.getChannelData(0)[0] !== 1
        );
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hTeWs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createUnknownError", ()=>createUnknownError
);
const createUnknownError = ()=>new DOMException('', 'UnknownError')
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8YqhL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWaveShaperNodeConstructor", ()=>createWaveShaperNodeConstructor
);
const DEFAULT_OPTIONS = {
    channelCount: 2,
    channelCountMode: 'max',
    channelInterpretation: 'speakers',
    curve: null,
    oversample: 'none'
};
const createWaveShaperNodeConstructor = (audioNodeConstructor, createInvalidStateError, createNativeWaveShaperNode, createWaveShaperNodeRenderer, getNativeContext, isNativeOfflineAudioContext, setAudioNodeTailTime)=>{
    return class WaveShaperNode1 extends audioNodeConstructor {
        constructor(context, options){
            const nativeContext = getNativeContext(context);
            const mergedOptions = {
                ...DEFAULT_OPTIONS,
                ...options
            };
            const nativeWaveShaperNode = createNativeWaveShaperNode(nativeContext, mergedOptions);
            const isOffline = isNativeOfflineAudioContext(nativeContext);
            const waveShaperNodeRenderer = isOffline ? createWaveShaperNodeRenderer() : null;
            // @todo Add a mechanism to only switch a WaveShaperNode to active while it is connected.
            super(context, true, nativeWaveShaperNode, waveShaperNodeRenderer);
            this._isCurveNullified = false;
            this._nativeWaveShaperNode = nativeWaveShaperNode;
            // @todo Determine a meaningful tail-time instead of just using one second.
            setAudioNodeTailTime(this, 1);
        }
        get curve() {
            if (this._isCurveNullified) return null;
            return this._nativeWaveShaperNode.curve;
        }
        set curve(value) {
            // Bug #103: Safari does not allow to set the curve to null.
            if (value === null) {
                this._isCurveNullified = true;
                this._nativeWaveShaperNode.curve = new Float32Array([
                    0,
                    0
                ]);
            } else {
                // Bug #102: Safari does not throw an InvalidStateError when the curve has less than two samples.
                // Bug #104: Chrome, Edge and Opera will throw an InvalidAccessError when the curve has less than two samples.
                if (value.length < 2) throw createInvalidStateError();
                this._isCurveNullified = false;
                this._nativeWaveShaperNode.curve = value;
            }
        }
        get oversample() {
            return this._nativeWaveShaperNode.oversample;
        }
        set oversample(value) {
            this._nativeWaveShaperNode.oversample = value;
        }
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1DUt3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWaveShaperNodeRendererFactory", ()=>createWaveShaperNodeRendererFactory
);
var _nativeAudioNodeFaker = require("../guards/native-audio-node-faker");
var _isOwnedByContext = require("../helpers/is-owned-by-context");
const createWaveShaperNodeRendererFactory = (createNativeWaveShaperNode, getNativeAudioNode, renderInputsOfAudioNode)=>{
    return ()=>{
        const renderedNativeWaveShaperNodes = new WeakMap();
        const createWaveShaperNode = async (proxy, nativeOfflineAudioContext, trace)=>{
            let nativeWaveShaperNode = getNativeAudioNode(proxy);
            // If the initially used nativeWaveShaperNode was not constructed on the same OfflineAudioContext it needs to be created again.
            const nativeWaveShaperNodeIsOwnedByContext = _isOwnedByContext.isOwnedByContext(nativeWaveShaperNode, nativeOfflineAudioContext);
            if (!nativeWaveShaperNodeIsOwnedByContext) {
                const options = {
                    channelCount: nativeWaveShaperNode.channelCount,
                    channelCountMode: nativeWaveShaperNode.channelCountMode,
                    channelInterpretation: nativeWaveShaperNode.channelInterpretation,
                    curve: nativeWaveShaperNode.curve,
                    oversample: nativeWaveShaperNode.oversample
                };
                nativeWaveShaperNode = createNativeWaveShaperNode(nativeOfflineAudioContext, options);
            }
            renderedNativeWaveShaperNodes.set(nativeOfflineAudioContext, nativeWaveShaperNode);
            if (_nativeAudioNodeFaker.isNativeAudioNodeFaker(nativeWaveShaperNode)) await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode.inputs[0], trace);
            else await renderInputsOfAudioNode(proxy, nativeOfflineAudioContext, nativeWaveShaperNode, trace);
            return nativeWaveShaperNode;
        };
        return {
            render (proxy, nativeOfflineAudioContext, trace) {
                const renderedNativeWaveShaperNode = renderedNativeWaveShaperNodes.get(nativeOfflineAudioContext);
                if (renderedNativeWaveShaperNode !== undefined) return Promise.resolve(renderedNativeWaveShaperNode);
                return createWaveShaperNode(proxy, nativeOfflineAudioContext, trace);
            }
        };
    };
};

},{"../guards/native-audio-node-faker":"9mpuK","../helpers/is-owned-by-context":"fFON4","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4q4HM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWindow", ()=>createWindow
);
const createWindow = ()=>typeof window === 'undefined' ? null : window
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5kCLR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWrapAudioBufferCopyChannelMethods", ()=>createWrapAudioBufferCopyChannelMethods
);
const createWrapAudioBufferCopyChannelMethods = (convertNumberToUnsignedLong, createIndexSizeError)=>{
    return (audioBuffer)=>{
        audioBuffer.copyFromChannel = (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
            if (channelNumber >= audioBuffer.numberOfChannels) throw createIndexSizeError();
            const audioBufferLength = audioBuffer.length;
            const channelData = audioBuffer.getChannelData(channelNumber);
            const destinationLength = destination.length;
            for(let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < destinationLength; i += 1)destination[i] = channelData[i + bufferOffset];
        };
        audioBuffer.copyToChannel = (source, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
            const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
            const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
            if (channelNumber >= audioBuffer.numberOfChannels) throw createIndexSizeError();
            const audioBufferLength = audioBuffer.length;
            const channelData = audioBuffer.getChannelData(channelNumber);
            const sourceLength = source.length;
            for(let i = bufferOffset < 0 ? -bufferOffset : 0; i + bufferOffset < audioBufferLength && i < sourceLength; i += 1)channelData[i + bufferOffset] = source[i];
        };
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lvdcn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWrapAudioBufferCopyChannelMethodsOutOfBounds", ()=>createWrapAudioBufferCopyChannelMethodsOutOfBounds
);
const createWrapAudioBufferCopyChannelMethodsOutOfBounds = (convertNumberToUnsignedLong)=>{
    return (audioBuffer)=>{
        audioBuffer.copyFromChannel = ((copyFromChannel)=>{
            return (destination, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                if (bufferOffset < audioBuffer.length) return copyFromChannel.call(audioBuffer, destination, channelNumber, bufferOffset);
            };
        })(audioBuffer.copyFromChannel);
        audioBuffer.copyToChannel = ((copyToChannel)=>{
            return (source, channelNumberAsNumber, bufferOffsetAsNumber = 0)=>{
                const bufferOffset = convertNumberToUnsignedLong(bufferOffsetAsNumber);
                const channelNumber = convertNumberToUnsignedLong(channelNumberAsNumber);
                if (bufferOffset < audioBuffer.length) return copyToChannel.call(audioBuffer, source, channelNumber, bufferOffset);
            };
        })(audioBuffer.copyToChannel);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"101CU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer", ()=>createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer
);
const createWrapAudioBufferSourceNodeStopMethodNullifiedBuffer = (overwriteAccessors)=>{
    return (nativeAudioBufferSourceNode, nativeContext)=>{
        const nullifiedBuffer = nativeContext.createBuffer(1, 1, 44100);
        if (nativeAudioBufferSourceNode.buffer === null) nativeAudioBufferSourceNode.buffer = nullifiedBuffer;
        overwriteAccessors(nativeAudioBufferSourceNode, 'buffer', (get)=>()=>{
                const value = get.call(nativeAudioBufferSourceNode);
                return value === nullifiedBuffer ? null : value;
            }
        , (set)=>(value)=>{
                return set.call(nativeAudioBufferSourceNode, value === null ? nullifiedBuffer : value);
            }
        );
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fFaQP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "createWrapChannelMergerNode", ()=>createWrapChannelMergerNode
);
const createWrapChannelMergerNode = (createInvalidStateError, monitorConnections)=>{
    return (nativeContext, channelMergerNode)=>{
        // Bug #15: Safari does not return the default properties.
        channelMergerNode.channelCount = 1;
        channelMergerNode.channelCountMode = 'explicit';
        // Bug #16: Safari does not throw an error when setting a different channelCount or channelCountMode.
        Object.defineProperty(channelMergerNode, 'channelCount', {
            get: ()=>1
            ,
            set: ()=>{
                throw createInvalidStateError();
            }
        });
        Object.defineProperty(channelMergerNode, 'channelCountMode', {
            get: ()=>'explicit'
            ,
            set: ()=>{
                throw createInvalidStateError();
            }
        });
        // Bug #20: Safari requires a connection of any kind to treat the input signal correctly.
        const audioBufferSourceNode = nativeContext.createBufferSource();
        const whenConnected = ()=>{
            const length = channelMergerNode.numberOfInputs;
            for(let i = 0; i < length; i += 1)audioBufferSourceNode.connect(channelMergerNode, 0, i);
        };
        const whenDisconnected = ()=>audioBufferSourceNode.disconnect(channelMergerNode)
        ;
        monitorConnections(channelMergerNode, whenConnected, whenDisconnected);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"idIDB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "getFirstSample", ()=>getFirstSample
);
const getFirstSample = (audioBuffer, buffer, channelNumber)=>{
    // Bug #5: Safari does not support copyFromChannel() and copyToChannel().
    if (audioBuffer.copyFromChannel === undefined) return audioBuffer.getChannelData(channelNumber)[0];
    audioBuffer.copyFromChannel(buffer, channelNumber);
    return buffer[0];
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ikasp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "isDCCurve", ()=>isDCCurve
);
const isDCCurve = (curve)=>{
    if (curve === null) return false;
    const length = curve.length;
    if (length % 2 !== 0) return curve[Math.floor(length / 2)] !== 0;
    return curve[length / 2 - 1] + curve[length / 2] !== 0;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jifeM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "overwriteAccessors", ()=>overwriteAccessors
);
const overwriteAccessors = (object, property, createGetter, createSetter)=>{
    let prototype = object;
    while(!prototype.hasOwnProperty(property))prototype = Object.getPrototypeOf(prototype);
    const { get , set  } = Object.getOwnPropertyDescriptor(prototype, property);
    Object.defineProperty(object, property, {
        get: createGetter(get),
        set: createSetter(set)
    });
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"WVucX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "sanitizeAudioWorkletNodeOptions", ()=>sanitizeAudioWorkletNodeOptions
);
const sanitizeAudioWorkletNodeOptions = (options)=>{
    return {
        ...options,
        outputChannelCount: options.outputChannelCount !== undefined ? options.outputChannelCount : options.numberOfInputs === 1 && options.numberOfOutputs === 1 ? /*
                   * Bug #61: This should be the computedNumberOfChannels, but unfortunately that is almost impossible to fake. That's why
                   * the channelCountMode is required to be 'explicit' as long as there is not a native implementation in every browser. That
                   * makes sure the computedNumberOfChannels is equivilant to the channelCount which makes it much easier to compute.
                   */ [
            options.channelCount
        ] : Array.from({
            length: options.numberOfOutputs
        }, ()=>1
        )
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9Pzxt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "sanitizeChannelSplitterOptions", ()=>sanitizeChannelSplitterOptions
);
const sanitizeChannelSplitterOptions = (options)=>{
    return {
        ...options,
        channelCount: options.numberOfOutputs
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"19pUc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "sanitizePeriodicWaveOptions", ()=>sanitizePeriodicWaveOptions
);
const sanitizePeriodicWaveOptions = (options)=>{
    const { imag , real  } = options;
    if (imag === undefined) {
        if (real === undefined) return {
            ...options,
            imag: [
                0,
                0
            ],
            real: [
                0,
                0
            ]
        };
        return {
            ...options,
            imag: Array.from(real, ()=>0
            ),
            real
        };
    }
    if (real === undefined) return {
        ...options,
        imag,
        real: Array.from(imag, ()=>0
        )
    };
    return {
        ...options,
        imag,
        real
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iYruz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "setValueAtTimeUntilPossible", ()=>setValueAtTimeUntilPossible
);
const setValueAtTimeUntilPossible = (audioParam, value, startTime)=>{
    try {
        audioParam.setValueAtTime(value, startTime);
    } catch (err) {
        if (err.code !== 9) throw err;
        setValueAtTimeUntilPossible(audioParam, value, startTime + 0.0000001);
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kZBYK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport", ()=>testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport
);
const testAudioBufferSourceNodeStartMethodConsecutiveCallsSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.start();
    try {
        nativeAudioBufferSourceNode.start();
    } catch  {
        return true;
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jeSkh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioBufferSourceNodeStartMethodOffsetClampingSupport", ()=>testAudioBufferSourceNodeStartMethodOffsetClampingSupport
);
const testAudioBufferSourceNodeStartMethodOffsetClampingSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);
    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
    try {
        nativeAudioBufferSourceNode.start(0, 1);
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5PZwx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioBufferSourceNodeStopMethodNullifiedBufferSupport", ()=>testAudioBufferSourceNodeStopMethodNullifiedBufferSupport
);
const testAudioBufferSourceNodeStopMethodNullifiedBufferSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.start();
    try {
        nativeAudioBufferSourceNode.stop();
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7zejX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioScheduledSourceNodeStartMethodNegativeParametersSupport", ()=>testAudioScheduledSourceNodeStartMethodNegativeParametersSupport
);
const testAudioScheduledSourceNodeStartMethodNegativeParametersSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createOscillator();
    try {
        nativeAudioBufferSourceNode.start(-1);
    } catch (err) {
        return err instanceof RangeError;
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ebWz3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport", ()=>testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport
);
const testAudioScheduledSourceNodeStopMethodConsecutiveCallsSupport = (nativeContext)=>{
    const nativeAudioBuffer = nativeContext.createBuffer(1, 1, 44100);
    const nativeAudioBufferSourceNode = nativeContext.createBufferSource();
    nativeAudioBufferSourceNode.buffer = nativeAudioBuffer;
    nativeAudioBufferSourceNode.start();
    nativeAudioBufferSourceNode.stop();
    try {
        nativeAudioBufferSourceNode.stop();
        return true;
    } catch  {
        return false;
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gpV16":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioScheduledSourceNodeStopMethodNegativeParametersSupport", ()=>testAudioScheduledSourceNodeStopMethodNegativeParametersSupport
);
const testAudioScheduledSourceNodeStopMethodNegativeParametersSupport = (nativeContext)=>{
    const nativeAudioBufferSourceNode = nativeContext.createOscillator();
    try {
        nativeAudioBufferSourceNode.stop(-1);
    } catch (err) {
        return err instanceof RangeError;
    }
    return false;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"rJW54":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testAudioWorkletNodeOptionsClonability", ()=>testAudioWorkletNodeOptionsClonability
);
const testAudioWorkletNodeOptionsClonability = (audioWorkletNodeOptions)=>{
    const { port1 , port2  } = new MessageChannel();
    try {
        // This will throw an error if the audioWorkletNodeOptions are not clonable.
        port1.postMessage(audioWorkletNodeOptions);
    } finally{
        port1.close();
        port2.close();
    }
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"boinr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testDomExceptionConstructorSupport", ()=>testDomExceptionConstructorSupport
);
const testDomExceptionConstructorSupport = ()=>{
    try {
        new DOMException(); // tslint:disable-line:no-unused-expression
    } catch  {
        return false;
    }
    return true;
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6xhFt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "testTransferablesSupport", ()=>testTransferablesSupport
);
const testTransferablesSupport = ()=>new Promise((resolve)=>{
        const arrayBuffer = new ArrayBuffer(0);
        const { port1 , port2  } = new MessageChannel();
        port1.onmessage = ({ data  })=>resolve(data !== null)
        ;
        port2.postMessage(arrayBuffer, [
            arrayBuffer
        ]);
    })
;

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1gYCo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioBufferSourceNodeStartMethodOffsetClamping", ()=>wrapAudioBufferSourceNodeStartMethodOffsetClamping
);
const wrapAudioBufferSourceNodeStartMethodOffsetClamping = (nativeAudioBufferSourceNode)=>{
    nativeAudioBufferSourceNode.start = ((start)=>{
        return (when = 0, offset = 0, duration)=>{
            const buffer = nativeAudioBufferSourceNode.buffer;
            // Bug #154: Safari does not clamp the offset if it is equal to or greater than the duration of the buffer.
            const clampedOffset = buffer === null ? offset : Math.min(buffer.duration, offset);
            // Bug #155: Safari does not handle the offset correctly if it would cause the buffer to be not be played at all.
            if (buffer !== null && clampedOffset > buffer.duration - 0.5 / nativeAudioBufferSourceNode.context.sampleRate) start.call(nativeAudioBufferSourceNode, when, 0, 0);
            else start.call(nativeAudioBufferSourceNode, when, clampedOffset, duration);
        };
    })(nativeAudioBufferSourceNode.start);
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fBU4X":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls", ()=>wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls
);
var _interceptConnections = require("./intercept-connections");
const wrapAudioScheduledSourceNodeStopMethodConsecutiveCalls = (nativeAudioScheduledSourceNode, nativeContext)=>{
    const nativeGainNode = nativeContext.createGain();
    nativeAudioScheduledSourceNode.connect(nativeGainNode);
    const disconnectGainNode = ((disconnect)=>{
        return ()=>{
            // @todo TypeScript cannot infer the overloaded signature with 1 argument yet.
            disconnect.call(nativeAudioScheduledSourceNode, nativeGainNode);
            nativeAudioScheduledSourceNode.removeEventListener('ended', disconnectGainNode);
        };
    })(nativeAudioScheduledSourceNode.disconnect);
    nativeAudioScheduledSourceNode.addEventListener('ended', disconnectGainNode);
    _interceptConnections.interceptConnections(nativeAudioScheduledSourceNode, nativeGainNode);
    nativeAudioScheduledSourceNode.stop = ((stop)=>{
        let isStopped = false;
        return (when = 0)=>{
            if (isStopped) try {
                stop.call(nativeAudioScheduledSourceNode, when);
            } catch  {
                nativeGainNode.gain.setValueAtTime(0, when);
            }
            else {
                stop.call(nativeAudioScheduledSourceNode, when);
                isStopped = true;
            }
        };
    })(nativeAudioScheduledSourceNode.stop);
};

},{"./intercept-connections":"7vk0h","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1G08j":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "wrapEventListener", ()=>wrapEventListener
);
const wrapEventListener = (target, eventListener)=>{
    return (event)=>{
        const descriptor = {
            value: target
        };
        Object.defineProperties(event, {
            currentTarget: descriptor,
            target: descriptor
        });
        if (typeof eventListener === 'function') return eventListener.call(target, event);
        return eventListener.handleEvent.call(target, event);
    };
};

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"go3d9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _analyserNode = require("./analyser-node");
parcelHelpers.exportAll(_analyserNode, exports);
var _analyserOptions = require("./analyser-options");
parcelHelpers.exportAll(_analyserOptions, exports);
var _audioBuffer = require("./audio-buffer");
parcelHelpers.exportAll(_audioBuffer, exports);
var _audioBufferOptions = require("./audio-buffer-options");
parcelHelpers.exportAll(_audioBufferOptions, exports);
var _audioBufferSourceNode = require("./audio-buffer-source-node");
parcelHelpers.exportAll(_audioBufferSourceNode, exports);
var _audioBufferSourceNodeRenderer = require("./audio-buffer-source-node-renderer");
parcelHelpers.exportAll(_audioBufferSourceNodeRenderer, exports);
var _audioBufferSourceOptions = require("./audio-buffer-source-options");
parcelHelpers.exportAll(_audioBufferSourceOptions, exports);
var _audioContext = require("./audio-context");
parcelHelpers.exportAll(_audioContext, exports);
var _audioContextOptions = require("./audio-context-options");
parcelHelpers.exportAll(_audioContextOptions, exports);
var _audioDestinationNode = require("./audio-destination-node");
parcelHelpers.exportAll(_audioDestinationNode, exports);
var _audioListener = require("./audio-listener");
parcelHelpers.exportAll(_audioListener, exports);
var _audioNode = require("./audio-node");
parcelHelpers.exportAll(_audioNode, exports);
var _audioNodeOptions = require("./audio-node-options");
parcelHelpers.exportAll(_audioNodeOptions, exports);
var _audioNodeRenderer = require("./audio-node-renderer");
parcelHelpers.exportAll(_audioNodeRenderer, exports);
var _audioParam = require("./audio-param");
parcelHelpers.exportAll(_audioParam, exports);
var _audioParamDescriptor = require("./audio-param-descriptor");
parcelHelpers.exportAll(_audioParamDescriptor, exports);
var _audioParamRenderer = require("./audio-param-renderer");
parcelHelpers.exportAll(_audioParamRenderer, exports);
var _audioScheduledSourceNode = require("./audio-scheduled-source-node");
parcelHelpers.exportAll(_audioScheduledSourceNode, exports);
var _audioScheduledSourceNodeEventMap = require("./audio-scheduled-source-node-event-map");
parcelHelpers.exportAll(_audioScheduledSourceNodeEventMap, exports);
var _audioWorklet = require("./audio-worklet");
parcelHelpers.exportAll(_audioWorklet, exports);
var _audioWorkletNode = require("./audio-worklet-node");
parcelHelpers.exportAll(_audioWorkletNode, exports);
var _audioWorkletNodeEventMap = require("./audio-worklet-node-event-map");
parcelHelpers.exportAll(_audioWorkletNodeEventMap, exports);
var _audioWorkletNodeOptions = require("./audio-worklet-node-options");
parcelHelpers.exportAll(_audioWorkletNodeOptions, exports);
var _audioWorkletProcessor = require("./audio-worklet-processor");
parcelHelpers.exportAll(_audioWorkletProcessor, exports);
var _audioWorkletProcessorConstructor = require("./audio-worklet-processor-constructor");
parcelHelpers.exportAll(_audioWorkletProcessorConstructor, exports);
var _automation = require("./automation");
parcelHelpers.exportAll(_automation, exports);
var _baseAudioContext = require("./base-audio-context");
parcelHelpers.exportAll(_baseAudioContext, exports);
var _biquadFilterNode = require("./biquad-filter-node");
parcelHelpers.exportAll(_biquadFilterNode, exports);
var _biquadFilterOptions = require("./biquad-filter-options");
parcelHelpers.exportAll(_biquadFilterOptions, exports);
var _channelMergerOptions = require("./channel-merger-options");
parcelHelpers.exportAll(_channelMergerOptions, exports);
var _channelSplitterOptions = require("./channel-splitter-options");
parcelHelpers.exportAll(_channelSplitterOptions, exports);
var _commonAudioContext = require("./common-audio-context");
parcelHelpers.exportAll(_commonAudioContext, exports);
var _commonOfflineAudioContext = require("./common-offline-audio-context");
parcelHelpers.exportAll(_commonOfflineAudioContext, exports);
var _constantSourceNode = require("./constant-source-node");
parcelHelpers.exportAll(_constantSourceNode, exports);
var _constantSourceNodeRenderer = require("./constant-source-node-renderer");
parcelHelpers.exportAll(_constantSourceNodeRenderer, exports);
var _constantSourceOptions = require("./constant-source-options");
parcelHelpers.exportAll(_constantSourceOptions, exports);
var _convolverNode = require("./convolver-node");
parcelHelpers.exportAll(_convolverNode, exports);
var _convolverOptions = require("./convolver-options");
parcelHelpers.exportAll(_convolverOptions, exports);
var _delayNode = require("./delay-node");
parcelHelpers.exportAll(_delayNode, exports);
var _delayOptions = require("./delay-options");
parcelHelpers.exportAll(_delayOptions, exports);
var _dynamicsCompressorNode = require("./dynamics-compressor-node");
parcelHelpers.exportAll(_dynamicsCompressorNode, exports);
var _dynamicsCompressorOptions = require("./dynamics-compressor-options");
parcelHelpers.exportAll(_dynamicsCompressorOptions, exports);
var _eventTarget = require("./event-target");
parcelHelpers.exportAll(_eventTarget, exports);
var _gainNode = require("./gain-node");
parcelHelpers.exportAll(_gainNode, exports);
var _gainOptions = require("./gain-options");
parcelHelpers.exportAll(_gainOptions, exports);
var _iirFilterNode = require("./iir-filter-node");
parcelHelpers.exportAll(_iirFilterNode, exports);
var _iirFilterOptions = require("./iir-filter-options");
parcelHelpers.exportAll(_iirFilterOptions, exports);
var _mediaElementAudioSourceNode = require("./media-element-audio-source-node");
parcelHelpers.exportAll(_mediaElementAudioSourceNode, exports);
var _mediaElementAudioSourceOptions = require("./media-element-audio-source-options");
parcelHelpers.exportAll(_mediaElementAudioSourceOptions, exports);
var _mediaStreamAudioDestinationNode = require("./media-stream-audio-destination-node");
parcelHelpers.exportAll(_mediaStreamAudioDestinationNode, exports);
var _mediaStreamAudioSourceNode = require("./media-stream-audio-source-node");
parcelHelpers.exportAll(_mediaStreamAudioSourceNode, exports);
var _mediaStreamAudioSourceOptions = require("./media-stream-audio-source-options");
parcelHelpers.exportAll(_mediaStreamAudioSourceOptions, exports);
var _mediaStreamTrackAudioSourceNode = require("./media-stream-track-audio-source-node");
parcelHelpers.exportAll(_mediaStreamTrackAudioSourceNode, exports);
var _mediaStreamTrackAudioSourceOptions = require("./media-stream-track-audio-source-options");
parcelHelpers.exportAll(_mediaStreamTrackAudioSourceOptions, exports);
var _minimalAudioContext = require("./minimal-audio-context");
parcelHelpers.exportAll(_minimalAudioContext, exports);
var _minimalBaseAudioContext = require("./minimal-base-audio-context");
parcelHelpers.exportAll(_minimalBaseAudioContext, exports);
var _minimalBaseAudioContextEventMap = require("./minimal-base-audio-context-event-map");
parcelHelpers.exportAll(_minimalBaseAudioContextEventMap, exports);
var _minimalOfflineAudioContext = require("./minimal-offline-audio-context");
parcelHelpers.exportAll(_minimalOfflineAudioContext, exports);
var _nativeAudioNodeFaker = require("./native-audio-node-faker");
parcelHelpers.exportAll(_nativeAudioNodeFaker, exports);
var _nativeAudioWorkletNodeFaker = require("./native-audio-worklet-node-faker");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFaker, exports);
var _nativeConstantSourceNodeFaker = require("./native-constant-source-node-faker");
parcelHelpers.exportAll(_nativeConstantSourceNodeFaker, exports);
var _nativeConvolverNodeFaker = require("./native-convolver-node-faker");
parcelHelpers.exportAll(_nativeConvolverNodeFaker, exports);
var _nativeIirFilterNodeFaker = require("./native-iir-filter-node-faker");
parcelHelpers.exportAll(_nativeIirFilterNodeFaker, exports);
var _nativePannerNodeFaker = require("./native-panner-node-faker");
parcelHelpers.exportAll(_nativePannerNodeFaker, exports);
var _nativeStereoPannerNodeFaker = require("./native-stereo-panner-node-faker");
parcelHelpers.exportAll(_nativeStereoPannerNodeFaker, exports);
var _nativeWaveShaperNodeFaker = require("./native-wave-shaper-node-faker");
parcelHelpers.exportAll(_nativeWaveShaperNodeFaker, exports);
var _offlineAudioCompletionEvent = require("./offline-audio-completion-event");
parcelHelpers.exportAll(_offlineAudioCompletionEvent, exports);
var _offlineAudioContext = require("./offline-audio-context");
parcelHelpers.exportAll(_offlineAudioContext, exports);
var _offlineAudioContextConstructor = require("./offline-audio-context-constructor");
parcelHelpers.exportAll(_offlineAudioContextConstructor, exports);
var _offlineAudioContextOptions = require("./offline-audio-context-options");
parcelHelpers.exportAll(_offlineAudioContextOptions, exports);
var _oscillatorNode = require("./oscillator-node");
parcelHelpers.exportAll(_oscillatorNode, exports);
var _oscillatorNodeRenderer = require("./oscillator-node-renderer");
parcelHelpers.exportAll(_oscillatorNodeRenderer, exports);
var _oscillatorOptions = require("./oscillator-options");
parcelHelpers.exportAll(_oscillatorOptions, exports);
var _pannerNode = require("./panner-node");
parcelHelpers.exportAll(_pannerNode, exports);
var _pannerOptions = require("./panner-options");
parcelHelpers.exportAll(_pannerOptions, exports);
var _periodicWave = require("./periodic-wave");
parcelHelpers.exportAll(_periodicWave, exports);
var _periodicWaveConstraints = require("./periodic-wave-constraints");
parcelHelpers.exportAll(_periodicWaveConstraints, exports);
var _periodicWaveOptions = require("./periodic-wave-options");
parcelHelpers.exportAll(_periodicWaveOptions, exports);
var _readOnlyMap = require("./read-only-map");
parcelHelpers.exportAll(_readOnlyMap, exports);
var _stereoPannerNode = require("./stereo-panner-node");
parcelHelpers.exportAll(_stereoPannerNode, exports);
var _stereoPannerOptions = require("./stereo-panner-options");
parcelHelpers.exportAll(_stereoPannerOptions, exports);
var _waveShaperNode = require("./wave-shaper-node");
parcelHelpers.exportAll(_waveShaperNode, exports);
var _waveShaperOptions = require("./wave-shaper-options");
parcelHelpers.exportAll(_waveShaperOptions, exports);
var _workletOptions = require("./worklet-options");
parcelHelpers.exportAll(_workletOptions, exports);

},{"./analyser-node":"jEOnV","./analyser-options":"9I0N4","./audio-buffer":"hulU1","./audio-buffer-options":"dF6uE","./audio-buffer-source-node":"fGbFr","./audio-buffer-source-node-renderer":"bUCrf","./audio-buffer-source-options":"74Jek","./audio-context":"7ttQS","./audio-context-options":"9RajA","./audio-destination-node":"aji4r","./audio-listener":"9LBgH","./audio-node":"3v4eu","./audio-node-options":"d4Oc5","./audio-node-renderer":"55715","./audio-param":"hbntl","./audio-param-descriptor":"1CRfg","./audio-param-renderer":"38Eqw","./audio-scheduled-source-node":"faL63","./audio-scheduled-source-node-event-map":"8ZkbC","./audio-worklet":"2TsYZ","./audio-worklet-node":"eM0sz","./audio-worklet-node-event-map":"2rrqE","./audio-worklet-node-options":"e5goB","./audio-worklet-processor":"dcmuK","./audio-worklet-processor-constructor":"1q8pq","./automation":"fs7R6","./base-audio-context":"3cDH9","./biquad-filter-node":"9j0bm","./biquad-filter-options":"h0yeK","./channel-merger-options":"4SwaI","./channel-splitter-options":"eUrPL","./common-audio-context":"dutQQ","./common-offline-audio-context":"it6NJ","./constant-source-node":"b4iw0","./constant-source-node-renderer":"3IDIE","./constant-source-options":"jLZbh","./convolver-node":"11qXz","./convolver-options":"lDWCe","./delay-node":"ipxO0","./delay-options":"8yMAT","./dynamics-compressor-node":"ceLqx","./dynamics-compressor-options":"2we7I","./event-target":"g2pTT","./gain-node":"4N3PR","./gain-options":"45FfL","./iir-filter-node":"hDpOw","./iir-filter-options":"2Lfet","./media-element-audio-source-node":"7bruH","./media-element-audio-source-options":"2TRHB","./media-stream-audio-destination-node":"1mISo","./media-stream-audio-source-node":"lSwQv","./media-stream-audio-source-options":"ll0yf","./media-stream-track-audio-source-node":"lj7Xe","./media-stream-track-audio-source-options":"9dCVx","./minimal-audio-context":"59PJF","./minimal-base-audio-context":"1Kf74","./minimal-base-audio-context-event-map":"9RE4F","./minimal-offline-audio-context":"8gJy3","./native-audio-node-faker":"ko5pz","./native-audio-worklet-node-faker":"iGTOT","./native-constant-source-node-faker":"7EIq0","./native-convolver-node-faker":"c1AdF","./native-iir-filter-node-faker":"lOZHq","./native-panner-node-faker":"aboRB","./native-stereo-panner-node-faker":"kYTka","./native-wave-shaper-node-faker":"5952F","./offline-audio-completion-event":"wAgEj","./offline-audio-context":"ezK7W","./offline-audio-context-constructor":"kmKi2","./offline-audio-context-options":"0Jcwb","./oscillator-node":"6s1Fe","./oscillator-node-renderer":"giCvq","./oscillator-options":"e1qcR","./panner-node":"49MJU","./panner-options":"e49rt","./periodic-wave":"1CmzS","./periodic-wave-constraints":"egAWb","./periodic-wave-options":"ZIufZ","./read-only-map":"3f46X","./stereo-panner-node":"89zVE","./stereo-panner-options":"bZMY7","./wave-shaper-node":"js56o","./wave-shaper-options":"byuai","./worklet-options":"1etSH","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jEOnV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9I0N4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hulU1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dF6uE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fGbFr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bUCrf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"74Jek":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7ttQS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9RajA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aji4r":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9LBgH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3v4eu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d4Oc5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"55715":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hbntl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1CRfg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"38Eqw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"faL63":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8ZkbC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2TsYZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eM0sz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2rrqE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e5goB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dcmuK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1q8pq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fs7R6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3cDH9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9j0bm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"h0yeK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4SwaI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eUrPL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dutQQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"it6NJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b4iw0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3IDIE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jLZbh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"11qXz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lDWCe":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ipxO0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8yMAT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ceLqx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2we7I":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"g2pTT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4N3PR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"45FfL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hDpOw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2Lfet":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7bruH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2TRHB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1mISo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lSwQv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ll0yf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lj7Xe":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9dCVx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"59PJF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1Kf74":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9RE4F":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8gJy3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ko5pz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iGTOT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7EIq0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"c1AdF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lOZHq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aboRB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kYTka":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5952F":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"wAgEj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ezK7W":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kmKi2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"0Jcwb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6s1Fe":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"giCvq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e1qcR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"49MJU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e49rt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1CmzS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"egAWb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ZIufZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3f46X":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"89zVE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bZMY7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"js56o":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"byuai":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1etSH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2sOgk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _abortErrorFactory = require("./abort-error-factory");
parcelHelpers.exportAll(_abortErrorFactory, exports);
var _activeAudioWorkletNodeInputsStore = require("./active-audio-worklet-node-inputs-store");
parcelHelpers.exportAll(_activeAudioWorkletNodeInputsStore, exports);
var _activeInputConnection = require("./active-input-connection");
parcelHelpers.exportAll(_activeInputConnection, exports);
var _addActiveInputConnectionToAudioNodeFactory = require("./add-active-input-connection-to-audio-node-factory");
parcelHelpers.exportAll(_addActiveInputConnectionToAudioNodeFactory, exports);
var _addActiveInputConnectionToAudioNodeFunction = require("./add-active-input-connection-to-audio-node-function");
parcelHelpers.exportAll(_addActiveInputConnectionToAudioNodeFunction, exports);
var _addAudioNodeConnectionsFactory = require("./add-audio-node-connections-factory");
parcelHelpers.exportAll(_addAudioNodeConnectionsFactory, exports);
var _addAudioNodeConnectionsFunction = require("./add-audio-node-connections-function");
parcelHelpers.exportAll(_addAudioNodeConnectionsFunction, exports);
var _addAudioParamConnectionsFactory = require("./add-audio-param-connections-factory");
parcelHelpers.exportAll(_addAudioParamConnectionsFactory, exports);
var _addAudioParamConnectionsFunction = require("./add-audio-param-connections-function");
parcelHelpers.exportAll(_addAudioParamConnectionsFunction, exports);
var _addAudioWorkletModuleFactory = require("./add-audio-worklet-module-factory");
parcelHelpers.exportAll(_addAudioWorkletModuleFactory, exports);
var _addAudioWorkletModuleFunction = require("./add-audio-worklet-module-function");
parcelHelpers.exportAll(_addAudioWorkletModuleFunction, exports);
var _addConnectionToAudioNodeFactory = require("./add-connection-to-audio-node-factory");
parcelHelpers.exportAll(_addConnectionToAudioNodeFactory, exports);
var _addConnectionToAudioNodeFunction = require("./add-connection-to-audio-node-function");
parcelHelpers.exportAll(_addConnectionToAudioNodeFunction, exports);
var _addPassiveInputConnectionToAudioNodeFactory = require("./add-passive-input-connection-to-audio-node-factory");
parcelHelpers.exportAll(_addPassiveInputConnectionToAudioNodeFactory, exports);
var _addPassiveInputConnectionToAudioNodeFunction = require("./add-passive-input-connection-to-audio-node-function");
parcelHelpers.exportAll(_addPassiveInputConnectionToAudioNodeFunction, exports);
var _addSilentConnectionFactory = require("./add-silent-connection-factory");
parcelHelpers.exportAll(_addSilentConnectionFactory, exports);
var _addSilentConnectionFunction = require("./add-silent-connection-function");
parcelHelpers.exportAll(_addSilentConnectionFunction, exports);
var _addUnrenderedAudioWorkletNodeFactory = require("./add-unrendered-audio-worklet-node-factory");
parcelHelpers.exportAll(_addUnrenderedAudioWorkletNodeFactory, exports);
var _addUnrenderedAudioWorkletNodeFunction = require("./add-unrendered-audio-worklet-node-function");
parcelHelpers.exportAll(_addUnrenderedAudioWorkletNodeFunction, exports);
var _analyserNodeConstructor = require("./analyser-node-constructor");
parcelHelpers.exportAll(_analyserNodeConstructor, exports);
var _analyserNodeConstructorFactory = require("./analyser-node-constructor-factory");
parcelHelpers.exportAll(_analyserNodeConstructorFactory, exports);
var _analyserNodeRendererFactory = require("./analyser-node-renderer-factory");
parcelHelpers.exportAll(_analyserNodeRendererFactory, exports);
var _analyserNodeRendererFactoryFactory = require("./analyser-node-renderer-factory-factory");
parcelHelpers.exportAll(_analyserNodeRendererFactoryFactory, exports);
var _anyAudioBuffer = require("./any-audio-buffer");
parcelHelpers.exportAll(_anyAudioBuffer, exports);
var _anyContext = require("./any-context");
parcelHelpers.exportAll(_anyContext, exports);
var _audioBufferConstructor = require("./audio-buffer-constructor");
parcelHelpers.exportAll(_audioBufferConstructor, exports);
var _audioBufferConstructorFactory = require("./audio-buffer-constructor-factory");
parcelHelpers.exportAll(_audioBufferConstructorFactory, exports);
var _audioBufferSourceNodeConstructor = require("./audio-buffer-source-node-constructor");
parcelHelpers.exportAll(_audioBufferSourceNodeConstructor, exports);
var _audioBufferSourceNodeConstructorFactory = require("./audio-buffer-source-node-constructor-factory");
parcelHelpers.exportAll(_audioBufferSourceNodeConstructorFactory, exports);
var _audioBufferSourceNodeRenderer = require("./audio-buffer-source-node-renderer");
parcelHelpers.exportAll(_audioBufferSourceNodeRenderer, exports);
var _audioBufferSourceNodeRendererFactory = require("./audio-buffer-source-node-renderer-factory");
parcelHelpers.exportAll(_audioBufferSourceNodeRendererFactory, exports);
var _audioBufferSourceNodeRendererFactoryFactory = require("./audio-buffer-source-node-renderer-factory-factory");
parcelHelpers.exportAll(_audioBufferSourceNodeRendererFactoryFactory, exports);
var _audioBufferStore = require("./audio-buffer-store");
parcelHelpers.exportAll(_audioBufferStore, exports);
var _audioContextConstructor = require("./audio-context-constructor");
parcelHelpers.exportAll(_audioContextConstructor, exports);
var _audioContextConstructorFactory = require("./audio-context-constructor-factory");
parcelHelpers.exportAll(_audioContextConstructorFactory, exports);
var _audioContextLatencyCategory = require("./audio-context-latency-category");
parcelHelpers.exportAll(_audioContextLatencyCategory, exports);
var _audioContextState = require("./audio-context-state");
parcelHelpers.exportAll(_audioContextState, exports);
var _audioDestinationNodeConstructor = require("./audio-destination-node-constructor");
parcelHelpers.exportAll(_audioDestinationNodeConstructor, exports);
var _audioDestinationNodeConstructorFactory = require("./audio-destination-node-constructor-factory");
parcelHelpers.exportAll(_audioDestinationNodeConstructorFactory, exports);
var _audioDestinationNodeRendererFactory = require("./audio-destination-node-renderer-factory");
parcelHelpers.exportAll(_audioDestinationNodeRendererFactory, exports);
var _audioListenerFactory = require("./audio-listener-factory");
parcelHelpers.exportAll(_audioListenerFactory, exports);
var _audioListenerFactoryFactory = require("./audio-listener-factory-factory");
parcelHelpers.exportAll(_audioListenerFactoryFactory, exports);
var _audioNodeConnections = require("./audio-node-connections");
parcelHelpers.exportAll(_audioNodeConnections, exports);
var _audioNodeConnectionsStore = require("./audio-node-connections-store");
parcelHelpers.exportAll(_audioNodeConnectionsStore, exports);
var _audioNodeConstructor = require("./audio-node-constructor");
parcelHelpers.exportAll(_audioNodeConstructor, exports);
var _audioNodeConstructorFactory = require("./audio-node-constructor-factory");
parcelHelpers.exportAll(_audioNodeConstructorFactory, exports);
var _audioNodeOutputConnection = require("./audio-node-output-connection");
parcelHelpers.exportAll(_audioNodeOutputConnection, exports);
var _audioNodeRenderer = require("./audio-node-renderer");
parcelHelpers.exportAll(_audioNodeRenderer, exports);
var _audioNodeStore = require("./audio-node-store");
parcelHelpers.exportAll(_audioNodeStore, exports);
var _audioNodeTailTimeStore = require("./audio-node-tail-time-store");
parcelHelpers.exportAll(_audioNodeTailTimeStore, exports);
var _audioParamAudioNodeStore = require("./audio-param-audio-node-store");
parcelHelpers.exportAll(_audioParamAudioNodeStore, exports);
var _audioParamConnections = require("./audio-param-connections");
parcelHelpers.exportAll(_audioParamConnections, exports);
var _audioParamConnectionsStore = require("./audio-param-connections-store");
parcelHelpers.exportAll(_audioParamConnectionsStore, exports);
var _audioParamFactory = require("./audio-param-factory");
parcelHelpers.exportAll(_audioParamFactory, exports);
var _audioParamFactoryFactory = require("./audio-param-factory-factory");
parcelHelpers.exportAll(_audioParamFactoryFactory, exports);
var _audioParamMap = require("./audio-param-map");
parcelHelpers.exportAll(_audioParamMap, exports);
var _audioParamOutputConnection = require("./audio-param-output-connection");
parcelHelpers.exportAll(_audioParamOutputConnection, exports);
var _audioParamRendererFactory = require("./audio-param-renderer-factory");
parcelHelpers.exportAll(_audioParamRendererFactory, exports);
var _audioParamStore = require("./audio-param-store");
parcelHelpers.exportAll(_audioParamStore, exports);
var _audioWorkletNodeConstructor = require("./audio-worklet-node-constructor");
parcelHelpers.exportAll(_audioWorkletNodeConstructor, exports);
var _audioWorkletNodeConstructorFactory = require("./audio-worklet-node-constructor-factory");
parcelHelpers.exportAll(_audioWorkletNodeConstructorFactory, exports);
var _audioWorkletNodeRendererFactory = require("./audio-worklet-node-renderer-factory");
parcelHelpers.exportAll(_audioWorkletNodeRendererFactory, exports);
var _audioWorkletNodeRendererFactoryFactory = require("./audio-worklet-node-renderer-factory-factory");
parcelHelpers.exportAll(_audioWorkletNodeRendererFactoryFactory, exports);
var _backupOfflineAudioContextStore = require("./backup-offline-audio-context-store");
parcelHelpers.exportAll(_backupOfflineAudioContextStore, exports);
var _baseAudioContextConstructor = require("./base-audio-context-constructor");
parcelHelpers.exportAll(_baseAudioContextConstructor, exports);
var _baseAudioContextConstructorFactory = require("./base-audio-context-constructor-factory");
parcelHelpers.exportAll(_baseAudioContextConstructorFactory, exports);
var _biquadFilterNodeConstructor = require("./biquad-filter-node-constructor");
parcelHelpers.exportAll(_biquadFilterNodeConstructor, exports);
var _biquadFilterNodeConstructorFactory = require("./biquad-filter-node-constructor-factory");
parcelHelpers.exportAll(_biquadFilterNodeConstructorFactory, exports);
var _biquadFilterNodeRendererFactory = require("./biquad-filter-node-renderer-factory");
parcelHelpers.exportAll(_biquadFilterNodeRendererFactory, exports);
var _biquadFilterNodeRendererFactoryFactory = require("./biquad-filter-node-renderer-factory-factory");
parcelHelpers.exportAll(_biquadFilterNodeRendererFactoryFactory, exports);
var _biquadFilterType = require("./biquad-filter-type");
parcelHelpers.exportAll(_biquadFilterType, exports);
var _channelCountMode = require("./channel-count-mode");
parcelHelpers.exportAll(_channelCountMode, exports);
var _channelInterpretation = require("./channel-interpretation");
parcelHelpers.exportAll(_channelInterpretation, exports);
var _channelMergerNodeConstructor = require("./channel-merger-node-constructor");
parcelHelpers.exportAll(_channelMergerNodeConstructor, exports);
var _channelMergerNodeConstructorFactory = require("./channel-merger-node-constructor-factory");
parcelHelpers.exportAll(_channelMergerNodeConstructorFactory, exports);
var _channelMergerNodeRendererFactory = require("./channel-merger-node-renderer-factory");
parcelHelpers.exportAll(_channelMergerNodeRendererFactory, exports);
var _channelMergerNodeRendererFactoryFactory = require("./channel-merger-node-renderer-factory-factory");
parcelHelpers.exportAll(_channelMergerNodeRendererFactoryFactory, exports);
var _channelSplitterNodeConstructor = require("./channel-splitter-node-constructor");
parcelHelpers.exportAll(_channelSplitterNodeConstructor, exports);
var _channelSplitterNodeConstructorFactory = require("./channel-splitter-node-constructor-factory");
parcelHelpers.exportAll(_channelSplitterNodeConstructorFactory, exports);
var _channelSplitterNodeRendererFactory = require("./channel-splitter-node-renderer-factory");
parcelHelpers.exportAll(_channelSplitterNodeRendererFactory, exports);
var _channelSplitterNodeRendererFactoryFactory = require("./channel-splitter-node-renderer-factory-factory");
parcelHelpers.exportAll(_channelSplitterNodeRendererFactoryFactory, exports);
var _cacheTestResultFactory = require("./cache-test-result-factory");
parcelHelpers.exportAll(_cacheTestResultFactory, exports);
var _cacheTestResultFunction = require("./cache-test-result-function");
parcelHelpers.exportAll(_cacheTestResultFunction, exports);
var _connectAudioParamFactory = require("./connect-audio-param-factory");
parcelHelpers.exportAll(_connectAudioParamFactory, exports);
var _connectAudioParamFunction = require("./connect-audio-param-function");
parcelHelpers.exportAll(_connectAudioParamFunction, exports);
var _connectMultipleOutputsFactory = require("./connect-multiple-outputs-factory");
parcelHelpers.exportAll(_connectMultipleOutputsFactory, exports);
var _connectMultipleOutputsFunction = require("./connect-multiple-outputs-function");
parcelHelpers.exportAll(_connectMultipleOutputsFunction, exports);
var _connectNativeAudioNodeToNativeAudioNodeFunction = require("./connect-native-audio-node-to-native-audio-node-function");
parcelHelpers.exportAll(_connectNativeAudioNodeToNativeAudioNodeFunction, exports);
var _connectedNativeAudioBufferSourceNodeFactory = require("./connected-native-audio-buffer-source-node-factory");
parcelHelpers.exportAll(_connectedNativeAudioBufferSourceNodeFactory, exports);
var _connectedNativeAudioBufferSourceNodeFactoryFactory = require("./connected-native-audio-buffer-source-node-factory-factory");
parcelHelpers.exportAll(_connectedNativeAudioBufferSourceNodeFactoryFactory, exports);
var _constantSourceNodeConstructor = require("./constant-source-node-constructor");
parcelHelpers.exportAll(_constantSourceNodeConstructor, exports);
var _constantSourceNodeConstructorFactory = require("./constant-source-node-constructor-factory");
parcelHelpers.exportAll(_constantSourceNodeConstructorFactory, exports);
var _constantSourceNodeRenderer = require("./constant-source-node-renderer");
parcelHelpers.exportAll(_constantSourceNodeRenderer, exports);
var _constantSourceNodeRendererFactory = require("./constant-source-node-renderer-factory");
parcelHelpers.exportAll(_constantSourceNodeRendererFactory, exports);
var _constantSourceNodeRendererFactoryFactory = require("./constant-source-node-renderer-factory-factory");
parcelHelpers.exportAll(_constantSourceNodeRendererFactoryFactory, exports);
var _constructor = require("./constructor");
parcelHelpers.exportAll(_constructor, exports);
var _context = require("./context");
parcelHelpers.exportAll(_context, exports);
var _contextStore = require("./context-store");
parcelHelpers.exportAll(_contextStore, exports);
var _convertNumberToUnsignedLongFactory = require("./convert-number-to-unsigned-long-factory");
parcelHelpers.exportAll(_convertNumberToUnsignedLongFactory, exports);
var _convertNumberToUnsignedLongFunction = require("./convert-number-to-unsigned-long-function");
parcelHelpers.exportAll(_convertNumberToUnsignedLongFunction, exports);
var _convolverNodeConstructor = require("./convolver-node-constructor");
parcelHelpers.exportAll(_convolverNodeConstructor, exports);
var _convolverNodeConstructorFactory = require("./convolver-node-constructor-factory");
parcelHelpers.exportAll(_convolverNodeConstructorFactory, exports);
var _convolverNodeRendererFactory = require("./convolver-node-renderer-factory");
parcelHelpers.exportAll(_convolverNodeRendererFactory, exports);
var _convolverNodeRendererFactoryFactory = require("./convolver-node-renderer-factory-factory");
parcelHelpers.exportAll(_convolverNodeRendererFactoryFactory, exports);
var _createNativeOfflineAudioContextFactory = require("./create-native-offline-audio-context-factory");
parcelHelpers.exportAll(_createNativeOfflineAudioContextFactory, exports);
var _createNativeOfflineAudioContextFunction = require("./create-native-offline-audio-context-function");
parcelHelpers.exportAll(_createNativeOfflineAudioContextFunction, exports);
var _cycleCounters = require("./cycle-counters");
parcelHelpers.exportAll(_cycleCounters, exports);
var _dataCloneErrorFactory = require("./data-clone-error-factory");
parcelHelpers.exportAll(_dataCloneErrorFactory, exports);
var _decodeAudioDataFactory = require("./decode-audio-data-factory");
parcelHelpers.exportAll(_decodeAudioDataFactory, exports);
var _decodeAudioDataFunction = require("./decode-audio-data-function");
parcelHelpers.exportAll(_decodeAudioDataFunction, exports);
var _decodeErrorCallback = require("./decode-error-callback");
parcelHelpers.exportAll(_decodeErrorCallback, exports);
var _decodeSuccessCallback = require("./decode-success-callback");
parcelHelpers.exportAll(_decodeSuccessCallback, exports);
var _decrementCycleCounterFactory = require("./decrement-cycle-counter-factory");
parcelHelpers.exportAll(_decrementCycleCounterFactory, exports);
var _decrementCycleCounterFunction = require("./decrement-cycle-counter-function");
parcelHelpers.exportAll(_decrementCycleCounterFunction, exports);
var _delayNodeConstructor = require("./delay-node-constructor");
parcelHelpers.exportAll(_delayNodeConstructor, exports);
var _delayNodeConstructorFactory = require("./delay-node-constructor-factory");
parcelHelpers.exportAll(_delayNodeConstructorFactory, exports);
var _delayNodeRendererFactory = require("./delay-node-renderer-factory");
parcelHelpers.exportAll(_delayNodeRendererFactory, exports);
var _delayNodeRendererFactoryFactory = require("./delay-node-renderer-factory-factory");
parcelHelpers.exportAll(_delayNodeRendererFactoryFactory, exports);
var _deleteActiveInputConnectionToAudioNodeFactory = require("./delete-active-input-connection-to-audio-node-factory");
parcelHelpers.exportAll(_deleteActiveInputConnectionToAudioNodeFactory, exports);
var _deleteActiveInputConnectionToAudioNodeFunction = require("./delete-active-input-connection-to-audio-node-function");
parcelHelpers.exportAll(_deleteActiveInputConnectionToAudioNodeFunction, exports);
var _deleteUnrenderedAudioWorkletNodeFactory = require("./delete-unrendered-audio-worklet-node-factory");
parcelHelpers.exportAll(_deleteUnrenderedAudioWorkletNodeFactory, exports);
var _deleteUnrenderedAudioWorkletNodeFunction = require("./delete-unrendered-audio-worklet-node-function");
parcelHelpers.exportAll(_deleteUnrenderedAudioWorkletNodeFunction, exports);
var _detectCyclesFactory = require("./detect-cycles-factory");
parcelHelpers.exportAll(_detectCyclesFactory, exports);
var _detectCyclesFunction = require("./detect-cycles-function");
parcelHelpers.exportAll(_detectCyclesFunction, exports);
var _disconnectMultipleOutputsFactory = require("./disconnect-multiple-outputs-factory");
parcelHelpers.exportAll(_disconnectMultipleOutputsFactory, exports);
var _disconnectMultipleOutputsFunction = require("./disconnect-multiple-outputs-function");
parcelHelpers.exportAll(_disconnectMultipleOutputsFunction, exports);
var _disconnectNativeAudioNodeFromNativeAudioNodeFunction = require("./disconnect-native-audio-node-from-native-audio-node-function");
parcelHelpers.exportAll(_disconnectNativeAudioNodeFromNativeAudioNodeFunction, exports);
var _distanceModelType = require("./distance-model-type");
parcelHelpers.exportAll(_distanceModelType, exports);
var _dynamicsCompressorNodeConstructor = require("./dynamics-compressor-node-constructor");
parcelHelpers.exportAll(_dynamicsCompressorNodeConstructor, exports);
var _dynamicsCompressorNodeConstructorFactory = require("./dynamics-compressor-node-constructor-factory");
parcelHelpers.exportAll(_dynamicsCompressorNodeConstructorFactory, exports);
var _dynamicsCompressorNodeRendererFactory = require("./dynamics-compressor-node-renderer-factory");
parcelHelpers.exportAll(_dynamicsCompressorNodeRendererFactory, exports);
var _dynamicsCompressorNodeRendererFactoryFactory = require("./dynamics-compressor-node-renderer-factory-factory");
parcelHelpers.exportAll(_dynamicsCompressorNodeRendererFactoryFactory, exports);
var _encodingErrorFactory = require("./encoding-error-factory");
parcelHelpers.exportAll(_encodingErrorFactory, exports);
var _errorEventHandler = require("./error-event-handler");
parcelHelpers.exportAll(_errorEventHandler, exports);
var _evaluateAudioWorkletGlobalScopeFunction = require("./evaluate-audio-worklet-global-scope-function");
parcelHelpers.exportAll(_evaluateAudioWorkletGlobalScopeFunction, exports);
var _evaluateSourceFactory = require("./evaluate-source-factory");
parcelHelpers.exportAll(_evaluateSourceFactory, exports);
var _evaluateSourceFunction = require("./evaluate-source-function");
parcelHelpers.exportAll(_evaluateSourceFunction, exports);
var _eventHandler = require("./event-handler");
parcelHelpers.exportAll(_eventHandler, exports);
var _eventTargetConstructor = require("./event-target-constructor");
parcelHelpers.exportAll(_eventTargetConstructor, exports);
var _eventTargetConstructorFactory = require("./event-target-constructor-factory");
parcelHelpers.exportAll(_eventTargetConstructorFactory, exports);
var _exposeCurrentFrameAndCurrentTimeFactory = require("./expose-current-frame-and-current-time-factory");
parcelHelpers.exportAll(_exposeCurrentFrameAndCurrentTimeFactory, exports);
var _exposeCurrentFrameAndCurrentTimeFunction = require("./expose-current-frame-and-current-time-function");
parcelHelpers.exportAll(_exposeCurrentFrameAndCurrentTimeFunction, exports);
var _fetchSourceFactory = require("./fetch-source-factory");
parcelHelpers.exportAll(_fetchSourceFactory, exports);
var _fetchSourceFunction = require("./fetch-source-function");
parcelHelpers.exportAll(_fetchSourceFunction, exports);
var _gainNodeConstructor = require("./gain-node-constructor");
parcelHelpers.exportAll(_gainNodeConstructor, exports);
var _gainNodeConstructorFactory = require("./gain-node-constructor-factory");
parcelHelpers.exportAll(_gainNodeConstructorFactory, exports);
var _gainNodeRendererFactory = require("./gain-node-renderer-factory");
parcelHelpers.exportAll(_gainNodeRendererFactory, exports);
var _gainNodeRendererFactoryFactory = require("./gain-node-renderer-factory-factory");
parcelHelpers.exportAll(_gainNodeRendererFactoryFactory, exports);
var _getActiveAudioWorkletNodeInputsFactory = require("./get-active-audio-worklet-node-inputs-factory");
parcelHelpers.exportAll(_getActiveAudioWorkletNodeInputsFactory, exports);
var _getActiveAudioWorkletNodeInputsFunction = require("./get-active-audio-worklet-node-inputs-function");
parcelHelpers.exportAll(_getActiveAudioWorkletNodeInputsFunction, exports);
var _getAudioNodeConnectionsFunction = require("./get-audio-node-connections-function");
parcelHelpers.exportAll(_getAudioNodeConnectionsFunction, exports);
var _getAudioNodeRendererFactory = require("./get-audio-node-renderer-factory");
parcelHelpers.exportAll(_getAudioNodeRendererFactory, exports);
var _getAudioNodeRendererFunction = require("./get-audio-node-renderer-function");
parcelHelpers.exportAll(_getAudioNodeRendererFunction, exports);
var _getAudioNodeTailTimeFactory = require("./get-audio-node-tail-time-factory");
parcelHelpers.exportAll(_getAudioNodeTailTimeFactory, exports);
var _getAudioNodeTailTimeFunction = require("./get-audio-node-tail-time-function");
parcelHelpers.exportAll(_getAudioNodeTailTimeFunction, exports);
var _getAudioParamConnectionsFunction = require("./get-audio-param-connections-function");
parcelHelpers.exportAll(_getAudioParamConnectionsFunction, exports);
var _getAudioParamRendererFactory = require("./get-audio-param-renderer-factory");
parcelHelpers.exportAll(_getAudioParamRendererFactory, exports);
var _getAudioParamRendererFunction = require("./get-audio-param-renderer-function");
parcelHelpers.exportAll(_getAudioParamRendererFunction, exports);
var _getBackupOfflineAudioContextFactory = require("./get-backup-offline-audio-context-factory");
parcelHelpers.exportAll(_getBackupOfflineAudioContextFactory, exports);
var _getBackupOfflineAudioContextFunction = require("./get-backup-offline-audio-context-function");
parcelHelpers.exportAll(_getBackupOfflineAudioContextFunction, exports);
var _getEventListenersOfAudioNodeFunction = require("./get-event-listeners-of-audio-node-function");
parcelHelpers.exportAll(_getEventListenersOfAudioNodeFunction, exports);
var _getFirstSampleFunction = require("./get-first-sample-function");
parcelHelpers.exportAll(_getFirstSampleFunction, exports);
var _getNativeAudioNodeFunction = require("./get-native-audio-node-function");
parcelHelpers.exportAll(_getNativeAudioNodeFunction, exports);
var _getNativeAudioParamFunction = require("./get-native-audio-param-function");
parcelHelpers.exportAll(_getNativeAudioParamFunction, exports);
var _getNativeContextFactory = require("./get-native-context-factory");
parcelHelpers.exportAll(_getNativeContextFactory, exports);
var _getNativeContextFunction = require("./get-native-context-function");
parcelHelpers.exportAll(_getNativeContextFunction, exports);
var _getOrCreateBackupOfflineAudioContextFactory = require("./get-or-create-backup-offline-audio-context-factory");
parcelHelpers.exportAll(_getOrCreateBackupOfflineAudioContextFactory, exports);
var _getOrCreateBackupOfflineAudioContextFunction = require("./get-or-create-backup-offline-audio-context-function");
parcelHelpers.exportAll(_getOrCreateBackupOfflineAudioContextFunction, exports);
var _getUnrenderedAudioWorkletNodesFactory = require("./get-unrendered-audio-worklet-nodes-factory");
parcelHelpers.exportAll(_getUnrenderedAudioWorkletNodesFactory, exports);
var _getUnrenderedAudioWorkletNodesFunction = require("./get-unrendered-audio-worklet-nodes-function");
parcelHelpers.exportAll(_getUnrenderedAudioWorkletNodesFunction, exports);
var _getValueForKeyFunction = require("./get-value-for-key-function");
parcelHelpers.exportAll(_getValueForKeyFunction, exports);
var _iirFilterNodeConstructor = require("./iir-filter-node-constructor");
parcelHelpers.exportAll(_iirFilterNodeConstructor, exports);
var _iirFilterNodeConstructorFactory = require("./iir-filter-node-constructor-factory");
parcelHelpers.exportAll(_iirFilterNodeConstructorFactory, exports);
var _iirFilterNodeRendererFactory = require("./iir-filter-node-renderer-factory");
parcelHelpers.exportAll(_iirFilterNodeRendererFactory, exports);
var _iirFilterNodeRendererFactoryFactory = require("./iir-filter-node-renderer-factory-factory");
parcelHelpers.exportAll(_iirFilterNodeRendererFactoryFactory, exports);
var _incrementCycleCounterFactory = require("./increment-cycle-counter-factory");
parcelHelpers.exportAll(_incrementCycleCounterFactory, exports);
var _incrementCycleCounterFactoryFactory = require("./increment-cycle-counter-factory-factory");
parcelHelpers.exportAll(_incrementCycleCounterFactoryFactory, exports);
var _incrementCycleCounterFunction = require("./increment-cycle-counter-function");
parcelHelpers.exportAll(_incrementCycleCounterFunction, exports);
var _indexSizeErrorFactory = require("./index-size-error-factory");
parcelHelpers.exportAll(_indexSizeErrorFactory, exports);
var _insertElementInSetFunction = require("./insert-element-in-set-function");
parcelHelpers.exportAll(_insertElementInSetFunction, exports);
var _internalStateEventListener = require("./internal-state-event-listener");
parcelHelpers.exportAll(_internalStateEventListener, exports);
var _invalidAccessErrorFactory = require("./invalid-access-error-factory");
parcelHelpers.exportAll(_invalidAccessErrorFactory, exports);
var _invalidStateErrorFactory = require("./invalid-state-error-factory");
parcelHelpers.exportAll(_invalidStateErrorFactory, exports);
var _isActiveAudioNodeFunction = require("./is-active-audio-node-function");
parcelHelpers.exportAll(_isActiveAudioNodeFunction, exports);
var _isAnyAudioContextFactory = require("./is-any-audio-context-factory");
parcelHelpers.exportAll(_isAnyAudioContextFactory, exports);
var _isAnyAudioContextFunction = require("./is-any-audio-context-function");
parcelHelpers.exportAll(_isAnyAudioContextFunction, exports);
var _isAnyAudioNodeFactory = require("./is-any-audio-node-factory");
parcelHelpers.exportAll(_isAnyAudioNodeFactory, exports);
var _isAnyAudioNodeFunction = require("./is-any-audio-node-function");
parcelHelpers.exportAll(_isAnyAudioNodeFunction, exports);
var _isAnyAudioParamFactory = require("./is-any-audio-param-factory");
parcelHelpers.exportAll(_isAnyAudioParamFactory, exports);
var _isAnyAudioParamFunction = require("./is-any-audio-param-function");
parcelHelpers.exportAll(_isAnyAudioParamFunction, exports);
var _isAnyOfflineAudioContextFactory = require("./is-any-offline-audio-context-factory");
parcelHelpers.exportAll(_isAnyOfflineAudioContextFactory, exports);
var _isAnyOfflineAudioContextFunction = require("./is-any-offline-audio-context-function");
parcelHelpers.exportAll(_isAnyOfflineAudioContextFunction, exports);
var _isDcCurveFunction = require("./is-dc-curve-function");
parcelHelpers.exportAll(_isDcCurveFunction, exports);
var _isNativeAudioContextFactory = require("./is-native-audio-context-factory");
parcelHelpers.exportAll(_isNativeAudioContextFactory, exports);
var _isNativeAudioContextFunction = require("./is-native-audio-context-function");
parcelHelpers.exportAll(_isNativeAudioContextFunction, exports);
var _isNativeAudioNodeFactory = require("./is-native-audio-node-factory");
parcelHelpers.exportAll(_isNativeAudioNodeFactory, exports);
var _isNativeAudioNodeFunction = require("./is-native-audio-node-function");
parcelHelpers.exportAll(_isNativeAudioNodeFunction, exports);
var _isNativeAudioParamFactory = require("./is-native-audio-param-factory");
parcelHelpers.exportAll(_isNativeAudioParamFactory, exports);
var _isNativeAudioParamFunction = require("./is-native-audio-param-function");
parcelHelpers.exportAll(_isNativeAudioParamFunction, exports);
var _isNativeContextFactory = require("./is-native-context-factory");
parcelHelpers.exportAll(_isNativeContextFactory, exports);
var _isNativeContextFunction = require("./is-native-context-function");
parcelHelpers.exportAll(_isNativeContextFunction, exports);
var _isNativeOfflineAudioContextFactory = require("./is-native-offline-audio-context-factory");
parcelHelpers.exportAll(_isNativeOfflineAudioContextFactory, exports);
var _isNativeOfflineAudioContextFunction = require("./is-native-offline-audio-context-function");
parcelHelpers.exportAll(_isNativeOfflineAudioContextFunction, exports);
var _isPartOfACycleFunction = require("./is-part-of-a-cycle-function");
parcelHelpers.exportAll(_isPartOfACycleFunction, exports);
var _isPassiveAudioNodeFunction = require("./is-passive-audio-node-function");
parcelHelpers.exportAll(_isPassiveAudioNodeFunction, exports);
var _isSecureContextFactory = require("./is-secure-context-factory");
parcelHelpers.exportAll(_isSecureContextFactory, exports);
var _isSupportedPromiseFactory = require("./is-supported-promise-factory");
parcelHelpers.exportAll(_isSupportedPromiseFactory, exports);
var _mediaElementAudioSourceNodeConstructor = require("./media-element-audio-source-node-constructor");
parcelHelpers.exportAll(_mediaElementAudioSourceNodeConstructor, exports);
var _mediaElementAudioSourceNodeConstructorFactory = require("./media-element-audio-source-node-constructor-factory");
parcelHelpers.exportAll(_mediaElementAudioSourceNodeConstructorFactory, exports);
var _mediaStreamAudioDestinationNodeConstructor = require("./media-stream-audio-destination-node-constructor");
parcelHelpers.exportAll(_mediaStreamAudioDestinationNodeConstructor, exports);
var _mediaStreamAudioDestinationNodeConstructorFactory = require("./media-stream-audio-destination-node-constructor-factory");
parcelHelpers.exportAll(_mediaStreamAudioDestinationNodeConstructorFactory, exports);
var _mediaStreamAudioSourceNodeConstructor = require("./media-stream-audio-source-node-constructor");
parcelHelpers.exportAll(_mediaStreamAudioSourceNodeConstructor, exports);
var _mediaStreamAudioSourceNodeConstructorFactory = require("./media-stream-audio-source-node-constructor-factory");
parcelHelpers.exportAll(_mediaStreamAudioSourceNodeConstructorFactory, exports);
var _mediaStreamTrackAudioSourceNodeConstructor = require("./media-stream-track-audio-source-node-constructor");
parcelHelpers.exportAll(_mediaStreamTrackAudioSourceNodeConstructor, exports);
var _mediaStreamTrackAudioSourceNodeConstructorFactory = require("./media-stream-track-audio-source-node-constructor-factory");
parcelHelpers.exportAll(_mediaStreamTrackAudioSourceNodeConstructorFactory, exports);
var _minimalAudioContextConstructor = require("./minimal-audio-context-constructor");
parcelHelpers.exportAll(_minimalAudioContextConstructor, exports);
var _minimalAudioContextConstructorFactory = require("./minimal-audio-context-constructor-factory");
parcelHelpers.exportAll(_minimalAudioContextConstructorFactory, exports);
var _minimalBaseAudioContextConstructor = require("./minimal-base-audio-context-constructor");
parcelHelpers.exportAll(_minimalBaseAudioContextConstructor, exports);
var _minimalBaseAudioContextConstructorFactory = require("./minimal-base-audio-context-constructor-factory");
parcelHelpers.exportAll(_minimalBaseAudioContextConstructorFactory, exports);
var _minimalOfflineAudioContextConstructor = require("./minimal-offline-audio-context-constructor");
parcelHelpers.exportAll(_minimalOfflineAudioContextConstructor, exports);
var _minimalOfflineAudioContextConstructorFactory = require("./minimal-offline-audio-context-constructor-factory");
parcelHelpers.exportAll(_minimalOfflineAudioContextConstructorFactory, exports);
var _monitorConnectionsFactory = require("./monitor-connections-factory");
parcelHelpers.exportAll(_monitorConnectionsFactory, exports);
var _monitorConnectionsFunction = require("./monitor-connections-function");
parcelHelpers.exportAll(_monitorConnectionsFunction, exports);
var _nativeAnalyserNode = require("./native-analyser-node");
parcelHelpers.exportAll(_nativeAnalyserNode, exports);
var _nativeAnalyserNodeFactory = require("./native-analyser-node-factory");
parcelHelpers.exportAll(_nativeAnalyserNodeFactory, exports);
var _nativeAnalyserNodeFactoryFactory = require("./native-analyser-node-factory-factory");
parcelHelpers.exportAll(_nativeAnalyserNodeFactoryFactory, exports);
var _nativeAudioBuffer = require("./native-audio-buffer");
parcelHelpers.exportAll(_nativeAudioBuffer, exports);
var _nativeAudioBufferConstructor = require("./native-audio-buffer-constructor");
parcelHelpers.exportAll(_nativeAudioBufferConstructor, exports);
var _nativeAudioBufferConstructorFactory = require("./native-audio-buffer-constructor-factory");
parcelHelpers.exportAll(_nativeAudioBufferConstructorFactory, exports);
var _nativeAudioBufferSourceNode = require("./native-audio-buffer-source-node");
parcelHelpers.exportAll(_nativeAudioBufferSourceNode, exports);
var _nativeAudioBufferSourceNodeFactory = require("./native-audio-buffer-source-node-factory");
parcelHelpers.exportAll(_nativeAudioBufferSourceNodeFactory, exports);
var _nativeAudioBufferSourceNodeFactoryFactory = require("./native-audio-buffer-source-node-factory-factory");
parcelHelpers.exportAll(_nativeAudioBufferSourceNodeFactoryFactory, exports);
var _nativeAudioContext = require("./native-audio-context");
parcelHelpers.exportAll(_nativeAudioContext, exports);
var _nativeAudioContextConstructor = require("./native-audio-context-constructor");
parcelHelpers.exportAll(_nativeAudioContextConstructor, exports);
var _nativeAudioContextConstructorFactory = require("./native-audio-context-constructor-factory");
parcelHelpers.exportAll(_nativeAudioContextConstructorFactory, exports);
var _nativeAudioDestinationNode = require("./native-audio-destination-node");
parcelHelpers.exportAll(_nativeAudioDestinationNode, exports);
var _nativeAudioDestinationNodeFactory = require("./native-audio-destination-node-factory");
parcelHelpers.exportAll(_nativeAudioDestinationNodeFactory, exports);
var _nativeAudioDestinationNodeFactoryFactory = require("./native-audio-destination-node-factory-factory");
parcelHelpers.exportAll(_nativeAudioDestinationNodeFactoryFactory, exports);
var _nativeAudioListener = require("./native-audio-listener");
parcelHelpers.exportAll(_nativeAudioListener, exports);
var _nativeAudioNode = require("./native-audio-node");
parcelHelpers.exportAll(_nativeAudioNode, exports);
var _nativeAudioParam = require("./native-audio-param");
parcelHelpers.exportAll(_nativeAudioParam, exports);
var _nativeAudioParamMap = require("./native-audio-param-map");
parcelHelpers.exportAll(_nativeAudioParamMap, exports);
var _nativeAudioWorklet = require("./native-audio-worklet");
parcelHelpers.exportAll(_nativeAudioWorklet, exports);
var _nativeAudioWorkletNode = require("./native-audio-worklet-node");
parcelHelpers.exportAll(_nativeAudioWorkletNode, exports);
var _nativeAudioWorkletNodeConstructor = require("./native-audio-worklet-node-constructor");
parcelHelpers.exportAll(_nativeAudioWorkletNodeConstructor, exports);
var _nativeAudioWorkletNodeConstructorFactory = require("./native-audio-worklet-node-constructor-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeConstructorFactory, exports);
var _nativeAudioWorkletNodeFactory = require("./native-audio-worklet-node-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFactory, exports);
var _nativeAudioWorkletNodeFactoryFactory = require("./native-audio-worklet-node-factory-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFactoryFactory, exports);
var _nativeAudioWorkletNodeFakerFactory = require("./native-audio-worklet-node-faker-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFakerFactory, exports);
var _nativeAudioWorkletNodeFakerFactoryFactory = require("./native-audio-worklet-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeAudioWorkletNodeFakerFactoryFactory, exports);
var _nativeAudioWorkletNodeOptions = require("./native-audio-worklet-node-options");
parcelHelpers.exportAll(_nativeAudioWorkletNodeOptions, exports);
var _nativeBiquadFilterNode = require("./native-biquad-filter-node");
parcelHelpers.exportAll(_nativeBiquadFilterNode, exports);
var _nativeBiquadFilterNodeFactory = require("./native-biquad-filter-node-factory");
parcelHelpers.exportAll(_nativeBiquadFilterNodeFactory, exports);
var _nativeChannelMergerNode = require("./native-channel-merger-node");
parcelHelpers.exportAll(_nativeChannelMergerNode, exports);
var _nativeChannelMergerNodeFactory = require("./native-channel-merger-node-factory");
parcelHelpers.exportAll(_nativeChannelMergerNodeFactory, exports);
var _nativeChannelMergerNodeFactoryFactory = require("./native-channel-merger-node-factory-factory");
parcelHelpers.exportAll(_nativeChannelMergerNodeFactoryFactory, exports);
var _nativeChannelSplitterNode = require("./native-channel-splitter-node");
parcelHelpers.exportAll(_nativeChannelSplitterNode, exports);
var _nativeChannelSplitterNodeFactory = require("./native-channel-splitter-node-factory");
parcelHelpers.exportAll(_nativeChannelSplitterNodeFactory, exports);
var _nativeConstantSourceNode = require("./native-constant-source-node");
parcelHelpers.exportAll(_nativeConstantSourceNode, exports);
var _nativeConstantSourceNodeFactory = require("./native-constant-source-node-factory");
parcelHelpers.exportAll(_nativeConstantSourceNodeFactory, exports);
var _nativeConstantSourceNodeFactoryFactory = require("./native-constant-source-node-factory-factory");
parcelHelpers.exportAll(_nativeConstantSourceNodeFactoryFactory, exports);
var _nativeConstantSourceNodeFakerFactory = require("./native-constant-source-node-faker-factory");
parcelHelpers.exportAll(_nativeConstantSourceNodeFakerFactory, exports);
var _nativeConstantSourceNodeFakerFactoryFactory = require("./native-constant-source-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeConstantSourceNodeFakerFactoryFactory, exports);
var _nativeContext = require("./native-context");
parcelHelpers.exportAll(_nativeContext, exports);
var _nativeConvolverNode = require("./native-convolver-node");
parcelHelpers.exportAll(_nativeConvolverNode, exports);
var _nativeConvolverNodeFactory = require("./native-convolver-node-factory");
parcelHelpers.exportAll(_nativeConvolverNodeFactory, exports);
var _nativeConvolverNodeFactoryFactory = require("./native-convolver-node-factory-factory");
parcelHelpers.exportAll(_nativeConvolverNodeFactoryFactory, exports);
var _nativeDelayNodeFactory = require("./native-delay-node-factory");
parcelHelpers.exportAll(_nativeDelayNodeFactory, exports);
var _nativeDelayNode = require("./native-delay-node");
parcelHelpers.exportAll(_nativeDelayNode, exports);
var _nativeDynamicsCompressorNode = require("./native-dynamics-compressor-node");
parcelHelpers.exportAll(_nativeDynamicsCompressorNode, exports);
var _nativeDynamicsCompressorNodeFactory = require("./native-dynamics-compressor-node-factory");
parcelHelpers.exportAll(_nativeDynamicsCompressorNodeFactory, exports);
var _nativeDynamicsCompressorNodeFactoryFactory = require("./native-dynamics-compressor-node-factory-factory");
parcelHelpers.exportAll(_nativeDynamicsCompressorNodeFactoryFactory, exports);
var _nativeEventTarget = require("./native-event-target");
parcelHelpers.exportAll(_nativeEventTarget, exports);
var _nativeGainNode = require("./native-gain-node");
parcelHelpers.exportAll(_nativeGainNode, exports);
var _nativeGainNodeFactory = require("./native-gain-node-factory");
parcelHelpers.exportAll(_nativeGainNodeFactory, exports);
var _nativeIirFilterNode = require("./native-iir-filter-node");
parcelHelpers.exportAll(_nativeIirFilterNode, exports);
var _nativeIirFilterNodeFactory = require("./native-iir-filter-node-factory");
parcelHelpers.exportAll(_nativeIirFilterNodeFactory, exports);
var _nativeIirFilterNodeFactoryFactory = require("./native-iir-filter-node-factory-factory");
parcelHelpers.exportAll(_nativeIirFilterNodeFactoryFactory, exports);
var _nativeIirFilterNodeFakerFactory = require("./native-iir-filter-node-faker-factory");
parcelHelpers.exportAll(_nativeIirFilterNodeFakerFactory, exports);
var _nativeIirFilterNodeFakerFactoryFactory = require("./native-iir-filter-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeIirFilterNodeFakerFactoryFactory, exports);
var _nativeMediaElementAudioSourceNode = require("./native-media-element-audio-source-node");
parcelHelpers.exportAll(_nativeMediaElementAudioSourceNode, exports);
var _nativeMediaElementAudioSourceNodeFactory = require("./native-media-element-audio-source-node-factory");
parcelHelpers.exportAll(_nativeMediaElementAudioSourceNodeFactory, exports);
var _nativeMediaStreamAudioDestinationNode = require("./native-media-stream-audio-destination-node");
parcelHelpers.exportAll(_nativeMediaStreamAudioDestinationNode, exports);
var _nativeMediaStreamAudioDestinationNodeFactory = require("./native-media-stream-audio-destination-node-factory");
parcelHelpers.exportAll(_nativeMediaStreamAudioDestinationNodeFactory, exports);
var _nativeMediaStreamAudioSourceNode = require("./native-media-stream-audio-source-node");
parcelHelpers.exportAll(_nativeMediaStreamAudioSourceNode, exports);
var _nativeMediaStreamAudioSourceNodeFactory = require("./native-media-stream-audio-source-node-factory");
parcelHelpers.exportAll(_nativeMediaStreamAudioSourceNodeFactory, exports);
var _nativeMediaStreamTrackAudioSourceNode = require("./native-media-stream-track-audio-source-node");
parcelHelpers.exportAll(_nativeMediaStreamTrackAudioSourceNode, exports);
var _nativeMediaStreamTrackAudioSourceNodeFactory = require("./native-media-stream-track-audio-source-node-factory");
parcelHelpers.exportAll(_nativeMediaStreamTrackAudioSourceNodeFactory, exports);
var _nativeMediaStreamTrackAudioSourceNodeFactoryFactory = require("./native-media-stream-track-audio-source-node-factory-factory");
parcelHelpers.exportAll(_nativeMediaStreamTrackAudioSourceNodeFactoryFactory, exports);
var _nativeOfflineAudioContext = require("./native-offline-audio-context");
parcelHelpers.exportAll(_nativeOfflineAudioContext, exports);
var _nativeOfflineAudioContextConstructor = require("./native-offline-audio-context-constructor");
parcelHelpers.exportAll(_nativeOfflineAudioContextConstructor, exports);
var _nativeOfflineAudioContextConstructorFactory = require("./native-offline-audio-context-constructor-factory");
parcelHelpers.exportAll(_nativeOfflineAudioContextConstructorFactory, exports);
var _nativeOscillatorNode = require("./native-oscillator-node");
parcelHelpers.exportAll(_nativeOscillatorNode, exports);
var _nativeOscillatorNodeFactory = require("./native-oscillator-node-factory");
parcelHelpers.exportAll(_nativeOscillatorNodeFactory, exports);
var _nativeOscillatorNodeFactoryFactory = require("./native-oscillator-node-factory-factory");
parcelHelpers.exportAll(_nativeOscillatorNodeFactoryFactory, exports);
var _nativePannerNode = require("./native-panner-node");
parcelHelpers.exportAll(_nativePannerNode, exports);
var _nativePannerNodeFactory = require("./native-panner-node-factory");
parcelHelpers.exportAll(_nativePannerNodeFactory, exports);
var _nativePannerNodeFactoryFactory = require("./native-panner-node-factory-factory");
parcelHelpers.exportAll(_nativePannerNodeFactoryFactory, exports);
var _nativePannerNodeFakerFactory = require("./native-panner-node-faker-factory");
parcelHelpers.exportAll(_nativePannerNodeFakerFactory, exports);
var _nativePannerNodeFakerFactoryFactory = require("./native-panner-node-faker-factory-factory");
parcelHelpers.exportAll(_nativePannerNodeFakerFactoryFactory, exports);
var _nativePeriodicWave = require("./native-periodic-wave");
parcelHelpers.exportAll(_nativePeriodicWave, exports);
var _nativePeriodicWaveFactory = require("./native-periodic-wave-factory");
parcelHelpers.exportAll(_nativePeriodicWaveFactory, exports);
var _nativePeriodicWaveFactoryFactory = require("./native-periodic-wave-factory-factory");
parcelHelpers.exportAll(_nativePeriodicWaveFactoryFactory, exports);
var _nativeScriptProcessorNode = require("./native-script-processor-node");
parcelHelpers.exportAll(_nativeScriptProcessorNode, exports);
var _nativeScriptProcessorNodeFactory = require("./native-script-processor-node-factory");
parcelHelpers.exportAll(_nativeScriptProcessorNodeFactory, exports);
var _nativeStereoPannerNode = require("./native-stereo-panner-node");
parcelHelpers.exportAll(_nativeStereoPannerNode, exports);
var _nativeStereoPannerNodeFactory = require("./native-stereo-panner-node-factory");
parcelHelpers.exportAll(_nativeStereoPannerNodeFactory, exports);
var _nativeStereoPannerNodeFactoryFactory = require("./native-stereo-panner-node-factory-factory");
parcelHelpers.exportAll(_nativeStereoPannerNodeFactoryFactory, exports);
var _nativeStereoPannerNodeFakerFactory = require("./native-stereo-panner-node-faker-factory");
parcelHelpers.exportAll(_nativeStereoPannerNodeFakerFactory, exports);
var _nativeStereoPannerNodeFakerFactoryFactory = require("./native-stereo-panner-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeStereoPannerNodeFakerFactoryFactory, exports);
var _nativeWaveShaperNode = require("./native-wave-shaper-node");
parcelHelpers.exportAll(_nativeWaveShaperNode, exports);
var _nativeWaveShaperNodeFactory = require("./native-wave-shaper-node-factory");
parcelHelpers.exportAll(_nativeWaveShaperNodeFactory, exports);
var _nativeWaveShaperNodeFactoryFactory = require("./native-wave-shaper-node-factory-factory");
parcelHelpers.exportAll(_nativeWaveShaperNodeFactoryFactory, exports);
var _nativeWaveShaperNodeFakerFactory = require("./native-wave-shaper-node-faker-factory");
parcelHelpers.exportAll(_nativeWaveShaperNodeFakerFactory, exports);
var _nativeWaveShaperNodeFakerFactoryFactory = require("./native-wave-shaper-node-faker-factory-factory");
parcelHelpers.exportAll(_nativeWaveShaperNodeFakerFactoryFactory, exports);
var _notSupportedErrorFactory = require("./not-supported-error-factory");
parcelHelpers.exportAll(_notSupportedErrorFactory, exports);
var _offlineAudioContextConstructorFactory = require("./offline-audio-context-constructor-factory");
parcelHelpers.exportAll(_offlineAudioContextConstructorFactory, exports);
var _oscillatorNodeConstructor = require("./oscillator-node-constructor");
parcelHelpers.exportAll(_oscillatorNodeConstructor, exports);
var _oscillatorNodeConstructorFactory = require("./oscillator-node-constructor-factory");
parcelHelpers.exportAll(_oscillatorNodeConstructorFactory, exports);
var _oscillatorNodeRenderer = require("./oscillator-node-renderer");
parcelHelpers.exportAll(_oscillatorNodeRenderer, exports);
var _oscillatorNodeRendererFactory = require("./oscillator-node-renderer-factory");
parcelHelpers.exportAll(_oscillatorNodeRendererFactory, exports);
var _oscillatorNodeRendererFactoryFactory = require("./oscillator-node-renderer-factory-factory");
parcelHelpers.exportAll(_oscillatorNodeRendererFactoryFactory, exports);
var _oscillatorType = require("./oscillator-type");
parcelHelpers.exportAll(_oscillatorType, exports);
var _outputConnection = require("./output-connection");
parcelHelpers.exportAll(_outputConnection, exports);
var _overSampleType = require("./over-sample-type");
parcelHelpers.exportAll(_overSampleType, exports);
var _overwriteAccessorsFunction = require("./overwrite-accessors-function");
parcelHelpers.exportAll(_overwriteAccessorsFunction, exports);
var _pannerNodeConstructor = require("./panner-node-constructor");
parcelHelpers.exportAll(_pannerNodeConstructor, exports);
var _pannerNodeConstructorFactory = require("./panner-node-constructor-factory");
parcelHelpers.exportAll(_pannerNodeConstructorFactory, exports);
var _pannerNodeRendererFactory = require("./panner-node-renderer-factory");
parcelHelpers.exportAll(_pannerNodeRendererFactory, exports);
var _pannerNodeRendererFactoryFactory = require("./panner-node-renderer-factory-factory");
parcelHelpers.exportAll(_pannerNodeRendererFactoryFactory, exports);
var _panningModelType = require("./panning-model-type");
parcelHelpers.exportAll(_panningModelType, exports);
var _passiveAudioNodeInputConnection = require("./passive-audio-node-input-connection");
parcelHelpers.exportAll(_passiveAudioNodeInputConnection, exports);
var _passiveAudioParamInputConnection = require("./passive-audio-param-input-connection");
parcelHelpers.exportAll(_passiveAudioParamInputConnection, exports);
var _periodicWaveConstructor = require("./periodic-wave-constructor");
parcelHelpers.exportAll(_periodicWaveConstructor, exports);
var _periodicWaveConstructorFactory = require("./periodic-wave-constructor-factory");
parcelHelpers.exportAll(_periodicWaveConstructorFactory, exports);
var _pickElementFromSetFunction = require("./pick-element-from-set-function");
parcelHelpers.exportAll(_pickElementFromSetFunction, exports);
var _renderAutomationFactory = require("./render-automation-factory");
parcelHelpers.exportAll(_renderAutomationFactory, exports);
var _renderAutomationFunction = require("./render-automation-function");
parcelHelpers.exportAll(_renderAutomationFunction, exports);
var _renderInputsOfAudioNodeFactory = require("./render-inputs-of-audio-node-factory");
parcelHelpers.exportAll(_renderInputsOfAudioNodeFactory, exports);
var _renderInputsOfAudioNodeFunction = require("./render-inputs-of-audio-node-function");
parcelHelpers.exportAll(_renderInputsOfAudioNodeFunction, exports);
var _renderInputsOfAudioParamFactory = require("./render-inputs-of-audio-param-factory");
parcelHelpers.exportAll(_renderInputsOfAudioParamFactory, exports);
var _renderInputsOfAudioParamFunction = require("./render-inputs-of-audio-param-function");
parcelHelpers.exportAll(_renderInputsOfAudioParamFunction, exports);
var _renderNativeOfflineAudioContextFactory = require("./render-native-offline-audio-context-factory");
parcelHelpers.exportAll(_renderNativeOfflineAudioContextFactory, exports);
var _renderNativeOfflineAudioContextFunction = require("./render-native-offline-audio-context-function");
parcelHelpers.exportAll(_renderNativeOfflineAudioContextFunction, exports);
var _sanitizeAudioWorkletNodeOptionsFunction = require("./sanitize-audio-worklet-node-options-function");
parcelHelpers.exportAll(_sanitizeAudioWorkletNodeOptionsFunction, exports);
var _sanitizeChannelSplitterOptionsFunction = require("./sanitize-channel-splitter-options-function");
parcelHelpers.exportAll(_sanitizeChannelSplitterOptionsFunction, exports);
var _sanitizePeriodicWaveOptionsFunction = require("./sanitize-periodic-wave-options-function");
parcelHelpers.exportAll(_sanitizePeriodicWaveOptionsFunction, exports);
var _setActiveAudioWorkletNodeInputsFactory = require("./set-active-audio-worklet-node-inputs-factory");
parcelHelpers.exportAll(_setActiveAudioWorkletNodeInputsFactory, exports);
var _setActiveAudioWorkletNodeInputsFunction = require("./set-active-audio-worklet-node-inputs-function");
parcelHelpers.exportAll(_setActiveAudioWorkletNodeInputsFunction, exports);
var _setAudioNodeTailTimeFactory = require("./set-audio-node-tail-time-factory");
parcelHelpers.exportAll(_setAudioNodeTailTimeFactory, exports);
var _setAudioNodeTailTimeFunction = require("./set-audio-node-tail-time-function");
parcelHelpers.exportAll(_setAudioNodeTailTimeFunction, exports);
var _setValueAtTimeUntilPossibleFunction = require("./set-value-at-time-until-possible-function");
parcelHelpers.exportAll(_setValueAtTimeUntilPossibleFunction, exports);
var _startRenderingFactory = require("./start-rendering-factory");
parcelHelpers.exportAll(_startRenderingFactory, exports);
var _startRenderingFunction = require("./start-rendering-function");
parcelHelpers.exportAll(_startRenderingFunction, exports);
var _stereoPannerNodeConstructor = require("./stereo-panner-node-constructor");
parcelHelpers.exportAll(_stereoPannerNodeConstructor, exports);
var _stereoPannerNodeConstructorFactory = require("./stereo-panner-node-constructor-factory");
parcelHelpers.exportAll(_stereoPannerNodeConstructorFactory, exports);
var _stereoPannerNodeRendererFactoryFactory = require("./stereo-panner-node-renderer-factory-factory");
parcelHelpers.exportAll(_stereoPannerNodeRendererFactoryFactory, exports);
var _stereoPannerNodeRendererFactory = require("./stereo-panner-node-renderer-factory");
parcelHelpers.exportAll(_stereoPannerNodeRendererFactory, exports);
var _testAudioBufferCopyChannelMethodsSubarraySupportFactory = require("./test-audio-buffer-copy-channel-methods-subarray-support-factory");
parcelHelpers.exportAll(_testAudioBufferCopyChannelMethodsSubarraySupportFactory, exports);
var _testAudioBufferConstructorSupportFactory = require("./test-audio-buffer-constructor-support-factory");
parcelHelpers.exportAll(_testAudioBufferConstructorSupportFactory, exports);
var _testAudioContextCloseMethodSupportFactory = require("./test-audio-context-close-method-support-factory");
parcelHelpers.exportAll(_testAudioContextCloseMethodSupportFactory, exports);
var _testAudioContextDecodeAudioDataMethodTypeErrorSupportFactory = require("./test-audio-context-decode-audio-data-method-type-error-support-factory");
parcelHelpers.exportAll(_testAudioContextDecodeAudioDataMethodTypeErrorSupportFactory, exports);
var _testAudioContextOptionsSupportFactory = require("./test-audio-context-options-support-factory");
parcelHelpers.exportAll(_testAudioContextOptionsSupportFactory, exports);
var _testAudioNodeConnectMethodSupportFactory = require("./test-audio-node-connect-method-support-factory");
parcelHelpers.exportAll(_testAudioNodeConnectMethodSupportFactory, exports);
var _testAudioWorkletNodeOptionsClonabilityFunction = require("./test-audio-worklet-node-options-clonability-function");
parcelHelpers.exportAll(_testAudioWorkletNodeOptionsClonabilityFunction, exports);
var _testAudioWorkletProcessorNoOutputsSupportFactory = require("./test-audio-worklet-processor-no-outputs-support-factory");
parcelHelpers.exportAll(_testAudioWorkletProcessorNoOutputsSupportFactory, exports);
var _testAudioWorkletProcessorPostMessageSupportFactory = require("./test-audio-worklet-processor-post-message-support-factory");
parcelHelpers.exportAll(_testAudioWorkletProcessorPostMessageSupportFactory, exports);
var _testChannelMergerNodeChannelCountSupportFactory = require("./test-channel-merger-node-channel-count-support-factory");
parcelHelpers.exportAll(_testChannelMergerNodeChannelCountSupportFactory, exports);
var _testConstantSourceNodeAccurateSchedulingSupportFactory = require("./test-constant-source-node-accurate-scheduling-support-factory");
parcelHelpers.exportAll(_testConstantSourceNodeAccurateSchedulingSupportFactory, exports);
var _testConvolverNodeBufferReassignabilitySupportFactory = require("./test-convolver-node-buffer-reassignability-support-factory");
parcelHelpers.exportAll(_testConvolverNodeBufferReassignabilitySupportFactory, exports);
var _testConvolverNodeChannelCountSupportFactory = require("./test-convolver-node-channel-count-support-factory");
parcelHelpers.exportAll(_testConvolverNodeChannelCountSupportFactory, exports);
var _testIsSecureContextSupportFactory = require("./test-is-secure-context-support-factory");
parcelHelpers.exportAll(_testIsSecureContextSupportFactory, exports);
var _testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport = require("./test-media-stream-audio-source-node-media-stream-without-audio-track-support");
parcelHelpers.exportAll(_testMediaStreamAudioSourceNodeMediaStreamWithoutAudioTrackSupport, exports);
var _testOfflineAudioContextCurrentTimeSupportFactory = require("./test-offline-audio-context-current-time-support-factory");
parcelHelpers.exportAll(_testOfflineAudioContextCurrentTimeSupportFactory, exports);
var _testStereoPannerNodeDefaultValueSupportFactory = require("./test-stereo-panner-node-default-value-support-factory");
parcelHelpers.exportAll(_testStereoPannerNodeDefaultValueSupportFactory, exports);
var _unknownErrorFactory = require("./unknown-error-factory");
parcelHelpers.exportAll(_unknownErrorFactory, exports);
var _unrenderedAudioWorkletNodeStore = require("./unrendered-audio-worklet-node-store");
parcelHelpers.exportAll(_unrenderedAudioWorkletNodeStore, exports);
var _unrenderedAudioWorkletNodes = require("./unrendered-audio-worklet-nodes");
parcelHelpers.exportAll(_unrenderedAudioWorkletNodes, exports);
var _waveShaperNodeConstructor = require("./wave-shaper-node-constructor");
parcelHelpers.exportAll(_waveShaperNodeConstructor, exports);
var _waveShaperNodeConstructorFactory = require("./wave-shaper-node-constructor-factory");
parcelHelpers.exportAll(_waveShaperNodeConstructorFactory, exports);
var _waveShaperNodeRendererFactoryFactory = require("./wave-shaper-node-renderer-factory-factory");
parcelHelpers.exportAll(_waveShaperNodeRendererFactoryFactory, exports);
var _waveShaperNodeRendererFactory = require("./wave-shaper-node-renderer-factory");
parcelHelpers.exportAll(_waveShaperNodeRendererFactory, exports);
var _window = require("./window");
parcelHelpers.exportAll(_window, exports);
var _windowFactory = require("./window-factory");
parcelHelpers.exportAll(_windowFactory, exports);
var _wrapAudioBufferCopyChannelMethodsFactory = require("./wrap-audio-buffer-copy-channel-methods-factory");
parcelHelpers.exportAll(_wrapAudioBufferCopyChannelMethodsFactory, exports);
var _wrapAudioBufferCopyChannelMethodsFunction = require("./wrap-audio-buffer-copy-channel-methods-function");
parcelHelpers.exportAll(_wrapAudioBufferCopyChannelMethodsFunction, exports);
var _wrapAudioBufferCopyChannelMethodsOutOfBoundsFactory = require("./wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory");
parcelHelpers.exportAll(_wrapAudioBufferCopyChannelMethodsOutOfBoundsFactory, exports);
var _wrapAudioBufferCopyChannelMethodsOutOfBoundsFunction = require("./wrap-audio-buffer-copy-channel-methods-out-of-bounds-function");
parcelHelpers.exportAll(_wrapAudioBufferCopyChannelMethodsOutOfBoundsFunction, exports);
var _wrapAudioBufferSourceNodeStartMethodOffsetClampingFunction = require("./wrap-audio-buffer-source-node-start-method-offset-clamping-function");
parcelHelpers.exportAll(_wrapAudioBufferSourceNodeStartMethodOffsetClampingFunction, exports);
var _wrapAudioBufferSourceNodeStopMethodNullifiedBufferFactory = require("./wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory");
parcelHelpers.exportAll(_wrapAudioBufferSourceNodeStopMethodNullifiedBufferFactory, exports);
var _wrapAudioBufferSourceNodeStopMethodNullifiedBufferFunction = require("./wrap-audio-buffer-source-node-stop-method-nullified-buffer-function");
parcelHelpers.exportAll(_wrapAudioBufferSourceNodeStopMethodNullifiedBufferFunction, exports);
var _wrapAudioScheduledSourceNodeStopMethodConsecutiveCallsFunction = require("./wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function");
parcelHelpers.exportAll(_wrapAudioScheduledSourceNodeStopMethodConsecutiveCallsFunction, exports);
var _wrapChannelMergerNodeFactory = require("./wrap-channel-merger-node-factory");
parcelHelpers.exportAll(_wrapChannelMergerNodeFactory, exports);
var _wrapChannelMergerNodeFunction = require("./wrap-channel-merger-node-function");
parcelHelpers.exportAll(_wrapChannelMergerNodeFunction, exports);
var _wrapEventListenerFunction = require("./wrap-event-listener-function");
parcelHelpers.exportAll(_wrapEventListenerFunction, exports);

},{"./abort-error-factory":"d5vER","./active-audio-worklet-node-inputs-store":"534AP","./active-input-connection":"g7NSC","./add-active-input-connection-to-audio-node-factory":"i202K","./add-active-input-connection-to-audio-node-function":"4FTQF","./add-audio-node-connections-factory":"23B8c","./add-audio-node-connections-function":"9wwUg","./add-audio-param-connections-factory":"a8Gtf","./add-audio-param-connections-function":"cu80G","./add-audio-worklet-module-factory":"1jRNg","./add-audio-worklet-module-function":"1GfTV","./add-connection-to-audio-node-factory":"h0pSu","./add-connection-to-audio-node-function":"bOBa6","./add-passive-input-connection-to-audio-node-factory":"c9UhA","./add-passive-input-connection-to-audio-node-function":"lQFCa","./add-silent-connection-factory":"fuSn1","./add-silent-connection-function":"gyFgw","./add-unrendered-audio-worklet-node-factory":"hVFQb","./add-unrendered-audio-worklet-node-function":"c0cJN","./analyser-node-constructor":"iTUcL","./analyser-node-constructor-factory":"8fDS4","./analyser-node-renderer-factory":"5YT9j","./analyser-node-renderer-factory-factory":"5ZaqK","./any-audio-buffer":"2WdgP","./any-context":"fwgPv","./audio-buffer-constructor":"83JVQ","./audio-buffer-constructor-factory":"gUsLm","./audio-buffer-source-node-constructor":"l8qZV","./audio-buffer-source-node-constructor-factory":"j1E2d","./audio-buffer-source-node-renderer":"duqnd","./audio-buffer-source-node-renderer-factory":"6cSZ9","./audio-buffer-source-node-renderer-factory-factory":"4MnVG","./audio-buffer-store":"aAqSw","./audio-context-constructor":"iVUqv","./audio-context-constructor-factory":"6St1C","./audio-context-latency-category":"jxGr8","./audio-context-state":"6mbYA","./audio-destination-node-constructor":"cqERr","./audio-destination-node-constructor-factory":"kpwTa","./audio-destination-node-renderer-factory":"7cOIm","./audio-listener-factory":"hayJb","./audio-listener-factory-factory":"8tZjp","./audio-node-connections":"bL1Ic","./audio-node-connections-store":"8JRh7","./audio-node-constructor":"cQyxt","./audio-node-constructor-factory":"cWjhQ","./audio-node-output-connection":"gvrT1","./audio-node-renderer":"byWK9","./audio-node-store":"idNyd","./audio-node-tail-time-store":"jiAZg","./audio-param-audio-node-store":"a3Sim","./audio-param-connections":"f9DEH","./audio-param-connections-store":"QmLxk","./audio-param-factory":"LjdDq","./audio-param-factory-factory":"3dPbb","./audio-param-map":"c2XTF","./audio-param-output-connection":"cvOF2","./audio-param-renderer-factory":"3eCBH","./audio-param-store":"lWLrl","./audio-worklet-node-constructor":"8YTg4","./audio-worklet-node-constructor-factory":"jlthx","./audio-worklet-node-renderer-factory":"2s4zO","./audio-worklet-node-renderer-factory-factory":"5iFWp","./backup-offline-audio-context-store":"bQfpO","./base-audio-context-constructor":"EXAnM","./base-audio-context-constructor-factory":"jjmlI","./biquad-filter-node-constructor":"2VcIZ","./biquad-filter-node-constructor-factory":"hh31c","./biquad-filter-node-renderer-factory":"iCCHV","./biquad-filter-node-renderer-factory-factory":"9VUdk","./biquad-filter-type":"etoXp","./channel-count-mode":"eF5Qw","./channel-interpretation":"leLlj","./channel-merger-node-constructor":"eFSZY","./channel-merger-node-constructor-factory":"2w260","./channel-merger-node-renderer-factory":"jkbvX","./channel-merger-node-renderer-factory-factory":"f1CYL","./channel-splitter-node-constructor":"6BqLW","./channel-splitter-node-constructor-factory":"8CcNN","./channel-splitter-node-renderer-factory":"egwNi","./channel-splitter-node-renderer-factory-factory":"fvWlt","./cache-test-result-factory":"4oAhD","./cache-test-result-function":"6WU0E","./connect-audio-param-factory":"cHgRo","./connect-audio-param-function":"bQxVn","./connect-multiple-outputs-factory":"gFQBr","./connect-multiple-outputs-function":"dCHyg","./connect-native-audio-node-to-native-audio-node-function":"960uC","./connected-native-audio-buffer-source-node-factory":"bmcEg","./connected-native-audio-buffer-source-node-factory-factory":"iYs5q","./constant-source-node-constructor":"7nzRf","./constant-source-node-constructor-factory":"85rsG","./constant-source-node-renderer":"l4psc","./constant-source-node-renderer-factory":"keHft","./constant-source-node-renderer-factory-factory":"1I1EY","./constructor":"6qoay","./context":"1llZq","./context-store":"aFj48","./convert-number-to-unsigned-long-factory":"bjIdl","./convert-number-to-unsigned-long-function":"jdLyW","./convolver-node-constructor":"g5mP9","./convolver-node-constructor-factory":"i0ZYL","./convolver-node-renderer-factory":"4Zg5L","./convolver-node-renderer-factory-factory":"4Mbwk","./create-native-offline-audio-context-factory":"6ljZZ","./create-native-offline-audio-context-function":"l2G1p","./cycle-counters":"arjcp","./data-clone-error-factory":"gF6Pt","./decode-audio-data-factory":"eZF6y","./decode-audio-data-function":"lA8Rb","./decode-error-callback":"dq3va","./decode-success-callback":"dMfWI","./decrement-cycle-counter-factory":"arxw9","./decrement-cycle-counter-function":"6zwA7","./delay-node-constructor":"akwMx","./delay-node-constructor-factory":"yoFlK","./delay-node-renderer-factory":"aOsL2","./delay-node-renderer-factory-factory":"3tVbG","./delete-active-input-connection-to-audio-node-factory":"8w4LV","./delete-active-input-connection-to-audio-node-function":"h75RU","./delete-unrendered-audio-worklet-node-factory":"5RDE0","./delete-unrendered-audio-worklet-node-function":"e0nFL","./detect-cycles-factory":"21TCO","./detect-cycles-function":"dia2N","./disconnect-multiple-outputs-factory":"lblmJ","./disconnect-multiple-outputs-function":"b5upt","./disconnect-native-audio-node-from-native-audio-node-function":"laCEb","./distance-model-type":"bXMkI","./dynamics-compressor-node-constructor":"d4tMW","./dynamics-compressor-node-constructor-factory":"4b2SR","./dynamics-compressor-node-renderer-factory":"iBq85","./dynamics-compressor-node-renderer-factory-factory":"ibKet","./encoding-error-factory":"ioW1g","./error-event-handler":"11ekt","./evaluate-audio-worklet-global-scope-function":"giy3r","./evaluate-source-factory":"8sUtG","./evaluate-source-function":"rlpNs","./event-handler":"2K6wn","./event-target-constructor":"45V5z","./event-target-constructor-factory":"fXG1T","./expose-current-frame-and-current-time-factory":"8DCLl","./expose-current-frame-and-current-time-function":"fybkF","./fetch-source-factory":"5V6xX","./fetch-source-function":"k00bv","./gain-node-constructor":"9920y","./gain-node-constructor-factory":"2cQio","./gain-node-renderer-factory":"34ZpI","./gain-node-renderer-factory-factory":"cOekU","./get-active-audio-worklet-node-inputs-factory":"gBmK2","./get-active-audio-worklet-node-inputs-function":"hDWmd","./get-audio-node-connections-function":"gH70V","./get-audio-node-renderer-factory":"exq8z","./get-audio-node-renderer-function":"goyo9","./get-audio-node-tail-time-factory":"1rrMA","./get-audio-node-tail-time-function":"8XeNN","./get-audio-param-connections-function":"8Qo71","./get-audio-param-renderer-factory":"dKt6a","./get-audio-param-renderer-function":"1LNE5","./get-backup-offline-audio-context-factory":"e0Hka","./get-backup-offline-audio-context-function":"dia5D","./get-event-listeners-of-audio-node-function":"epvJI","./get-first-sample-function":"cctJ0","./get-native-audio-node-function":"bMJ83","./get-native-audio-param-function":"c9t9m","./get-native-context-factory":"dsf18","./get-native-context-function":"exCsZ","./get-or-create-backup-offline-audio-context-factory":"jnEYZ","./get-or-create-backup-offline-audio-context-function":"fmYuO","./get-unrendered-audio-worklet-nodes-factory":"qEike","./get-unrendered-audio-worklet-nodes-function":"7tZ8a","./get-value-for-key-function":"fNxcx","./iir-filter-node-constructor":"1EhjZ","./iir-filter-node-constructor-factory":"ak3Bn","./iir-filter-node-renderer-factory":"5Apz5","./iir-filter-node-renderer-factory-factory":"b5pEM","./increment-cycle-counter-factory":"7CFCC","./increment-cycle-counter-factory-factory":"oCphS","./increment-cycle-counter-function":"jYKQV","./index-size-error-factory":"fKJxt","./insert-element-in-set-function":"7rtg6","./internal-state-event-listener":"lqtDz","./invalid-access-error-factory":"iqhAI","./invalid-state-error-factory":"g1fTw","./is-active-audio-node-function":"cJItv","./is-any-audio-context-factory":"6Clsl","./is-any-audio-context-function":"jSFx6","./is-any-audio-node-factory":"4NQ8s","./is-any-audio-node-function":"15RJI","./is-any-audio-param-factory":"1TxCJ","./is-any-audio-param-function":"1RsCg","./is-any-offline-audio-context-factory":"3JtGI","./is-any-offline-audio-context-function":"9w6vt","./is-dc-curve-function":"5iRIs","./is-native-audio-context-factory":"dWJxr","./is-native-audio-context-function":"61wj9","./is-native-audio-node-factory":"e1GNp","./is-native-audio-node-function":"jydHW","./is-native-audio-param-factory":"1Kzmj","./is-native-audio-param-function":"6gMNS","./is-native-context-factory":"2Bu25","./is-native-context-function":"3lOiZ","./is-native-offline-audio-context-factory":"HYeIB","./is-native-offline-audio-context-function":"kQFKK","./is-part-of-a-cycle-function":"1yL0g","./is-passive-audio-node-function":"6gB0R","./is-secure-context-factory":"jBJVb","./is-supported-promise-factory":"1D8u8","./media-element-audio-source-node-constructor":"4SWMC","./media-element-audio-source-node-constructor-factory":"55GwT","./media-stream-audio-destination-node-constructor":"5j7li","./media-stream-audio-destination-node-constructor-factory":"e9etR","./media-stream-audio-source-node-constructor":"2Ycop","./media-stream-audio-source-node-constructor-factory":"cnGVM","./media-stream-track-audio-source-node-constructor":"ihPl6","./media-stream-track-audio-source-node-constructor-factory":"4Rgq2","./minimal-audio-context-constructor":"3xjpO","./minimal-audio-context-constructor-factory":"kftkx","./minimal-base-audio-context-constructor":"fFO7Y","./minimal-base-audio-context-constructor-factory":"jrnN1","./minimal-offline-audio-context-constructor":"4eb71","./minimal-offline-audio-context-constructor-factory":"egY5I","./monitor-connections-factory":"1znWH","./monitor-connections-function":"5P4g9","./native-analyser-node":"213q1","./native-analyser-node-factory":"bjwNY","./native-analyser-node-factory-factory":"b3pIb","./native-audio-buffer":"cZn1w","./native-audio-buffer-constructor":"6Jw8E","./native-audio-buffer-constructor-factory":"fqmhf","./native-audio-buffer-source-node":"cXZMO","./native-audio-buffer-source-node-factory":"6Io1s","./native-audio-buffer-source-node-factory-factory":"hDdza","./native-audio-context":"cAykO","./native-audio-context-constructor":"bH32Q","./native-audio-context-constructor-factory":"bRz4I","./native-audio-destination-node":"jb19W","./native-audio-destination-node-factory":"2znZk","./native-audio-destination-node-factory-factory":"22uQs","./native-audio-listener":"iPYrQ","./native-audio-node":"hqKur","./native-audio-param":"aTwUo","./native-audio-param-map":"lkShM","./native-audio-worklet":"aXSqE","./native-audio-worklet-node":"dHvyi","./native-audio-worklet-node-constructor":"hZXGD","./native-audio-worklet-node-constructor-factory":"2x5b9","./native-audio-worklet-node-factory":"1P0RZ","./native-audio-worklet-node-factory-factory":"eJXXy","./native-audio-worklet-node-faker-factory":"iJEHa","./native-audio-worklet-node-faker-factory-factory":"iRqys","./native-audio-worklet-node-options":"i4gq5","./native-biquad-filter-node":"855Oz","./native-biquad-filter-node-factory":"b8Fo8","./native-channel-merger-node":"wouwT","./native-channel-merger-node-factory":"f7CK7","./native-channel-merger-node-factory-factory":"b1dtW","./native-channel-splitter-node":"jSyHh","./native-channel-splitter-node-factory":"7yJYa","./native-constant-source-node":"bDJSA","./native-constant-source-node-factory":"8Rg2i","./native-constant-source-node-factory-factory":"trPGv","./native-constant-source-node-faker-factory":"jOb9O","./native-constant-source-node-faker-factory-factory":"ennwr","./native-context":"cvgd2","./native-convolver-node":"2785E","./native-convolver-node-factory":"5aANF","./native-convolver-node-factory-factory":"jw3tF","./native-delay-node-factory":"afeeX","./native-delay-node":"bH0rO","./native-dynamics-compressor-node":"fQ4KK","./native-dynamics-compressor-node-factory":"11dG0","./native-dynamics-compressor-node-factory-factory":"eYYBB","./native-event-target":"1n3xU","./native-gain-node":"kXkIT","./native-gain-node-factory":"4UPsn","./native-iir-filter-node":"lEfYz","./native-iir-filter-node-factory":"ivl0c","./native-iir-filter-node-factory-factory":"jw9oN","./native-iir-filter-node-faker-factory":"oGvjz","./native-iir-filter-node-faker-factory-factory":"cfABQ","./native-media-element-audio-source-node":"ae4Cf","./native-media-element-audio-source-node-factory":"eYjLR","./native-media-stream-audio-destination-node":"1sjQS","./native-media-stream-audio-destination-node-factory":"8UA05","./native-media-stream-audio-source-node":"iNL0E","./native-media-stream-audio-source-node-factory":"eb3Rv","./native-media-stream-track-audio-source-node":"bJUGB","./native-media-stream-track-audio-source-node-factory":"2rmW4","./native-media-stream-track-audio-source-node-factory-factory":"k0pB5","./native-offline-audio-context":"2gIoZ","./native-offline-audio-context-constructor":"1NpnF","./native-offline-audio-context-constructor-factory":"hUmlg","./native-oscillator-node":"1QYEq","./native-oscillator-node-factory":"8HmyE","./native-oscillator-node-factory-factory":"NGnm2","./native-panner-node":"hE6IC","./native-panner-node-factory":"gWYrL","./native-panner-node-factory-factory":"6SNtd","./native-panner-node-faker-factory":"j4yCt","./native-panner-node-faker-factory-factory":"f7krr","./native-periodic-wave":"aQupJ","./native-periodic-wave-factory":"5EDq2","./native-periodic-wave-factory-factory":"9Aye4","./native-script-processor-node":"lwlgr","./native-script-processor-node-factory":"1nvzk","./native-stereo-panner-node":"2qTXI","./native-stereo-panner-node-factory":"5zCIO","./native-stereo-panner-node-factory-factory":"4mI66","./native-stereo-panner-node-faker-factory":"6NLpn","./native-stereo-panner-node-faker-factory-factory":"511FE","./native-wave-shaper-node":"gqdt4","./native-wave-shaper-node-factory":"hClKp","./native-wave-shaper-node-factory-factory":"igIZX","./native-wave-shaper-node-faker-factory":"8i1WR","./native-wave-shaper-node-faker-factory-factory":"46Zp1","./not-supported-error-factory":"hoU7c","./offline-audio-context-constructor-factory":"fqVYe","./oscillator-node-constructor":"iWoi1","./oscillator-node-constructor-factory":"2XZDd","./oscillator-node-renderer":"8cUiy","./oscillator-node-renderer-factory":"cM7qR","./oscillator-node-renderer-factory-factory":"475lW","./oscillator-type":"73n4n","./output-connection":"c2by2","./over-sample-type":"9mJPE","./overwrite-accessors-function":"6RGfs","./panner-node-constructor":"j7PuW","./panner-node-constructor-factory":"eZCyZ","./panner-node-renderer-factory":"kk4Nv","./panner-node-renderer-factory-factory":"bzPRi","./panning-model-type":"1kEtm","./passive-audio-node-input-connection":"WFHvR","./passive-audio-param-input-connection":"bgamm","./periodic-wave-constructor":"gxYxl","./periodic-wave-constructor-factory":"fVEHF","./pick-element-from-set-function":"2nvzC","./render-automation-factory":"9k33b","./render-automation-function":"4l0dG","./render-inputs-of-audio-node-factory":"9OlMX","./render-inputs-of-audio-node-function":"39Us7","./render-inputs-of-audio-param-factory":"ehPQK","./render-inputs-of-audio-param-function":"4KSsw","./render-native-offline-audio-context-factory":"74Deg","./render-native-offline-audio-context-function":"fL1oo","./sanitize-audio-worklet-node-options-function":"32OSf","./sanitize-channel-splitter-options-function":"53VLv","./sanitize-periodic-wave-options-function":"2w8aP","./set-active-audio-worklet-node-inputs-factory":"a5hqS","./set-active-audio-worklet-node-inputs-function":"hXYOo","./set-audio-node-tail-time-factory":"cH1nq","./set-audio-node-tail-time-function":"d3kaC","./set-value-at-time-until-possible-function":"idNS9","./start-rendering-factory":"bv144","./start-rendering-function":"lEV8b","./stereo-panner-node-constructor":"728Pe","./stereo-panner-node-constructor-factory":"jft1l","./stereo-panner-node-renderer-factory-factory":"hKXG7","./stereo-panner-node-renderer-factory":"4uQ53","./test-audio-buffer-copy-channel-methods-subarray-support-factory":"bm6P1","./test-audio-buffer-constructor-support-factory":"2gyIt","./test-audio-context-close-method-support-factory":"eci2j","./test-audio-context-decode-audio-data-method-type-error-support-factory":"cDdsj","./test-audio-context-options-support-factory":"4x6ll","./test-audio-node-connect-method-support-factory":"ceUS5","./test-audio-worklet-node-options-clonability-function":"5pMvA","./test-audio-worklet-processor-no-outputs-support-factory":"lmNAb","./test-audio-worklet-processor-post-message-support-factory":"kvcqD","./test-channel-merger-node-channel-count-support-factory":"eCBKZ","./test-constant-source-node-accurate-scheduling-support-factory":"gbKw9","./test-convolver-node-buffer-reassignability-support-factory":"hOyzx","./test-convolver-node-channel-count-support-factory":"a9S06","./test-is-secure-context-support-factory":"792j2","./test-media-stream-audio-source-node-media-stream-without-audio-track-support":"enEUn","./test-offline-audio-context-current-time-support-factory":"cF5XB","./test-stereo-panner-node-default-value-support-factory":"8hjUo","./unknown-error-factory":"lSHcU","./unrendered-audio-worklet-node-store":"f6MuT","./unrendered-audio-worklet-nodes":"jJKOY","./wave-shaper-node-constructor":"5mEWg","./wave-shaper-node-constructor-factory":"6i49v","./wave-shaper-node-renderer-factory-factory":"3P1PD","./wave-shaper-node-renderer-factory":"lVAJd","./window":"kZYqQ","./window-factory":"9Fg6X","./wrap-audio-buffer-copy-channel-methods-factory":"iEDz5","./wrap-audio-buffer-copy-channel-methods-function":"8PrrL","./wrap-audio-buffer-copy-channel-methods-out-of-bounds-factory":"ftsLt","./wrap-audio-buffer-copy-channel-methods-out-of-bounds-function":"4Lp3r","./wrap-audio-buffer-source-node-start-method-offset-clamping-function":"dMXRw","./wrap-audio-buffer-source-node-stop-method-nullified-buffer-factory":"lkEiq","./wrap-audio-buffer-source-node-stop-method-nullified-buffer-function":"jSnmv","./wrap-audio-scheduled-source-node-stop-method-consecutive-calls-function":"8Ra8F","./wrap-channel-merger-node-factory":"6KcE4","./wrap-channel-merger-node-function":"acxjR","./wrap-event-listener-function":"9yc1J","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d5vER":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"534AP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"g7NSC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"i202K":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4FTQF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"23B8c":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9wwUg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"a8Gtf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cu80G":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1jRNg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1GfTV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"h0pSu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bOBa6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"c9UhA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lQFCa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fuSn1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gyFgw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hVFQb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"c0cJN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iTUcL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8fDS4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5YT9j":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5ZaqK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2WdgP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fwgPv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"83JVQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gUsLm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"l8qZV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j1E2d":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"duqnd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6cSZ9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4MnVG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aAqSw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iVUqv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6St1C":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jxGr8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6mbYA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cqERr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kpwTa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7cOIm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hayJb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8tZjp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bL1Ic":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8JRh7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cQyxt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cWjhQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gvrT1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"byWK9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"idNyd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jiAZg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"a3Sim":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"f9DEH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"QmLxk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"LjdDq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3dPbb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"c2XTF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cvOF2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3eCBH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lWLrl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8YTg4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jlthx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2s4zO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5iFWp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bQfpO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"EXAnM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jjmlI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2VcIZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hh31c":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iCCHV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9VUdk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"etoXp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eF5Qw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"leLlj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eFSZY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2w260":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jkbvX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"f1CYL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6BqLW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8CcNN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"egwNi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fvWlt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4oAhD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6WU0E":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cHgRo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bQxVn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gFQBr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dCHyg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"960uC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bmcEg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iYs5q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7nzRf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"85rsG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"l4psc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"keHft":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1I1EY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6qoay":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1llZq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aFj48":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bjIdl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jdLyW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"g5mP9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"i0ZYL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4Zg5L":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4Mbwk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6ljZZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"l2G1p":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"arjcp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gF6Pt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eZF6y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lA8Rb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dq3va":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dMfWI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"arxw9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6zwA7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"akwMx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"yoFlK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aOsL2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3tVbG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8w4LV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"h75RU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5RDE0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e0nFL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"21TCO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dia2N":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lblmJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b5upt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"laCEb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bXMkI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d4tMW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4b2SR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iBq85":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ibKet":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ioW1g":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"11ekt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"giy3r":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8sUtG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"rlpNs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2K6wn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"45V5z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fXG1T":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8DCLl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fybkF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5V6xX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"k00bv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9920y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2cQio":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"34ZpI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cOekU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gBmK2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hDWmd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gH70V":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"exq8z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"goyo9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1rrMA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8XeNN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8Qo71":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dKt6a":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1LNE5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e0Hka":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dia5D":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"epvJI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cctJ0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bMJ83":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"c9t9m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dsf18":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"exCsZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jnEYZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fmYuO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"qEike":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7tZ8a":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fNxcx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1EhjZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ak3Bn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5Apz5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b5pEM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7CFCC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"oCphS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jYKQV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fKJxt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7rtg6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lqtDz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iqhAI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"g1fTw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cJItv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6Clsl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jSFx6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4NQ8s":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"15RJI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1TxCJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1RsCg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3JtGI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9w6vt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5iRIs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dWJxr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"61wj9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e1GNp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jydHW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1Kzmj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6gMNS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2Bu25":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3lOiZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"HYeIB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kQFKK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1yL0g":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6gB0R":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jBJVb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1D8u8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4SWMC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"55GwT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5j7li":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"e9etR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2Ycop":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cnGVM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ihPl6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4Rgq2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3xjpO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kftkx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fFO7Y":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jrnN1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4eb71":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"egY5I":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1znWH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5P4g9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"213q1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bjwNY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b3pIb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cZn1w":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6Jw8E":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fqmhf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cXZMO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6Io1s":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hDdza":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cAykO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bH32Q":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bRz4I":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jb19W":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2znZk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"22uQs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iPYrQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hqKur":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aTwUo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lkShM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aXSqE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dHvyi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hZXGD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2x5b9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1P0RZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eJXXy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iJEHa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iRqys":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"i4gq5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"855Oz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b8Fo8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"wouwT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"f7CK7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b1dtW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jSyHh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7yJYa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bDJSA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8Rg2i":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"trPGv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jOb9O":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ennwr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cvgd2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2785E":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5aANF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jw3tF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"afeeX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bH0rO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fQ4KK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"11dG0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eYYBB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1n3xU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kXkIT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4UPsn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lEfYz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ivl0c":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jw9oN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"oGvjz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cfABQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ae4Cf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eYjLR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1sjQS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8UA05":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iNL0E":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eb3Rv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bJUGB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2rmW4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"k0pB5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2gIoZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1NpnF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hUmlg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1QYEq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8HmyE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"NGnm2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hE6IC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gWYrL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6SNtd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j4yCt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"f7krr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aQupJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5EDq2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9Aye4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lwlgr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1nvzk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2qTXI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5zCIO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4mI66":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6NLpn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"511FE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gqdt4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hClKp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"igIZX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8i1WR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"46Zp1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hoU7c":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fqVYe":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iWoi1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2XZDd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8cUiy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cM7qR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"475lW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"73n4n":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"c2by2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9mJPE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6RGfs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j7PuW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eZCyZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kk4Nv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bzPRi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1kEtm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"WFHvR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bgamm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gxYxl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fVEHF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2nvzC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9k33b":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4l0dG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9OlMX":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"39Us7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ehPQK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4KSsw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"74Deg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fL1oo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"32OSf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"53VLv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2w8aP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"a5hqS":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hXYOo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cH1nq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d3kaC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"idNS9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bv144":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lEV8b":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"728Pe":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jft1l":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hKXG7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4uQ53":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bm6P1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2gyIt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eci2j":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cDdsj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4x6ll":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ceUS5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5pMvA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lmNAb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kvcqD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eCBKZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gbKw9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hOyzx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"a9S06":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"792j2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"enEUn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cF5XB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8hjUo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lSHcU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"f6MuT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jJKOY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5mEWg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6i49v":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3P1PD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lVAJd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kZYqQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9Fg6X":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iEDz5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8PrrL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ftsLt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4Lp3r":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dMXRw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lkEiq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jSnmv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8Ra8F":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6KcE4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"acxjR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9yc1J":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bsxl9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Assert that the statement is true, otherwise invoke the error.
 * @param statement
 * @param error The message which is passed into an Error
 */ parcelHelpers.export(exports, "assert", ()=>assert
);
/**
 * Make sure that the given value is within the range
 */ parcelHelpers.export(exports, "assertRange", ()=>assertRange
);
/**
 * Make sure that the given value is within the range
 */ parcelHelpers.export(exports, "assertContextRunning", ()=>assertContextRunning
);
/**
 * Set the logging interface
 */ parcelHelpers.export(exports, "setLogger", ()=>setLogger
);
/**
 * Log anything
 */ parcelHelpers.export(exports, "log", ()=>log
);
/**
 * Warn anything
 */ parcelHelpers.export(exports, "warn", ()=>warn
);
function assert(statement, error) {
    if (!statement) throw new Error(error);
}
function assertRange(value, gte, lte = Infinity) {
    if (!(gte <= value && value <= lte)) throw new RangeError(`Value must be within [${gte}, ${lte}], got: ${value}`);
}
function assertContextRunning(context) {
    // add a warning if the context is not started
    if (!context.isOffline && context.state !== "running") warn("The AudioContext is \"suspended\". Invoke Tone.start() from a user action to start the audio.");
}
/**
 * The default logger is the console
 */ let defaultLogger = console;
function setLogger(logger) {
    defaultLogger = logger;
}
function log(...args) {
    defaultLogger.log(...args);
}
function warn(...args) {
    defaultLogger.warn(...args);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lCqGC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Test if the arg is undefined
 */ parcelHelpers.export(exports, "isUndef", ()=>isUndef
);
/**
 * Test if the arg is not undefined
 */ parcelHelpers.export(exports, "isDefined", ()=>isDefined
);
/**
 * Test if the arg is a function
 */ parcelHelpers.export(exports, "isFunction", ()=>isFunction
);
/**
 * Test if the argument is a number.
 */ parcelHelpers.export(exports, "isNumber", ()=>isNumber
);
/**
 * Test if the given argument is an object literal (i.e. `{}`);
 */ parcelHelpers.export(exports, "isObject", ()=>isObject
);
/**
 * Test if the argument is a boolean.
 */ parcelHelpers.export(exports, "isBoolean", ()=>isBoolean
);
/**
 * Test if the argument is an Array
 */ parcelHelpers.export(exports, "isArray", ()=>isArray
);
/**
 * Test if the argument is a string.
 */ parcelHelpers.export(exports, "isString", ()=>isString
);
/**
 * Test if the argument is in the form of a note in scientific pitch notation.
 * e.g. "C4"
 */ parcelHelpers.export(exports, "isNote", ()=>isNote
);
function isUndef(arg) {
    return typeof arg === "undefined";
}
function isDefined(arg) {
    return !isUndef(arg);
}
function isFunction(arg) {
    return typeof arg === "function";
}
function isNumber(arg) {
    return typeof arg === "number";
}
function isObject(arg) {
    return Object.prototype.toString.call(arg) === "[object Object]" && arg.constructor === Object;
}
function isBoolean(arg) {
    return typeof arg === "boolean";
}
function isArray(arg) {
    return Array.isArray(arg);
}
function isString(arg) {
    return typeof arg === "string";
}
function isNote(arg) {
    return isString(arg) && /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i.test(arg);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"44HXc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native AudioContext.
 * @category Core
 */ parcelHelpers.export(exports, "Context", ()=>Context
);
var _tslib = require("tslib");
var _ticker = require("../clock/Ticker");
var _advancedTypeCheck = require("../util/AdvancedTypeCheck");
var _defaults = require("../util/Defaults");
var _timeline = require("../util/Timeline");
var _typeCheck = require("../util/TypeCheck");
var _audioContext = require("./AudioContext");
var _contextInitialization = require("./ContextInitialization");
var _baseContext = require("./BaseContext");
var _debug = require("../util/Debug");
class Context extends _baseContext.BaseContext {
    constructor(){
        super();
        this.name = "Context";
        /**
         * An object containing all of the constants AudioBufferSourceNodes
         */ this._constants = new Map();
        /**
         * All of the setTimeout events.
         */ this._timeouts = new _timeline.Timeline();
        /**
         * The timeout id counter
         */ this._timeoutIds = 0;
        /**
         * Private indicator if the context has been initialized
         */ this._initialized = false;
        /**
         * Indicates if the context is an OfflineAudioContext or an AudioContext
         */ this.isOffline = false;
        //--------------------------------------------
        // AUDIO WORKLET
        //--------------------------------------------
        /**
         * Maps a module name to promise of the addModule method
         */ this._workletModules = new Map();
        const options1 = _defaults.optionsFromArguments(Context.getDefaults(), arguments, [
            "context", 
        ]);
        if (options1.context) this._context = options1.context;
        else this._context = _audioContext.createAudioContext({
            latencyHint: options1.latencyHint
        });
        this._ticker = new _ticker.Ticker(this.emit.bind(this, "tick"), options1.clockSource, options1.updateInterval);
        this.on("tick", this._timeoutLoop.bind(this));
        // fwd events from the context
        this._context.onstatechange = ()=>{
            this.emit("statechange", this.state);
        };
        this._setLatencyHint(options1.latencyHint);
        this.lookAhead = options1.lookAhead;
    }
    static getDefaults() {
        return {
            clockSource: "worker",
            latencyHint: "interactive",
            lookAhead: 0.1,
            updateInterval: 0.05
        };
    }
    /**
     * Finish setting up the context. **You usually do not need to do this manually.**
     */ initialize() {
        if (!this._initialized) {
            // add any additional modules
            _contextInitialization.initializeContext(this);
            this._initialized = true;
        }
        return this;
    }
    //---------------------------
    // BASE AUDIO CONTEXT METHODS
    //---------------------------
    createAnalyser() {
        return this._context.createAnalyser();
    }
    createOscillator() {
        return this._context.createOscillator();
    }
    createBufferSource() {
        return this._context.createBufferSource();
    }
    createBiquadFilter() {
        return this._context.createBiquadFilter();
    }
    createBuffer(numberOfChannels, length, sampleRate) {
        return this._context.createBuffer(numberOfChannels, length, sampleRate);
    }
    createChannelMerger(numberOfInputs) {
        return this._context.createChannelMerger(numberOfInputs);
    }
    createChannelSplitter(numberOfOutputs) {
        return this._context.createChannelSplitter(numberOfOutputs);
    }
    createConstantSource() {
        return this._context.createConstantSource();
    }
    createConvolver() {
        return this._context.createConvolver();
    }
    createDelay(maxDelayTime) {
        return this._context.createDelay(maxDelayTime);
    }
    createDynamicsCompressor() {
        return this._context.createDynamicsCompressor();
    }
    createGain() {
        return this._context.createGain();
    }
    createIIRFilter(feedForward, feedback) {
        // @ts-ignore
        return this._context.createIIRFilter(feedForward, feedback);
    }
    createPanner() {
        return this._context.createPanner();
    }
    createPeriodicWave(real, imag, constraints) {
        return this._context.createPeriodicWave(real, imag, constraints);
    }
    createStereoPanner() {
        return this._context.createStereoPanner();
    }
    createWaveShaper() {
        return this._context.createWaveShaper();
    }
    createMediaStreamSource(stream) {
        _debug.assert(_advancedTypeCheck.isAudioContext(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaStreamSource(stream);
    }
    createMediaElementSource(element) {
        _debug.assert(_advancedTypeCheck.isAudioContext(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaElementSource(element);
    }
    createMediaStreamDestination() {
        _debug.assert(_advancedTypeCheck.isAudioContext(this._context), "Not available if OfflineAudioContext");
        const context = this._context;
        return context.createMediaStreamDestination();
    }
    decodeAudioData(audioData) {
        return this._context.decodeAudioData(audioData);
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get currentTime() {
        return this._context.currentTime;
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get state() {
        return this._context.state;
    }
    /**
     * The current time in seconds of the AudioContext.
     */ get sampleRate() {
        return this._context.sampleRate;
    }
    /**
     * The listener
     */ get listener() {
        this.initialize();
        return this._listener;
    }
    set listener(l) {
        _debug.assert(!this._initialized, "The listener cannot be set after initialization.");
        this._listener = l;
    }
    /**
     * There is only one Transport per Context. It is created on initialization.
     */ get transport() {
        this.initialize();
        return this._transport;
    }
    set transport(t) {
        _debug.assert(!this._initialized, "The transport cannot be set after initialization.");
        this._transport = t;
    }
    /**
     * This is the Draw object for the context which is useful for synchronizing the draw frame with the Tone.js clock.
     */ get draw() {
        this.initialize();
        return this._draw;
    }
    set draw(d) {
        _debug.assert(!this._initialized, "Draw cannot be set after initialization.");
        this._draw = d;
    }
    /**
     * A reference to the Context's destination node.
     */ get destination() {
        this.initialize();
        return this._destination;
    }
    set destination(d) {
        _debug.assert(!this._initialized, "The destination cannot be set after initialization.");
        this._destination = d;
    }
    /**
     * Create an audio worklet node from a name and options. The module
     * must first be loaded using [[addAudioWorkletModule]].
     */ createAudioWorkletNode(name, options) {
        return _audioContext.createAudioWorkletNode(this.rawContext, name, options);
    }
    /**
     * Add an AudioWorkletProcessor module
     * @param url The url of the module
     * @param name The name of the module
     */ addAudioWorkletModule(url, name) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            _debug.assert(_typeCheck.isDefined(this.rawContext.audioWorklet), "AudioWorkletNode is only available in a secure context (https or localhost)");
            if (!this._workletModules.has(name)) this._workletModules.set(name, this.rawContext.audioWorklet.addModule(url));
            yield this._workletModules.get(name);
        });
    }
    /**
     * Returns a promise which resolves when all of the worklets have been loaded on this context
     */ workletsAreReady() {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            const promises = [];
            this._workletModules.forEach((promise)=>promises.push(promise)
            );
            yield Promise.all(promises);
        });
    }
    //---------------------------
    // TICKER
    //---------------------------
    /**
     * How often the interval callback is invoked.
     * This number corresponds to how responsive the scheduling
     * can be. context.updateInterval + context.lookAhead gives you the
     * total latency between scheduling an event and hearing it.
     */ get updateInterval() {
        return this._ticker.updateInterval;
    }
    set updateInterval(interval) {
        this._ticker.updateInterval = interval;
    }
    /**
     * What the source of the clock is, either "worker" (default),
     * "timeout", or "offline" (none).
     */ get clockSource() {
        return this._ticker.type;
    }
    set clockSource(type) {
        this._ticker.type = type;
    }
    /**
     * The type of playback, which affects tradeoffs between audio
     * output latency and responsiveness.
     * In addition to setting the value in seconds, the latencyHint also
     * accepts the strings "interactive" (prioritizes low latency),
     * "playback" (prioritizes sustained playback), "balanced" (balances
     * latency and performance).
     * @example
     * // prioritize sustained playback
     * const context = new Tone.Context({ latencyHint: "playback" });
     * // set this context as the global Context
     * Tone.setContext(context);
     * // the global context is gettable with Tone.getContext()
     * console.log(Tone.getContext().latencyHint);
     */ get latencyHint() {
        return this._latencyHint;
    }
    /**
     * Update the lookAhead and updateInterval based on the latencyHint
     */ _setLatencyHint(hint) {
        let lookAheadValue = 0;
        this._latencyHint = hint;
        if (_typeCheck.isString(hint)) switch(hint){
            case "interactive":
                lookAheadValue = 0.1;
                break;
            case "playback":
                lookAheadValue = 0.5;
                break;
            case "balanced":
                lookAheadValue = 0.25;
                break;
        }
        this.lookAhead = lookAheadValue;
        this.updateInterval = lookAheadValue / 2;
    }
    /**
     * The unwrapped AudioContext or OfflineAudioContext
     */ get rawContext() {
        return this._context;
    }
    /**
     * The current audio context time plus a short [[lookAhead]].
     */ now() {
        return this._context.currentTime + this.lookAhead;
    }
    /**
     * The current audio context time without the [[lookAhead]].
     * In most cases it is better to use [[now]] instead of [[immediate]] since
     * with [[now]] the [[lookAhead]] is applied equally to _all_ components including internal components,
     * to making sure that everything is scheduled in sync. Mixing [[now]] and [[immediate]]
     * can cause some timing issues. If no lookAhead is desired, you can set the [[lookAhead]] to `0`.
     */ immediate() {
        return this._context.currentTime;
    }
    /**
     * Starts the audio context from a suspended state. This is required
     * to initially start the AudioContext. See [[Tone.start]]
     */ resume() {
        if (_advancedTypeCheck.isAudioContext(this._context)) return this._context.resume();
        else return Promise.resolve();
    }
    /**
     * Close the context. Once closed, the context can no longer be used and
     * any AudioNodes created from the context will be silent.
     */ close() {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            if (_advancedTypeCheck.isAudioContext(this._context)) yield this._context.close();
            if (this._initialized) _contextInitialization.closeContext(this);
        });
    }
    /**
     * **Internal** Generate a looped buffer at some constant value.
     */ getConstant(val) {
        if (this._constants.has(val)) return this._constants.get(val);
        else {
            const buffer = this._context.createBuffer(1, 128, this._context.sampleRate);
            const arr = buffer.getChannelData(0);
            for(let i = 0; i < arr.length; i++)arr[i] = val;
            const constant = this._context.createBufferSource();
            constant.channelCount = 1;
            constant.channelCountMode = "explicit";
            constant.buffer = buffer;
            constant.loop = true;
            constant.start(0);
            this._constants.set(val, constant);
            return constant;
        }
    }
    /**
     * Clean up. Also closes the audio context.
     */ dispose() {
        super.dispose();
        this._ticker.dispose();
        this._timeouts.dispose();
        Object.keys(this._constants).map((val)=>this._constants[val].disconnect()
        );
        return this;
    }
    //---------------------------
    // TIMEOUTS
    //---------------------------
    /**
     * The private loop which keeps track of the context scheduled timeouts
     * Is invoked from the clock source
     */ _timeoutLoop() {
        const now = this.now();
        let firstEvent = this._timeouts.peek();
        while(this._timeouts.length && firstEvent && firstEvent.time <= now){
            // invoke the callback
            firstEvent.callback();
            // shift the first event off
            this._timeouts.shift();
            // get the next one
            firstEvent = this._timeouts.peek();
        }
    }
    /**
     * A setTimeout which is guaranteed by the clock source.
     * Also runs in the offline context.
     * @param  fn       The callback to invoke
     * @param  timeout  The timeout in seconds
     * @returns ID to use when invoking Context.clearTimeout
     */ setTimeout(fn, timeout) {
        this._timeoutIds++;
        const now = this.now();
        this._timeouts.add({
            callback: fn,
            id: this._timeoutIds,
            time: now + timeout
        });
        return this._timeoutIds;
    }
    /**
     * Clears a previously scheduled timeout with Tone.context.setTimeout
     * @param  id  The ID returned from setTimeout
     */ clearTimeout(id) {
        this._timeouts.forEach((event)=>{
            if (event.id === id) this._timeouts.remove(event);
        });
        return this;
    }
    /**
     * Clear the function scheduled by [[setInterval]]
     */ clearInterval(id) {
        return this.clearTimeout(id);
    }
    /**
     * Adds a repeating event to the context's callback clock
     */ setInterval(fn, interval) {
        const id = ++this._timeoutIds;
        const intervalFn = ()=>{
            const now = this.now();
            this._timeouts.add({
                callback: ()=>{
                    // invoke the callback
                    fn();
                    // invoke the event to repeat it
                    intervalFn();
                },
                id,
                time: now + interval
            });
        };
        // kick it off
        intervalFn();
        return id;
    }
}

},{"tslib":"bjkXk","../clock/Ticker":"fEYYi","../util/AdvancedTypeCheck":"arR2z","../util/Defaults":"kSyYt","../util/Timeline":"leurn","../util/TypeCheck":"lCqGC","./AudioContext":"6cX1c","./ContextInitialization":"6PyHY","./BaseContext":"71NXP","../util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bjkXk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "__extends", ()=>__extends
);
parcelHelpers.export(exports, "__assign", ()=>__assign
);
parcelHelpers.export(exports, "__rest", ()=>__rest
);
parcelHelpers.export(exports, "__decorate", ()=>__decorate
);
parcelHelpers.export(exports, "__param", ()=>__param
);
parcelHelpers.export(exports, "__metadata", ()=>__metadata
);
parcelHelpers.export(exports, "__awaiter", ()=>__awaiter
);
parcelHelpers.export(exports, "__generator", ()=>__generator
);
parcelHelpers.export(exports, "__createBinding", ()=>__createBinding
);
parcelHelpers.export(exports, "__exportStar", ()=>__exportStar
);
parcelHelpers.export(exports, "__values", ()=>__values
);
parcelHelpers.export(exports, "__read", ()=>__read
);
/** @deprecated */ parcelHelpers.export(exports, "__spread", ()=>__spread
);
/** @deprecated */ parcelHelpers.export(exports, "__spreadArrays", ()=>__spreadArrays
);
parcelHelpers.export(exports, "__spreadArray", ()=>__spreadArray
);
parcelHelpers.export(exports, "__await", ()=>__await
);
parcelHelpers.export(exports, "__asyncGenerator", ()=>__asyncGenerator
);
parcelHelpers.export(exports, "__asyncDelegator", ()=>__asyncDelegator
);
parcelHelpers.export(exports, "__asyncValues", ()=>__asyncValues
);
parcelHelpers.export(exports, "__makeTemplateObject", ()=>__makeTemplateObject
);
parcelHelpers.export(exports, "__importStar", ()=>__importStar
);
parcelHelpers.export(exports, "__importDefault", ()=>__importDefault
);
parcelHelpers.export(exports, "__classPrivateFieldGet", ()=>__classPrivateFieldGet
);
parcelHelpers.export(exports, "__classPrivateFieldSet", ()=>__classPrivateFieldSet
);
/*! *****************************************************************************
Copyright (c) Microsoft Corporation.

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY
AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM
LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR
OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR
PERFORMANCE OF THIS SOFTWARE.
***************************************************************************** */ /* global Reflect, Promise */ var extendStatics = function(d, b) {
    extendStatics = Object.setPrototypeOf || ({
        __proto__: []
    }) instanceof Array && function(d1, b1) {
        d1.__proto__ = b1;
    } || function(d1, b1) {
        for(var p in b1)if (Object.prototype.hasOwnProperty.call(b1, p)) d1[p] = b1[p];
    };
    return extendStatics(d, b);
};
function __extends(d, b) {
    if (typeof b !== "function" && b !== null) throw new TypeError("Class extends value " + String(b) + " is not a constructor or null");
    extendStatics(d, b);
    function __() {
        this.constructor = d;
    }
    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());
}
var __assign = function() {
    __assign = Object.assign || function __assign1(t) {
        for(var s, i = 1, n = arguments.length; i < n; i++){
            s = arguments[i];
            for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];
        }
        return t;
    };
    return __assign.apply(this, arguments);
};
function __rest(s, e) {
    var t = {
    };
    for(var p in s)if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];
    if (s != null && typeof Object.getOwnPropertySymbols === "function") for(var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++)if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];
    return t;
}
function __decorate(decorators, target, key, desc) {
    var c = arguments.length, r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc, d;
    if (typeof Reflect === "object" && typeof Reflect.decorate === "function") r = Reflect.decorate(decorators, target, key, desc);
    else for(var i = decorators.length - 1; i >= 0; i--)if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;
    return c > 3 && r && Object.defineProperty(target, key, r), r;
}
function __param(paramIndex, decorator) {
    return function(target, key) {
        decorator(target, key, paramIndex);
    };
}
function __metadata(metadataKey, metadataValue) {
    if (typeof Reflect === "object" && typeof Reflect.metadata === "function") return Reflect.metadata(metadataKey, metadataValue);
}
function __awaiter(thisArg, _arguments, P, generator) {
    function adopt(value) {
        return value instanceof P ? value : new P(function(resolve) {
            resolve(value);
        });
    }
    return new (P || (P = Promise))(function(resolve, reject) {
        function fulfilled(value) {
            try {
                step(generator.next(value));
            } catch (e) {
                reject(e);
            }
        }
        function rejected(value) {
            try {
                step(generator["throw"](value));
            } catch (e) {
                reject(e);
            }
        }
        function step(result) {
            result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected);
        }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
}
function __generator(thisArg, body) {
    var _ = {
        label: 0,
        sent: function() {
            if (t[0] & 1) throw t[1];
            return t[1];
        },
        trys: [],
        ops: []
    }, f, y, t, g;
    function verb(n) {
        return function(v) {
            return step([
                n,
                v
            ]);
        };
    }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while(_)try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [
                op[0] & 2,
                t.value
            ];
            switch(op[0]){
                case 0:
                case 1:
                    t = op;
                    break;
                case 4:
                    _.label++;
                    return {
                        value: op[1],
                        done: false
                    };
                case 5:
                    _.label++;
                    y = op[1];
                    op = [
                        0
                    ];
                    continue;
                case 7:
                    op = _.ops.pop();
                    _.trys.pop();
                    continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {
                        _ = 0;
                        continue;
                    }
                    if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {
                        _.label = op[1];
                        break;
                    }
                    if (op[0] === 6 && _.label < t[1]) {
                        _.label = t[1];
                        t = op;
                        break;
                    }
                    if (t && _.label < t[2]) {
                        _.label = t[2];
                        _.ops.push(op);
                        break;
                    }
                    if (t[2]) _.ops.pop();
                    _.trys.pop();
                    continue;
            }
            op = body.call(thisArg, _);
        } catch (e) {
            op = [
                6,
                e
            ];
            y = 0;
        } finally{
            f = t = 0;
        }
        if (op[0] & 5) throw op[1];
        return {
            value: op[0] ? op[1] : void 0,
            done: true
        };
    }
    return g = {
        next: verb(0),
        "throw": verb(1),
        "return": verb(2)
    }, typeof Symbol === "function" && (g[Symbol.iterator] = function() {
        return this;
    }), g;
}
var __createBinding = Object.create ? function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    Object.defineProperty(o, k2, {
        enumerable: true,
        get: function() {
            return m[k];
        }
    });
} : function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
};
function __exportStar(m, o) {
    for(var p in m)if (p !== "default" && !Object.prototype.hasOwnProperty.call(o, p)) __createBinding(o, m, p);
}
function __values(o) {
    var s = typeof Symbol === "function" && Symbol.iterator, m = s && o[s], i = 0;
    if (m) return m.call(o);
    if (o && typeof o.length === "number") return {
        next: function() {
            if (o && i >= o.length) o = void 0;
            return {
                value: o && o[i++],
                done: !o
            };
        }
    };
    throw new TypeError(s ? "Object is not iterable." : "Symbol.iterator is not defined.");
}
function __read(o, n) {
    var m = typeof Symbol === "function" && o[Symbol.iterator];
    if (!m) return o;
    var i = m.call(o), r, ar = [], e;
    try {
        while((n === void 0 || (n--) > 0) && !(r = i.next()).done)ar.push(r.value);
    } catch (error) {
        e = {
            error: error
        };
    } finally{
        try {
            if (r && !r.done && (m = i["return"])) m.call(i);
        } finally{
            if (e) throw e.error;
        }
    }
    return ar;
}
function __spread() {
    for(var ar = [], i = 0; i < arguments.length; i++)ar = ar.concat(__read(arguments[i]));
    return ar;
}
function __spreadArrays() {
    for(var s = 0, i = 0, il = arguments.length; i < il; i++)s += arguments[i].length;
    for(var r = Array(s), k = 0, i = 0; i < il; i++)for(var a = arguments[i], j = 0, jl = a.length; j < jl; j++, k++)r[k] = a[j];
    return r;
}
function __spreadArray(to, from, pack) {
    if (pack || arguments.length === 2) for(var i = 0, l = from.length, ar; i < l; i++)if (ar || !(i in from)) {
        if (!ar) ar = Array.prototype.slice.call(from, 0, i);
        ar[i] = from[i];
    }
    return to.concat(ar || Array.prototype.slice.call(from));
}
function __await(v) {
    return this instanceof __await ? (this.v = v, this) : new __await(v);
}
function __asyncGenerator(thisArg, _arguments, generator) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var g = generator.apply(thisArg, _arguments || []), i, q = [];
    function verb(n) {
        if (g[n]) i[n] = function(v) {
            return new Promise(function(a, b) {
                q.push([
                    n,
                    v,
                    a,
                    b
                ]) > 1 || resume(n, v);
            });
        };
    }
    function resume(n, v) {
        try {
            step(g[n](v));
        } catch (e) {
            settle(q[0][3], e);
        }
    }
    function step(r) {
        r.value instanceof __await ? Promise.resolve(r.value.v).then(fulfill, reject) : settle(q[0][2], r);
    }
    function fulfill(value) {
        resume("next", value);
    }
    function reject(value) {
        resume("throw", value);
    }
    function settle(f, v) {
        if (f(v), q.shift(), q.length) resume(q[0][0], q[0][1]);
    }
    return i = {
    }, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
        return this;
    }, i;
}
function __asyncDelegator(o) {
    var i, p;
    function verb(n, f) {
        i[n] = o[n] ? function(v) {
            return (p = !p) ? {
                value: __await(o[n](v)),
                done: n === "return"
            } : f ? f(v) : v;
        } : f;
    }
    return i = {
    }, verb("next"), verb("throw", function(e) {
        throw e;
    }), verb("return"), i[Symbol.iterator] = function() {
        return this;
    }, i;
}
function __asyncValues(o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    function verb(n) {
        i[n] = o[n] && function(v) {
            return new Promise(function(resolve, reject) {
                v = o[n](v), settle(resolve, reject, v.done, v.value);
            });
        };
    }
    function settle(resolve, reject, d, v) {
        Promise.resolve(v).then(function(v1) {
            resolve({
                value: v1,
                done: d
            });
        }, reject);
    }
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {
    }, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function() {
        return this;
    }, i);
}
function __makeTemplateObject(cooked, raw) {
    if (Object.defineProperty) Object.defineProperty(cooked, "raw", {
        value: raw
    });
    else cooked.raw = raw;
    return cooked;
}
var __setModuleDefault = Object.create ? function(o, v) {
    Object.defineProperty(o, "default", {
        enumerable: true,
        value: v
    });
} : function(o, v) {
    o["default"] = v;
};
function __importStar(mod) {
    if (mod && mod.__esModule) return mod;
    var result = {
    };
    if (mod != null) for(var k in mod)if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
}
function __importDefault(mod) {
    return mod && mod.__esModule ? mod : {
        default: mod
    };
}
function __classPrivateFieldGet(receiver, state, kind, f) {
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a getter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot read private member from an object whose class did not declare it");
    return kind === "m" ? f : kind === "a" ? f.call(receiver) : f ? f.value : state.get(receiver);
}
function __classPrivateFieldSet(receiver, state, value, kind, f) {
    if (kind === "m") throw new TypeError("Private method is not writable");
    if (kind === "a" && !f) throw new TypeError("Private accessor was defined without a setter");
    if (typeof state === "function" ? receiver !== state || !f : !state.has(receiver)) throw new TypeError("Cannot write private member to an object whose class did not declare it");
    return kind === "a" ? f.call(receiver, value) : f ? f.value = value : state.set(receiver, value), value;
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fEYYi":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A class which provides a reliable callback using either
 * a Web Worker, or if that isn't supported, falls back to setTimeout.
 */ parcelHelpers.export(exports, "Ticker", ()=>Ticker
);
class Ticker {
    constructor(callback, type1, updateInterval){
        this._callback = callback;
        this._type = type1;
        this._updateInterval = updateInterval;
        // create the clock source for the first time
        this._createClock();
    }
    /**
     * Generate a web worker
     */ _createWorker() {
        const blob = new Blob([
            /* javascript */ `\n			// the initial timeout time\n			let timeoutTime =  ${(this._updateInterval * 1000).toFixed(1)};\n			// onmessage callback\n			self.onmessage = function(msg){\n				timeoutTime = parseInt(msg.data);\n			};\n			// the tick function which posts a message\n			// and schedules a new tick\n			function tick(){\n				setTimeout(tick, timeoutTime);\n				self.postMessage('tick');\n			}\n			// call tick initially\n			tick();\n			`
        ], {
            type: "text/javascript"
        });
        const blobUrl = URL.createObjectURL(blob);
        const worker = new Worker(blobUrl);
        worker.onmessage = this._callback.bind(this);
        this._worker = worker;
    }
    /**
     * Create a timeout loop
     */ _createTimeout() {
        this._timeout = setTimeout(()=>{
            this._createTimeout();
            this._callback();
        }, this._updateInterval * 1000);
    }
    /**
     * Create the clock source.
     */ _createClock() {
        if (this._type === "worker") try {
            this._createWorker();
        } catch (e) {
            // workers not supported, fallback to timeout
            this._type = "timeout";
            this._createClock();
        }
        else if (this._type === "timeout") this._createTimeout();
    }
    /**
     * Clean up the current clock source
     */ _disposeClock() {
        if (this._timeout) {
            clearTimeout(this._timeout);
            this._timeout = 0;
        }
        if (this._worker) {
            this._worker.terminate();
            this._worker.onmessage = null;
        }
    }
    /**
     * The rate in seconds the ticker will update
     */ get updateInterval() {
        return this._updateInterval;
    }
    set updateInterval(interval) {
        this._updateInterval = Math.max(interval, 128 / 44100);
        if (this._type === "worker") this._worker.postMessage(Math.max(interval * 1000, 1));
    }
    /**
     * The type of the ticker, either a worker or a timeout
     */ get type() {
        return this._type;
    }
    set type(type) {
        this._disposeClock();
        this._type = type;
        this._createClock();
    }
    /**
     * Clean up
     */ dispose() {
        this._disposeClock();
    }
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"arR2z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Test if the given value is an instanceof AudioParam
 */ parcelHelpers.export(exports, "isAudioParam", ()=>isAudioParam
);
/**
 * Test if the given value is an instanceof AudioNode
 */ parcelHelpers.export(exports, "isAudioNode", ()=>isAudioNode
);
/**
 * Test if the arg is instanceof an OfflineAudioContext
 */ parcelHelpers.export(exports, "isOfflineAudioContext", ()=>isOfflineAudioContext
);
/**
 * Test if the arg is an instanceof AudioContext
 */ parcelHelpers.export(exports, "isAudioContext", ()=>isAudioContext
);
/**
 * Test if the arg is instanceof an AudioBuffer
 */ parcelHelpers.export(exports, "isAudioBuffer", ()=>isAudioBuffer
);
var _standardizedAudioContext = require("standardized-audio-context");
function isAudioParam(arg) {
    return _standardizedAudioContext.isAnyAudioParam(arg);
}
function isAudioNode(arg) {
    return _standardizedAudioContext.isAnyAudioNode(arg);
}
function isOfflineAudioContext(arg) {
    return _standardizedAudioContext.isAnyOfflineAudioContext(arg);
}
function isAudioContext(arg) {
    return _standardizedAudioContext.isAnyAudioContext(arg);
}
function isAudioBuffer(arg) {
    return arg instanceof AudioBuffer;
}

},{"standardized-audio-context":"ef7FQ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kSyYt":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "deepMerge", ()=>deepMerge
);
/**
 * Returns true if the two arrays have the same value for each of the elements
 */ parcelHelpers.export(exports, "deepEquals", ()=>deepEquals
);
/**
 * Convert an args array into an object.
 */ parcelHelpers.export(exports, "optionsFromArguments", ()=>optionsFromArguments
);
/**
 * Return this instances default values by calling Constructor.getDefaults()
 */ parcelHelpers.export(exports, "getDefaultsFromInstance", ()=>getDefaultsFromInstance
);
/**
 * Returns the fallback if the given object is undefined.
 * Take an array of arguments and return a formatted options object.
 */ parcelHelpers.export(exports, "defaultArg", ()=>defaultArg
);
/**
 * Remove all of the properties belonging to omit from obj.
 */ parcelHelpers.export(exports, "omitFromObject", ()=>omitFromObject
);
var _advancedTypeCheck = require("./AdvancedTypeCheck");
var _typeCheck = require("./TypeCheck");
/**
 * Some objects should not be merged
 */ function noCopy(key, arg) {
    return key === "value" || _advancedTypeCheck.isAudioParam(arg) || _advancedTypeCheck.isAudioNode(arg) || _advancedTypeCheck.isAudioBuffer(arg);
}
function deepMerge(target, ...sources) {
    if (!sources.length) return target;
    const source = sources.shift();
    if (_typeCheck.isObject(target) && _typeCheck.isObject(source)) for(const key in source){
        if (noCopy(key, source[key])) target[key] = source[key];
        else if (_typeCheck.isObject(source[key])) {
            if (!target[key]) Object.assign(target, {
                [key]: {
                }
            });
            deepMerge(target[key], source[key]);
        } else Object.assign(target, {
            [key]: source[key]
        });
    }
    // @ts-ignore
    return deepMerge(target, ...sources);
}
function deepEquals(arrayA, arrayB) {
    return arrayA.length === arrayB.length && arrayA.every((element, index)=>arrayB[index] === element
    );
}
function optionsFromArguments(defaults, argsArray, keys = [], objKey) {
    const opts = {
    };
    const args = Array.from(argsArray);
    // if the first argument is an object and has an object key
    if (_typeCheck.isObject(args[0]) && objKey && !Reflect.has(args[0], objKey)) {
        // if it's not part of the defaults
        const partOfDefaults = Object.keys(args[0]).some((key)=>Reflect.has(defaults, key)
        );
        if (!partOfDefaults) {
            // merge that key
            deepMerge(opts, {
                [objKey]: args[0]
            });
            // remove the obj key from the keys
            keys.splice(keys.indexOf(objKey), 1);
            // shift the first argument off
            args.shift();
        }
    }
    if (args.length === 1 && _typeCheck.isObject(args[0])) deepMerge(opts, args[0]);
    else {
        for(let i = 0; i < keys.length; i++)if (_typeCheck.isDefined(args[i])) opts[keys[i]] = args[i];
    }
    return deepMerge(defaults, opts);
}
function getDefaultsFromInstance(instance) {
    return instance.constructor.getDefaults();
}
function defaultArg(given, fallback) {
    if (_typeCheck.isUndef(given)) return fallback;
    else return given;
}
function omitFromObject(obj, omit) {
    omit.forEach((prop)=>{
        if (Reflect.has(obj, prop)) delete obj[prop];
    });
    return obj;
}

},{"./AdvancedTypeCheck":"arR2z","./TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"leurn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A Timeline class for scheduling and maintaining state
 * along a timeline. All events must have a "time" property.
 * Internally, events are stored in time order for fast
 * retrieval.
 */ parcelHelpers.export(exports, "Timeline", ()=>Timeline
);
var _tone = require("../Tone");
var _defaults = require("./Defaults");
var _debug = require("./Debug");
var _math = require("./Math");
class Timeline extends _tone.Tone {
    constructor(){
        super();
        this.name = "Timeline";
        /**
         * The array of scheduled timeline events
         */ this._timeline = [];
        const options = _defaults.optionsFromArguments(Timeline.getDefaults(), arguments, [
            "memory"
        ]);
        this.memory = options.memory;
        this.increasing = options.increasing;
    }
    static getDefaults() {
        return {
            memory: Infinity,
            increasing: false
        };
    }
    /**
     * The number of items in the timeline.
     */ get length() {
        return this._timeline.length;
    }
    /**
     * Insert an event object onto the timeline. Events must have a "time" attribute.
     * @param event  The event object to insert into the timeline.
     */ add(event) {
        // the event needs to have a time attribute
        _debug.assert(Reflect.has(event, "time"), "Timeline: events must have a time attribute");
        event.time = event.time.valueOf();
        if (this.increasing && this.length) {
            const lastValue = this._timeline[this.length - 1];
            _debug.assert(_math.GTE(event.time, lastValue.time), "The time must be greater than or equal to the last scheduled time");
            this._timeline.push(event);
        } else {
            const index = this._search(event.time);
            this._timeline.splice(index + 1, 0, event);
        }
        // if the length is more than the memory, remove the previous ones
        if (this.length > this.memory) {
            const diff = this.length - this.memory;
            this._timeline.splice(0, diff);
        }
        return this;
    }
    /**
     * Remove an event from the timeline.
     * @param  {Object}  event  The event object to remove from the list.
     * @returns {Timeline} this
     */ remove(event) {
        const index = this._timeline.indexOf(event);
        if (index !== -1) this._timeline.splice(index, 1);
        return this;
    }
    /**
     * Get the nearest event whose time is less than or equal to the given time.
     * @param  time  The time to query.
     */ get(time, param = "time") {
        const index = this._search(time, param);
        if (index !== -1) return this._timeline[index];
        else return null;
    }
    /**
     * Return the first event in the timeline without removing it
     * @returns {Object} The first event object
     */ peek() {
        return this._timeline[0];
    }
    /**
     * Return the first event in the timeline and remove it
     */ shift() {
        return this._timeline.shift();
    }
    /**
     * Get the event which is scheduled after the given time.
     * @param  time  The time to query.
     */ getAfter(time, param = "time") {
        const index = this._search(time, param);
        if (index + 1 < this._timeline.length) return this._timeline[index + 1];
        else return null;
    }
    /**
     * Get the event before the event at the given time.
     * @param  time  The time to query.
     */ getBefore(time) {
        const len = this._timeline.length;
        // if it's after the last item, return the last item
        if (len > 0 && this._timeline[len - 1].time < time) return this._timeline[len - 1];
        const index = this._search(time);
        if (index - 1 >= 0) return this._timeline[index - 1];
        else return null;
    }
    /**
     * Cancel events at and after the given time
     * @param  after  The time to query.
     */ cancel(after) {
        if (this._timeline.length > 1) {
            let index = this._search(after);
            if (index >= 0) {
                if (_math.EQ(this._timeline[index].time, after)) {
                    // get the first item with that time
                    for(let i = index; i >= 0; i--){
                        if (_math.EQ(this._timeline[i].time, after)) index = i;
                        else break;
                    }
                    this._timeline = this._timeline.slice(0, index);
                } else this._timeline = this._timeline.slice(0, index + 1);
            } else this._timeline = [];
        } else if (this._timeline.length === 1) // the first item's time
        {
            if (_math.GTE(this._timeline[0].time, after)) this._timeline = [];
        }
        return this;
    }
    /**
     * Cancel events before or equal to the given time.
     * @param  time  The time to cancel before.
     */ cancelBefore(time) {
        const index = this._search(time);
        if (index >= 0) this._timeline = this._timeline.slice(index + 1);
        return this;
    }
    /**
     * Returns the previous event if there is one. null otherwise
     * @param  event The event to find the previous one of
     * @return The event right before the given event
     */ previousEvent(event) {
        const index = this._timeline.indexOf(event);
        if (index > 0) return this._timeline[index - 1];
        else return null;
    }
    /**
     * Does a binary search on the timeline array and returns the
     * nearest event index whose time is after or equal to the given time.
     * If a time is searched before the first index in the timeline, -1 is returned.
     * If the time is after the end, the index of the last item is returned.
     */ _search(time, param = "time") {
        if (this._timeline.length === 0) return -1;
        let beginning = 0;
        const len = this._timeline.length;
        let end = len;
        if (len > 0 && this._timeline[len - 1][param] <= time) return len - 1;
        while(beginning < end){
            // calculate the midpoint for roughly equal partition
            let midPoint = Math.floor(beginning + (end - beginning) / 2);
            const event = this._timeline[midPoint];
            const nextEvent = this._timeline[midPoint + 1];
            if (_math.EQ(event[param], time)) {
                // choose the last one that has the same time
                for(let i = midPoint; i < this._timeline.length; i++){
                    const testEvent = this._timeline[i];
                    if (_math.EQ(testEvent[param], time)) midPoint = i;
                    else break;
                }
                return midPoint;
            } else if (_math.LT(event[param], time) && _math.GT(nextEvent[param], time)) return midPoint;
            else if (_math.GT(event[param], time)) // search lower
            end = midPoint;
            else // search upper
            beginning = midPoint + 1;
        }
        return -1;
    }
    /**
     * Internal iterator. Applies extra safety checks for
     * removing items from the array.
     */ _iterate(callback, lowerBound = 0, upperBound = this._timeline.length - 1) {
        this._timeline.slice(lowerBound, upperBound + 1).forEach(callback);
    }
    /**
     * Iterate over everything in the array
     * @param  callback The callback to invoke with every item
     */ forEach(callback) {
        this._iterate(callback);
        return this;
    }
    /**
     * Iterate over everything in the array at or before the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachBefore(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const upperBound = this._search(time);
        if (upperBound !== -1) this._iterate(callback, 0, upperBound);
        return this;
    }
    /**
     * Iterate over everything in the array after the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachAfter(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const lowerBound = this._search(time);
        this._iterate(callback, lowerBound + 1);
        return this;
    }
    /**
     * Iterate over everything in the array between the startTime and endTime.
     * The timerange is inclusive of the startTime, but exclusive of the endTime.
     * range = [startTime, endTime).
     * @param  startTime The time to check if items are before
     * @param  endTime The end of the test interval.
     * @param  callback The callback to invoke with every item
     */ forEachBetween(startTime, endTime, callback) {
        let lowerBound = this._search(startTime);
        let upperBound = this._search(endTime);
        if (lowerBound !== -1 && upperBound !== -1) {
            if (this._timeline[lowerBound].time !== startTime) lowerBound += 1;
            // exclusive of the end time
            if (this._timeline[upperBound].time === endTime) upperBound -= 1;
            this._iterate(callback, lowerBound, upperBound);
        } else if (lowerBound === -1) this._iterate(callback, 0, upperBound);
        return this;
    }
    /**
     * Iterate over everything in the array at or after the given time. Similar to
     * forEachAfter, but includes the item(s) at the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachFrom(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        let lowerBound = this._search(time);
        // work backwards until the event time is less than time
        while(lowerBound >= 0 && this._timeline[lowerBound].time >= time)lowerBound--;
        this._iterate(callback, lowerBound + 1);
        return this;
    }
    /**
     * Iterate over everything in the array at the given time
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachAtTime(time, callback) {
        // iterate over the items in reverse so that removing an item doesn't break things
        const upperBound = this._search(time);
        if (upperBound !== -1 && _math.EQ(this._timeline[upperBound].time, time)) {
            let lowerBound = upperBound;
            for(let i = upperBound; i >= 0; i--){
                if (_math.EQ(this._timeline[i].time, time)) lowerBound = i;
                else break;
            }
            this._iterate((event)=>{
                callback(event);
            }, lowerBound, upperBound);
        }
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._timeline = [];
        return this;
    }
}

},{"../Tone":"dTzBa","./Defaults":"kSyYt","./Debug":"bsxl9","./Math":"gdhOV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dTzBa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * @class  Tone is the base class of all other classes.
 * @category Core
 * @constructor
 */ parcelHelpers.export(exports, "Tone", ()=>Tone
);
/**
 * Tone.js
 * @author Yotam Mann
 * @license http://opensource.org/licenses/MIT MIT License
 * @copyright 2014-2019 Yotam Mann
 */ var _version = require("../version");
var _audioContext = require("./context/AudioContext");
var _debug = require("./util/Debug");
class Tone {
    constructor(){
        //-------------------------------------
        // 	DEBUGGING
        //-------------------------------------
        /**
         * Set this debug flag to log all events that happen in this class.
         */ this.debug = false;
        //-------------------------------------
        // 	DISPOSING
        //-------------------------------------
        /**
         * Indicates if the instance was disposed
         */ this._wasDisposed = false;
    }
    /**
     * Returns all of the default options belonging to the class.
     */ static getDefaults() {
        return {
        };
    }
    /**
     * Prints the outputs to the console log for debugging purposes.
     * Prints the contents only if either the object has a property
     * called `debug` set to true, or a variable called TONE_DEBUG_CLASS
     * is set to the name of the class.
     * @example
     * const osc = new Tone.Oscillator();
     * // prints all logs originating from this oscillator
     * osc.debug = true;
     * // calls to start/stop will print in the console
     * osc.start();
     */ log(...args) {
        // if the object is either set to debug = true
        // or if there is a string on the Tone.global.with the class name
        if (this.debug || _audioContext.theWindow && this.toString() === _audioContext.theWindow.TONE_DEBUG_CLASS) _debug.log(this, ...args);
    }
    /**
     * disconnect and dispose.
     */ dispose() {
        this._wasDisposed = true;
        return this;
    }
    /**
     * Indicates if the instance was disposed. 'Disposing' an
     * instance means that all of the Web Audio nodes that were
     * created for the instance are disconnected and freed for garbage collection.
     */ get disposed() {
        return this._wasDisposed;
    }
    /**
     * Convert the class to a string
     * @example
     * const osc = new Tone.Oscillator();
     * console.log(osc.toString());
     */ toString() {
        return this.name;
    }
}
/**
 * The version number semver
 */ Tone.version = _version.version;

},{"../version":"hDknC","./context/AudioContext":"6cX1c","./util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gdhOV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Test if A is greater than B
 */ parcelHelpers.export(exports, "GT", ()=>GT
);
/**
 * Test if A is greater than or equal to B
 */ parcelHelpers.export(exports, "GTE", ()=>GTE
);
/**
 * Test if A is less than B
 */ parcelHelpers.export(exports, "LT", ()=>LT
);
/**
 * Test if A is less than B
 */ parcelHelpers.export(exports, "EQ", ()=>EQ
);
/**
 * Clamp the value within the given range
 */ parcelHelpers.export(exports, "clamp", ()=>clamp
);
/**
 * The threshold for correctness for operators. Less than one sample even
 * at very high sampling rates (e.g. `1e-6 < 1 / 192000`).
 */ const EPSILON = 0.000001;
function GT(a, b) {
    return a > b + EPSILON;
}
function GTE(a, b) {
    return GT(a, b) || EQ(a, b);
}
function LT(a, b) {
    return a + EPSILON < b;
}
function EQ(a, b) {
    return Math.abs(a - b) < EPSILON;
}
function clamp(value, min, max) {
    return Math.max(Math.min(value, max), min);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6PyHY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Used internally to setup a new Context
 */ parcelHelpers.export(exports, "onContextInit", ()=>onContextInit
);
/**
 * Invoke any classes which need to also be initialized when a new context is created.
 */ parcelHelpers.export(exports, "initializeContext", ()=>initializeContext
);
/**
 * Used internally to tear down a Context
 */ parcelHelpers.export(exports, "onContextClose", ()=>onContextClose
);
parcelHelpers.export(exports, "closeContext", ()=>closeContext
);
//-------------------------------------
// INITIALIZING NEW CONTEXT
//-------------------------------------
/**
 * Array of callbacks to invoke when a new context is created
 */ const notifyNewContext = [];
function onContextInit(cb) {
    notifyNewContext.push(cb);
}
function initializeContext(ctx) {
    // add any additional modules
    notifyNewContext.forEach((cb)=>cb(ctx)
    );
}
/**
 * Array of callbacks to invoke when a new context is created
 */ const notifyCloseContext = [];
function onContextClose(cb) {
    notifyCloseContext.push(cb);
}
function closeContext(ctx) {
    // add any additional modules
    notifyCloseContext.forEach((cb)=>cb(ctx)
    );
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"71NXP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "BaseContext", ()=>BaseContext
);
var _emitter = require("../util/Emitter");
class BaseContext extends _emitter.Emitter {
    constructor(){
        super(...arguments);
        this.isOffline = false;
    }
    /*
     * This is a placeholder so that JSON.stringify does not throw an error
     * This matches what JSON.stringify(audioContext) returns on a native
     * audioContext instance.
     */ toJSON() {
        return {
        };
    }
}

},{"../util/Emitter":"bzta6","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bzta6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Emitter gives classes which extend it
 * the ability to listen for and emit events.
 * Inspiration and reference from Jerome Etienne's [MicroEvent](https://github.com/jeromeetienne/microevent.js).
 * MIT (c) 2011 Jerome Etienne.
 * @category Core
 */ parcelHelpers.export(exports, "Emitter", ()=>Emitter
);
var _tone = require("../Tone");
var _typeCheck = require("./TypeCheck");
class Emitter extends _tone.Tone {
    constructor(){
        super(...arguments);
        this.name = "Emitter";
    }
    /**
     * Bind a callback to a specific event.
     * @param  event     The name of the event to listen for.
     * @param  callback  The callback to invoke when the event is emitted
     */ on(event, callback) {
        // split the event
        const events = event.split(/\W+/);
        events.forEach((eventName)=>{
            if (_typeCheck.isUndef(this._events)) this._events = {
            };
            if (!this._events.hasOwnProperty(eventName)) this._events[eventName] = [];
            this._events[eventName].push(callback);
        });
        return this;
    }
    /**
     * Bind a callback which is only invoked once
     * @param  event     The name of the event to listen for.
     * @param  callback  The callback to invoke when the event is emitted
     */ once(event, callback) {
        const boundCallback = (...args)=>{
            // invoke the callback
            callback(...args);
            // remove the event
            this.off(event, boundCallback);
        };
        this.on(event, boundCallback);
        return this;
    }
    /**
     * Remove the event listener.
     * @param  event     The event to stop listening to.
     * @param  callback  The callback which was bound to the event with Emitter.on.
     *                   If no callback is given, all callbacks events are removed.
     */ off(event, callback) {
        const events = event.split(/\W+/);
        events.forEach((eventName)=>{
            if (_typeCheck.isUndef(this._events)) this._events = {
            };
            if (this._events.hasOwnProperty(event)) {
                if (_typeCheck.isUndef(callback)) this._events[event] = [];
                else {
                    const eventList = this._events[event];
                    for(let i = eventList.length - 1; i >= 0; i--)if (eventList[i] === callback) eventList.splice(i, 1);
                }
            }
        });
        return this;
    }
    /**
     * Invoke all of the callbacks bound to the event
     * with any arguments passed in.
     * @param  event  The name of the event.
     * @param args The arguments to pass to the functions listening.
     */ emit(event, ...args) {
        if (this._events) {
            if (this._events.hasOwnProperty(event)) {
                const eventList = this._events[event].slice(0);
                for(let i = 0, len = eventList.length; i < len; i++)eventList[i].apply(this, args);
            }
        }
        return this;
    }
    /**
     * Add Emitter functions (on/off/emit) to the object
     */ static mixin(constr) {
        // instance._events = {};
        [
            "on",
            "once",
            "off",
            "emit"
        ].forEach((name)=>{
            const property = Object.getOwnPropertyDescriptor(Emitter.prototype, name);
            Object.defineProperty(constr.prototype, name, property);
        });
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._events = undefined;
        return this;
    }
}

},{"../Tone":"dTzBa","./TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6ANrT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "DummyContext", ()=>DummyContext
);
var _tslib = require("tslib");
var _baseContext = require("./BaseContext");
class DummyContext extends _baseContext.BaseContext {
    constructor(){
        super(...arguments);
        this.lookAhead = 0;
        this.latencyHint = 0;
        this.isOffline = false;
    }
    //---------------------------
    // BASE AUDIO CONTEXT METHODS
    //---------------------------
    createAnalyser() {
        return {
        };
    }
    createOscillator() {
        return {
        };
    }
    createBufferSource() {
        return {
        };
    }
    createBiquadFilter() {
        return {
        };
    }
    createBuffer(_numberOfChannels, _length, _sampleRate) {
        return {
        };
    }
    createChannelMerger(_numberOfInputs) {
        return {
        };
    }
    createChannelSplitter(_numberOfOutputs) {
        return {
        };
    }
    createConstantSource() {
        return {
        };
    }
    createConvolver() {
        return {
        };
    }
    createDelay(_maxDelayTime) {
        return {
        };
    }
    createDynamicsCompressor() {
        return {
        };
    }
    createGain() {
        return {
        };
    }
    createIIRFilter(_feedForward, _feedback) {
        return {
        };
    }
    createPanner() {
        return {
        };
    }
    createPeriodicWave(_real, _imag, _constraints) {
        return {
        };
    }
    createStereoPanner() {
        return {
        };
    }
    createWaveShaper() {
        return {
        };
    }
    createMediaStreamSource(_stream) {
        return {
        };
    }
    createMediaElementSource(_element) {
        return {
        };
    }
    createMediaStreamDestination() {
        return {
        };
    }
    decodeAudioData(_audioData) {
        return Promise.resolve({
        });
    }
    //---------------------------
    // TONE AUDIO CONTEXT METHODS
    //---------------------------
    createAudioWorkletNode(_name, _options) {
        return {
        };
    }
    get rawContext() {
        return {
        };
    }
    addAudioWorkletModule(_url, _name) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            return Promise.resolve();
        });
    }
    resume() {
        return Promise.resolve();
    }
    setTimeout(_fn, _timeout) {
        return 0;
    }
    clearTimeout(_id) {
        return this;
    }
    setInterval(_fn, _interval) {
        return 0;
    }
    clearInterval(_id) {
        return this;
    }
    getConstant(_val) {
        return {
        };
    }
    get currentTime() {
        return 0;
    }
    get state() {
        return {
        };
    }
    get sampleRate() {
        return 0;
    }
    get listener() {
        return {
        };
    }
    get transport() {
        return {
        };
    }
    get draw() {
        return {
        };
    }
    set draw(_d) {
    }
    get destination() {
        return {
        };
    }
    set destination(_d) {
    }
    now() {
        return 0;
    }
    immediate() {
        return 0;
    }
}

},{"tslib":"bjkXk","./BaseContext":"71NXP","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"KYtWQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the OfflineAudioContext
 * @category Core
 * @example
 * // generate a single channel, 0.5 second buffer
 * const context = new Tone.OfflineContext(1, 0.5, 44100);
 * const osc = new Tone.Oscillator({ context });
 * context.render().then(buffer => {
 * 	console.log(buffer.numberOfChannels, buffer.duration);
 * });
 */ parcelHelpers.export(exports, "OfflineContext", ()=>OfflineContext
);
var _tslib = require("tslib");
var _audioContext = require("../context/AudioContext");
var _context = require("../context/Context");
var _advancedTypeCheck = require("../util/AdvancedTypeCheck");
var _toneAudioBuffer = require("./ToneAudioBuffer");
class OfflineContext extends _context.Context {
    constructor(){
        super({
            clockSource: "offline",
            context: _advancedTypeCheck.isOfflineAudioContext(arguments[0]) ? arguments[0] : _audioContext.createOfflineAudioContext(arguments[0], arguments[1] * arguments[2], arguments[2]),
            lookAhead: 0,
            updateInterval: _advancedTypeCheck.isOfflineAudioContext(arguments[0]) ? 128 / arguments[0].sampleRate : 128 / arguments[2]
        });
        this.name = "OfflineContext";
        /**
         * An artificial clock source
         */ this._currentTime = 0;
        this.isOffline = true;
        this._duration = _advancedTypeCheck.isOfflineAudioContext(arguments[0]) ? arguments[0].length / arguments[0].sampleRate : arguments[1];
    }
    /**
     * Override the now method to point to the internal clock time
     */ now() {
        return this._currentTime;
    }
    /**
     * Same as this.now()
     */ get currentTime() {
        return this._currentTime;
    }
    /**
     * Render just the clock portion of the audio context.
     */ _renderClock(asynchronous) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            let index = 0;
            while(this._duration - this._currentTime >= 0){
                // invoke all the callbacks on that time
                this.emit("tick");
                // increment the clock in block-sized chunks
                this._currentTime += 128 / this.sampleRate;
                // yield once a second of audio
                index++;
                const yieldEvery = Math.floor(this.sampleRate / 128);
                if (asynchronous && index % yieldEvery === 0) yield new Promise((done)=>setTimeout(done, 1)
                );
            }
        });
    }
    /**
     * Render the output of the OfflineContext
     * @param asynchronous If the clock should be rendered asynchronously, which will not block the main thread, but be slightly slower.
     */ render(asynchronous = true) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            yield this.workletsAreReady();
            yield this._renderClock(asynchronous);
            const buffer = yield this._context.startRendering();
            return new _toneAudioBuffer.ToneAudioBuffer(buffer);
        });
    }
    /**
     * Close the context
     */ close() {
        return Promise.resolve();
    }
}

},{"tslib":"bjkXk","../context/AudioContext":"6cX1c","../context/Context":"44HXc","../util/AdvancedTypeCheck":"arR2z","./ToneAudioBuffer":"gpPIV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gpPIV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AudioBuffer loading and storage. ToneAudioBuffer is used internally by all
 * classes that make requests for audio files such as Tone.Player,
 * Tone.Sampler and Tone.Convolver.
 * @example
 * const buffer = new Tone.ToneAudioBuffer("https://tonejs.github.io/audio/casio/A1.mp3", () => {
 * 	console.log("loaded");
 * });
 * @category Core
 */ parcelHelpers.export(exports, "ToneAudioBuffer", ()=>ToneAudioBuffer
);
var _tslib = require("tslib");
var _global = require("../Global");
var _tone = require("../Tone");
var _advancedTypeCheck = require("../util/AdvancedTypeCheck");
var _defaults = require("../util/Defaults");
var _interface = require("../util/Interface");
var _typeCheck = require("../util/TypeCheck");
var _debug = require("../util/Debug");
class ToneAudioBuffer extends _tone.Tone {
    constructor(){
        super();
        this.name = "ToneAudioBuffer";
        /**
         * Callback when the buffer is loaded.
         */ this.onload = _interface.noOp;
        const options = _defaults.optionsFromArguments(ToneAudioBuffer.getDefaults(), arguments, [
            "url",
            "onload",
            "onerror"
        ]);
        this.reverse = options.reverse;
        this.onload = options.onload;
        if (options.url && _advancedTypeCheck.isAudioBuffer(options.url) || options.url instanceof ToneAudioBuffer) this.set(options.url);
        else if (_typeCheck.isString(options.url)) // initiate the download
        this.load(options.url).catch(options.onerror);
    }
    static getDefaults() {
        return {
            onerror: _interface.noOp,
            onload: _interface.noOp,
            reverse: false
        };
    }
    /**
     * The sample rate of the AudioBuffer
     */ get sampleRate() {
        if (this._buffer) return this._buffer.sampleRate;
        else return _global.getContext().sampleRate;
    }
    /**
     * Pass in an AudioBuffer or ToneAudioBuffer to set the value of this buffer.
     */ set(buffer) {
        if (buffer instanceof ToneAudioBuffer) {
            // if it's loaded, set it
            if (buffer.loaded) this._buffer = buffer.get();
            else // otherwise when it's loaded, invoke it's callback
            buffer.onload = ()=>{
                this.set(buffer);
                this.onload(this);
            };
        } else this._buffer = buffer;
        // reverse it initially
        if (this._reversed) this._reverse();
        return this;
    }
    /**
     * The audio buffer stored in the object.
     */ get() {
        return this._buffer;
    }
    /**
     * Makes an fetch request for the selected url then decodes the file as an audio buffer.
     * Invokes the callback once the audio buffer loads.
     * @param url The url of the buffer to load. filetype support depends on the browser.
     * @returns A Promise which resolves with this ToneAudioBuffer
     */ load(url) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            const doneLoading = ToneAudioBuffer.load(url).then((audioBuffer)=>{
                this.set(audioBuffer);
                // invoke the onload method
                this.onload(this);
            });
            ToneAudioBuffer.downloads.push(doneLoading);
            try {
                yield doneLoading;
            } finally{
                // remove the downloaded file
                const index = ToneAudioBuffer.downloads.indexOf(doneLoading);
                ToneAudioBuffer.downloads.splice(index, 1);
            }
            return this;
        });
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._buffer = undefined;
        return this;
    }
    /**
     * Set the audio buffer from the array.
     * To create a multichannel AudioBuffer, pass in a multidimensional array.
     * @param array The array to fill the audio buffer
     */ fromArray(array) {
        const isMultidimensional = _typeCheck.isArray(array) && array[0].length > 0;
        const channels = isMultidimensional ? array.length : 1;
        const len = isMultidimensional ? array[0].length : array.length;
        const context = _global.getContext();
        const buffer = context.createBuffer(channels, len, context.sampleRate);
        const multiChannelArray = !isMultidimensional && channels === 1 ? [
            array
        ] : array;
        for(let c = 0; c < channels; c++)buffer.copyToChannel(multiChannelArray[c], c);
        this._buffer = buffer;
        return this;
    }
    /**
     * Sums multiple channels into 1 channel
     * @param chanNum Optionally only copy a single channel from the array.
     */ toMono(chanNum) {
        if (_typeCheck.isNumber(chanNum)) this.fromArray(this.toArray(chanNum));
        else {
            let outputArray = new Float32Array(this.length);
            const numChannels = this.numberOfChannels;
            for(let channel = 0; channel < numChannels; channel++){
                const channelArray = this.toArray(channel);
                for(let i = 0; i < channelArray.length; i++)outputArray[i] += channelArray[i];
            }
            // divide by the number of channels
            outputArray = outputArray.map((sample)=>sample / numChannels
            );
            this.fromArray(outputArray);
        }
        return this;
    }
    /**
     * Get the buffer as an array. Single channel buffers will return a 1-dimensional
     * Float32Array, and multichannel buffers will return multidimensional arrays.
     * @param channel Optionally only copy a single channel from the array.
     */ toArray(channel) {
        if (_typeCheck.isNumber(channel)) return this.getChannelData(channel);
        else if (this.numberOfChannels === 1) return this.toArray(0);
        else {
            const ret = [];
            for(let c = 0; c < this.numberOfChannels; c++)ret[c] = this.getChannelData(c);
            return ret;
        }
    }
    /**
     * Returns the Float32Array representing the PCM audio data for the specific channel.
     * @param  channel  The channel number to return
     * @return The audio as a TypedArray
     */ getChannelData(channel) {
        if (this._buffer) return this._buffer.getChannelData(channel);
        else return new Float32Array(0);
    }
    /**
     * Cut a subsection of the array and return a buffer of the
     * subsection. Does not modify the original buffer
     * @param start The time to start the slice
     * @param end The end time to slice. If none is given will default to the end of the buffer
     */ slice(start, end = this.duration) {
        const startSamples = Math.floor(start * this.sampleRate);
        const endSamples = Math.floor(end * this.sampleRate);
        _debug.assert(startSamples < endSamples, "The start time must be less than the end time");
        const length = endSamples - startSamples;
        const retBuffer = _global.getContext().createBuffer(this.numberOfChannels, length, this.sampleRate);
        for(let channel = 0; channel < this.numberOfChannels; channel++)retBuffer.copyToChannel(this.getChannelData(channel).subarray(startSamples, endSamples), channel);
        return new ToneAudioBuffer(retBuffer);
    }
    /**
     * Reverse the buffer.
     */ _reverse() {
        if (this.loaded) for(let i = 0; i < this.numberOfChannels; i++)this.getChannelData(i).reverse();
        return this;
    }
    /**
     * If the buffer is loaded or not
     */ get loaded() {
        return this.length > 0;
    }
    /**
     * The duration of the buffer in seconds.
     */ get duration() {
        if (this._buffer) return this._buffer.duration;
        else return 0;
    }
    /**
     * The length of the buffer in samples
     */ get length() {
        if (this._buffer) return this._buffer.length;
        else return 0;
    }
    /**
     * The number of discrete audio channels. Returns 0 if no buffer is loaded.
     */ get numberOfChannels() {
        if (this._buffer) return this._buffer.numberOfChannels;
        else return 0;
    }
    /**
     * Reverse the buffer.
     */ get reverse() {
        return this._reversed;
    }
    set reverse(rev) {
        if (this._reversed !== rev) {
            this._reversed = rev;
            this._reverse();
        }
    }
    /**
     * Create a ToneAudioBuffer from the array. To create a multichannel AudioBuffer,
     * pass in a multidimensional array.
     * @param array The array to fill the audio buffer
     * @return A ToneAudioBuffer created from the array
     */ static fromArray(array) {
        return new ToneAudioBuffer().fromArray(array);
    }
    /**
     * Creates a ToneAudioBuffer from a URL, returns a promise which resolves to a ToneAudioBuffer
     * @param  url The url to load.
     * @return A promise which resolves to a ToneAudioBuffer
     */ static fromUrl(url) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            const buffer = new ToneAudioBuffer();
            return yield buffer.load(url);
        });
    }
    /**
     * Loads a url using fetch and returns the AudioBuffer.
     */ static load(url) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            // test if the url contains multiple extensions
            const matches = url.match(/\[([^\]\[]+\|.+)\]$/);
            if (matches) {
                const extensions = matches[1].split("|");
                let extension = extensions[0];
                for (const ext of extensions)if (ToneAudioBuffer.supportsType(ext)) {
                    extension = ext;
                    break;
                }
                url = url.replace(matches[0], extension);
            }
            // make sure there is a slash between the baseUrl and the url
            const baseUrl = ToneAudioBuffer.baseUrl === "" || ToneAudioBuffer.baseUrl.endsWith("/") ? ToneAudioBuffer.baseUrl : ToneAudioBuffer.baseUrl + "/";
            const response = yield fetch(baseUrl + url);
            if (!response.ok) throw new Error(`could not load url: ${url}`);
            const arrayBuffer = yield response.arrayBuffer();
            const audioBuffer = yield _global.getContext().decodeAudioData(arrayBuffer);
            return audioBuffer;
        });
    }
    /**
     * Checks a url's extension to see if the current browser can play that file type.
     * @param url The url/extension to test
     * @return If the file extension can be played
     * @static
     * @example
     * Tone.ToneAudioBuffer.supportsType("wav"); // returns true
     * Tone.ToneAudioBuffer.supportsType("path/to/file.wav"); // returns true
     */ static supportsType(url) {
        const extensions = url.split(".");
        const extension = extensions[extensions.length - 1];
        const response = document.createElement("audio").canPlayType("audio/" + extension);
        return response !== "";
    }
    /**
     * Returns a Promise which resolves when all of the buffers have loaded
     */ static loaded() {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            // this makes sure that the function is always async
            yield Promise.resolve();
            while(ToneAudioBuffer.downloads.length)yield ToneAudioBuffer.downloads[0];
        });
    }
}
//-------------------------------------
// STATIC METHODS
//-------------------------------------
/**
 * A path which is prefixed before every url.
 */ ToneAudioBuffer.baseUrl = "";
/**
 * All of the downloads
 */ ToneAudioBuffer.downloads = [];

},{"tslib":"bjkXk","../Global":"6b8rd","../Tone":"dTzBa","../util/AdvancedTypeCheck":"arR2z","../util/Defaults":"kSyYt","../util/Interface":"fVoXs","../util/TypeCheck":"lCqGC","../util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fVoXs":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Make the property not writable using `defineProperty`. Internal use only.
 */ parcelHelpers.export(exports, "readOnly", ()=>readOnly
);
/**
 * Make an attribute writeable. Internal use only.
 */ parcelHelpers.export(exports, "writable", ()=>writable
);
parcelHelpers.export(exports, "noOp", ()=>noOp
);
var _typeCheck = require("./TypeCheck");
function readOnly(target, property) {
    if (_typeCheck.isArray(property)) property.forEach((str)=>readOnly(target, str)
    );
    else Object.defineProperty(target, property, {
        enumerable: true,
        writable: false
    });
}
function writable(target, property) {
    if (_typeCheck.isArray(property)) property.forEach((str)=>writable(target, str)
    );
    else Object.defineProperty(target, property, {
        writable: true
    });
}
const noOp = ()=>{
// no operation here!
};

},{"./TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bm3Bk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _index = require("./core/index");
parcelHelpers.exportAll(_index, exports);
var _index1 = require("./source/index");
parcelHelpers.exportAll(_index1, exports);
var _index2 = require("./signal/index");
parcelHelpers.exportAll(_index2, exports);
var _index3 = require("./instrument/index");
parcelHelpers.exportAll(_index3, exports);
var _index4 = require("./event/index");
parcelHelpers.exportAll(_index4, exports);
var _index5 = require("./effect/index");
parcelHelpers.exportAll(_index5, exports);
var _index6 = require("./component/index");
parcelHelpers.exportAll(_index6, exports);

},{"./core/index":"fb4eU","./source/index":"IrCGx","./signal/index":"kD2C3","./instrument/index":"13JoI","./event/index":"701IP","./effect/index":"9Z6bM","./component/index":"42PNa","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fb4eU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "dbToGain", ()=>_conversions.dbToGain
);
parcelHelpers.export(exports, "gainToDb", ()=>_conversions.gainToDb
);
parcelHelpers.export(exports, "intervalToFrequencyRatio", ()=>_conversions.intervalToFrequencyRatio
);
parcelHelpers.export(exports, "ftom", ()=>_conversions.ftom
);
parcelHelpers.export(exports, "mtof", ()=>_conversions.mtof
);
parcelHelpers.export(exports, "optionsFromArguments", ()=>_defaults.optionsFromArguments
);
parcelHelpers.export(exports, "defaultArg", ()=>_defaults.defaultArg
);
parcelHelpers.export(exports, "Unit", ()=>_units
);
parcelHelpers.export(exports, "debug", ()=>_debug
);
var _draw = require("./util/Draw");
// get the units and export them under the "Unit" namespace
var _units = require("./type/Units");
// export the debug stuff as Debug
var _debug = require("./util/Debug");
var _clock = require("./clock/Clock");
parcelHelpers.exportAll(_clock, exports);
// export * from "./clock/Transport";
var _context = require("./context/Context");
parcelHelpers.exportAll(_context, exports);
var _baseContext = require("./context/BaseContext");
parcelHelpers.exportAll(_baseContext, exports);
var _delay = require("./context/Delay");
parcelHelpers.exportAll(_delay, exports);
// export * from "./context/Destination";
var _gain = require("./context/Gain");
parcelHelpers.exportAll(_gain, exports);
var _offline = require("./context/Offline");
parcelHelpers.exportAll(_offline, exports);
var _offlineContext = require("./context/OfflineContext");
parcelHelpers.exportAll(_offlineContext, exports);
var _param = require("./context/Param");
parcelHelpers.exportAll(_param, exports);
var _toneAudioBuffer = require("./context/ToneAudioBuffer");
parcelHelpers.exportAll(_toneAudioBuffer, exports);
var _toneAudioBuffers = require("./context/ToneAudioBuffers");
parcelHelpers.exportAll(_toneAudioBuffers, exports);
var _toneAudioNode = require("./context/ToneAudioNode");
parcelHelpers.exportAll(_toneAudioNode, exports);
var _frequency = require("./type/Frequency");
parcelHelpers.exportAll(_frequency, exports);
var _midi = require("./type/Midi");
parcelHelpers.exportAll(_midi, exports);
var _time = require("./type/Time");
parcelHelpers.exportAll(_time, exports);
var _ticks = require("./type/Ticks");
parcelHelpers.exportAll(_ticks, exports);
var _transportTime = require("./type/TransportTime");
parcelHelpers.exportAll(_transportTime, exports);
var _emitter = require("./util/Emitter");
parcelHelpers.exportAll(_emitter, exports);
var _intervalTimeline = require("./util/IntervalTimeline");
parcelHelpers.exportAll(_intervalTimeline, exports);
var _stateTimeline = require("./util/StateTimeline");
parcelHelpers.exportAll(_stateTimeline, exports);
var _timeline = require("./util/Timeline");
parcelHelpers.exportAll(_timeline, exports);
var _typeCheck = require("./util/TypeCheck");
parcelHelpers.exportAll(_typeCheck, exports);
var _conversions = require("./type/Conversions");
var _defaults = require("./util/Defaults");

},{"./clock/Clock":"2WJVT","./context/Context":"44HXc","./context/BaseContext":"71NXP","./context/Delay":"fGWul","./context/Gain":"7kpMn","./context/Offline":"jt41T","./context/OfflineContext":"KYtWQ","./context/Param":"2qxaM","./context/ToneAudioBuffer":"gpPIV","./context/ToneAudioBuffers":"g1eoF","./context/ToneAudioNode":"iT1SZ","./type/Frequency":"b1aPl","./type/Midi":"6VA3d","./type/Time":"1HtHW","./type/Ticks":"8zKuk","./type/TransportTime":"kcsdx","./util/Draw":"4l3Cj","./util/Emitter":"bzta6","./util/IntervalTimeline":"EpXgL","./util/StateTimeline":"am3qa","./util/Timeline":"leurn","./util/TypeCheck":"lCqGC","./type/Conversions":"kOcnG","./util/Defaults":"kSyYt","./type/Units":"7oXrx","./util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2WJVT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A sample accurate clock which provides a callback at the given rate.
 * While the callback is not sample-accurate (it is still susceptible to
 * loose JS timing), the time passed in as the argument to the callback
 * is precise. For most applications, it is better to use Tone.Transport
 * instead of the Clock by itself since you can synchronize multiple callbacks.
 * @example
 * // the callback will be invoked approximately once a second
 * // and will print the time exactly once a second apart.
 * const clock = new Tone.Clock(time => {
 * 	console.log(time);
 * }, 1);
 * clock.start();
 * @category Core
 */ parcelHelpers.export(exports, "Clock", ()=>Clock
);
var _toneWithContext = require("../context/ToneWithContext");
var _defaults = require("../util/Defaults");
var _emitter = require("../util/Emitter");
var _interface = require("../util/Interface");
var _stateTimeline = require("../util/StateTimeline");
var _tickSource = require("./TickSource");
var _debug = require("../util/Debug");
class Clock extends _toneWithContext.ToneWithContext {
    constructor(){
        super(_defaults.optionsFromArguments(Clock.getDefaults(), arguments, [
            "callback",
            "frequency"
        ]));
        this.name = "Clock";
        /**
         * The callback function to invoke at the scheduled tick.
         */ this.callback = _interface.noOp;
        /**
         * The last time the loop callback was invoked
         */ this._lastUpdate = 0;
        /**
         * Keep track of the playback state
         */ this._state = new _stateTimeline.StateTimeline("stopped");
        /**
         * Context bound reference to the _loop method
         * This is necessary to remove the event in the end.
         */ this._boundLoop = this._loop.bind(this);
        const options = _defaults.optionsFromArguments(Clock.getDefaults(), arguments, [
            "callback",
            "frequency"
        ]);
        this.callback = options.callback;
        this._tickSource = new _tickSource.TickSource({
            context: this.context,
            frequency: options.frequency,
            units: options.units
        });
        this._lastUpdate = 0;
        this.frequency = this._tickSource.frequency;
        _interface.readOnly(this, "frequency");
        // add an initial state
        this._state.setStateAtTime("stopped", 0);
        // bind a callback to the worker thread
        this.context.on("tick", this._boundLoop);
    }
    static getDefaults() {
        return Object.assign(_toneWithContext.ToneWithContext.getDefaults(), {
            callback: _interface.noOp,
            frequency: 1,
            units: "hertz"
        });
    }
    /**
     * Returns the playback state of the source, either "started", "stopped" or "paused".
     */ get state() {
        return this._state.getValueAtTime(this.now());
    }
    /**
     * Start the clock at the given time. Optionally pass in an offset
     * of where to start the tick counter from.
     * @param  time    The time the clock should start
     * @param offset  Where the tick counter starts counting from.
     */ start(time, offset) {
        // make sure the context is running
        _debug.assertContextRunning(this.context);
        // start the loop
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        if (this._state.getValueAtTime(computedTime) !== "started") {
            this._state.setStateAtTime("started", computedTime);
            this._tickSource.start(computedTime, offset);
            if (computedTime < this._lastUpdate) this.emit("start", computedTime, offset);
        }
        return this;
    }
    /**
     * Stop the clock. Stopping the clock resets the tick counter to 0.
     * @param time The time when the clock should stop.
     * @example
     * const clock = new Tone.Clock(time => {
     * 	console.log(time);
     * }, 1);
     * clock.start();
     * // stop the clock after 10 seconds
     * clock.stop("+10");
     */ stop(time) {
        const computedTime = this.toSeconds(time);
        this.log("stop", computedTime);
        this._state.cancel(computedTime);
        this._state.setStateAtTime("stopped", computedTime);
        this._tickSource.stop(computedTime);
        if (computedTime < this._lastUpdate) this.emit("stop", computedTime);
        return this;
    }
    /**
     * Pause the clock. Pausing does not reset the tick counter.
     * @param time The time when the clock should stop.
     */ pause(time) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) === "started") {
            this._state.setStateAtTime("paused", computedTime);
            this._tickSource.pause(computedTime);
            if (computedTime < this._lastUpdate) this.emit("pause", computedTime);
        }
        return this;
    }
    /**
     * The number of times the callback was invoked. Starts counting at 0
     * and increments after the callback was invoked.
     */ get ticks() {
        return Math.ceil(this.getTicksAtTime(this.now()));
    }
    set ticks(t) {
        this._tickSource.ticks = t;
    }
    /**
     * The time since ticks=0 that the Clock has been running. Accounts for tempo curves
     */ get seconds() {
        return this._tickSource.seconds;
    }
    set seconds(s) {
        this._tickSource.seconds = s;
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        return this._tickSource.getSecondsAtTime(time);
    }
    /**
     * Set the clock's ticks at the given time.
     * @param  ticks The tick value to set
     * @param  time  When to set the tick value
     */ setTicksAtTime(ticks, time) {
        this._tickSource.setTicksAtTime(ticks, time);
        return this;
    }
    /**
     * Get the time of the given tick. The second argument
     * is when to test before. Since ticks can be set (with setTicksAtTime)
     * there may be multiple times for a given tick value.
     * @param  tick The tick number.
     * @param  before When to measure the tick value from.
     * @return The time of the tick
     */ getTimeOfTick(tick, before = this.now()) {
        return this._tickSource.getTimeOfTick(tick, before);
    }
    /**
     * Get the clock's ticks at the given time.
     * @param  time  When to get the tick value
     * @return The tick value at the given time.
     */ getTicksAtTime(time) {
        return this._tickSource.getTicksAtTime(time);
    }
    /**
     * Get the time of the next tick
     * @param  offset The tick number.
     */ nextTickTime(offset, when) {
        const computedTime = this.toSeconds(when);
        const currentTick = this.getTicksAtTime(computedTime);
        return this._tickSource.getTimeOfTick(currentTick + offset, computedTime);
    }
    /**
     * The scheduling loop.
     */ _loop() {
        const startTime = this._lastUpdate;
        const endTime = this.now();
        this._lastUpdate = endTime;
        this.log("loop", startTime, endTime);
        if (startTime !== endTime) {
            // the state change events
            this._state.forEachBetween(startTime, endTime, (e)=>{
                switch(e.state){
                    case "started":
                        const offset = this._tickSource.getTicksAtTime(e.time);
                        this.emit("start", e.time, offset);
                        break;
                    case "stopped":
                        if (e.time !== 0) this.emit("stop", e.time);
                        break;
                    case "paused":
                        this.emit("pause", e.time);
                        break;
                }
            });
            // the tick callbacks
            this._tickSource.forEachTickBetween(startTime, endTime, (time, ticks)=>{
                this.callback(time, ticks);
            });
        }
    }
    /**
     * Returns the scheduled state at the given time.
     * @param  time  The time to query.
     * @return  The name of the state input in setStateAtTime.
     * @example
     * const clock = new Tone.Clock();
     * clock.start("+0.1");
     * clock.getStateAtTime("+0.1"); // returns "started"
     */ getStateAtTime(time) {
        const computedTime = this.toSeconds(time);
        return this._state.getValueAtTime(computedTime);
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.context.off("tick", this._boundLoop);
        this._tickSource.dispose();
        this._state.dispose();
        return this;
    }
}
_emitter.Emitter.mixin(Clock);

},{"../context/ToneWithContext":"ez5Mk","../util/Defaults":"kSyYt","../util/Emitter":"bzta6","../util/Interface":"fVoXs","../util/StateTimeline":"am3qa","./TickSource":"do1wE","../util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ez5Mk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * The Base class for all nodes that have an AudioContext.
 */ parcelHelpers.export(exports, "ToneWithContext", ()=>ToneWithContext
);
var _global = require("../Global");
var _tone = require("../Tone");
var _frequency = require("../type/Frequency");
var _time = require("../type/Time");
var _transportTime = require("../type/TransportTime");
var _defaults = require("../util/Defaults");
var _typeCheck = require("../util/TypeCheck");
class ToneWithContext extends _tone.Tone {
    constructor(){
        super();
        const options = _defaults.optionsFromArguments(ToneWithContext.getDefaults(), arguments, [
            "context"
        ]);
        if (this.defaultContext) this.context = this.defaultContext;
        else this.context = options.context;
    }
    static getDefaults() {
        return {
            context: _global.getContext()
        };
    }
    /**
     * Return the current time of the Context clock plus the lookAhead.
     * @example
     * setInterval(() => {
     * 	console.log(Tone.now());
     * }, 100);
     */ now() {
        return this.context.currentTime + this.context.lookAhead;
    }
    /**
     * Return the current time of the Context clock without any lookAhead.
     * @example
     * setInterval(() => {
     * 	console.log(Tone.immediate());
     * }, 100);
     */ immediate() {
        return this.context.currentTime;
    }
    /**
     * The duration in seconds of one sample.
     * @example
     * console.log(Tone.Transport.sampleTime);
     */ get sampleTime() {
        return 1 / this.context.sampleRate;
    }
    /**
     * The number of seconds of 1 processing block (128 samples)
     * @example
     * console.log(Tone.Destination.blockTime);
     */ get blockTime() {
        return 128 / this.context.sampleRate;
    }
    /**
     * Convert the incoming time to seconds.
     * This is calculated against the current [[Tone.Transport]] bpm
     * @example
     * const gain = new Tone.Gain();
     * setInterval(() => console.log(gain.toSeconds("4n")), 100);
     * // ramp the tempo to 60 bpm over 30 seconds
     * Tone.getTransport().bpm.rampTo(60, 30);
     */ toSeconds(time) {
        return new _time.TimeClass(this.context, time).toSeconds();
    }
    /**
     * Convert the input to a frequency number
     * @example
     * const gain = new Tone.Gain();
     * console.log(gain.toFrequency("4n"));
     */ toFrequency(freq) {
        return new _frequency.FrequencyClass(this.context, freq).toFrequency();
    }
    /**
     * Convert the input time into ticks
     * @example
     * const gain = new Tone.Gain();
     * console.log(gain.toTicks("4n"));
     */ toTicks(time) {
        return new _transportTime.TransportTimeClass(this.context, time).toTicks();
    }
    //-------------------------------------
    // 	GET/SET
    //-------------------------------------
    /**
     * Get a subset of the properties which are in the partial props
     */ _getPartialProperties(props) {
        const options1 = this.get();
        // remove attributes from the prop that are not in the partial
        Object.keys(options1).forEach((name)=>{
            if (_typeCheck.isUndef(props[name])) delete options1[name];
        });
        return options1;
    }
    /**
     * Get the object's attributes.
     * @example
     * const osc = new Tone.Oscillator();
     * console.log(osc.get());
     */ get() {
        const defaults = _defaults.getDefaultsFromInstance(this);
        Object.keys(defaults).forEach((attribute)=>{
            if (Reflect.has(this, attribute)) {
                const member = this[attribute];
                if (_typeCheck.isDefined(member) && _typeCheck.isDefined(member.value) && _typeCheck.isDefined(member.setValueAtTime)) defaults[attribute] = member.value;
                else if (member instanceof ToneWithContext) defaults[attribute] = member._getPartialProperties(defaults[attribute]);
                else if (_typeCheck.isArray(member) || _typeCheck.isNumber(member) || _typeCheck.isString(member) || _typeCheck.isBoolean(member)) defaults[attribute] = member;
                else // remove all undefined and unserializable attributes
                delete defaults[attribute];
            }
        });
        return defaults;
    }
    /**
     * Set multiple properties at once with an object.
     * @example
     * const filter = new Tone.Filter().toDestination();
     * // set values using an object
     * filter.set({
     * 	frequency: "C6",
     * 	type: "highpass"
     * });
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/Analogsynth_octaves_highmid.mp3").connect(filter);
     * player.autostart = true;
     */ set(props) {
        Object.keys(props).forEach((attribute)=>{
            if (Reflect.has(this, attribute) && _typeCheck.isDefined(this[attribute])) {
                if (this[attribute] && _typeCheck.isDefined(this[attribute].value) && _typeCheck.isDefined(this[attribute].setValueAtTime)) // small optimization
                {
                    if (this[attribute].value !== props[attribute]) this[attribute].value = props[attribute];
                } else if (this[attribute] instanceof ToneWithContext) this[attribute].set(props[attribute]);
                else this[attribute] = props[attribute];
            }
        });
        return this;
    }
}

},{"../Global":"6b8rd","../Tone":"dTzBa","../type/Frequency":"b1aPl","../type/Time":"1HtHW","../type/TransportTime":"kcsdx","../util/Defaults":"kSyYt","../util/TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"b1aPl":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Frequency is a primitive type for encoding Frequency values.
 * Eventually all time values are evaluated to hertz using the `valueOf` method.
 * @example
 * Tone.Frequency("C3"); // 261
 * Tone.Frequency(38, "midi");
 * Tone.Frequency("C3").transpose(4);
 * @category Unit
 */ parcelHelpers.export(exports, "FrequencyClass", ()=>FrequencyClass
);
/**
 * Convert a value into a FrequencyClass object.
 * @category Unit
 * @example
 * const midi = Tone.Frequency("C3").toMidi();
 * console.log(midi);
 * @example
 * const hertz = Tone.Frequency(38, "midi").toFrequency();
 * console.log(hertz);
 */ parcelHelpers.export(exports, "Frequency", ()=>Frequency
);
var _global = require("../Global");
var _conversions = require("./Conversions");
var _time = require("./Time");
class FrequencyClass extends _time.TimeClass {
    constructor(){
        super(...arguments);
        this.name = "Frequency";
        this.defaultUnits = "hz";
    }
    /**
     * The [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
     * to generate all the other pitch values from notes. A4's values in Hertz.
     */ static get A4() {
        return _conversions.getA4();
    }
    static set A4(freq) {
        _conversions.setA4(freq);
    }
    //-------------------------------------
    // 	AUGMENT BASE EXPRESSIONS
    //-------------------------------------
    _getExpressions() {
        return Object.assign({
        }, super._getExpressions(), {
            midi: {
                regexp: /^(\d+(?:\.\d+)?midi)/,
                method (value) {
                    if (this.defaultUnits === "midi") return value;
                    else return FrequencyClass.mtof(value);
                }
            },
            note: {
                regexp: /^([a-g]{1}(?:b|#|x|bb)?)(-?[0-9]+)/i,
                method (pitch, octave) {
                    const index = noteToScaleIndex[pitch.toLowerCase()];
                    const noteNumber = index + (parseInt(octave, 10) + 1) * 12;
                    if (this.defaultUnits === "midi") return noteNumber;
                    else return FrequencyClass.mtof(noteNumber);
                }
            },
            tr: {
                regexp: /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?/,
                method (m, q, s) {
                    let total = 1;
                    if (m && m !== "0") total *= this._beatsToUnits(this._getTimeSignature() * parseFloat(m));
                    if (q && q !== "0") total *= this._beatsToUnits(parseFloat(q));
                    if (s && s !== "0") total *= this._beatsToUnits(parseFloat(s) / 4);
                    return total;
                }
            }
        });
    }
    //-------------------------------------
    // 	EXPRESSIONS
    //-------------------------------------
    /**
     * Transposes the frequency by the given number of semitones.
     * @return  A new transposed frequency
     * @example
     * Tone.Frequency("A4").transpose(3); // "C5"
     */ transpose(interval) {
        return new FrequencyClass(this.context, this.valueOf() * _conversions.intervalToFrequencyRatio(interval));
    }
    /**
     * Takes an array of semitone intervals and returns
     * an array of frequencies transposed by those intervals.
     * @return  Returns an array of Frequencies
     * @example
     * Tone.Frequency("A4").harmonize([0, 3, 7]); // ["A4", "C5", "E5"]
     */ harmonize(intervals) {
        return intervals.map((interval)=>{
            return this.transpose(interval);
        });
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS
    //-------------------------------------
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Frequency("C4").toMidi(); // 60
     */ toMidi() {
        return _conversions.ftom(this.valueOf());
    }
    /**
     * Return the value of the frequency in Scientific Pitch Notation
     * @example
     * Tone.Frequency(69, "midi").toNote(); // "A4"
     */ toNote() {
        const freq = this.toFrequency();
        const log = Math.log2(freq / FrequencyClass.A4);
        let noteNumber = Math.round(12 * log) + 57;
        const octave = Math.floor(noteNumber / 12);
        if (octave < 0) noteNumber += -12 * octave;
        const noteName = scaleIndexToNote[noteNumber % 12];
        return noteName + octave.toString();
    }
    /**
     * Return the duration of one cycle in seconds.
     */ toSeconds() {
        return 1 / super.toSeconds();
    }
    /**
     * Return the duration of one cycle in ticks
     */ toTicks() {
        const quarterTime = this._beatsToUnits(1);
        const quarters = this.valueOf() / quarterTime;
        return Math.floor(quarters * this._getPPQ());
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS HELPERS
    //-------------------------------------
    /**
     * With no arguments, return 0
     */ _noArg() {
        return 0;
    }
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return freq;
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return 1 / (ticks * 60 / (this._getBpm() * this._getPPQ()));
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return 1 / super._beatsToUnits(beats);
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return 1 / seconds;
    }
    /**
     * Convert a MIDI note to frequency value.
     * @param  midi The midi number to convert.
     * @return The corresponding frequency value
     */ static mtof(midi) {
        return _conversions.mtof(midi);
    }
    /**
     * Convert a frequency value to a MIDI note.
     * @param frequency The value to frequency value to convert.
     */ static ftom(frequency) {
        return _conversions.ftom(frequency);
    }
}
//-------------------------------------
// 	FREQUENCY CONVERSIONS
//-------------------------------------
/**
 * Note to scale index.
 * @hidden
 */ const noteToScaleIndex = {
    cbb: -2,
    cb: -1,
    c: 0,
    "c#": 1,
    cx: 2,
    dbb: 0,
    db: 1,
    d: 2,
    "d#": 3,
    dx: 4,
    ebb: 2,
    eb: 3,
    e: 4,
    "e#": 5,
    ex: 6,
    fbb: 3,
    fb: 4,
    f: 5,
    "f#": 6,
    fx: 7,
    gbb: 5,
    gb: 6,
    g: 7,
    "g#": 8,
    gx: 9,
    abb: 7,
    ab: 8,
    a: 9,
    "a#": 10,
    ax: 11,
    bbb: 9,
    bb: 10,
    b: 11,
    "b#": 12,
    bx: 13
};
/**
 * scale index to note (sharps)
 * @hidden
 */ const scaleIndexToNote = [
    "C",
    "C#",
    "D",
    "D#",
    "E",
    "F",
    "F#",
    "G",
    "G#",
    "A",
    "A#",
    "B"
];
function Frequency(value, units) {
    return new FrequencyClass(_global.getContext(), value, units);
}

},{"../Global":"6b8rd","./Conversions":"kOcnG","./Time":"1HtHW","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kOcnG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Equal power gain scale. Good for cross-fading.
 * @param  percent (0-1)
 */ parcelHelpers.export(exports, "equalPowerScale", ()=>equalPowerScale
);
/**
 * Convert decibels into gain.
 */ parcelHelpers.export(exports, "dbToGain", ()=>dbToGain
);
/**
 * Convert gain to decibels.
 */ parcelHelpers.export(exports, "gainToDb", ()=>gainToDb
);
/**
 * Convert an interval (in semitones) to a frequency ratio.
 * @param interval the number of semitones above the base note
 * @example
 * Tone.intervalToFrequencyRatio(0); // 1
 * Tone.intervalToFrequencyRatio(12); // 2
 * Tone.intervalToFrequencyRatio(-12); // 0.5
 */ parcelHelpers.export(exports, "intervalToFrequencyRatio", ()=>intervalToFrequencyRatio
);
parcelHelpers.export(exports, "getA4", ()=>getA4
);
parcelHelpers.export(exports, "setA4", ()=>setA4
);
/**
 * Convert a frequency value to a MIDI note.
 * @param frequency The value to frequency value to convert.
 * @example
 * Tone.ftom(440); // returns 69
 */ parcelHelpers.export(exports, "ftom", ()=>ftom
);
/**
 * Convert a frequency to a floating point midi value
 */ parcelHelpers.export(exports, "ftomf", ()=>ftomf
);
/**
 * Convert a MIDI note to frequency value.
 * @param  midi The midi number to convert.
 * @return The corresponding frequency value
 * @example
 * Tone.mtof(69); // 440
 */ parcelHelpers.export(exports, "mtof", ()=>mtof
);
function equalPowerScale(percent) {
    const piFactor = 0.5 * Math.PI;
    return Math.sin(percent * piFactor);
}
function dbToGain(db) {
    return Math.pow(10, db / 20);
}
function gainToDb(gain) {
    return 20 * (Math.log(gain) / Math.LN10);
}
function intervalToFrequencyRatio(interval) {
    return Math.pow(2, interval / 12);
}
/**
 * The Global [concert tuning pitch](https://en.wikipedia.org/wiki/Concert_pitch) which is used
 * to generate all the other pitch values from notes. A4's values in Hertz.
 */ let A4 = 440;
function getA4() {
    return A4;
}
function setA4(freq) {
    A4 = freq;
}
function ftom(frequency) {
    return Math.round(ftomf(frequency));
}
function ftomf(frequency) {
    return 69 + 12 * Math.log2(frequency / A4);
}
function mtof(midi) {
    return A4 * Math.pow(2, (midi - 69) / 12);
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1HtHW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TimeClass is a primitive type for encoding and decoding Time values.
 * TimeClass can be passed into the parameter of any method which takes time as an argument.
 * @param  val    The time value.
 * @param  units  The units of the value.
 * @example
 * const time = Tone.Time("4n"); // a quarter note
 * @category Unit
 */ parcelHelpers.export(exports, "TimeClass", ()=>TimeClass
);
/**
 * Create a TimeClass from a time string or number. The time is computed against the
 * global Tone.Context. To use a specific context, use [[TimeClass]]
 * @param value A value which represents time
 * @param units The value's units if they can't be inferred by the value.
 * @category Unit
 * @example
 * const time = Tone.Time("4n").toSeconds();
 * console.log(time);
 * @example
 * const note = Tone.Time(1).toNotation();
 * console.log(note);
 * @example
 * const freq = Tone.Time(0.5).toFrequency();
 * console.log(freq);
 */ parcelHelpers.export(exports, "Time", ()=>Time
);
var _global = require("../Global");
var _conversions = require("./Conversions");
var _timeBase = require("./TimeBase");
class TimeClass extends _timeBase.TimeBaseClass {
    constructor(){
        super(...arguments);
        this.name = "TimeClass";
    }
    _getExpressions() {
        return Object.assign(super._getExpressions(), {
            now: {
                method: (capture)=>{
                    return this._now() + new this.constructor(this.context, capture).valueOf();
                },
                regexp: /^\+(.+)/
            },
            quantize: {
                method: (capture)=>{
                    const quantTo = new TimeClass(this.context, capture).valueOf();
                    return this._secondsToUnits(this.context.transport.nextSubdivision(quantTo));
                },
                regexp: /^@(.+)/
            }
        });
    }
    /**
     * Quantize the time by the given subdivision. Optionally add a
     * percentage which will move the time value towards the ideal
     * quantized value by that percentage.
     * @param  subdiv    The subdivision to quantize to
     * @param  percent  Move the time value towards the quantized value by a percentage.
     * @example
     * Tone.Time(21).quantize(2); // returns 22
     * Tone.Time(0.6).quantize("4n", 0.5); // returns 0.55
     */ quantize(subdiv, percent = 1) {
        const subdivision = new this.constructor(this.context, subdiv).valueOf();
        const value = this.valueOf();
        const multiple = Math.round(value / subdivision);
        const ideal = multiple * subdivision;
        const diff = ideal - value;
        return value + diff * percent;
    }
    //-------------------------------------
    // CONVERSIONS
    //-------------------------------------
    /**
     * Convert a Time to Notation. The notation values are will be the
     * closest representation between 1m to 128th note.
     * @return {Notation}
     * @example
     * // if the Transport is at 120bpm:
     * Tone.Time(2).toNotation(); // returns "1m"
     */ toNotation() {
        const time = this.toSeconds();
        const testNotations = [
            "1m"
        ];
        for(let power = 1; power < 9; power++){
            const subdiv = Math.pow(2, power);
            testNotations.push(subdiv + "n.");
            testNotations.push(subdiv + "n");
            testNotations.push(subdiv + "t");
        }
        testNotations.push("0");
        // find the closets notation representation
        let closest = testNotations[0];
        let closestSeconds = new TimeClass(this.context, testNotations[0]).toSeconds();
        testNotations.forEach((notation)=>{
            const notationSeconds = new TimeClass(this.context, notation).toSeconds();
            if (Math.abs(notationSeconds - time) < Math.abs(closestSeconds - time)) {
                closest = notation;
                closestSeconds = notationSeconds;
            }
        });
        return closest;
    }
    /**
     * Return the time encoded as Bars:Beats:Sixteenths.
     */ toBarsBeatsSixteenths() {
        const quarterTime = this._beatsToUnits(1);
        let quarters = this.valueOf() / quarterTime;
        quarters = parseFloat(quarters.toFixed(4));
        const measures = Math.floor(quarters / this._getTimeSignature());
        let sixteenths = quarters % 1 * 4;
        quarters = Math.floor(quarters) % this._getTimeSignature();
        const sixteenthString = sixteenths.toString();
        if (sixteenthString.length > 3) // the additional parseFloat removes insignificant trailing zeroes
        sixteenths = parseFloat(parseFloat(sixteenthString).toFixed(3));
        const progress = [
            measures,
            quarters,
            sixteenths
        ];
        return progress.join(":");
    }
    /**
     * Return the time in ticks.
     */ toTicks() {
        const quarterTime = this._beatsToUnits(1);
        const quarters = this.valueOf() / quarterTime;
        return Math.round(quarters * this._getPPQ());
    }
    /**
     * Return the time in seconds.
     */ toSeconds() {
        return this.valueOf();
    }
    /**
     * Return the value as a midi note.
     */ toMidi() {
        return _conversions.ftom(this.toFrequency());
    }
    _now() {
        return this.context.now();
    }
}
function Time(value, units) {
    return new TimeClass(_global.getContext(), value, units);
}

},{"../Global":"6b8rd","./Conversions":"kOcnG","./TimeBase":"9QgNG","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9QgNG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TimeBase is a flexible encoding of time which can be evaluated to and from a string.
 */ parcelHelpers.export(exports, "TimeBaseClass", ()=>TimeBaseClass
);
var _tone = require("../Tone");
var _typeCheck = require("../util/TypeCheck");
class TimeBaseClass extends _tone.Tone {
    /**
     * @param context The context associated with the time value. Used to compute
     * Transport and context-relative timing.
     * @param  value  The time value as a number, string or object
     * @param  units  Unit values
     */ constructor(context, value, units){
        super();
        /**
         * The default units
         */ this.defaultUnits = "s";
        this._val = value;
        this._units = units;
        this.context = context;
        this._expressions = this._getExpressions();
    }
    /**
     * All of the time encoding expressions
     */ _getExpressions() {
        return {
            hz: {
                method: (value1)=>{
                    return this._frequencyToUnits(parseFloat(value1));
                },
                regexp: /^(\d+(?:\.\d+)?)hz$/i
            },
            i: {
                method: (value1)=>{
                    return this._ticksToUnits(parseInt(value1, 10));
                },
                regexp: /^(\d+)i$/i
            },
            m: {
                method: (value1)=>{
                    return this._beatsToUnits(parseInt(value1, 10) * this._getTimeSignature());
                },
                regexp: /^(\d+)m$/i
            },
            n: {
                method: (value1, dot)=>{
                    const numericValue = parseInt(value1, 10);
                    const scalar = dot === "." ? 1.5 : 1;
                    if (numericValue === 1) return this._beatsToUnits(this._getTimeSignature()) * scalar;
                    else return this._beatsToUnits(4 / numericValue) * scalar;
                },
                regexp: /^(\d+)n(\.?)$/i
            },
            number: {
                method: (value1)=>{
                    return this._expressions[this.defaultUnits].method.call(this, value1);
                },
                regexp: /^(\d+(?:\.\d+)?)$/
            },
            s: {
                method: (value1)=>{
                    return this._secondsToUnits(parseFloat(value1));
                },
                regexp: /^(\d+(?:\.\d+)?)s$/
            },
            samples: {
                method: (value1)=>{
                    return parseInt(value1, 10) / this.context.sampleRate;
                },
                regexp: /^(\d+)samples$/
            },
            t: {
                method: (value1)=>{
                    const numericValue = parseInt(value1, 10);
                    return this._beatsToUnits(8 / (Math.floor(numericValue) * 3));
                },
                regexp: /^(\d+)t$/i
            },
            tr: {
                method: (m, q, s)=>{
                    let total = 0;
                    if (m && m !== "0") total += this._beatsToUnits(this._getTimeSignature() * parseFloat(m));
                    if (q && q !== "0") total += this._beatsToUnits(parseFloat(q));
                    if (s && s !== "0") total += this._beatsToUnits(parseFloat(s) / 4);
                    return total;
                },
                regexp: /^(\d+(?:\.\d+)?):(\d+(?:\.\d+)?):?(\d+(?:\.\d+)?)?$/
            }
        };
    }
    //-------------------------------------
    // 	VALUE OF
    //-------------------------------------
    /**
     * Evaluate the time value. Returns the time in seconds.
     */ valueOf() {
        if (this._val instanceof TimeBaseClass) this.fromType(this._val);
        if (_typeCheck.isUndef(this._val)) return this._noArg();
        else if (_typeCheck.isString(this._val) && _typeCheck.isUndef(this._units)) {
            for(const units1 in this._expressions)if (this._expressions[units1].regexp.test(this._val.trim())) {
                this._units = units1;
                break;
            }
        } else if (_typeCheck.isObject(this._val)) {
            let total = 0;
            for(const typeName in this._val)if (_typeCheck.isDefined(this._val[typeName])) {
                const quantity = this._val[typeName];
                // @ts-ignore
                const time = new this.constructor(this.context, typeName).valueOf() * quantity;
                total += time;
            }
            return total;
        }
        if (_typeCheck.isDefined(this._units)) {
            const expr = this._expressions[this._units];
            const matching = this._val.toString().trim().match(expr.regexp);
            if (matching) return expr.method.apply(this, matching.slice(1));
            else return expr.method.call(this, this._val);
        } else if (_typeCheck.isString(this._val)) return parseFloat(this._val);
        else return this._val;
    }
    //-------------------------------------
    // 	UNIT CONVERSIONS
    //-------------------------------------
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return 1 / freq;
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return 60 / this._getBpm() * beats;
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return seconds;
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return ticks * this._beatsToUnits(1) / this._getPPQ();
    }
    /**
     * With no arguments, return 'now'
     */ _noArg() {
        return this._now();
    }
    //-------------------------------------
    // 	TEMPO CONVERSIONS
    //-------------------------------------
    /**
     * Return the bpm
     */ _getBpm() {
        return this.context.transport.bpm.value;
    }
    /**
     * Return the timeSignature
     */ _getTimeSignature() {
        return this.context.transport.timeSignature;
    }
    /**
     * Return the PPQ or 192 if Transport is not available
     */ _getPPQ() {
        return this.context.transport.PPQ;
    }
    //-------------------------------------
    // 	CONVERSION INTERFACE
    //-------------------------------------
    /**
     * Coerce a time type into this units type.
     * @param type Any time type units
     */ fromType(type) {
        this._units = undefined;
        switch(this.defaultUnits){
            case "s":
                this._val = type.toSeconds();
                break;
            case "i":
                this._val = type.toTicks();
                break;
            case "hz":
                this._val = type.toFrequency();
                break;
            case "midi":
                this._val = type.toMidi();
                break;
        }
        return this;
    }
    /**
     * Return the value in hertz
     */ toFrequency() {
        return 1 / this.toSeconds();
    }
    /**
     * Return the time in samples
     */ toSamples() {
        return this.toSeconds() * this.context.sampleRate;
    }
    /**
     * Return the time in milliseconds.
     */ toMilliseconds() {
        return this.toSeconds() * 1000;
    }
}

},{"../Tone":"dTzBa","../util/TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kcsdx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TransportTime is a the time along the Transport's
 * timeline. It is similar to Tone.Time, but instead of evaluating
 * against the AudioContext's clock, it is evaluated against
 * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
 * @category Unit
 */ parcelHelpers.export(exports, "TransportTimeClass", ()=>TransportTimeClass
);
/**
 * TransportTime is a the time along the Transport's
 * timeline. It is similar to [[Time]], but instead of evaluating
 * against the AudioContext's clock, it is evaluated against
 * the Transport's position. See [TransportTime wiki](https://github.com/Tonejs/Tone.js/wiki/TransportTime).
 * @category Unit
 */ parcelHelpers.export(exports, "TransportTime", ()=>TransportTime
);
var _global = require("../Global");
var _time = require("./Time");
class TransportTimeClass extends _time.TimeClass {
    constructor(){
        super(...arguments);
        this.name = "TransportTime";
    }
    /**
     * Return the current time in whichever context is relevant
     */ _now() {
        return this.context.transport.seconds;
    }
}
function TransportTime(value, units) {
    return new TransportTimeClass(_global.getContext(), value, units);
}

},{"../Global":"6b8rd","./Time":"1HtHW","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"am3qa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A Timeline State. Provides the methods: `setStateAtTime("state", time)` and `getValueAtTime(time)`
 * @param initial The initial state of the StateTimeline.  Defaults to `undefined`
 */ parcelHelpers.export(exports, "StateTimeline", ()=>StateTimeline
);
var _timeline = require("./Timeline");
var _debug = require("./Debug");
class StateTimeline extends _timeline.Timeline {
    constructor(initial = "stopped"){
        super();
        this.name = "StateTimeline";
        this._initial = initial;
        this.setStateAtTime(this._initial, 0);
    }
    /**
     * Returns the scheduled state scheduled before or at
     * the given time.
     * @param  time  The time to query.
     * @return  The name of the state input in setStateAtTime.
     */ getValueAtTime(time) {
        const event = this.get(time);
        if (event !== null) return event.state;
        else return this._initial;
    }
    /**
     * Add a state to the timeline.
     * @param  state The name of the state to set.
     * @param  time  The time to query.
     * @param options Any additional options that are needed in the timeline.
     */ setStateAtTime(state, time, options) {
        _debug.assertRange(time, 0);
        this.add(Object.assign({
        }, options, {
            state,
            time
        }));
        return this;
    }
    /**
     * Return the event before the time with the given state
     * @param  state The state to look for
     * @param  time  When to check before
     * @return  The event with the given state before the time
     */ getLastState(state, time) {
        // time = this.toSeconds(time);
        const index = this._search(time);
        for(let i = index; i >= 0; i--){
            const event = this._timeline[i];
            if (event.state === state) return event;
        }
    }
    /**
     * Return the event after the time with the given state
     * @param  state The state to look for
     * @param  time  When to check from
     * @return  The event with the given state after the time
     */ getNextState(state, time) {
        // time = this.toSeconds(time);
        const index = this._search(time);
        if (index !== -1) for(let i = index; i < this._timeline.length; i++){
            const event = this._timeline[i];
            if (event.state === state) return event;
        }
    }
}

},{"./Timeline":"leurn","./Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"do1wE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Uses [TickSignal](TickSignal) to track elapsed ticks with complex automation curves.
 */ parcelHelpers.export(exports, "TickSource", ()=>TickSource
);
var _toneWithContext = require("../context/ToneWithContext");
var _defaults = require("../util/Defaults");
var _interface = require("../util/Interface");
var _stateTimeline = require("../util/StateTimeline");
var _timeline = require("../util/Timeline");
var _typeCheck = require("../util/TypeCheck");
var _tickSignal = require("./TickSignal");
var _math = require("../util/Math");
class TickSource extends _toneWithContext.ToneWithContext {
    constructor(){
        super(_defaults.optionsFromArguments(TickSource.getDefaults(), arguments, [
            "frequency"
        ]));
        this.name = "TickSource";
        /**
         * The state timeline
         */ this._state = new _stateTimeline.StateTimeline();
        /**
         * The offset values of the ticks
         */ this._tickOffset = new _timeline.Timeline();
        const options = _defaults.optionsFromArguments(TickSource.getDefaults(), arguments, [
            "frequency"
        ]);
        this.frequency = new _tickSignal.TickSignal({
            context: this.context,
            units: options.units,
            value: options.frequency
        });
        _interface.readOnly(this, "frequency");
        // set the initial state
        this._state.setStateAtTime("stopped", 0);
        // add the first event
        this.setTicksAtTime(0, 0);
    }
    static getDefaults() {
        return Object.assign({
            frequency: 1,
            units: "hertz"
        }, _toneWithContext.ToneWithContext.getDefaults());
    }
    /**
     * Returns the playback state of the source, either "started", "stopped" or "paused".
     */ get state() {
        return this.getStateAtTime(this.now());
    }
    /**
     * Start the clock at the given time. Optionally pass in an offset
     * of where to start the tick counter from.
     * @param  time    The time the clock should start
     * @param offset The number of ticks to start the source at
     */ start(time, offset) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) !== "started") {
            this._state.setStateAtTime("started", computedTime);
            if (_typeCheck.isDefined(offset)) this.setTicksAtTime(offset, computedTime);
        }
        return this;
    }
    /**
     * Stop the clock. Stopping the clock resets the tick counter to 0.
     * @param time The time when the clock should stop.
     */ stop(time) {
        const computedTime = this.toSeconds(time);
        // cancel the previous stop
        if (this._state.getValueAtTime(computedTime) === "stopped") {
            const event = this._state.get(computedTime);
            if (event && event.time > 0) {
                this._tickOffset.cancel(event.time);
                this._state.cancel(event.time);
            }
        }
        this._state.cancel(computedTime);
        this._state.setStateAtTime("stopped", computedTime);
        this.setTicksAtTime(0, computedTime);
        return this;
    }
    /**
     * Pause the clock. Pausing does not reset the tick counter.
     * @param time The time when the clock should stop.
     */ pause(time) {
        const computedTime = this.toSeconds(time);
        if (this._state.getValueAtTime(computedTime) === "started") this._state.setStateAtTime("paused", computedTime);
        return this;
    }
    /**
     * Cancel start/stop/pause and setTickAtTime events scheduled after the given time.
     * @param time When to clear the events after
     */ cancel(time) {
        time = this.toSeconds(time);
        this._state.cancel(time);
        this._tickOffset.cancel(time);
        return this;
    }
    /**
     * Get the elapsed ticks at the given time
     * @param  time  When to get the tick value
     * @return The number of ticks
     */ getTicksAtTime(time) {
        const computedTime = this.toSeconds(time);
        const stopEvent = this._state.getLastState("stopped", computedTime);
        // this event allows forEachBetween to iterate until the current time
        const tmpEvent = {
            state: "paused",
            time: computedTime
        };
        this._state.add(tmpEvent);
        // keep track of the previous offset event
        let lastState = stopEvent;
        let elapsedTicks = 0;
        // iterate through all the events since the last stop
        this._state.forEachBetween(stopEvent.time, computedTime + this.sampleTime, (e)=>{
            let periodStartTime = lastState.time;
            // if there is an offset event in this period use that
            const offsetEvent = this._tickOffset.get(e.time);
            if (offsetEvent && offsetEvent.time >= lastState.time) {
                elapsedTicks = offsetEvent.ticks;
                periodStartTime = offsetEvent.time;
            }
            if (lastState.state === "started" && e.state !== "started") elapsedTicks += this.frequency.getTicksAtTime(e.time) - this.frequency.getTicksAtTime(periodStartTime);
            lastState = e;
        });
        // remove the temporary event
        this._state.remove(tmpEvent);
        // return the ticks
        return elapsedTicks;
    }
    /**
     * The number of times the callback was invoked. Starts counting at 0
     * and increments after the callback was invoked. Returns -1 when stopped.
     */ get ticks() {
        return this.getTicksAtTime(this.now());
    }
    set ticks(t) {
        this.setTicksAtTime(t, this.now());
    }
    /**
     * The time since ticks=0 that the TickSource has been running. Accounts
     * for tempo curves
     */ get seconds() {
        return this.getSecondsAtTime(this.now());
    }
    set seconds(s) {
        const now = this.now();
        const ticks = this.frequency.timeToTicks(s, now);
        this.setTicksAtTime(ticks, now);
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        time = this.toSeconds(time);
        const stopEvent = this._state.getLastState("stopped", time);
        // this event allows forEachBetween to iterate until the current time
        const tmpEvent = {
            state: "paused",
            time
        };
        this._state.add(tmpEvent);
        // keep track of the previous offset event
        let lastState = stopEvent;
        let elapsedSeconds = 0;
        // iterate through all the events since the last stop
        this._state.forEachBetween(stopEvent.time, time + this.sampleTime, (e)=>{
            let periodStartTime = lastState.time;
            // if there is an offset event in this period use that
            const offsetEvent = this._tickOffset.get(e.time);
            if (offsetEvent && offsetEvent.time >= lastState.time) {
                elapsedSeconds = offsetEvent.seconds;
                periodStartTime = offsetEvent.time;
            }
            if (lastState.state === "started" && e.state !== "started") elapsedSeconds += e.time - periodStartTime;
            lastState = e;
        });
        // remove the temporary event
        this._state.remove(tmpEvent);
        // return the ticks
        return elapsedSeconds;
    }
    /**
     * Set the clock's ticks at the given time.
     * @param  ticks The tick value to set
     * @param  time  When to set the tick value
     */ setTicksAtTime(ticks, time) {
        time = this.toSeconds(time);
        this._tickOffset.cancel(time);
        this._tickOffset.add({
            seconds: this.frequency.getDurationOfTicks(ticks, time),
            ticks,
            time
        });
        return this;
    }
    /**
     * Returns the scheduled state at the given time.
     * @param  time  The time to query.
     */ getStateAtTime(time) {
        time = this.toSeconds(time);
        return this._state.getValueAtTime(time);
    }
    /**
     * Get the time of the given tick. The second argument
     * is when to test before. Since ticks can be set (with setTicksAtTime)
     * there may be multiple times for a given tick value.
     * @param  tick The tick number.
     * @param  before When to measure the tick value from.
     * @return The time of the tick
     */ getTimeOfTick(tick, before = this.now()) {
        const offset = this._tickOffset.get(before);
        const event = this._state.get(before);
        const startTime = Math.max(offset.time, event.time);
        const absoluteTicks = this.frequency.getTicksAtTime(startTime) + tick - offset.ticks;
        return this.frequency.getTimeOfTick(absoluteTicks);
    }
    /**
     * Invoke the callback event at all scheduled ticks between the
     * start time and the end time
     * @param  startTime  The beginning of the search range
     * @param  endTime    The end of the search range
     * @param  callback   The callback to invoke with each tick
     */ forEachTickBetween(startTime, endTime, callback) {
        // only iterate through the sections where it is "started"
        let lastStateEvent = this._state.get(startTime);
        this._state.forEachBetween(startTime, endTime, (event)=>{
            if (lastStateEvent && lastStateEvent.state === "started" && event.state !== "started") this.forEachTickBetween(Math.max(lastStateEvent.time, startTime), event.time - this.sampleTime, callback);
            lastStateEvent = event;
        });
        let error = null;
        if (lastStateEvent && lastStateEvent.state === "started") {
            const maxStartTime = Math.max(lastStateEvent.time, startTime);
            // figure out the difference between the frequency ticks and the
            const startTicks = this.frequency.getTicksAtTime(maxStartTime);
            const ticksAtStart = this.frequency.getTicksAtTime(lastStateEvent.time);
            const diff = startTicks - ticksAtStart;
            let offset = Math.ceil(diff) - diff;
            // guard against floating point issues
            offset = _math.EQ(offset, 1) ? 0 : offset;
            let nextTickTime = this.frequency.getTimeOfTick(startTicks + offset);
            while(nextTickTime < endTime){
                try {
                    callback(nextTickTime, Math.round(this.getTicksAtTime(nextTickTime)));
                } catch (e) {
                    error = e;
                    break;
                }
                nextTickTime += this.frequency.getDurationOfTicks(1, nextTickTime);
            }
        }
        if (error) throw error;
        return this;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._state.dispose();
        this._tickOffset.dispose();
        this.frequency.dispose();
        return this;
    }
}

},{"../context/ToneWithContext":"ez5Mk","../util/Defaults":"kSyYt","../util/Interface":"fVoXs","../util/StateTimeline":"am3qa","../util/Timeline":"leurn","../util/TypeCheck":"lCqGC","./TickSignal":"bqXmy","../util/Math":"gdhOV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bqXmy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TickSignal extends Tone.Signal, but adds the capability
 * to calculate the number of elapsed ticks. exponential and target curves
 * are approximated with multiple linear ramps.
 *
 * Thank you Bruno Dias, H. Sofia Pinto, and David M. Matos,
 * for your [WAC paper](https://smartech.gatech.edu/bitstream/handle/1853/54588/WAC2016-49.pdf)
 * describing integrating timing functions for tempo calculations.
 */ parcelHelpers.export(exports, "TickSignal", ()=>TickSignal
);
var _signal = require("../../signal/Signal");
var _defaults = require("../util/Defaults");
var _tickParam = require("./TickParam");
class TickSignal extends _signal.Signal {
    constructor(){
        super(_defaults.optionsFromArguments(TickSignal.getDefaults(), arguments, [
            "value"
        ]));
        this.name = "TickSignal";
        const options = _defaults.optionsFromArguments(TickSignal.getDefaults(), arguments, [
            "value"
        ]);
        this.input = this._param = new _tickParam.TickParam({
            context: this.context,
            convert: options.convert,
            multiplier: options.multiplier,
            param: this._constantSource.offset,
            units: options.units,
            value: options.value
        });
    }
    static getDefaults() {
        return Object.assign(_signal.Signal.getDefaults(), {
            multiplier: 1,
            units: "hertz",
            value: 1
        });
    }
    ticksToTime(ticks, when) {
        return this._param.ticksToTime(ticks, when);
    }
    timeToTicks(duration, when) {
        return this._param.timeToTicks(duration, when);
    }
    getTimeOfTick(tick) {
        return this._param.getTimeOfTick(tick);
    }
    getDurationOfTicks(ticks, time) {
        return this._param.getDurationOfTicks(ticks, time);
    }
    getTicksAtTime(time) {
        return this._param.getTicksAtTime(time);
    }
    /**
     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
     */ get multiplier() {
        return this._param.multiplier;
    }
    set multiplier(m) {
        this._param.multiplier = m;
    }
    dispose() {
        super.dispose();
        this._param.dispose();
        return this;
    }
}

},{"../../signal/Signal":"kfryg","../util/Defaults":"kSyYt","./TickParam":"feUbN","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kfryg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A signal is an audio-rate value. Tone.Signal is a core component of the library.
 * Unlike a number, Signals can be scheduled with sample-level accuracy. Tone.Signal
 * has all of the methods available to native Web Audio
 * [AudioParam](http://webaudio.github.io/web-audio-api/#the-audioparam-interface)
 * as well as additional conveniences. Read more about working with signals
 * [here](https://github.com/Tonejs/Tone.js/wiki/Signals).
 *
 * @example
 * const osc = new Tone.Oscillator().toDestination().start();
 * // a scheduleable signal which can be connected to control an AudioParam or another Signal
 * const signal = new Tone.Signal({
 * 	value: "C4",
 * 	units: "frequency"
 * }).connect(osc.frequency);
 * // the scheduled ramp controls the connected signal
 * signal.rampTo("C2", 4, "+0.5");
 * @category Signal
 */ parcelHelpers.export(exports, "Signal", ()=>Signal
);
/**
 * When connecting from a signal, it's necessary to zero out the node destination
 * node if that node is also a signal. If the destination is not 0, then the values
 * will be summed. This method insures that the output of the destination signal will
 * be the same as the source signal, making the destination signal a pass through node.
 * @param signal The output signal to connect from
 * @param destination the destination to connect to
 * @param outputNum the optional output number
 * @param inputNum the input number
 */ parcelHelpers.export(exports, "connectSignal", ()=>connectSignal
);
var _param = require("../core/context/Param");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _advancedTypeCheck = require("../core/util/AdvancedTypeCheck");
var _defaults = require("../core/util/Defaults");
var _toneConstantSource = require("./ToneConstantSource");
class Signal extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Signal.getDefaults(), arguments, [
            "value",
            "units"
        ]));
        this.name = "Signal";
        /**
         * Indicates if the value should be overridden on connection.
         */ this.override = true;
        const options = _defaults.optionsFromArguments(Signal.getDefaults(), arguments, [
            "value",
            "units"
        ]);
        this.output = this._constantSource = new _toneConstantSource.ToneConstantSource({
            context: this.context,
            convert: options.convert,
            offset: options.value,
            units: options.units,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        this._constantSource.start(0);
        this.input = this._param = this._constantSource.offset;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            convert: true,
            units: "number",
            value: 0
        });
    }
    connect(destination, outputNum = 0, inputNum = 0) {
        // start it only when connected to something
        connectSignal(this, destination, outputNum, inputNum);
        return this;
    }
    dispose() {
        super.dispose();
        this._param.dispose();
        this._constantSource.dispose();
        return this;
    }
    //-------------------------------------
    // ABSTRACT PARAM INTERFACE
    // just a proxy for the ConstantSourceNode's offset AudioParam
    // all docs are generated from AbstractParam.ts
    //-------------------------------------
    setValueAtTime(value, time) {
        this._param.setValueAtTime(value, time);
        return this;
    }
    getValueAtTime(time) {
        return this._param.getValueAtTime(time);
    }
    setRampPoint(time) {
        this._param.setRampPoint(time);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        this._param.linearRampToValueAtTime(value, time);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        this._param.exponentialRampToValueAtTime(value, time);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        this._param.exponentialRampTo(value, rampTime, startTime);
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        this._param.linearRampTo(value, rampTime, startTime);
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        this._param.targetRampTo(value, rampTime, startTime);
        return this;
    }
    exponentialApproachValueAtTime(value, time, rampTime) {
        this._param.exponentialApproachValueAtTime(value, time, rampTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        this._param.setTargetAtTime(value, startTime, timeConstant);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling) {
        this._param.setValueCurveAtTime(values, startTime, duration, scaling);
        return this;
    }
    cancelScheduledValues(time) {
        this._param.cancelScheduledValues(time);
        return this;
    }
    cancelAndHoldAtTime(time) {
        this._param.cancelAndHoldAtTime(time);
        return this;
    }
    rampTo(value, rampTime, startTime) {
        this._param.rampTo(value, rampTime, startTime);
        return this;
    }
    get value() {
        return this._param.value;
    }
    set value(value) {
        this._param.value = value;
    }
    get convert() {
        return this._param.convert;
    }
    set convert(convert) {
        this._param.convert = convert;
    }
    get units() {
        return this._param.units;
    }
    get overridden() {
        return this._param.overridden;
    }
    set overridden(overridden) {
        this._param.overridden = overridden;
    }
    get maxValue() {
        return this._param.maxValue;
    }
    get minValue() {
        return this._param.minValue;
    }
    /**
     * See [[Param.apply]].
     */ apply(param) {
        this._param.apply(param);
        return this;
    }
}
function connectSignal(signal, destination, outputNum, inputNum) {
    if (destination instanceof _param.Param || _advancedTypeCheck.isAudioParam(destination) || destination instanceof Signal && destination.override) {
        // cancel changes
        destination.cancelScheduledValues(0);
        // reset the value
        destination.setValueAtTime(0, 0);
        // mark the value as overridden
        if (destination instanceof Signal) destination.overridden = true;
    }
    _toneAudioNode.connect(signal, destination, outputNum, inputNum);
}

},{"../core/context/Param":"2qxaM","../core/context/ToneAudioNode":"iT1SZ","../core/util/AdvancedTypeCheck":"arR2z","../core/util/Defaults":"kSyYt","./ToneConstantSource":"iRz6E","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2qxaM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Param wraps the native Web Audio's AudioParam to provide
 * additional unit conversion functionality. It also
 * serves as a base-class for classes which have a single,
 * automatable parameter.
 * @category Core
 */ parcelHelpers.export(exports, "Param", ()=>Param
);
var _conversions = require("../type/Conversions");
var _advancedTypeCheck = require("../util/AdvancedTypeCheck");
var _defaults = require("../util/Defaults");
var _timeline = require("../util/Timeline");
var _typeCheck = require("../util/TypeCheck");
var _toneWithContext = require("./ToneWithContext");
var _math = require("../util/Math");
var _debug = require("../util/Debug");
class Param extends _toneWithContext.ToneWithContext {
    constructor(){
        super(_defaults.optionsFromArguments(Param.getDefaults(), arguments, [
            "param",
            "units",
            "convert"
        ]));
        this.name = "Param";
        this.overridden = false;
        /**
         * The minimum output value
         */ this._minOutput = 0.0000001;
        const options = _defaults.optionsFromArguments(Param.getDefaults(), arguments, [
            "param",
            "units",
            "convert"
        ]);
        _debug.assert(_typeCheck.isDefined(options.param) && (_advancedTypeCheck.isAudioParam(options.param) || options.param instanceof Param), "param must be an AudioParam");
        while(!_advancedTypeCheck.isAudioParam(options.param))options.param = options.param._param;
        this._swappable = _typeCheck.isDefined(options.swappable) ? options.swappable : false;
        if (this._swappable) {
            this.input = this.context.createGain();
            // initialize
            this._param = options.param;
            this.input.connect(this._param);
        } else this._param = this.input = options.param;
        this._events = new _timeline.Timeline(1000);
        this._initialValue = this._param.defaultValue;
        this.units = options.units;
        this.convert = options.convert;
        this._minValue = options.minValue;
        this._maxValue = options.maxValue;
        // if the value is defined, set it immediately
        if (_typeCheck.isDefined(options.value) && options.value !== this._toType(this._initialValue)) this.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign(_toneWithContext.ToneWithContext.getDefaults(), {
            convert: true,
            units: "number"
        });
    }
    get value() {
        const now = this.now();
        return this.getValueAtTime(now);
    }
    set value(value) {
        this.cancelScheduledValues(this.now());
        this.setValueAtTime(value, this.now());
    }
    get minValue() {
        // if it's not the default minValue, return it
        if (_typeCheck.isDefined(this._minValue)) return this._minValue;
        else if (this.units === "time" || this.units === "frequency" || this.units === "normalRange" || this.units === "positive" || this.units === "transportTime" || this.units === "ticks" || this.units === "bpm" || this.units === "hertz" || this.units === "samples") return 0;
        else if (this.units === "audioRange") return -1;
        else if (this.units === "decibels") return -Infinity;
        else return this._param.minValue;
    }
    get maxValue() {
        if (_typeCheck.isDefined(this._maxValue)) return this._maxValue;
        else if (this.units === "normalRange" || this.units === "audioRange") return 1;
        else return this._param.maxValue;
    }
    /**
     * Type guard based on the unit name
     */ _is(arg, type) {
        return this.units === type;
    }
    /**
     * Make sure the value is always in the defined range
     */ _assertRange(value) {
        if (_typeCheck.isDefined(this.maxValue) && _typeCheck.isDefined(this.minValue)) _debug.assertRange(value, this._fromType(this.minValue), this._fromType(this.maxValue));
        return value;
    }
    /**
     * Convert the given value from the type specified by Param.units
     * into the destination value (such as Gain or Frequency).
     */ _fromType(val) {
        if (this.convert && !this.overridden) {
            if (this._is(val, "time")) return this.toSeconds(val);
            else if (this._is(val, "decibels")) return _conversions.dbToGain(val);
            else if (this._is(val, "frequency")) return this.toFrequency(val);
            else return val;
        } else if (this.overridden) // if it's overridden, should only schedule 0s
        return 0;
        else return val;
    }
    /**
     * Convert the parameters value into the units specified by Param.units.
     */ _toType(val) {
        if (this.convert && this.units === "decibels") return _conversions.gainToDb(val);
        else return val;
    }
    //-------------------------------------
    // ABSTRACT PARAM INTERFACE
    // all docs are generated from ParamInterface.ts
    //-------------------------------------
    setValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        const numericValue = this._fromType(value);
        _debug.assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(time)}`);
        this._assertRange(numericValue);
        this.log(this.units, "setValueAtTime", value, computedTime);
        this._events.add({
            time: computedTime,
            type: "setValueAtTime",
            value: numericValue
        });
        this._param.setValueAtTime(numericValue, computedTime);
        return this;
    }
    getValueAtTime(time) {
        const computedTime = Math.max(this.toSeconds(time), 0);
        const after = this._events.getAfter(computedTime);
        const before = this._events.get(computedTime);
        let value = this._initialValue;
        // if it was set by
        if (before === null) value = this._initialValue;
        else if (before.type === "setTargetAtTime" && (after === null || after.type === "setValueAtTime")) {
            const previous = this._events.getBefore(before.time);
            let previousVal;
            if (previous === null) previousVal = this._initialValue;
            else previousVal = previous.value;
            if (before.type === "setTargetAtTime") value = this._exponentialApproach(before.time, previousVal, before.value, before.constant, computedTime);
        } else if (after === null) value = before.value;
        else if (after.type === "linearRampToValueAtTime" || after.type === "exponentialRampToValueAtTime") {
            let beforeValue = before.value;
            if (before.type === "setTargetAtTime") {
                const previous = this._events.getBefore(before.time);
                if (previous === null) beforeValue = this._initialValue;
                else beforeValue = previous.value;
            }
            if (after.type === "linearRampToValueAtTime") value = this._linearInterpolate(before.time, beforeValue, after.time, after.value, computedTime);
            else value = this._exponentialInterpolate(before.time, beforeValue, after.time, after.value, computedTime);
        } else value = before.value;
        return this._toType(value);
    }
    setRampPoint(time) {
        time = this.toSeconds(time);
        let currentVal = this.getValueAtTime(time);
        this.cancelAndHoldAtTime(time);
        if (this._fromType(currentVal) === 0) currentVal = this._toType(this._minOutput);
        this.setValueAtTime(currentVal, time);
        return this;
    }
    linearRampToValueAtTime(value, endTime) {
        const numericValue = this._fromType(value);
        const computedTime = this.toSeconds(endTime);
        _debug.assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to linearRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);
        this._assertRange(numericValue);
        this._events.add({
            time: computedTime,
            type: "linearRampToValueAtTime",
            value: numericValue
        });
        this.log(this.units, "linearRampToValueAtTime", value, computedTime);
        this._param.linearRampToValueAtTime(numericValue, computedTime);
        return this;
    }
    exponentialRampToValueAtTime(value, endTime) {
        let numericValue = this._fromType(value);
        // the value can't be 0
        numericValue = _math.EQ(numericValue, 0) ? this._minOutput : numericValue;
        this._assertRange(numericValue);
        const computedTime = this.toSeconds(endTime);
        _debug.assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to exponentialRampToValueAtTime: ${JSON.stringify(value)}, ${JSON.stringify(endTime)}`);
        // store the event
        this._events.add({
            time: computedTime,
            type: "exponentialRampToValueAtTime",
            value: numericValue
        });
        this.log(this.units, "exponentialRampToValueAtTime", value, computedTime);
        this._param.exponentialRampToValueAtTime(numericValue, computedTime);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.exponentialRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.linearRampToValueAtTime(value, startTime + this.toSeconds(rampTime));
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        startTime = this.toSeconds(startTime);
        this.setRampPoint(startTime);
        this.exponentialApproachValueAtTime(value, startTime, rampTime);
        return this;
    }
    exponentialApproachValueAtTime(value, time, rampTime) {
        time = this.toSeconds(time);
        rampTime = this.toSeconds(rampTime);
        const timeConstant = Math.log(rampTime + 1) / Math.log(200);
        this.setTargetAtTime(value, time, timeConstant);
        // at 90% start a linear ramp to the final value
        this.cancelAndHoldAtTime(time + rampTime * 0.9);
        this.linearRampToValueAtTime(value, time + rampTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        const numericValue = this._fromType(value);
        // The value will never be able to approach without timeConstant > 0.
        _debug.assert(isFinite(timeConstant) && timeConstant > 0, "timeConstant must be a number greater than 0");
        const computedTime = this.toSeconds(startTime);
        this._assertRange(numericValue);
        _debug.assert(isFinite(numericValue) && isFinite(computedTime), `Invalid argument(s) to setTargetAtTime: ${JSON.stringify(value)}, ${JSON.stringify(startTime)}`);
        this._events.add({
            constant: timeConstant,
            time: computedTime,
            type: "setTargetAtTime",
            value: numericValue
        });
        this.log(this.units, "setTargetAtTime", value, computedTime, timeConstant);
        this._param.setTargetAtTime(numericValue, computedTime, timeConstant);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling = 1) {
        duration = this.toSeconds(duration);
        startTime = this.toSeconds(startTime);
        const startingValue = this._fromType(values[0]) * scaling;
        this.setValueAtTime(this._toType(startingValue), startTime);
        const segTime = duration / (values.length - 1);
        for(let i = 1; i < values.length; i++){
            const numericValue = this._fromType(values[i]) * scaling;
            this.linearRampToValueAtTime(this._toType(numericValue), startTime + i * segTime);
        }
        return this;
    }
    cancelScheduledValues(time) {
        const computedTime = this.toSeconds(time);
        _debug.assert(isFinite(computedTime), `Invalid argument to cancelScheduledValues: ${JSON.stringify(time)}`);
        this._events.cancel(computedTime);
        this._param.cancelScheduledValues(computedTime);
        this.log(this.units, "cancelScheduledValues", computedTime);
        return this;
    }
    cancelAndHoldAtTime(time) {
        const computedTime = this.toSeconds(time);
        const valueAtTime = this._fromType(this.getValueAtTime(computedTime));
        // remove the schedule events
        _debug.assert(isFinite(computedTime), `Invalid argument to cancelAndHoldAtTime: ${JSON.stringify(time)}`);
        this.log(this.units, "cancelAndHoldAtTime", computedTime, "value=" + valueAtTime);
        // if there is an event at the given computedTime
        // and that even is not a "set"
        const before = this._events.get(computedTime);
        const after = this._events.getAfter(computedTime);
        if (before && _math.EQ(before.time, computedTime)) {
            // remove everything after
            if (after) {
                this._param.cancelScheduledValues(after.time);
                this._events.cancel(after.time);
            } else {
                this._param.cancelAndHoldAtTime(computedTime);
                this._events.cancel(computedTime + this.sampleTime);
            }
        } else if (after) {
            this._param.cancelScheduledValues(after.time);
            // cancel the next event(s)
            this._events.cancel(after.time);
            if (after.type === "linearRampToValueAtTime") this.linearRampToValueAtTime(this._toType(valueAtTime), computedTime);
            else if (after.type === "exponentialRampToValueAtTime") this.exponentialRampToValueAtTime(this._toType(valueAtTime), computedTime);
        }
        // set the value at the given time
        this._events.add({
            time: computedTime,
            type: "setValueAtTime",
            value: valueAtTime
        });
        this._param.setValueAtTime(valueAtTime, computedTime);
        return this;
    }
    rampTo(value, rampTime = 0.1, startTime) {
        if (this.units === "frequency" || this.units === "bpm" || this.units === "decibels") this.exponentialRampTo(value, rampTime, startTime);
        else this.linearRampTo(value, rampTime, startTime);
        return this;
    }
    /**
     * Apply all of the previously scheduled events to the passed in Param or AudioParam.
     * The applied values will start at the context's current time and schedule
     * all of the events which are scheduled on this Param onto the passed in param.
     */ apply(param) {
        const now = this.context.currentTime;
        // set the param's value at the current time and schedule everything else
        param.setValueAtTime(this.getValueAtTime(now), now);
        // if the previous event was a curve, then set the rest of it
        const previousEvent = this._events.get(now);
        if (previousEvent && previousEvent.type === "setTargetAtTime") {
            // approx it until the next event with linear ramps
            const nextEvent = this._events.getAfter(previousEvent.time);
            // or for 2 seconds if there is no event
            const endTime = nextEvent ? nextEvent.time : now + 2;
            const subdivisions = (endTime - now) / 10;
            for(let i = now; i < endTime; i += subdivisions)param.linearRampToValueAtTime(this.getValueAtTime(i), i);
        }
        this._events.forEachAfter(this.context.currentTime, (event)=>{
            if (event.type === "cancelScheduledValues") param.cancelScheduledValues(event.time);
            else if (event.type === "setTargetAtTime") param.setTargetAtTime(event.value, event.time, event.constant);
            else param[event.type](event.value, event.time);
        });
        return this;
    }
    /**
     * Replace the Param's internal AudioParam. Will apply scheduled curves
     * onto the parameter and replace the connections.
     */ setParam(param) {
        _debug.assert(this._swappable, "The Param must be assigned as 'swappable' in the constructor");
        const input = this.input;
        input.disconnect(this._param);
        this.apply(param);
        this._param = param;
        input.connect(this._param);
        return this;
    }
    dispose() {
        super.dispose();
        this._events.dispose();
        return this;
    }
    get defaultValue() {
        return this._toType(this._param.defaultValue);
    }
    //-------------------------------------
    // 	AUTOMATION CURVE CALCULATIONS
    // 	MIT License, copyright (c) 2014 Jordan Santell
    //-------------------------------------
    // Calculates the the value along the curve produced by setTargetAtTime
    _exponentialApproach(t0, v0, v1, timeConstant, t) {
        return v1 + (v0 - v1) * Math.exp(-(t - t0) / timeConstant);
    }
    // Calculates the the value along the curve produced by linearRampToValueAtTime
    _linearInterpolate(t0, v0, t1, v1, t) {
        return v0 + (v1 - v0) * ((t - t0) / (t1 - t0));
    }
    // Calculates the the value along the curve produced by exponentialRampToValueAtTime
    _exponentialInterpolate(t0, v0, t1, v1, t) {
        return v0 * Math.pow(v1 / v0, (t - t0) / (t1 - t0));
    }
}

},{"../type/Conversions":"kOcnG","../util/AdvancedTypeCheck":"arR2z","../util/Defaults":"kSyYt","../util/Timeline":"leurn","../util/TypeCheck":"lCqGC","./ToneWithContext":"ez5Mk","../util/Math":"gdhOV","../util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iT1SZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * ToneAudioNode is the base class for classes which process audio.
 */ parcelHelpers.export(exports, "ToneAudioNode", ()=>ToneAudioNode
);
//-------------------------------------
// CONNECTIONS
//-------------------------------------
/**
 * connect together all of the arguments in series
 * @param nodes
 */ parcelHelpers.export(exports, "connectSeries", ()=>connectSeries
);
/**
 * Connect two nodes together so that signal flows from the
 * first node to the second. Optionally specify the input and output channels.
 * @param srcNode The source node
 * @param dstNode The destination node
 * @param outputNumber The output channel of the srcNode
 * @param inputNumber The input channel of the dstNode
 */ parcelHelpers.export(exports, "connect", ()=>connect
);
/**
 * Disconnect a node from all nodes or optionally include a destination node and input/output channels.
 * @param srcNode The source node
 * @param dstNode The destination node
 * @param outputNumber The output channel of the srcNode
 * @param inputNumber The input channel of the dstNode
 */ parcelHelpers.export(exports, "disconnect", ()=>disconnect
);
var _advancedTypeCheck = require("../util/AdvancedTypeCheck");
var _typeCheck = require("../util/TypeCheck");
var _param = require("./Param");
var _toneWithContext = require("./ToneWithContext");
var _debug = require("../util/Debug");
class ToneAudioNode extends _toneWithContext.ToneWithContext {
    constructor(){
        super(...arguments);
        /**
         * The name of the class
         */ this.name = "ToneAudioNode";
        /**
         * List all of the node that must be set to match the ChannelProperties
         */ this._internalChannels = [];
    }
    /**
     * The number of inputs feeding into the AudioNode.
     * For source nodes, this will be 0.
     * @example
     * const node = new Tone.Gain();
     * console.log(node.numberOfInputs);
     */ get numberOfInputs() {
        if (_typeCheck.isDefined(this.input)) {
            if (_advancedTypeCheck.isAudioParam(this.input) || this.input instanceof _param.Param) return 1;
            else return this.input.numberOfInputs;
        } else return 0;
    }
    /**
     * The number of outputs of the AudioNode.
     * @example
     * const node = new Tone.Gain();
     * console.log(node.numberOfOutputs);
     */ get numberOfOutputs() {
        if (_typeCheck.isDefined(this.output)) return this.output.numberOfOutputs;
        else return 0;
    }
    //-------------------------------------
    // AUDIO PROPERTIES
    //-------------------------------------
    /**
     * Used to decide which nodes to get/set properties on
     */ _isAudioNode(node) {
        return _typeCheck.isDefined(node) && (node instanceof ToneAudioNode || _advancedTypeCheck.isAudioNode(node));
    }
    /**
     * Get all of the audio nodes (either internal or input/output) which together
     * make up how the class node responds to channel input/output
     */ _getInternalNodes() {
        const nodeList = this._internalChannels.slice(0);
        if (this._isAudioNode(this.input)) nodeList.push(this.input);
        if (this._isAudioNode(this.output)) {
            if (this.input !== this.output) nodeList.push(this.output);
        }
        return nodeList;
    }
    /**
     * Set the audio options for this node such as channelInterpretation
     * channelCount, etc.
     * @param options
     */ _setChannelProperties(options) {
        const nodeList = this._getInternalNodes();
        nodeList.forEach((node)=>{
            node.channelCount = options.channelCount;
            node.channelCountMode = options.channelCountMode;
            node.channelInterpretation = options.channelInterpretation;
        });
    }
    /**
     * Get the current audio options for this node such as channelInterpretation
     * channelCount, etc.
     */ _getChannelProperties() {
        const nodeList = this._getInternalNodes();
        _debug.assert(nodeList.length > 0, "ToneAudioNode does not have any internal nodes");
        // use the first node to get properties
        // they should all be the same
        const node = nodeList[0];
        return {
            channelCount: node.channelCount,
            channelCountMode: node.channelCountMode,
            channelInterpretation: node.channelInterpretation
        };
    }
    /**
     * channelCount is the number of channels used when up-mixing and down-mixing
     * connections to any inputs to the node. The default value is 2 except for
     * specific nodes where its value is specially determined.
     */ get channelCount() {
        return this._getChannelProperties().channelCount;
    }
    set channelCount(channelCount) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelCount
        }));
    }
    /**
     * channelCountMode determines how channels will be counted when up-mixing and
     * down-mixing connections to any inputs to the node.
     * The default value is "max". This attribute has no effect for nodes with no inputs.
     * * "max" - computedNumberOfChannels is the maximum of the number of channels of all connections to an input. In this mode channelCount is ignored.
     * * "clamped-max" - computedNumberOfChannels is determined as for "max" and then clamped to a maximum value of the given channelCount.
     * * "explicit" - computedNumberOfChannels is the exact value as specified by the channelCount.
     */ get channelCountMode() {
        return this._getChannelProperties().channelCountMode;
    }
    set channelCountMode(channelCountMode) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelCountMode
        }));
    }
    /**
     * channelInterpretation determines how individual channels will be treated
     * when up-mixing and down-mixing connections to any inputs to the node.
     * The default value is "speakers".
     */ get channelInterpretation() {
        return this._getChannelProperties().channelInterpretation;
    }
    set channelInterpretation(channelInterpretation) {
        const props = this._getChannelProperties();
        // merge it with the other properties
        this._setChannelProperties(Object.assign(props, {
            channelInterpretation
        }));
    }
    //-------------------------------------
    // CONNECTIONS
    //-------------------------------------
    /**
     * connect the output of a ToneAudioNode to an AudioParam, AudioNode, or ToneAudioNode
     * @param destination The output to connect to
     * @param outputNum The output to connect from
     * @param inputNum The input to connect to
     */ connect(destination, outputNum = 0, inputNum = 0) {
        connect(this, destination, outputNum, inputNum);
        return this;
    }
    /**
     * Connect the output to the context's destination node.
     * @example
     * const osc = new Tone.Oscillator("C2").start();
     * osc.toDestination();
     */ toDestination() {
        this.connect(this.context.destination);
        return this;
    }
    /**
     * Connect the output to the context's destination node.
     * See [[toDestination]]
     * @deprecated
     */ toMaster() {
        _debug.warn("toMaster() has been renamed toDestination()");
        return this.toDestination();
    }
    /**
     * disconnect the output
     */ disconnect(destination, outputNum = 0, inputNum = 0) {
        disconnect(this, destination, outputNum, inputNum);
        return this;
    }
    /**
     * Connect the output of this node to the rest of the nodes in series.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/handdrum-loop.mp3");
     * player.autostart = true;
     * const filter = new Tone.AutoFilter(4).start();
     * const distortion = new Tone.Distortion(0.5);
     * // connect the player to the filter, distortion and then to the master output
     * player.chain(filter, distortion, Tone.Destination);
     */ chain(...nodes) {
        connectSeries(this, ...nodes);
        return this;
    }
    /**
     * connect the output of this node to the rest of the nodes in parallel.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/conga-rhythm.mp3");
     * player.autostart = true;
     * const pitchShift = new Tone.PitchShift(4).toDestination();
     * const filter = new Tone.Filter("G5").toDestination();
     * // connect a node to the pitch shift and filter in parallel
     * player.fan(pitchShift, filter);
     */ fan(...nodes) {
        nodes.forEach((node)=>this.connect(node)
        );
        return this;
    }
    /**
     * Dispose and disconnect
     */ dispose() {
        super.dispose();
        if (_typeCheck.isDefined(this.input)) {
            if (this.input instanceof ToneAudioNode) this.input.dispose();
            else if (_advancedTypeCheck.isAudioNode(this.input)) this.input.disconnect();
        }
        if (_typeCheck.isDefined(this.output)) {
            if (this.output instanceof ToneAudioNode) this.output.dispose();
            else if (_advancedTypeCheck.isAudioNode(this.output)) this.output.disconnect();
        }
        this._internalChannels = [];
        return this;
    }
}
function connectSeries(...nodes) {
    const first = nodes.shift();
    nodes.reduce((prev, current)=>{
        if (prev instanceof ToneAudioNode) prev.connect(current);
        else if (_advancedTypeCheck.isAudioNode(prev)) connect(prev, current);
        return current;
    }, first);
}
function connect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {
    _debug.assert(_typeCheck.isDefined(srcNode), "Cannot connect from undefined node");
    _debug.assert(_typeCheck.isDefined(dstNode), "Cannot connect to undefined node");
    if (dstNode instanceof ToneAudioNode || _advancedTypeCheck.isAudioNode(dstNode)) _debug.assert(dstNode.numberOfInputs > 0, "Cannot connect to node with no inputs");
    _debug.assert(srcNode.numberOfOutputs > 0, "Cannot connect from node with no outputs");
    // resolve the input of the dstNode
    while(dstNode instanceof ToneAudioNode || dstNode instanceof _param.Param)if (_typeCheck.isDefined(dstNode.input)) dstNode = dstNode.input;
    while(srcNode instanceof ToneAudioNode)if (_typeCheck.isDefined(srcNode.output)) srcNode = srcNode.output;
    // make the connection
    if (_advancedTypeCheck.isAudioParam(dstNode)) srcNode.connect(dstNode, outputNumber);
    else srcNode.connect(dstNode, outputNumber, inputNumber);
}
function disconnect(srcNode, dstNode, outputNumber = 0, inputNumber = 0) {
    // resolve the destination node
    if (_typeCheck.isDefined(dstNode)) while(dstNode instanceof ToneAudioNode)dstNode = dstNode.input;
    // resolve the src node
    while(!_advancedTypeCheck.isAudioNode(srcNode))if (_typeCheck.isDefined(srcNode.output)) srcNode = srcNode.output;
    if (_advancedTypeCheck.isAudioParam(dstNode)) srcNode.disconnect(dstNode, outputNumber);
    else if (_advancedTypeCheck.isAudioNode(dstNode)) srcNode.disconnect(dstNode, outputNumber, inputNumber);
    else srcNode.disconnect();
}

},{"../util/AdvancedTypeCheck":"arR2z","../util/TypeCheck":"lCqGC","./Param":"2qxaM","./ToneWithContext":"ez5Mk","../util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iRz6E":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native fire-and-forget ConstantSource.
 * Adds the ability to reschedule the stop method.
 * @category Signal
 */ parcelHelpers.export(exports, "ToneConstantSource", ()=>ToneConstantSource
);
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _param = require("../core/context/Param");
var _defaults = require("../core/util/Defaults");
var _oneShotSource = require("../source/OneShotSource");
class ToneConstantSource extends _oneShotSource.OneShotSource {
    constructor(){
        super(_defaults.optionsFromArguments(ToneConstantSource.getDefaults(), arguments, [
            "offset"
        ]));
        this.name = "ToneConstantSource";
        /**
         * The signal generator
         */ this._source = this.context.createConstantSource();
        const options = _defaults.optionsFromArguments(ToneConstantSource.getDefaults(), arguments, [
            "offset"
        ]);
        _toneAudioNode.connect(this._source, this._gainNode);
        this.offset = new _param.Param({
            context: this.context,
            convert: options.convert,
            param: this._source.offset,
            units: options.units,
            value: options.offset,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
    }
    static getDefaults() {
        return Object.assign(_oneShotSource.OneShotSource.getDefaults(), {
            convert: true,
            offset: 1,
            units: "number"
        });
    }
    /**
     * Start the source node at the given time
     * @param  time When to start the source
     */ start(time) {
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        this._startGain(computedTime);
        this._source.start(computedTime);
        return this;
    }
    _stopSource(time) {
        this._source.stop(time);
    }
    dispose() {
        super.dispose();
        if (this.state === "started") this.stop();
        this._source.disconnect();
        this.offset.dispose();
        return this;
    }
}

},{"../core/context/ToneAudioNode":"iT1SZ","../core/context/Param":"2qxaM","../core/util/Defaults":"kSyYt","../source/OneShotSource":"hEB90","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hEB90":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for fire-and-forget nodes
 */ parcelHelpers.export(exports, "OneShotSource", ()=>OneShotSource
);
var _gain = require("../core/context/Gain");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _interface = require("../core/util/Interface");
var _debug = require("../core/util/Debug");
class OneShotSource extends _toneAudioNode.ToneAudioNode {
    constructor(options){
        super(options);
        /**
         * The callback to invoke after the
         * source is done playing.
         */ this.onended = _interface.noOp;
        /**
         * The start time
         */ this._startTime = -1;
        /**
         * The stop time
         */ this._stopTime = -1;
        /**
         * The id of the timeout
         */ this._timeout = -1;
        /**
         * The public output node
         */ this.output = new _gain.Gain({
            context: this.context,
            gain: 0
        });
        /**
         * The output gain node.
         */ this._gainNode = this.output;
        /**
         * Get the playback state at the given time
         */ this.getStateAtTime = function(time) {
            const computedTime = this.toSeconds(time);
            if (this._startTime !== -1 && computedTime >= this._startTime && (this._stopTime === -1 || computedTime <= this._stopTime)) return "started";
            else return "stopped";
        };
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
        this._curve = options.curve;
        this.onended = options.onended;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            curve: "linear",
            fadeIn: 0,
            fadeOut: 0,
            onended: _interface.noOp
        });
    }
    /**
     * Start the source at the given time
     * @param  time When to start the source
     */ _startGain(time, gain = 1) {
        _debug.assert(this._startTime === -1, "Source cannot be started more than once");
        // apply a fade in envelope
        const fadeInTime = this.toSeconds(this._fadeIn);
        // record the start time
        this._startTime = time + fadeInTime;
        this._startTime = Math.max(this._startTime, this.context.currentTime);
        // schedule the envelope
        if (fadeInTime > 0) {
            this._gainNode.gain.setValueAtTime(0, time);
            if (this._curve === "linear") this._gainNode.gain.linearRampToValueAtTime(gain, time + fadeInTime);
            else this._gainNode.gain.exponentialApproachValueAtTime(gain, time, fadeInTime);
        } else this._gainNode.gain.setValueAtTime(gain, time);
        return this;
    }
    /**
     * Stop the source node at the given time.
     * @param time When to stop the source
     */ stop(time) {
        this.log("stop", time);
        this._stopGain(this.toSeconds(time));
        return this;
    }
    /**
     * Stop the source at the given time
     * @param  time When to stop the source
     */ _stopGain(time) {
        _debug.assert(this._startTime !== -1, "'start' must be called before 'stop'");
        // cancel the previous stop
        this.cancelStop();
        // the fadeOut time
        const fadeOutTime = this.toSeconds(this._fadeOut);
        // schedule the stop callback
        this._stopTime = this.toSeconds(time) + fadeOutTime;
        this._stopTime = Math.max(this._stopTime, this.context.currentTime);
        if (fadeOutTime > 0) {
            // start the fade out curve at the given time
            if (this._curve === "linear") this._gainNode.gain.linearRampTo(0, fadeOutTime, time);
            else this._gainNode.gain.targetRampTo(0, fadeOutTime, time);
        } else {
            // stop any ongoing ramps, and set the value to 0
            this._gainNode.gain.cancelAndHoldAtTime(time);
            this._gainNode.gain.setValueAtTime(0, time);
        }
        this.context.clearTimeout(this._timeout);
        this._timeout = this.context.setTimeout(()=>{
            // allow additional time for the exponential curve to fully decay
            const additionalTail = this._curve === "exponential" ? fadeOutTime * 2 : 0;
            this._stopSource(this.now() + additionalTail);
            this._onended();
        }, this._stopTime - this.context.currentTime);
        return this;
    }
    /**
     * Invoke the onended callback
     */ _onended() {
        if (this.onended !== _interface.noOp) {
            this.onended(this);
            // overwrite onended to make sure it only is called once
            this.onended = _interface.noOp;
            // dispose when it's ended to free up for garbage collection only in the online context
            if (!this.context.isOffline) {
                const disposeCallback = ()=>this.dispose()
                ;
                // @ts-ignore
                if (typeof window.requestIdleCallback !== "undefined") // @ts-ignore
                window.requestIdleCallback(disposeCallback);
                else setTimeout(disposeCallback, 1000);
            }
        }
    }
    /**
     * Get the playback state at the current time
     */ get state() {
        return this.getStateAtTime(this.now());
    }
    /**
     * Cancel a scheduled stop event
     */ cancelStop() {
        this.log("cancelStop");
        _debug.assert(this._startTime !== -1, "Source is not started");
        // cancel the stop envelope
        this._gainNode.gain.cancelScheduledValues(this._startTime + this.sampleTime);
        this.context.clearTimeout(this._timeout);
        this._stopTime = -1;
        return this;
    }
    dispose() {
        super.dispose();
        this._gainNode.disconnect();
        return this;
    }
}

},{"../core/context/Gain":"7kpMn","../core/context/ToneAudioNode":"iT1SZ","../core/util/Interface":"fVoXs","../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7kpMn":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A thin wrapper around the Native Web Audio GainNode.
 * The GainNode is a basic building block of the Web Audio
 * API and is useful for routing audio and adjusting gains.
 * @category Core
 * @example
 * return Tone.Offline(() => {
 * 	const gainNode = new Tone.Gain(0).toDestination();
 * 	const osc = new Tone.Oscillator(30).connect(gainNode).start();
 * 	gainNode.gain.rampTo(1, 0.1);
 * 	gainNode.gain.rampTo(0, 0.4, 0.2);
 * }, 0.7, 1);
 */ parcelHelpers.export(exports, "Gain", ()=>Gain
);
var _param = require("../context/Param");
var _defaults = require("../util/Defaults");
var _interface = require("../util/Interface");
var _toneAudioNode = require("./ToneAudioNode");
class Gain extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Gain.getDefaults(), arguments, [
            "gain",
            "units"
        ]));
        this.name = "Gain";
        /**
         * The wrapped GainNode.
         */ this._gainNode = this.context.createGain();
        // input = output
        this.input = this._gainNode;
        this.output = this._gainNode;
        const options = _defaults.optionsFromArguments(Gain.getDefaults(), arguments, [
            "gain",
            "units"
        ]);
        this.gain = new _param.Param({
            context: this.context,
            convert: options.convert,
            param: this._gainNode.gain,
            units: options.units,
            value: options.gain,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        _interface.readOnly(this, "gain");
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            convert: true,
            gain: 1,
            units: "gain"
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._gainNode.disconnect();
        this.gain.dispose();
        return this;
    }
}

},{"../context/Param":"2qxaM","../util/Defaults":"kSyYt","../util/Interface":"fVoXs","./ToneAudioNode":"iT1SZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"feUbN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A Param class just for computing ticks. Similar to the [[Param]] class,
 * but offers conversion to BPM values as well as ability to compute tick
 * duration and elapsed ticks
 */ parcelHelpers.export(exports, "TickParam", ()=>TickParam
);
var _param = require("../context/Param");
var _defaults = require("../util/Defaults");
var _timeline = require("../util/Timeline");
var _typeCheck = require("../util/TypeCheck");
class TickParam extends _param.Param {
    constructor(){
        super(_defaults.optionsFromArguments(TickParam.getDefaults(), arguments, [
            "value"
        ]));
        this.name = "TickParam";
        /**
         * The timeline which tracks all of the automations.
         */ this._events = new _timeline.Timeline(Infinity);
        /**
         * The internal holder for the multiplier value
         */ this._multiplier = 1;
        const options = _defaults.optionsFromArguments(TickParam.getDefaults(), arguments, [
            "value"
        ]);
        // set the multiplier
        this._multiplier = options.multiplier;
        // clear the ticks from the beginning
        this._events.cancel(0);
        // set an initial event
        this._events.add({
            ticks: 0,
            time: 0,
            type: "setValueAtTime",
            value: this._fromType(options.value)
        });
        this.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign(_param.Param.getDefaults(), {
            multiplier: 1,
            units: "hertz",
            value: 1
        });
    }
    setTargetAtTime(value, time, constant) {
        // approximate it with multiple linear ramps
        time = this.toSeconds(time);
        this.setRampPoint(time);
        const computedValue = this._fromType(value);
        // start from previously scheduled value
        const prevEvent = this._events.get(time);
        const segments = Math.round(Math.max(1 / constant, 1));
        for(let i = 0; i <= segments; i++){
            const segTime = constant * i + time;
            const rampVal = this._exponentialApproach(prevEvent.time, prevEvent.value, computedValue, constant, segTime);
            this.linearRampToValueAtTime(this._toType(rampVal), segTime);
        }
        return this;
    }
    setValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        super.setValueAtTime(value, time);
        const event = this._events.get(computedTime);
        const previousEvent = this._events.previousEvent(event);
        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);
        event.ticks = Math.max(ticksUntilTime, 0);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        const computedTime = this.toSeconds(time);
        super.linearRampToValueAtTime(value, time);
        const event = this._events.get(computedTime);
        const previousEvent = this._events.previousEvent(event);
        const ticksUntilTime = this._getTicksUntilEvent(previousEvent, computedTime);
        event.ticks = Math.max(ticksUntilTime, 0);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        // aproximate it with multiple linear ramps
        time = this.toSeconds(time);
        const computedVal = this._fromType(value);
        // start from previously scheduled value
        const prevEvent = this._events.get(time);
        // approx 10 segments per second
        const segments = Math.round(Math.max((time - prevEvent.time) * 10, 1));
        const segmentDur = (time - prevEvent.time) / segments;
        for(let i = 0; i <= segments; i++){
            const segTime = segmentDur * i + prevEvent.time;
            const rampVal = this._exponentialInterpolate(prevEvent.time, prevEvent.value, time, computedVal, segTime);
            this.linearRampToValueAtTime(this._toType(rampVal), segTime);
        }
        return this;
    }
    /**
     * Returns the tick value at the time. Takes into account
     * any automation curves scheduled on the signal.
     * @param  event The time to get the tick count at
     * @return The number of ticks which have elapsed at the time given any automations.
     */ _getTicksUntilEvent(event, time) {
        if (event === null) event = {
            ticks: 0,
            time: 0,
            type: "setValueAtTime",
            value: 0
        };
        else if (_typeCheck.isUndef(event.ticks)) {
            const previousEvent = this._events.previousEvent(event);
            event.ticks = this._getTicksUntilEvent(previousEvent, event.time);
        }
        const val0 = this._fromType(this.getValueAtTime(event.time));
        let val1 = this._fromType(this.getValueAtTime(time));
        // if it's right on the line, take the previous value
        const onTheLineEvent = this._events.get(time);
        if (onTheLineEvent && onTheLineEvent.time === time && onTheLineEvent.type === "setValueAtTime") val1 = this._fromType(this.getValueAtTime(time - this.sampleTime));
        return 0.5 * (time - event.time) * (val0 + val1) + event.ticks;
    }
    /**
     * Returns the tick value at the time. Takes into account
     * any automation curves scheduled on the signal.
     * @param  time The time to get the tick count at
     * @return The number of ticks which have elapsed at the time given any automations.
     */ getTicksAtTime(time) {
        const computedTime = this.toSeconds(time);
        const event = this._events.get(computedTime);
        return Math.max(this._getTicksUntilEvent(event, computedTime), 0);
    }
    /**
     * Return the elapsed time of the number of ticks from the given time
     * @param ticks The number of ticks to calculate
     * @param  time The time to get the next tick from
     * @return The duration of the number of ticks from the given time in seconds
     */ getDurationOfTicks(ticks, time) {
        const computedTime = this.toSeconds(time);
        const currentTick = this.getTicksAtTime(time);
        return this.getTimeOfTick(currentTick + ticks) - computedTime;
    }
    /**
     * Given a tick, returns the time that tick occurs at.
     * @return The time that the tick occurs.
     */ getTimeOfTick(tick) {
        const before = this._events.get(tick, "ticks");
        const after = this._events.getAfter(tick, "ticks");
        if (before && before.ticks === tick) return before.time;
        else if (before && after && after.type === "linearRampToValueAtTime" && before.value !== after.value) {
            const val0 = this._fromType(this.getValueAtTime(before.time));
            const val1 = this._fromType(this.getValueAtTime(after.time));
            const delta = (val1 - val0) / (after.time - before.time);
            const k = Math.sqrt(Math.pow(val0, 2) - 2 * delta * (before.ticks - tick));
            const sol1 = (-val0 + k) / delta;
            const sol2 = (-val0 - k) / delta;
            return (sol1 > 0 ? sol1 : sol2) + before.time;
        } else if (before) {
            if (before.value === 0) return Infinity;
            else return before.time + (tick - before.ticks) / before.value;
        } else return tick / this._initialValue;
    }
    /**
     * Convert some number of ticks their the duration in seconds accounting
     * for any automation curves starting at the given time.
     * @param  ticks The number of ticks to convert to seconds.
     * @param  when  When along the automation timeline to convert the ticks.
     * @return The duration in seconds of the ticks.
     */ ticksToTime(ticks, when) {
        return this.getDurationOfTicks(ticks, when);
    }
    /**
     * The inverse of [[ticksToTime]]. Convert a duration in
     * seconds to the corresponding number of ticks accounting for any
     * automation curves starting at the given time.
     * @param  duration The time interval to convert to ticks.
     * @param  when When along the automation timeline to convert the ticks.
     * @return The duration in ticks.
     */ timeToTicks(duration, when) {
        const computedTime = this.toSeconds(when);
        const computedDuration = this.toSeconds(duration);
        const startTicks = this.getTicksAtTime(computedTime);
        const endTicks = this.getTicksAtTime(computedTime + computedDuration);
        return endTicks - startTicks;
    }
    /**
     * Convert from the type when the unit value is BPM
     */ _fromType(val) {
        if (this.units === "bpm" && this.multiplier) return 1 / (60 / val / this.multiplier);
        else return super._fromType(val);
    }
    /**
     * Special case of type conversion where the units === "bpm"
     */ _toType(val) {
        if (this.units === "bpm" && this.multiplier) return val / this.multiplier * 60;
        else return super._toType(val);
    }
    /**
     * A multiplier on the bpm value. Useful for setting a PPQ relative to the base frequency value.
     */ get multiplier() {
        return this._multiplier;
    }
    set multiplier(m) {
        // get and reset the current value with the new multiplier
        // might be necessary to clear all the previous values
        const currentVal = this.value;
        this._multiplier = m;
        this.cancelScheduledValues(0);
        this.setValueAtTime(currentVal, 0);
    }
}

},{"../context/Param":"2qxaM","../util/Defaults":"kSyYt","../util/Timeline":"leurn","../util/TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fGWul":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around Web Audio's native [DelayNode](http://webaudio.github.io/web-audio-api/#the-delaynode-interface).
 * @category Core
 * @example
 * return Tone.Offline(() => {
 * 	const delay = new Tone.Delay(0.1).toDestination();
 * 	// connect the signal to both the delay and the destination
 * 	const pulse = new Tone.PulseOscillator().connect(delay).toDestination();
 * 	// start and stop the pulse
 * 	pulse.start(0).stop(0.01);
 * }, 0.5, 1);
 */ parcelHelpers.export(exports, "Delay", ()=>Delay
);
var _param = require("../context/Param");
var _defaults = require("../util/Defaults");
var _interface = require("../util/Interface");
var _toneAudioNode = require("./ToneAudioNode");
class Delay extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Delay.getDefaults(), arguments, [
            "delayTime",
            "maxDelay"
        ]));
        this.name = "Delay";
        const options = _defaults.optionsFromArguments(Delay.getDefaults(), arguments, [
            "delayTime",
            "maxDelay"
        ]);
        const maxDelayInSeconds = this.toSeconds(options.maxDelay);
        this._maxDelay = Math.max(maxDelayInSeconds, this.toSeconds(options.delayTime));
        this._delayNode = this.input = this.output = this.context.createDelay(maxDelayInSeconds);
        this.delayTime = new _param.Param({
            context: this.context,
            param: this._delayNode.delayTime,
            units: "time",
            value: options.delayTime,
            minValue: 0,
            maxValue: this.maxDelay
        });
        _interface.readOnly(this, "delayTime");
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            delayTime: 0,
            maxDelay: 1
        });
    }
    /**
     * The maximum delay time. This cannot be changed after
     * the value is passed into the constructor.
     */ get maxDelay() {
        return this._maxDelay;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._delayNode.disconnect();
        this.delayTime.dispose();
        return this;
    }
}

},{"../context/Param":"2qxaM","../util/Defaults":"kSyYt","../util/Interface":"fVoXs","./ToneAudioNode":"iT1SZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jt41T":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Generate a buffer by rendering all of the Tone.js code within the callback using the OfflineAudioContext.
 * The OfflineAudioContext is capable of rendering much faster than real time in many cases.
 * The callback function also passes in an offline instance of [[Context]] which can be used
 * to schedule events along the Transport.
 * @param  callback  All Tone.js nodes which are created and scheduled within this callback are recorded into the output Buffer.
 * @param  duration     the amount of time to record for.
 * @return  The promise which is invoked with the ToneAudioBuffer of the recorded output.
 * @example
 * // render 2 seconds of the oscillator
 * Tone.Offline(() => {
 * 	// only nodes created in this callback will be recorded
 * 	const oscillator = new Tone.Oscillator().toDestination().start(0);
 * }, 2).then((buffer) => {
 * 	// do something with the output buffer
 * 	console.log(buffer);
 * });
 * @example
 * // can also schedule events along the Transport
 * // using the passed in Offline Transport
 * Tone.Offline(({ transport }) => {
 * 	const osc = new Tone.Oscillator().toDestination();
 * 	transport.schedule(time => {
 * 		osc.start(time).stop(time + 0.1);
 * 	}, 1);
 * 	// make sure to start the transport
 * 	transport.start(0.2);
 * }, 4).then((buffer) => {
 * 	// do something with the output buffer
 * 	console.log(buffer);
 * });
 * @category Core
 */ parcelHelpers.export(exports, "Offline", ()=>Offline
);
var _tslib = require("tslib");
var _global = require("../Global");
var _offlineContext = require("./OfflineContext");
var _toneAudioBuffer = require("./ToneAudioBuffer");
function Offline(callback, duration, channels = 2, sampleRate = _global.getContext().sampleRate) {
    return _tslib.__awaiter(this, void 0, void 0, function*() {
        // set the OfflineAudioContext based on the current context
        const originalContext = _global.getContext();
        const context = new _offlineContext.OfflineContext(channels, duration, sampleRate);
        _global.setContext(context);
        // invoke the callback/scheduling
        yield callback(context);
        // then render the audio
        const bufferPromise = context.render();
        // return the original AudioContext
        _global.setContext(originalContext);
        // await the rendering
        const buffer = yield bufferPromise;
        // return the audio
        return new _toneAudioBuffer.ToneAudioBuffer(buffer);
    });
}

},{"tslib":"bjkXk","../Global":"6b8rd","./OfflineContext":"KYtWQ","./ToneAudioBuffer":"gpPIV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"g1eoF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A data structure for holding multiple buffers in a Map-like datastructure.
 *
 * @example
 * const pianoSamples = new Tone.ToneAudioBuffers({
 * 	A1: "https://tonejs.github.io/audio/casio/A1.mp3",
 * 	A2: "https://tonejs.github.io/audio/casio/A2.mp3",
 * }, () => {
 * 	const player = new Tone.Player().toDestination();
 * 	// play one of the samples when they all load
 * 	player.buffer = pianoSamples.get("A2");
 * 	player.start();
 * });
 * @example
 * // To pass in additional parameters in the second parameter
 * const buffers = new Tone.ToneAudioBuffers({
 * 	 urls: {
 * 		 A1: "A1.mp3",
 * 		 A2: "A2.mp3",
 * 	 },
 * 	 onload: () => console.log("loaded"),
 * 	 baseUrl: "https://tonejs.github.io/audio/casio/"
 * });
 * @category Core
 */ parcelHelpers.export(exports, "ToneAudioBuffers", ()=>ToneAudioBuffers
);
var _tone = require("../Tone");
var _defaults = require("../util/Defaults");
var _interface = require("../util/Interface");
var _typeCheck = require("../util/TypeCheck");
var _toneAudioBuffer = require("./ToneAudioBuffer");
var _debug = require("../util/Debug");
class ToneAudioBuffers extends _tone.Tone {
    constructor(){
        super();
        this.name = "ToneAudioBuffers";
        /**
         * All of the buffers
         */ this._buffers = new Map();
        /**
         * Keep track of the number of loaded buffers
         */ this._loadingCount = 0;
        const options = _defaults.optionsFromArguments(ToneAudioBuffers.getDefaults(), arguments, [
            "urls",
            "onload",
            "baseUrl"
        ], "urls");
        this.baseUrl = options.baseUrl;
        // add each one
        Object.keys(options.urls).forEach((name)=>{
            this._loadingCount++;
            const url = options.urls[name];
            this.add(name, url, this._bufferLoaded.bind(this, options.onload), options.onerror);
        });
    }
    static getDefaults() {
        return {
            baseUrl: "",
            onerror: _interface.noOp,
            onload: _interface.noOp,
            urls: {
            }
        };
    }
    /**
     * True if the buffers object has a buffer by that name.
     * @param  name  The key or index of the buffer.
     */ has(name) {
        return this._buffers.has(name.toString());
    }
    /**
     * Get a buffer by name. If an array was loaded,
     * then use the array index.
     * @param  name  The key or index of the buffer.
     */ get(name) {
        _debug.assert(this.has(name), `ToneAudioBuffers has no buffer named: ${name}`);
        return this._buffers.get(name.toString());
    }
    /**
     * A buffer was loaded. decrement the counter.
     */ _bufferLoaded(callback) {
        this._loadingCount--;
        if (this._loadingCount === 0 && callback) callback();
    }
    /**
     * If the buffers are loaded or not
     */ get loaded() {
        return Array.from(this._buffers).every(([_, buffer])=>buffer.loaded
        );
    }
    /**
     * Add a buffer by name and url to the Buffers
     * @param  name      A unique name to give the buffer
     * @param  url  Either the url of the bufer, or a buffer which will be added with the given name.
     * @param  callback  The callback to invoke when the url is loaded.
     * @param  onerror  Invoked if the buffer can't be loaded
     */ add(name, url, callback = _interface.noOp, onerror = _interface.noOp) {
        if (_typeCheck.isString(url)) this._buffers.set(name.toString(), new _toneAudioBuffer.ToneAudioBuffer(this.baseUrl + url, callback, onerror));
        else this._buffers.set(name.toString(), new _toneAudioBuffer.ToneAudioBuffer(url, callback, onerror));
        return this;
    }
    dispose() {
        super.dispose();
        this._buffers.forEach((buffer)=>buffer.dispose()
        );
        this._buffers.clear();
        return this;
    }
}

},{"../Tone":"dTzBa","../util/Defaults":"kSyYt","../util/Interface":"fVoXs","../util/TypeCheck":"lCqGC","./ToneAudioBuffer":"gpPIV","../util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6VA3d":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Midi is a primitive type for encoding Time values.
 * Midi can be constructed with or without the `new` keyword. Midi can be passed
 * into the parameter of any method which takes time as an argument.
 * @category Unit
 */ parcelHelpers.export(exports, "MidiClass", ()=>MidiClass
);
/**
 * Convert a value into a FrequencyClass object.
 * @category Unit
 */ parcelHelpers.export(exports, "Midi", ()=>Midi
);
var _global = require("../Global");
var _conversions = require("./Conversions");
var _frequency = require("./Frequency");
class MidiClass extends _frequency.FrequencyClass {
    constructor(){
        super(...arguments);
        this.name = "MidiClass";
        this.defaultUnits = "midi";
    }
    /**
     * Returns the value of a frequency in the current units
     */ _frequencyToUnits(freq) {
        return _conversions.ftom(super._frequencyToUnits(freq));
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return _conversions.ftom(super._ticksToUnits(ticks));
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return _conversions.ftom(super._beatsToUnits(beats));
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return _conversions.ftom(super._secondsToUnits(seconds));
    }
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Midi(60).toMidi(); // 60
     */ toMidi() {
        return this.valueOf();
    }
    /**
     * Return the value of the frequency as a MIDI note
     * @example
     * Tone.Midi(60).toFrequency(); // 261.6255653005986
     */ toFrequency() {
        return _conversions.mtof(this.toMidi());
    }
    /**
     * Transposes the frequency by the given number of semitones.
     * @return A new transposed MidiClass
     * @example
     * Tone.Midi("A4").transpose(3); // "C5"
     */ transpose(interval) {
        return new MidiClass(this.context, this.toMidi() + interval);
    }
}
function Midi(value, units) {
    return new MidiClass(_global.getContext(), value, units);
}

},{"../Global":"6b8rd","./Conversions":"kOcnG","./Frequency":"b1aPl","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8zKuk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Ticks is a primitive type for encoding Time values.
 * Ticks can be constructed with or without the `new` keyword. Ticks can be passed
 * into the parameter of any method which takes time as an argument.
 * @example
 * const t = Tone.Ticks("4n"); // a quarter note as ticks
 * @category Unit
 */ parcelHelpers.export(exports, "TicksClass", ()=>TicksClass
);
/**
 * Convert a time representation to ticks
 * @category Unit
 */ parcelHelpers.export(exports, "Ticks", ()=>Ticks
);
var _global = require("../Global");
var _transportTime = require("./TransportTime");
class TicksClass extends _transportTime.TransportTimeClass {
    constructor(){
        super(...arguments);
        this.name = "Ticks";
        this.defaultUnits = "i";
    }
    /**
     * Get the current time in the given units
     */ _now() {
        return this.context.transport.ticks;
    }
    /**
     * Return the value of the beats in the current units
     */ _beatsToUnits(beats) {
        return this._getPPQ() * beats;
    }
    /**
     * Returns the value of a second in the current units
     */ _secondsToUnits(seconds) {
        return Math.floor(seconds / (60 / this._getBpm()) * this._getPPQ());
    }
    /**
     * Returns the value of a tick in the current time units
     */ _ticksToUnits(ticks) {
        return ticks;
    }
    /**
     * Return the time in ticks
     */ toTicks() {
        return this.valueOf();
    }
    /**
     * Return the time in seconds
     */ toSeconds() {
        return this.valueOf() / this._getPPQ() * (60 / this._getBpm());
    }
}
function Ticks(value, units) {
    return new TicksClass(_global.getContext(), value, units);
}

},{"../Global":"6b8rd","./TransportTime":"kcsdx","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4l3Cj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Draw is useful for synchronizing visuals and audio events.
 * Callbacks from Tone.Transport or any of the Tone.Event classes
 * always happen _before_ the scheduled time and are not synchronized
 * to the animation frame so they are not good for triggering tightly
 * synchronized visuals and sound. Draw makes it easy to schedule
 * callbacks using the AudioContext time and uses requestAnimationFrame.
 * @example
 * Tone.Transport.schedule((time) => {
 * 	// use the time argument to schedule a callback with Draw
 * 	Tone.Draw.schedule(() => {
 * 		// do drawing or DOM manipulation here
 * 		console.log(time);
 * 	}, time);
 * }, "+0.5");
 * Tone.Transport.start();
 * @category Core
 */ parcelHelpers.export(exports, "Draw", ()=>Draw
);
var _toneWithContext = require("../context/ToneWithContext");
var _timeline = require("./Timeline");
var _contextInitialization = require("../context/ContextInitialization");
class Draw extends _toneWithContext.ToneWithContext {
    constructor(){
        super(...arguments);
        this.name = "Draw";
        /**
         * The duration after which events are not invoked.
         */ this.expiration = 0.25;
        /**
         * The amount of time before the scheduled time
         * that the callback can be invoked. Default is
         * half the time of an animation frame (0.008 seconds).
         */ this.anticipation = 0.008;
        /**
         * All of the events.
         */ this._events = new _timeline.Timeline();
        /**
         * The draw loop
         */ this._boundDrawLoop = this._drawLoop.bind(this);
        /**
         * The animation frame id
         */ this._animationFrame = -1;
    }
    /**
     * Schedule a function at the given time to be invoked
     * on the nearest animation frame.
     * @param  callback  Callback is invoked at the given time.
     * @param  time      The time relative to the AudioContext time to invoke the callback.
     * @example
     * Tone.Transport.scheduleRepeat(time => {
     * 	Tone.Draw.schedule(() => console.log(time), time);
     * }, 1);
     * Tone.Transport.start();
     */ schedule(callback, time) {
        this._events.add({
            callback,
            time: this.toSeconds(time)
        });
        // start the draw loop on the first event
        if (this._events.length === 1) this._animationFrame = requestAnimationFrame(this._boundDrawLoop);
        return this;
    }
    /**
     * Cancel events scheduled after the given time
     * @param  after  Time after which scheduled events will be removed from the scheduling timeline.
     */ cancel(after) {
        this._events.cancel(this.toSeconds(after));
        return this;
    }
    /**
     * The draw loop
     */ _drawLoop() {
        const now = this.context.currentTime;
        while(this._events.length && this._events.peek().time - this.anticipation <= now){
            const event = this._events.shift();
            if (event && now - event.time <= this.expiration) event.callback();
        }
        if (this._events.length > 0) this._animationFrame = requestAnimationFrame(this._boundDrawLoop);
    }
    dispose() {
        super.dispose();
        this._events.dispose();
        cancelAnimationFrame(this._animationFrame);
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
_contextInitialization.onContextInit((context)=>{
    context.draw = new Draw({
        context
    });
});
_contextInitialization.onContextClose((context)=>{
    context.draw.dispose();
});

},{"../context/ToneWithContext":"ez5Mk","./Timeline":"leurn","../context/ContextInitialization":"6PyHY","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"EpXgL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Similar to Tone.Timeline, but all events represent
 * intervals with both "time" and "duration" times. The
 * events are placed in a tree structure optimized
 * for querying an intersection point with the timeline
 * events. Internally uses an [Interval Tree](https://en.wikipedia.org/wiki/Interval_tree)
 * to represent the data.
 */ parcelHelpers.export(exports, "IntervalTimeline", ()=>IntervalTimeline
);
var _tone = require("../Tone");
var _typeCheck = require("./TypeCheck");
var _debug = require("./Debug");
class IntervalTimeline extends _tone.Tone {
    constructor(){
        super(...arguments);
        this.name = "IntervalTimeline";
        /**
         * The root node of the inteval tree
         */ this._root = null;
        /**
         * Keep track of the length of the timeline.
         */ this._length = 0;
    }
    /**
     * The event to add to the timeline. All events must
     * have a time and duration value
     * @param  event  The event to add to the timeline
     */ add(event) {
        _debug.assert(_typeCheck.isDefined(event.time), "Events must have a time property");
        _debug.assert(_typeCheck.isDefined(event.duration), "Events must have a duration parameter");
        event.time = event.time.valueOf();
        let node = new IntervalNode(event.time, event.time + event.duration, event);
        if (this._root === null) this._root = node;
        else this._root.insert(node);
        this._length++;
        // Restructure tree to be balanced
        while(node !== null){
            node.updateHeight();
            node.updateMax();
            this._rebalance(node);
            node = node.parent;
        }
        return this;
    }
    /**
     * Remove an event from the timeline.
     * @param  event  The event to remove from the timeline
     */ remove(event) {
        if (this._root !== null) {
            const results = [];
            this._root.search(event.time, results);
            for (const node of results)if (node.event === event) {
                this._removeNode(node);
                this._length--;
                break;
            }
        }
        return this;
    }
    /**
     * The number of items in the timeline.
     * @readOnly
     */ get length() {
        return this._length;
    }
    /**
     * Remove events whose time time is after the given time
     * @param  after  The time to query.
     */ cancel(after) {
        this.forEachFrom(after, (event)=>this.remove(event)
        );
        return this;
    }
    /**
     * Set the root node as the given node
     */ _setRoot(node) {
        this._root = node;
        if (this._root !== null) this._root.parent = null;
    }
    /**
     * Replace the references to the node in the node's parent
     * with the replacement node.
     */ _replaceNodeInParent(node, replacement) {
        if (node.parent !== null) {
            if (node.isLeftChild()) node.parent.left = replacement;
            else node.parent.right = replacement;
            this._rebalance(node.parent);
        } else this._setRoot(replacement);
    }
    /**
     * Remove the node from the tree and replace it with
     * a successor which follows the schema.
     */ _removeNode(node) {
        if (node.left === null && node.right === null) this._replaceNodeInParent(node, null);
        else if (node.right === null) this._replaceNodeInParent(node, node.left);
        else if (node.left === null) this._replaceNodeInParent(node, node.right);
        else {
            const balance = node.getBalance();
            let replacement;
            let temp = null;
            if (balance > 0) {
                if (node.left.right === null) {
                    replacement = node.left;
                    replacement.right = node.right;
                    temp = replacement;
                } else {
                    replacement = node.left.right;
                    while(replacement.right !== null)replacement = replacement.right;
                    if (replacement.parent) {
                        replacement.parent.right = replacement.left;
                        temp = replacement.parent;
                        replacement.left = node.left;
                        replacement.right = node.right;
                    }
                }
            } else if (node.right.left === null) {
                replacement = node.right;
                replacement.left = node.left;
                temp = replacement;
            } else {
                replacement = node.right.left;
                while(replacement.left !== null)replacement = replacement.left;
                if (replacement.parent) {
                    replacement.parent.left = replacement.right;
                    temp = replacement.parent;
                    replacement.left = node.left;
                    replacement.right = node.right;
                }
            }
            if (node.parent !== null) {
                if (node.isLeftChild()) node.parent.left = replacement;
                else node.parent.right = replacement;
            } else this._setRoot(replacement);
            if (temp) this._rebalance(temp);
        }
        node.dispose();
    }
    /**
     * Rotate the tree to the left
     */ _rotateLeft(node) {
        const parent = node.parent;
        const isLeftChild = node.isLeftChild();
        // Make node.right the new root of this sub tree (instead of node)
        const pivotNode = node.right;
        if (pivotNode) {
            node.right = pivotNode.left;
            pivotNode.left = node;
        }
        if (parent !== null) {
            if (isLeftChild) parent.left = pivotNode;
            else parent.right = pivotNode;
        } else this._setRoot(pivotNode);
    }
    /**
     * Rotate the tree to the right
     */ _rotateRight(node) {
        const parent = node.parent;
        const isLeftChild = node.isLeftChild();
        // Make node.left the new root of this sub tree (instead of node)
        const pivotNode = node.left;
        if (pivotNode) {
            node.left = pivotNode.right;
            pivotNode.right = node;
        }
        if (parent !== null) {
            if (isLeftChild) parent.left = pivotNode;
            else parent.right = pivotNode;
        } else this._setRoot(pivotNode);
    }
    /**
     * Balance the BST
     */ _rebalance(node) {
        const balance = node.getBalance();
        if (balance > 1 && node.left) {
            if (node.left.getBalance() < 0) this._rotateLeft(node.left);
            else this._rotateRight(node);
        } else if (balance < -1 && node.right) {
            if (node.right.getBalance() > 0) this._rotateRight(node.right);
            else this._rotateLeft(node);
        }
    }
    /**
     * Get an event whose time and duration span the give time. Will
     * return the match whose "time" value is closest to the given time.
     * @return  The event which spans the desired time
     */ get(time) {
        if (this._root !== null) {
            const results = [];
            this._root.search(time, results);
            if (results.length > 0) {
                let max = results[0];
                for(let i = 1; i < results.length; i++)if (results[i].low > max.low) max = results[i];
                return max.event;
            }
        }
        return null;
    }
    /**
     * Iterate over everything in the timeline.
     * @param  callback The callback to invoke with every item
     */ forEach(callback) {
        if (this._root !== null) {
            const allNodes = [];
            this._root.traverse((node)=>allNodes.push(node)
            );
            allNodes.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Iterate over everything in the array in which the given time
     * overlaps with the time and duration time of the event.
     * @param  time The time to check if items are overlapping
     * @param  callback The callback to invoke with every item
     */ forEachAtTime(time, callback) {
        if (this._root !== null) {
            const results = [];
            this._root.search(time, results);
            results.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Iterate over everything in the array in which the time is greater
     * than or equal to the given time.
     * @param  time The time to check if items are before
     * @param  callback The callback to invoke with every item
     */ forEachFrom(time, callback) {
        if (this._root !== null) {
            const results = [];
            this._root.searchAfter(time, results);
            results.forEach((node)=>{
                if (node.event) callback(node.event);
            });
        }
        return this;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        if (this._root !== null) this._root.traverse((node)=>node.dispose()
        );
        this._root = null;
        return this;
    }
}
//-------------------------------------
// 	INTERVAL NODE HELPER
//-------------------------------------
/**
 * Represents a node in the binary search tree, with the addition
 * of a "high" value which keeps track of the highest value of
 * its children.
 * References:
 * https://brooknovak.wordpress.com/2013/12/07/augmented-interval-tree-in-c/
 * http://www.mif.vu.lt/~valdas/ALGORITMAI/LITERATURA/Cormen/Cormen.pdf
 * @param low
 * @param high
 */ class IntervalNode {
    constructor(low, high, event){
        // the nodes to the left
        this._left = null;
        // the nodes to the right
        this._right = null;
        // the parent node
        this.parent = null;
        // the number of child nodes
        this.height = 0;
        this.event = event;
        // the low value
        this.low = low;
        // the high value
        this.high = high;
        // the high value for this and all child nodes
        this.max = this.high;
    }
    /**
     * Insert a node into the correct spot in the tree
     */ insert(node) {
        if (node.low <= this.low) {
            if (this.left === null) this.left = node;
            else this.left.insert(node);
        } else if (this.right === null) this.right = node;
        else this.right.insert(node);
    }
    /**
     * Search the tree for nodes which overlap
     * with the given point
     * @param  point  The point to query
     * @param  results  The array to put the results
     */ search(point, results) {
        // If p is to the right of the rightmost point of any interval
        // in this node and all children, there won't be any matches.
        if (point > this.max) return;
        // Search left children
        if (this.left !== null) this.left.search(point, results);
        // Check this node
        if (this.low <= point && this.high > point) results.push(this);
        // If p is to the left of the time of this interval,
        // then it can't be in any child to the right.
        if (this.low > point) return;
        // Search right children
        if (this.right !== null) this.right.search(point, results);
    }
    /**
     * Search the tree for nodes which are less
     * than the given point
     * @param  point  The point to query
     * @param  results  The array to put the results
     */ searchAfter(point, results) {
        // Check this node
        if (this.low >= point) {
            results.push(this);
            if (this.left !== null) this.left.searchAfter(point, results);
        }
        // search the right side
        if (this.right !== null) this.right.searchAfter(point, results);
    }
    /**
     * Invoke the callback on this element and both it's branches
     * @param  {Function}  callback
     */ traverse(callback) {
        callback(this);
        if (this.left !== null) this.left.traverse(callback);
        if (this.right !== null) this.right.traverse(callback);
    }
    /**
     * Update the height of the node
     */ updateHeight() {
        if (this.left !== null && this.right !== null) this.height = Math.max(this.left.height, this.right.height) + 1;
        else if (this.right !== null) this.height = this.right.height + 1;
        else if (this.left !== null) this.height = this.left.height + 1;
        else this.height = 0;
    }
    /**
     * Update the height of the node
     */ updateMax() {
        this.max = this.high;
        if (this.left !== null) this.max = Math.max(this.max, this.left.max);
        if (this.right !== null) this.max = Math.max(this.max, this.right.max);
    }
    /**
     * The balance is how the leafs are distributed on the node
     * @return  Negative numbers are balanced to the right
     */ getBalance() {
        let balance = 0;
        if (this.left !== null && this.right !== null) balance = this.left.height - this.right.height;
        else if (this.left !== null) balance = this.left.height + 1;
        else if (this.right !== null) balance = -(this.right.height + 1);
        return balance;
    }
    /**
     * @returns true if this node is the left child of its parent
     */ isLeftChild() {
        return this.parent !== null && this.parent.left === this;
    }
    /**
     * get/set the left node
     */ get left() {
        return this._left;
    }
    set left(node) {
        this._left = node;
        if (node !== null) node.parent = this;
        this.updateHeight();
        this.updateMax();
    }
    /**
     * get/set the right node
     */ get right() {
        return this._right;
    }
    set right(node) {
        this._right = node;
        if (node !== null) node.parent = this;
        this.updateHeight();
        this.updateMax();
    }
    /**
     * null out references.
     */ dispose() {
        this.parent = null;
        this._left = null;
        this._right = null;
        this.event = null;
    }
}

},{"../Tone":"dTzBa","./TypeCheck":"lCqGC","./Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7oXrx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _noteUnits = require("./NoteUnits");
parcelHelpers.exportAll(_noteUnits, exports);

},{"./NoteUnits":"iAGIU","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iAGIU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"IrCGx":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _noise = require("./Noise");
parcelHelpers.exportAll(_noise, exports);
var _userMedia = require("./UserMedia");
parcelHelpers.exportAll(_userMedia, exports);
var _oscillator = require("./oscillator/Oscillator");
parcelHelpers.exportAll(_oscillator, exports);
var _amoscillator = require("./oscillator/AMOscillator");
parcelHelpers.exportAll(_amoscillator, exports);
var _fmoscillator = require("./oscillator/FMOscillator");
parcelHelpers.exportAll(_fmoscillator, exports);
var _pulseOscillator = require("./oscillator/PulseOscillator");
parcelHelpers.exportAll(_pulseOscillator, exports);
var _fatOscillator = require("./oscillator/FatOscillator");
parcelHelpers.exportAll(_fatOscillator, exports);
var _pwmoscillator = require("./oscillator/PWMOscillator");
parcelHelpers.exportAll(_pwmoscillator, exports);
var _omniOscillator = require("./oscillator/OmniOscillator");
parcelHelpers.exportAll(_omniOscillator, exports);
var _toneOscillatorNode = require("./oscillator/ToneOscillatorNode");
parcelHelpers.exportAll(_toneOscillatorNode, exports);
var _lfo = require("./oscillator/LFO");
parcelHelpers.exportAll(_lfo, exports);
var _toneBufferSource = require("./buffer/ToneBufferSource");
parcelHelpers.exportAll(_toneBufferSource, exports);
var _player = require("./buffer/Player");
parcelHelpers.exportAll(_player, exports);
var _players = require("./buffer/Players");
parcelHelpers.exportAll(_players, exports);
var _grainPlayer = require("./buffer/GrainPlayer");
parcelHelpers.exportAll(_grainPlayer, exports);

},{"./Noise":"hF5D5","./UserMedia":"9Syrh","./oscillator/Oscillator":"715Gq","./oscillator/AMOscillator":"dECQc","./oscillator/FMOscillator":"9a3wa","./oscillator/PulseOscillator":"aYxy9","./oscillator/FatOscillator":"fcPql","./oscillator/PWMOscillator":"frnTW","./oscillator/OmniOscillator":"fKqBe","./oscillator/ToneOscillatorNode":"ahlJc","./oscillator/LFO":"d8Ivp","./buffer/ToneBufferSource":"6y7FM","./buffer/Player":"9Kbsu","./buffer/Players":"bKxBU","./buffer/GrainPlayer":"6kdLY","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hF5D5":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Noise is a noise generator. It uses looped noise buffers to save on performance.
 * Noise supports the noise types: "pink", "white", and "brown". Read more about
 * colors of noise on [Wikipedia](https://en.wikipedia.org/wiki/Colors_of_noise).
 *
 * @example
 * // initialize the noise and start
 * const noise = new Tone.Noise("pink").start();
 * // make an autofilter to shape the noise
 * const autoFilter = new Tone.AutoFilter({
 * 	frequency: "8n",
 * 	baseFrequency: 200,
 * 	octaves: 8
 * }).toDestination().start();
 * // connect the noise
 * noise.connect(autoFilter);
 * // start the autofilter LFO
 * autoFilter.start();
 * @category Source
 */ parcelHelpers.export(exports, "Noise", ()=>Noise
);
var _toneAudioBuffer = require("../core/context/ToneAudioBuffer");
var _defaults = require("../core/util/Defaults");
var _debug = require("../core/util/Debug");
var _source = require("../source/Source");
var _toneBufferSource = require("./buffer/ToneBufferSource");
class Noise extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(Noise.getDefaults(), arguments, [
            "type"
        ]));
        this.name = "Noise";
        /**
         * Private reference to the source
         */ this._source = null;
        const options = _defaults.optionsFromArguments(Noise.getDefaults(), arguments, [
            "type"
        ]);
        this._playbackRate = options.playbackRate;
        this.type = options.type;
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign(_source.Source.getDefaults(), {
            fadeIn: 0,
            fadeOut: 0,
            playbackRate: 1,
            type: "white"
        });
    }
    /**
     * The type of the noise. Can be "white", "brown", or "pink".
     * @example
     * const noise = new Tone.Noise().toDestination().start();
     * noise.type = "brown";
     */ get type() {
        return this._type;
    }
    set type(type) {
        _debug.assert(type in _noiseBuffers, "Noise: invalid type: " + type);
        if (this._type !== type) {
            this._type = type;
            // if it's playing, stop and restart it
            if (this.state === "started") {
                const now = this.now();
                this._stop(now);
                this._start(now);
            }
        }
    }
    /**
     * The playback rate of the noise. Affects
     * the "frequency" of the noise.
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        if (this._source) this._source.playbackRate.value = rate;
    }
    /**
     * internal start method
     */ _start(time) {
        const buffer = _noiseBuffers[this._type];
        this._source = new _toneBufferSource.ToneBufferSource({
            url: buffer,
            context: this.context,
            fadeIn: this._fadeIn,
            fadeOut: this._fadeOut,
            loop: true,
            onended: ()=>this.onstop(this)
            ,
            playbackRate: this._playbackRate
        }).connect(this.output);
        this._source.start(this.toSeconds(time), Math.random() * (buffer.duration - 0.001));
    }
    /**
     * internal stop method
     */ _stop(time) {
        if (this._source) {
            this._source.stop(this.toSeconds(time));
            this._source = null;
        }
    }
    /**
     * The fadeIn time of the amplitude envelope.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(time) {
        this._fadeIn = time;
        if (this._source) this._source.fadeIn = this._fadeIn;
    }
    /**
     * The fadeOut time of the amplitude envelope.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(time) {
        this._fadeOut = time;
        if (this._source) this._source.fadeOut = this._fadeOut;
    }
    _restart(time) {
        // TODO could be optimized by cancelling the buffer source 'stop'
        this._stop(time);
        this._start(time);
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        if (this._source) this._source.disconnect();
        return this;
    }
}
//--------------------
// THE NOISE BUFFERS
//--------------------
// Noise buffer stats
const BUFFER_LENGTH = 220500;
const NUM_CHANNELS = 2;
/**
 * Cache the noise buffers
 */ const _noiseCache = {
    brown: null,
    pink: null,
    white: null
};
/**
 * The noise arrays. Generated on initialization.
 * borrowed heavily from https://github.com/zacharydenton/noise.js
 * (c) 2013 Zach Denton (MIT)
 */ const _noiseBuffers = {
    get brown () {
        if (!_noiseCache.brown) {
            const buffer = [];
            for(let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++){
                const channel = new Float32Array(BUFFER_LENGTH);
                buffer[channelNum] = channel;
                let lastOut = 0;
                for(let i = 0; i < BUFFER_LENGTH; i++){
                    const white = Math.random() * 2 - 1;
                    channel[i] = (lastOut + 0.02 * white) / 1.02;
                    lastOut = channel[i];
                    channel[i] *= 3.5; // (roughly) compensate for gain
                }
            }
            _noiseCache.brown = new _toneAudioBuffer.ToneAudioBuffer().fromArray(buffer);
        }
        return _noiseCache.brown;
    },
    get pink () {
        if (!_noiseCache.pink) {
            const buffer = [];
            for(let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++){
                const channel = new Float32Array(BUFFER_LENGTH);
                buffer[channelNum] = channel;
                let b0, b1, b2, b3, b4, b5, b6;
                b0 = b1 = b2 = b3 = b4 = b5 = b6 = 0;
                for(let i = 0; i < BUFFER_LENGTH; i++){
                    const white = Math.random() * 2 - 1;
                    b0 = 0.99886 * b0 + white * 0.0555179;
                    b1 = 0.99332 * b1 + white * 0.0750759;
                    b2 = 0.969 * b2 + white * 0.153852;
                    b3 = 0.8665 * b3 + white * 0.3104856;
                    b4 = 0.55 * b4 + white * 0.5329522;
                    b5 = -0.7616 * b5 - white * 0.016898;
                    channel[i] = b0 + b1 + b2 + b3 + b4 + b5 + b6 + white * 0.5362;
                    channel[i] *= 0.11; // (roughly) compensate for gain
                    b6 = white * 0.115926;
                }
            }
            _noiseCache.pink = new _toneAudioBuffer.ToneAudioBuffer().fromArray(buffer);
        }
        return _noiseCache.pink;
    },
    get white () {
        if (!_noiseCache.white) {
            const buffer = [];
            for(let channelNum = 0; channelNum < NUM_CHANNELS; channelNum++){
                const channel = new Float32Array(BUFFER_LENGTH);
                buffer[channelNum] = channel;
                for(let i = 0; i < BUFFER_LENGTH; i++)channel[i] = Math.random() * 2 - 1;
            }
            _noiseCache.white = new _toneAudioBuffer.ToneAudioBuffer().fromArray(buffer);
        }
        return _noiseCache.white;
    }
};

},{"../core/context/ToneAudioBuffer":"gpPIV","../core/util/Defaults":"kSyYt","../core/util/Debug":"bsxl9","../source/Source":"31KwW","./buffer/ToneBufferSource":"6y7FM","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"31KwW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for sources.
 * start/stop of this.context.transport.
 *
 * ```
 * // Multiple state change events can be chained together,
 * // but must be set in the correct order and with ascending times
 * // OK
 * state.start().stop("+0.2");
 * // OK
 * state.start().stop("+0.2").start("+0.4").stop("+0.7")
 * // BAD
 * state.stop("+0.2").start();
 * // BAD
 * state.start("+0.3").stop("+0.2");
 * ```
 */ parcelHelpers.export(exports, "Source", ()=>Source
);
var _volume = require("../component/channel/Volume");
var _destination = require("../core/context/Destination");
var _transport = require("../core/clock/Transport");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _stateTimeline = require("../core/util/StateTimeline");
var _typeCheck = require("../core/util/TypeCheck");
var _debug = require("../core/util/Debug");
var _math = require("../core/util/Math");
class Source extends _toneAudioNode.ToneAudioNode {
    constructor(options){
        super(options);
        /**
         * Sources have no inputs
         */ this.input = undefined;
        /**
         * Keep track of the scheduled state.
         */ this._state = new _stateTimeline.StateTimeline("stopped");
        /**
         * The synced `start` callback function from the transport
         */ this._synced = false;
        /**
         * Keep track of all of the scheduled event ids
         */ this._scheduled = [];
        /**
         * Placeholder functions for syncing/unsyncing to transport
         */ this._syncedStart = _interface.noOp;
        this._syncedStop = _interface.noOp;
        this._state.memory = 100;
        this._state.increasing = true;
        this._volume = this.output = new _volume.Volume({
            context: this.context,
            mute: options.mute,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        _interface.readOnly(this, "volume");
        this.onstop = options.onstop;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            mute: false,
            onstop: _interface.noOp,
            volume: 0
        });
    }
    /**
     * Returns the playback state of the source, either "started" or "stopped".
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/ahntone_c3.mp3", () => {
     * 	player.start();
     * 	console.log(player.state);
     * }).toDestination();
     */ get state() {
        if (this._synced) {
            if (this.context.transport.state === "started") return this._state.getValueAtTime(this.context.transport.seconds);
            else return "stopped";
        } else return this._state.getValueAtTime(this.now());
    }
    /**
     * Mute the output.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * // mute the output
     * osc.mute = true;
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    /**
     * Ensure that the scheduled time is not before the current time.
     * Should only be used when scheduled unsynced.
     */ _clampToCurrentTime(time) {
        if (this._synced) return time;
        else return Math.max(time, this.context.currentTime);
    }
    /**
     * Start the source at the specified time. If no time is given,
     * start the source now.
     * @param  time When the source should be started.
     * @example
     * const source = new Tone.Oscillator().toDestination();
     * source.start("+0.5"); // starts the source 0.5 seconds from now
     */ start(time, offset, duration) {
        let computedTime = _typeCheck.isUndef(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);
        computedTime = this._clampToCurrentTime(computedTime);
        // if it's started, stop it and restart it
        if (!this._synced && this._state.getValueAtTime(computedTime) === "started") {
            // time should be strictly greater than the previous start time
            _debug.assert(_math.GT(computedTime, this._state.get(computedTime).time), "Start time must be strictly greater than previous start time");
            this._state.cancel(computedTime);
            this._state.setStateAtTime("started", computedTime);
            this.log("restart", computedTime);
            this.restart(computedTime, offset, duration);
        } else {
            this.log("start", computedTime);
            this._state.setStateAtTime("started", computedTime);
            if (this._synced) {
                // add the offset time to the event
                const event = this._state.get(computedTime);
                if (event) {
                    event.offset = this.toSeconds(_defaults.defaultArg(offset, 0));
                    event.duration = duration ? this.toSeconds(duration) : undefined;
                }
                const sched = this.context.transport.schedule((t)=>{
                    this._start(t, offset, duration);
                }, computedTime);
                this._scheduled.push(sched);
                // if the transport is already started
                // and the time is greater than where the transport is
                if (this.context.transport.state === "started" && this.context.transport.getSecondsAtTime(this.immediate()) > computedTime) this._syncedStart(this.now(), this.context.transport.seconds);
            } else {
                _debug.assertContextRunning(this.context);
                this._start(computedTime, offset, duration);
            }
        }
        return this;
    }
    /**
     * Stop the source at the specified time. If no time is given,
     * stop the source now.
     * @param  time When the source should be stopped.
     * @example
     * const source = new Tone.Oscillator().toDestination();
     * source.start();
     * source.stop("+0.5"); // stops the source 0.5 seconds from now
     */ stop(time) {
        let computedTime = _typeCheck.isUndef(time) && this._synced ? this.context.transport.seconds : this.toSeconds(time);
        computedTime = this._clampToCurrentTime(computedTime);
        if (this._state.getValueAtTime(computedTime) === "started" || _typeCheck.isDefined(this._state.getNextState("started", computedTime))) {
            this.log("stop", computedTime);
            if (!this._synced) this._stop(computedTime);
            else {
                const sched = this.context.transport.schedule(this._stop.bind(this), computedTime);
                this._scheduled.push(sched);
            }
            this._state.cancel(computedTime);
            this._state.setStateAtTime("stopped", computedTime);
        }
        return this;
    }
    /**
     * Restart the source.
     */ restart(time, offset, duration) {
        time = this.toSeconds(time);
        if (this._state.getValueAtTime(time) === "started") {
            this._state.cancel(time);
            this._restart(time, offset, duration);
        }
        return this;
    }
    /**
     * Sync the source to the Transport so that all subsequent
     * calls to `start` and `stop` are synced to the TransportTime
     * instead of the AudioContext time.
     *
     * @example
     * const osc = new Tone.Oscillator().toDestination();
     * // sync the source so that it plays between 0 and 0.3 on the Transport's timeline
     * osc.sync().start(0).stop(0.3);
     * // start the transport.
     * Tone.Transport.start();
     * // set it to loop once a second
     * Tone.Transport.loop = true;
     * Tone.Transport.loopEnd = 1;
     */ sync() {
        if (!this._synced) {
            this._synced = true;
            this._syncedStart = (time, offset)=>{
                if (offset > 0) {
                    // get the playback state at that time
                    const stateEvent = this._state.get(offset);
                    // listen for start events which may occur in the middle of the sync'ed time
                    if (stateEvent && stateEvent.state === "started" && stateEvent.time !== offset) {
                        // get the offset
                        const startOffset = offset - this.toSeconds(stateEvent.time);
                        let duration;
                        if (stateEvent.duration) duration = this.toSeconds(stateEvent.duration) - startOffset;
                        this._start(time, this.toSeconds(stateEvent.offset) + startOffset, duration);
                    }
                }
            };
            this._syncedStop = (time)=>{
                const seconds = this.context.transport.getSecondsAtTime(Math.max(time - this.sampleTime, 0));
                if (this._state.getValueAtTime(seconds) === "started") this._stop(time);
            };
            this.context.transport.on("start", this._syncedStart);
            this.context.transport.on("loopStart", this._syncedStart);
            this.context.transport.on("stop", this._syncedStop);
            this.context.transport.on("pause", this._syncedStop);
            this.context.transport.on("loopEnd", this._syncedStop);
        }
        return this;
    }
    /**
     * Unsync the source to the Transport. See Source.sync
     */ unsync() {
        if (this._synced) {
            this.context.transport.off("stop", this._syncedStop);
            this.context.transport.off("pause", this._syncedStop);
            this.context.transport.off("loopEnd", this._syncedStop);
            this.context.transport.off("start", this._syncedStart);
            this.context.transport.off("loopStart", this._syncedStart);
        }
        this._synced = false;
        // clear all of the scheduled ids
        this._scheduled.forEach((id)=>this.context.transport.clear(id)
        );
        this._scheduled = [];
        this._state.cancel(0);
        // stop it also
        this._stop(0);
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.onstop = _interface.noOp;
        this.unsync();
        this._volume.dispose();
        this._state.dispose();
        return this;
    }
}

},{"../component/channel/Volume":"j5Q9V","../core/context/Destination":"5JqA1","../core/clock/Transport":"7Q4LA","../core/context/ToneAudioNode":"iT1SZ","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../core/util/StateTimeline":"am3qa","../core/util/TypeCheck":"lCqGC","../core/util/Debug":"bsxl9","../core/util/Math":"gdhOV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j5Q9V":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Volume is a simple volume node, useful for creating a volume fader.
 *
 * @example
 * const vol = new Tone.Volume(-12).toDestination();
 * const osc = new Tone.Oscillator().connect(vol).start();
 * @category Component
 */ parcelHelpers.export(exports, "Volume", ()=>Volume
);
var _gain = require("../../core/context/Gain");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
class Volume extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Volume.getDefaults(), arguments, [
            "volume"
        ]));
        this.name = "Volume";
        const options = _defaults.optionsFromArguments(Volume.getDefaults(), arguments, [
            "volume"
        ]);
        this.input = this.output = new _gain.Gain({
            context: this.context,
            gain: options.volume,
            units: "decibels"
        });
        this.volume = this.output.gain;
        _interface.readOnly(this, "volume");
        this._unmutedVolume = options.volume;
        // set the mute initially
        this.mute = options.mute;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Mute the output.
     * @example
     * const vol = new Tone.Volume(-12).toDestination();
     * const osc = new Tone.Oscillator().connect(vol).start();
     * // mute the output
     * vol.mute = true;
     */ get mute() {
        return this.volume.value === -Infinity;
    }
    set mute(mute) {
        if (!this.mute && mute) {
            this._unmutedVolume = this.volume.value;
            // maybe it should ramp here?
            this.volume.value = -Infinity;
        } else if (this.mute && !mute) this.volume.value = this._unmutedVolume;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this.input.dispose();
        this.volume.dispose();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5JqA1":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A single master output which is connected to the
 * AudioDestinationNode (aka your speakers).
 * It provides useful conveniences such as the ability
 * to set the volume and mute the entire application.
 * It also gives you the ability to apply master effects to your application.
 *
 * @example
 * const oscillator = new Tone.Oscillator().start();
 * // the audio will go from the oscillator to the speakers
 * oscillator.connect(Tone.getDestination());
 * // a convenience for connecting to the master output is also provided:
 * oscillator.toDestination();
 * @category Core
 */ parcelHelpers.export(exports, "Destination", ()=>Destination
);
var _volume = require("../../component/channel/Volume");
var _defaults = require("../util/Defaults");
var _contextInitialization = require("./ContextInitialization");
var _gain = require("./Gain");
var _toneAudioNode = require("./ToneAudioNode");
class Destination extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Destination.getDefaults(), arguments));
        this.name = "Destination";
        this.input = new _volume.Volume({
            context: this.context
        });
        this.output = new _gain.Gain({
            context: this.context
        });
        /**
         * The volume of the master output in decibels. -Infinity is silent, and 0 is no change.
         * @example
         * const osc = new Tone.Oscillator().toDestination();
         * osc.start();
         * // ramp the volume down to silent over 10 seconds
         * Tone.getDestination().volume.rampTo(-Infinity, 10);
         */ this.volume = this.input.volume;
        const options = _defaults.optionsFromArguments(Destination.getDefaults(), arguments);
        _toneAudioNode.connectSeries(this.input, this.output, this.context.rawContext.destination);
        this.mute = options.mute;
        this._internalChannels = [
            this.input,
            this.context.rawContext.destination,
            this.output
        ];
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Mute the output.
     * @example
     * const oscillator = new Tone.Oscillator().start().toDestination();
     * setTimeout(() => {
     * 	// mute the output
     * 	Tone.Destination.mute = true;
     * }, 1000);
     */ get mute() {
        return this.input.mute;
    }
    set mute(mute) {
        this.input.mute = mute;
    }
    /**
     * Add a master effects chain. NOTE: this will disconnect any nodes which were previously
     * chained in the master effects chain.
     * @param args All arguments will be connected in a row and the Master will be routed through it.
     * @example
     * // route all audio through a filter and compressor
     * const lowpass = new Tone.Filter(800, "lowpass");
     * const compressor = new Tone.Compressor(-18);
     * Tone.Destination.chain(lowpass, compressor);
     */ chain(...args) {
        this.input.disconnect();
        args.unshift(this.input);
        args.push(this.output);
        _toneAudioNode.connectSeries(...args);
        return this;
    }
    /**
     * The maximum number of channels the system can output
     * @example
     * console.log(Tone.Destination.maxChannelCount);
     */ get maxChannelCount() {
        return this.context.rawContext.destination.maxChannelCount;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.volume.dispose();
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
_contextInitialization.onContextInit((context)=>{
    context.destination = new Destination({
        context
    });
});
_contextInitialization.onContextClose((context)=>{
    context.destination.dispose();
});

},{"../../component/channel/Volume":"j5Q9V","../util/Defaults":"kSyYt","./ContextInitialization":"6PyHY","./Gain":"7kpMn","./ToneAudioNode":"iT1SZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7Q4LA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Transport for timing musical events.
 * Supports tempo curves and time changes. Unlike browser-based timing (setInterval, requestAnimationFrame)
 * Transport timing events pass in the exact time of the scheduled event
 * in the argument of the callback function. Pass that time value to the object
 * you're scheduling. <br><br>
 * A single transport is created for you when the library is initialized.
 * <br><br>
 * The transport emits the events: "start", "stop", "pause", and "loop" which are
 * called with the time of that event as the argument.
 *
 * @example
 * const osc = new Tone.Oscillator().toDestination();
 * // repeated event every 8th note
 * Tone.Transport.scheduleRepeat((time) => {
 * 	// use the callback time to schedule events
 * 	osc.start(time).stop(time + 0.1);
 * }, "8n");
 * // transport must be started before it starts invoking events
 * Tone.Transport.start();
 * @category Core
 */ parcelHelpers.export(exports, "Transport", ()=>Transport
);
var _time = require("../../core/type/Time");
var _timelineValue = require("../../core/util/TimelineValue");
var _contextInitialization = require("../context/ContextInitialization");
var _gain = require("../context/Gain");
var _toneWithContext = require("../context/ToneWithContext");
var _ticks = require("../type/Ticks");
var _transportTime = require("../type/TransportTime");
var _defaults = require("../util/Defaults");
var _emitter = require("../util/Emitter");
var _interface = require("../util/Interface");
var _intervalTimeline = require("../util/IntervalTimeline");
var _timeline = require("../util/Timeline");
var _typeCheck = require("../util/TypeCheck");
var _clock = require("./Clock");
var _transportEvent = require("./TransportEvent");
var _transportRepeatEvent = require("./TransportRepeatEvent");
class Transport extends _toneWithContext.ToneWithContext {
    constructor(){
        super(_defaults.optionsFromArguments(Transport.getDefaults(), arguments));
        this.name = "Transport";
        //-------------------------------------
        // 	LOOPING
        //-------------------------------------
        /**
         * If the transport loops or not.
         */ this._loop = new _timelineValue.TimelineValue(false);
        /**
         * The loop start position in ticks
         */ this._loopStart = 0;
        /**
         * The loop end position in ticks
         */ this._loopEnd = 0;
        //-------------------------------------
        // 	TIMELINE EVENTS
        //-------------------------------------
        /**
         * All the events in an object to keep track by ID
         */ this._scheduledEvents = {
        };
        /**
         * The scheduled events.
         */ this._timeline = new _timeline.Timeline();
        /**
         * Repeated events
         */ this._repeatedEvents = new _intervalTimeline.IntervalTimeline();
        /**
         * All of the synced Signals
         */ this._syncedSignals = [];
        /**
         * The swing amount
         */ this._swingAmount = 0;
        const options = _defaults.optionsFromArguments(Transport.getDefaults(), arguments);
        // CLOCK/TEMPO
        this._ppq = options.ppq;
        this._clock = new _clock.Clock({
            callback: this._processTick.bind(this),
            context: this.context,
            frequency: 0,
            units: "bpm"
        });
        this._bindClockEvents();
        this.bpm = this._clock.frequency;
        this._clock.frequency.multiplier = options.ppq;
        this.bpm.setValueAtTime(options.bpm, 0);
        _interface.readOnly(this, "bpm");
        this._timeSignature = options.timeSignature;
        // SWING
        this._swingTicks = options.ppq / 2; // 8n
    }
    static getDefaults() {
        return Object.assign(_toneWithContext.ToneWithContext.getDefaults(), {
            bpm: 120,
            loopEnd: "4m",
            loopStart: 0,
            ppq: 192,
            swing: 0,
            swingSubdivision: "8n",
            timeSignature: 4
        });
    }
    //-------------------------------------
    // 	TICKS
    //-------------------------------------
    /**
     * called on every tick
     * @param  tickTime clock relative tick time
     */ _processTick(tickTime, ticks) {
        // do the loop test
        if (this._loop.get(tickTime)) {
            if (ticks >= this._loopEnd) {
                this.emit("loopEnd", tickTime);
                this._clock.setTicksAtTime(this._loopStart, tickTime);
                ticks = this._loopStart;
                this.emit("loopStart", tickTime, this._clock.getSecondsAtTime(tickTime));
                this.emit("loop", tickTime);
            }
        }
        // handle swing
        if (this._swingAmount > 0 && ticks % this._ppq !== 0 && ticks % (this._swingTicks * 2) !== 0) {
            // add some swing
            const progress = ticks % (this._swingTicks * 2) / (this._swingTicks * 2);
            const amount = Math.sin(progress * Math.PI) * this._swingAmount;
            tickTime += new _ticks.TicksClass(this.context, this._swingTicks * 2 / 3).toSeconds() * amount;
        }
        // invoke the timeline events scheduled on this tick
        this._timeline.forEachAtTime(ticks, (event)=>event.invoke(tickTime)
        );
    }
    //-------------------------------------
    // 	SCHEDULABLE EVENTS
    //-------------------------------------
    /**
     * Schedule an event along the timeline.
     * @param callback The callback to be invoked at the time.
     * @param time The time to invoke the callback at.
     * @return The id of the event which can be used for canceling the event.
     * @example
     * // schedule an event on the 16th measure
     * Tone.Transport.schedule((time) => {
     * 	// invoked on measure 16
     * 	console.log("measure 16!");
     * }, "16:0:0");
     */ schedule(callback, time) {
        const event = new _transportEvent.TransportEvent(this, {
            callback,
            time: new _transportTime.TransportTimeClass(this.context, time).toTicks()
        });
        return this._addEvent(event, this._timeline);
    }
    /**
     * Schedule a repeated event along the timeline. The event will fire
     * at the `interval` starting at the `startTime` and for the specified
     * `duration`.
     * @param  callback   The callback to invoke.
     * @param  interval   The duration between successive callbacks. Must be a positive number.
     * @param  startTime  When along the timeline the events should start being invoked.
     * @param  duration How long the event should repeat.
     * @return  The ID of the scheduled event. Use this to cancel the event.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * // a callback invoked every eighth note after the first measure
     * Tone.Transport.scheduleRepeat((time) => {
     * 	osc.start(time).stop(time + 0.1);
     * }, "8n", "1m");
     */ scheduleRepeat(callback, interval, startTime, duration = Infinity) {
        const event = new _transportRepeatEvent.TransportRepeatEvent(this, {
            callback,
            duration: new _time.TimeClass(this.context, duration).toTicks(),
            interval: new _time.TimeClass(this.context, interval).toTicks(),
            time: new _transportTime.TransportTimeClass(this.context, startTime).toTicks()
        });
        // kick it off if the Transport is started
        // @ts-ignore
        return this._addEvent(event, this._repeatedEvents);
    }
    /**
     * Schedule an event that will be removed after it is invoked.
     * @param callback The callback to invoke once.
     * @param time The time the callback should be invoked.
     * @returns The ID of the scheduled event.
     */ scheduleOnce(callback, time) {
        const event = new _transportEvent.TransportEvent(this, {
            callback,
            once: true,
            time: new _transportTime.TransportTimeClass(this.context, time).toTicks()
        });
        return this._addEvent(event, this._timeline);
    }
    /**
     * Clear the passed in event id from the timeline
     * @param eventId The id of the event.
     */ clear(eventId) {
        if (this._scheduledEvents.hasOwnProperty(eventId)) {
            const item = this._scheduledEvents[eventId.toString()];
            item.timeline.remove(item.event);
            item.event.dispose();
            delete this._scheduledEvents[eventId.toString()];
        }
        return this;
    }
    /**
     * Add an event to the correct timeline. Keep track of the
     * timeline it was added to.
     * @returns the event id which was just added
     */ _addEvent(event, timeline) {
        this._scheduledEvents[event.id.toString()] = {
            event,
            timeline
        };
        timeline.add(event);
        return event.id;
    }
    /**
     * Remove scheduled events from the timeline after
     * the given time. Repeated events will be removed
     * if their startTime is after the given time
     * @param after Clear all events after this time.
     */ cancel(after = 0) {
        const computedAfter = this.toTicks(after);
        this._timeline.forEachFrom(computedAfter, (event)=>this.clear(event.id)
        );
        this._repeatedEvents.forEachFrom(computedAfter, (event)=>this.clear(event.id)
        );
        return this;
    }
    //-------------------------------------
    // 	START/STOP/PAUSE
    //-------------------------------------
    /**
     * Bind start/stop/pause events from the clock and emit them.
     */ _bindClockEvents() {
        this._clock.on("start", (time, offset)=>{
            offset = new _ticks.TicksClass(this.context, offset).toSeconds();
            this.emit("start", time, offset);
        });
        this._clock.on("stop", (time)=>{
            this.emit("stop", time);
        });
        this._clock.on("pause", (time)=>{
            this.emit("pause", time);
        });
    }
    /**
     * Returns the playback state of the source, either "started", "stopped", or "paused"
     */ get state() {
        return this._clock.getStateAtTime(this.now());
    }
    /**
     * Start the transport and all sources synced to the transport.
     * @param  time The time when the transport should start.
     * @param  offset The timeline offset to start the transport.
     * @example
     * // start the transport in one second starting at beginning of the 5th measure.
     * Tone.Transport.start("+1", "4:0:0");
     */ start(time, offset) {
        let offsetTicks;
        if (_typeCheck.isDefined(offset)) offsetTicks = this.toTicks(offset);
        // start the clock
        this._clock.start(time, offsetTicks);
        return this;
    }
    /**
     * Stop the transport and all sources synced to the transport.
     * @param time The time when the transport should stop.
     * @example
     * Tone.Transport.stop();
     */ stop(time) {
        this._clock.stop(time);
        return this;
    }
    /**
     * Pause the transport and all sources synced to the transport.
     */ pause(time) {
        this._clock.pause(time);
        return this;
    }
    /**
     * Toggle the current state of the transport. If it is
     * started, it will stop it, otherwise it will start the Transport.
     * @param  time The time of the event
     */ toggle(time) {
        time = this.toSeconds(time);
        if (this._clock.getStateAtTime(time) !== "started") this.start(time);
        else this.stop(time);
        return this;
    }
    //-------------------------------------
    // 	SETTERS/GETTERS
    //-------------------------------------
    /**
     * The time signature as just the numerator over 4.
     * For example 4/4 would be just 4 and 6/8 would be 3.
     * @example
     * // common time
     * Tone.Transport.timeSignature = 4;
     * // 7/8
     * Tone.Transport.timeSignature = [7, 8];
     * // this will be reduced to a single number
     * Tone.Transport.timeSignature; // returns 3.5
     */ get timeSignature() {
        return this._timeSignature;
    }
    set timeSignature(timeSig) {
        if (_typeCheck.isArray(timeSig)) timeSig = timeSig[0] / timeSig[1] * 4;
        this._timeSignature = timeSig;
    }
    /**
     * When the Transport.loop = true, this is the starting position of the loop.
     */ get loopStart() {
        return new _time.TimeClass(this.context, this._loopStart, "i").toSeconds();
    }
    set loopStart(startPosition) {
        this._loopStart = this.toTicks(startPosition);
    }
    /**
     * When the Transport.loop = true, this is the ending position of the loop.
     */ get loopEnd() {
        return new _time.TimeClass(this.context, this._loopEnd, "i").toSeconds();
    }
    set loopEnd(endPosition) {
        this._loopEnd = this.toTicks(endPosition);
    }
    /**
     * If the transport loops or not.
     */ get loop() {
        return this._loop.get(this.now());
    }
    set loop(loop) {
        this._loop.set(loop, this.now());
    }
    /**
     * Set the loop start and stop at the same time.
     * @example
     * // loop over the first measure
     * Tone.Transport.setLoopPoints(0, "1m");
     * Tone.Transport.loop = true;
     */ setLoopPoints(startPosition, endPosition) {
        this.loopStart = startPosition;
        this.loopEnd = endPosition;
        return this;
    }
    /**
     * The swing value. Between 0-1 where 1 equal to the note + half the subdivision.
     */ get swing() {
        return this._swingAmount;
    }
    set swing(amount) {
        // scale the values to a normal range
        this._swingAmount = amount;
    }
    /**
     * Set the subdivision which the swing will be applied to.
     * The default value is an 8th note. Value must be less
     * than a quarter note.
     */ get swingSubdivision() {
        return new _ticks.TicksClass(this.context, this._swingTicks).toNotation();
    }
    set swingSubdivision(subdivision) {
        this._swingTicks = this.toTicks(subdivision);
    }
    /**
     * The Transport's position in Bars:Beats:Sixteenths.
     * Setting the value will jump to that position right away.
     */ get position() {
        const now = this.now();
        const ticks = this._clock.getTicksAtTime(now);
        return new _ticks.TicksClass(this.context, ticks).toBarsBeatsSixteenths();
    }
    set position(progress) {
        const ticks = this.toTicks(progress);
        this.ticks = ticks;
    }
    /**
     * The Transport's position in seconds
     * Setting the value will jump to that position right away.
     */ get seconds() {
        return this._clock.seconds;
    }
    set seconds(s) {
        const now = this.now();
        const ticks = this._clock.frequency.timeToTicks(s, now);
        this.ticks = ticks;
    }
    /**
     * The Transport's loop position as a normalized value. Always
     * returns 0 if the transport if loop is not true.
     */ get progress() {
        if (this.loop) {
            const now = this.now();
            const ticks = this._clock.getTicksAtTime(now);
            return (ticks - this._loopStart) / (this._loopEnd - this._loopStart);
        } else return 0;
    }
    /**
     * The transports current tick position.
     */ get ticks() {
        return this._clock.ticks;
    }
    set ticks(t) {
        if (this._clock.ticks !== t) {
            const now = this.now();
            // stop everything synced to the transport
            if (this.state === "started") {
                const ticks = this._clock.getTicksAtTime(now);
                // schedule to start on the next tick, #573
                const remainingTick = this._clock.frequency.getDurationOfTicks(Math.ceil(ticks) - ticks, now);
                const time = now + remainingTick;
                this.emit("stop", time);
                this._clock.setTicksAtTime(t, time);
                // restart it with the new time
                this.emit("start", time, this._clock.getSecondsAtTime(time));
            } else this._clock.setTicksAtTime(t, now);
        }
    }
    /**
     * Get the clock's ticks at the given time.
     * @param  time  When to get the tick value
     * @return The tick value at the given time.
     */ getTicksAtTime(time) {
        return Math.round(this._clock.getTicksAtTime(time));
    }
    /**
     * Return the elapsed seconds at the given time.
     * @param  time  When to get the elapsed seconds
     * @return  The number of elapsed seconds
     */ getSecondsAtTime(time) {
        return this._clock.getSecondsAtTime(time);
    }
    /**
     * Pulses Per Quarter note. This is the smallest resolution
     * the Transport timing supports. This should be set once
     * on initialization and not set again. Changing this value
     * after other objects have been created can cause problems.
     */ get PPQ() {
        return this._clock.frequency.multiplier;
    }
    set PPQ(ppq) {
        this._clock.frequency.multiplier = ppq;
    }
    //-------------------------------------
    // 	SYNCING
    //-------------------------------------
    /**
     * Returns the time aligned to the next subdivision
     * of the Transport. If the Transport is not started,
     * it will return 0.
     * Note: this will not work precisely during tempo ramps.
     * @param  subdivision  The subdivision to quantize to
     * @return  The context time of the next subdivision.
     * @example
     * // the transport must be started, otherwise returns 0
     * Tone.Transport.start();
     * Tone.Transport.nextSubdivision("4n");
     */ nextSubdivision(subdivision) {
        subdivision = this.toTicks(subdivision);
        if (this.state !== "started") // if the transport's not started, return 0
        return 0;
        else {
            const now = this.now();
            // the remainder of the current ticks and the subdivision
            const transportPos = this.getTicksAtTime(now);
            const remainingTicks = subdivision - transportPos % subdivision;
            return this._clock.nextTickTime(remainingTicks, now);
        }
    }
    /**
     * Attaches the signal to the tempo control signal so that
     * any changes in the tempo will change the signal in the same
     * ratio.
     *
     * @param signal
     * @param ratio Optionally pass in the ratio between the two signals.
     * 			Otherwise it will be computed based on their current values.
     */ syncSignal(signal, ratio) {
        if (!ratio) {
            // get the sync ratio
            const now = this.now();
            if (signal.getValueAtTime(now) !== 0) {
                const bpm = this.bpm.getValueAtTime(now);
                const computedFreq = 1 / (60 / bpm / this.PPQ);
                ratio = signal.getValueAtTime(now) / computedFreq;
            } else ratio = 0;
        }
        const ratioSignal = new _gain.Gain(ratio);
        // @ts-ignore
        this.bpm.connect(ratioSignal);
        // @ts-ignore
        ratioSignal.connect(signal._param);
        this._syncedSignals.push({
            initial: signal.value,
            ratio: ratioSignal,
            signal
        });
        signal.value = 0;
        return this;
    }
    /**
     * Unsyncs a previously synced signal from the transport's control.
     * See Transport.syncSignal.
     */ unsyncSignal(signal) {
        for(let i = this._syncedSignals.length - 1; i >= 0; i--){
            const syncedSignal = this._syncedSignals[i];
            if (syncedSignal.signal === signal) {
                syncedSignal.ratio.dispose();
                syncedSignal.signal.value = syncedSignal.initial;
                this._syncedSignals.splice(i, 1);
            }
        }
        return this;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._clock.dispose();
        _interface.writable(this, "bpm");
        this._timeline.dispose();
        this._repeatedEvents.dispose();
        return this;
    }
}
_emitter.Emitter.mixin(Transport);
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
_contextInitialization.onContextInit((context)=>{
    context.transport = new Transport({
        context
    });
});
_contextInitialization.onContextClose((context)=>{
    context.transport.dispose();
});

},{"../../core/type/Time":"1HtHW","../../core/util/TimelineValue":"4lgtC","../context/ContextInitialization":"6PyHY","../context/Gain":"7kpMn","../context/ToneWithContext":"ez5Mk","../type/Ticks":"8zKuk","../type/TransportTime":"kcsdx","../util/Defaults":"kSyYt","../util/Emitter":"bzta6","../util/Interface":"fVoXs","../util/IntervalTimeline":"EpXgL","../util/Timeline":"leurn","../util/TypeCheck":"lCqGC","./Clock":"2WJVT","./TransportEvent":"lV4Cv","./TransportRepeatEvent":"5XoMv","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4lgtC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Represents a single value which is gettable and settable in a timed way
 */ parcelHelpers.export(exports, "TimelineValue", ()=>TimelineValue
);
var _timeline = require("./Timeline");
var _tone = require("../Tone");
class TimelineValue extends _tone.Tone {
    /**
     * @param initialValue The value to return if there is no scheduled values
     */ constructor(initialValue){
        super();
        this.name = "TimelineValue";
        /**
         * The timeline which stores the values
         */ this._timeline = new _timeline.Timeline({
            memory: 10
        });
        this._initialValue = initialValue;
    }
    /**
     * Set the value at the given time
     */ set(value, time) {
        this._timeline.add({
            value,
            time
        });
        return this;
    }
    /**
     * Get the value at the given time
     */ get(time) {
        const event = this._timeline.get(time);
        if (event) return event.value;
        else return this._initialValue;
    }
}

},{"./Timeline":"leurn","../Tone":"dTzBa","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lV4Cv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TransportEvent is an internal class used by [[Transport]]
 * to schedule events. Do no invoke this class directly, it is
 * handled from within Tone.Transport.
 */ parcelHelpers.export(exports, "TransportEvent", ()=>TransportEvent
);
var _interface = require("../util/Interface");
class TransportEvent {
    /**
     * @param transport The transport object which the event belongs to
     */ constructor(transport, opts){
        /**
         * The unique id of the event
         */ this.id = TransportEvent._eventId++;
        const options = Object.assign(TransportEvent.getDefaults(), opts);
        this.transport = transport;
        this.callback = options.callback;
        this._once = options.once;
        this.time = options.time;
    }
    static getDefaults() {
        return {
            callback: _interface.noOp,
            once: false,
            time: 0
        };
    }
    /**
     * Invoke the event callback.
     * @param  time  The AudioContext time in seconds of the event
     */ invoke(time) {
        if (this.callback) {
            this.callback(time);
            if (this._once) this.transport.clear(this.id);
        }
    }
    /**
     * Clean up
     */ dispose() {
        this.callback = undefined;
        return this;
    }
}
/**
 * Current ID counter
 */ TransportEvent._eventId = 0;

},{"../util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5XoMv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * TransportRepeatEvent is an internal class used by Tone.Transport
 * to schedule repeat events. This class should not be instantiated directly.
 */ parcelHelpers.export(exports, "TransportRepeatEvent", ()=>TransportRepeatEvent
);
var _ticks = require("../type/Ticks");
var _transportEvent = require("./TransportEvent");
class TransportRepeatEvent extends _transportEvent.TransportEvent {
    /**
     * @param transport The transport object which the event belongs to
     */ constructor(transport, opts){
        super(transport, opts);
        /**
         * The ID of the current timeline event
         */ this._currentId = -1;
        /**
         * The ID of the next timeline event
         */ this._nextId = -1;
        /**
         * The time of the next event
         */ this._nextTick = this.time;
        /**
         * a reference to the bound start method
         */ this._boundRestart = this._restart.bind(this);
        const options = Object.assign(TransportRepeatEvent.getDefaults(), opts);
        this.duration = new _ticks.TicksClass(transport.context, options.duration).valueOf();
        this._interval = new _ticks.TicksClass(transport.context, options.interval).valueOf();
        this._nextTick = options.time;
        this.transport.on("start", this._boundRestart);
        this.transport.on("loopStart", this._boundRestart);
        this.context = this.transport.context;
        this._restart();
    }
    static getDefaults() {
        return Object.assign({
        }, _transportEvent.TransportEvent.getDefaults(), {
            duration: Infinity,
            interval: 1,
            once: false
        });
    }
    /**
     * Invoke the callback. Returns the tick time which
     * the next event should be scheduled at.
     * @param  time  The AudioContext time in seconds of the event
     */ invoke(time) {
        // create more events if necessary
        this._createEvents(time);
        // call the super class
        super.invoke(time);
    }
    /**
     * Push more events onto the timeline to keep up with the position of the timeline
     */ _createEvents(time) {
        // schedule the next event
        const ticks = this.transport.getTicksAtTime(time);
        if (ticks >= this.time && ticks >= this._nextTick && this._nextTick + this._interval < this.time + this.duration) {
            this._nextTick += this._interval;
            this._currentId = this._nextId;
            this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new _ticks.TicksClass(this.context, this._nextTick).toSeconds());
        }
    }
    /**
     * Push more events onto the timeline to keep up with the position of the timeline
     */ _restart(time) {
        this.transport.clear(this._currentId);
        this.transport.clear(this._nextId);
        this._nextTick = this.time;
        const ticks = this.transport.getTicksAtTime(time);
        if (ticks > this.time) this._nextTick = this.time + Math.ceil((ticks - this.time) / this._interval) * this._interval;
        this._currentId = this.transport.scheduleOnce(this.invoke.bind(this), new _ticks.TicksClass(this.context, this._nextTick).toSeconds());
        this._nextTick += this._interval;
        this._nextId = this.transport.scheduleOnce(this.invoke.bind(this), new _ticks.TicksClass(this.context, this._nextTick).toSeconds());
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this.transport.clear(this._currentId);
        this.transport.clear(this._nextId);
        this.transport.off("start", this._boundRestart);
        this.transport.off("loopStart", this._boundRestart);
        return this;
    }
}

},{"../type/Ticks":"8zKuk","./TransportEvent":"lV4Cv","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6y7FM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native BufferSourceNode.
 * @category Source
 */ parcelHelpers.export(exports, "ToneBufferSource", ()=>ToneBufferSource
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _param = require("../../core/context/Param");
var _toneAudioBuffer = require("../../core/context/ToneAudioBuffer");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _typeCheck = require("../../core/util/TypeCheck");
var _debug = require("../../core/util/Debug");
var _oneShotSource = require("../OneShotSource");
var _math = require("../../core/util/Math");
class ToneBufferSource extends _oneShotSource.OneShotSource {
    constructor(){
        super(_defaults.optionsFromArguments(ToneBufferSource.getDefaults(), arguments, [
            "url",
            "onload"
        ]));
        this.name = "ToneBufferSource";
        /**
         * The oscillator
         */ this._source = this.context.createBufferSource();
        this._internalChannels = [
            this._source
        ];
        /**
         * indicators if the source has started/stopped
         */ this._sourceStarted = false;
        this._sourceStopped = false;
        const options = _defaults.optionsFromArguments(ToneBufferSource.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        _toneAudioNode.connect(this._source, this._gainNode);
        this._source.onended = ()=>this._stopSource()
        ;
        /**
         * The playbackRate of the buffer
         */ this.playbackRate = new _param.Param({
            context: this.context,
            param: this._source.playbackRate,
            units: "positive",
            value: options.playbackRate
        });
        // set some values initially
        this.loop = options.loop;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this._buffer = new _toneAudioBuffer.ToneAudioBuffer(options.url, options.onload, options.onerror);
        this._internalChannels.push(this._source);
    }
    static getDefaults() {
        return Object.assign(_oneShotSource.OneShotSource.getDefaults(), {
            url: new _toneAudioBuffer.ToneAudioBuffer(),
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            onload: _interface.noOp,
            onerror: _interface.noOp,
            playbackRate: 1
        });
    }
    /**
     * The fadeIn time of the amplitude envelope.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(t) {
        this._fadeIn = t;
    }
    /**
     * The fadeOut time of the amplitude envelope.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(t) {
        this._fadeOut = t;
    }
    /**
     * The curve applied to the fades, either "linear" or "exponential"
     */ get curve() {
        return this._curve;
    }
    set curve(t) {
        this._curve = t;
    }
    /**
     * Start the buffer
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
     * @param  gain  The gain to play the buffer back at.
     */ start(time, offset, duration, gain = 1) {
        _debug.assert(this.buffer.loaded, "buffer is either not set or not loaded");
        const computedTime = this.toSeconds(time);
        // apply the gain envelope
        this._startGain(computedTime, gain);
        // if it's a loop the default offset is the loopstart point
        if (this.loop) offset = _defaults.defaultArg(offset, this.loopStart);
        else // otherwise the default offset is 0
        offset = _defaults.defaultArg(offset, 0);
        // make sure the offset is not less than 0
        let computedOffset = Math.max(this.toSeconds(offset), 0);
        // start the buffer source
        if (this.loop) {
            // modify the offset if it's greater than the loop time
            const loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;
            const loopStart = this.toSeconds(this.loopStart);
            const loopDuration = loopEnd - loopStart;
            // move the offset back
            if (_math.GTE(computedOffset, loopEnd)) computedOffset = (computedOffset - loopStart) % loopDuration + loopStart;
            // when the offset is very close to the duration, set it to 0
            if (_math.EQ(computedOffset, this.buffer.duration)) computedOffset = 0;
        }
        // this.buffer.loaded would have return false if the AudioBuffer was undefined
        this._source.buffer = this.buffer.get();
        this._source.loopEnd = this.toSeconds(this.loopEnd) || this.buffer.duration;
        if (_math.LT(computedOffset, this.buffer.duration)) {
            this._sourceStarted = true;
            this._source.start(computedTime, computedOffset);
        }
        // if a duration is given, schedule a stop
        if (_typeCheck.isDefined(duration)) {
            let computedDur = this.toSeconds(duration);
            // make sure it's never negative
            computedDur = Math.max(computedDur, 0);
            this.stop(computedTime + computedDur);
        }
        return this;
    }
    _stopSource(time) {
        if (!this._sourceStopped && this._sourceStarted) {
            this._sourceStopped = true;
            this._source.stop(this.toSeconds(time));
            this._onended();
        }
    }
    /**
     * If loop is true, the loop will start at this position.
     */ get loopStart() {
        return this._source.loopStart;
    }
    set loopStart(loopStart) {
        this._source.loopStart = this.toSeconds(loopStart);
    }
    /**
     * If loop is true, the loop will end at this position.
     */ get loopEnd() {
        return this._source.loopEnd;
    }
    set loopEnd(loopEnd) {
        this._source.loopEnd = this.toSeconds(loopEnd);
    }
    /**
     * The audio buffer belonging to the player.
     */ get buffer() {
        return this._buffer;
    }
    set buffer(buffer) {
        this._buffer.set(buffer);
    }
    /**
     * If the buffer should loop once it's over.
     */ get loop() {
        return this._source.loop;
    }
    set loop(loop) {
        this._source.loop = loop;
        if (this._sourceStarted) this.cancelStop();
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._source.onended = null;
        this._source.disconnect();
        this._buffer.dispose();
        this.playbackRate.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/context/Param":"2qxaM","../../core/context/ToneAudioBuffer":"gpPIV","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../core/util/TypeCheck":"lCqGC","../../core/util/Debug":"bsxl9","../OneShotSource":"hEB90","../../core/util/Math":"gdhOV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9Syrh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * UserMedia uses MediaDevices.getUserMedia to open up and external microphone or audio input.
 * Check [MediaDevices API Support](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)
 * to see which browsers are supported. Access to an external input
 * is limited to secure (HTTPS) connections.
 * @example
 * const meter = new Tone.Meter();
 * const mic = new Tone.UserMedia().connect(meter);
 * mic.open().then(() => {
 * 	// promise resolves when input is available
 * 	console.log("mic open");
 * 	// print the incoming mic levels in decibels
 * 	setInterval(() => console.log(meter.getValue()), 100);
 * }).catch(e => {
 * 	// promise is rejected when the user doesn't have or allow mic access
 * 	console.log("mic not open");
 * });
 * @category Source
 */ parcelHelpers.export(exports, "UserMedia", ()=>UserMedia
);
var _tslib = require("tslib");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _volume = require("../component/channel/Volume");
var _defaults = require("../core/util/Defaults");
var _debug = require("../core/util/Debug");
var _interface = require("../core/util/Interface");
var _typeCheck = require("../core/util/TypeCheck");
class UserMedia extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(UserMedia.getDefaults(), arguments, [
            "volume"
        ]));
        this.name = "UserMedia";
        const options = _defaults.optionsFromArguments(UserMedia.getDefaults(), arguments, [
            "volume"
        ]);
        this._volume = this.output = new _volume.Volume({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        _interface.readOnly(this, "volume");
        this.mute = options.mute;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            mute: false,
            volume: 0
        });
    }
    /**
     * Open the media stream. If a string is passed in, it is assumed
     * to be the label or id of the stream, if a number is passed in,
     * it is the input number of the stream.
     * @param  labelOrId The label or id of the audio input media device.
     *                   With no argument, the default stream is opened.
     * @return The promise is resolved when the stream is open.
     */ open(labelOrId) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            _debug.assert(UserMedia.supported, "UserMedia is not supported");
            // close the previous stream
            if (this.state === "started") this.close();
            const devices = yield UserMedia.enumerateDevices();
            if (_typeCheck.isNumber(labelOrId)) this._device = devices[labelOrId];
            else {
                this._device = devices.find((device)=>{
                    return device.label === labelOrId || device.deviceId === labelOrId;
                });
                // didn't find a matching device
                if (!this._device && devices.length > 0) this._device = devices[0];
                _debug.assert(_typeCheck.isDefined(this._device), `No matching device ${labelOrId}`);
            }
            // do getUserMedia
            const constraints = {
                audio: {
                    echoCancellation: false,
                    sampleRate: this.context.sampleRate,
                    noiseSuppression: false,
                    mozNoiseSuppression: false
                }
            };
            if (this._device) // @ts-ignore
            constraints.audio.deviceId = this._device.deviceId;
            const stream = yield navigator.mediaDevices.getUserMedia(constraints);
            // start a new source only if the previous one is closed
            if (!this._stream) {
                this._stream = stream;
                // Wrap a MediaStreamSourceNode around the live input stream.
                const mediaStreamNode = this.context.createMediaStreamSource(stream);
                // Connect the MediaStreamSourceNode to a gate gain node
                _toneAudioNode.connect(mediaStreamNode, this.output);
                this._mediaStream = mediaStreamNode;
            }
            return this;
        });
    }
    /**
     * Close the media stream
     */ close() {
        if (this._stream && this._mediaStream) {
            this._stream.getAudioTracks().forEach((track)=>{
                track.stop();
            });
            this._stream = undefined;
            // remove the old media stream
            this._mediaStream.disconnect();
            this._mediaStream = undefined;
        }
        this._device = undefined;
        return this;
    }
    /**
     * Returns a promise which resolves with the list of audio input devices available.
     * @return The promise that is resolved with the devices
     * @example
     * Tone.UserMedia.enumerateDevices().then((devices) => {
     * 	// print the device labels
     * 	console.log(devices.map(device => device.label));
     * });
     */ static enumerateDevices() {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            const allDevices = yield navigator.mediaDevices.enumerateDevices();
            return allDevices.filter((device)=>{
                return device.kind === "audioinput";
            });
        });
    }
    /**
     * Returns the playback state of the source, "started" when the microphone is open
     * and "stopped" when the mic is closed.
     */ get state() {
        return this._stream && this._stream.active ? "started" : "stopped";
    }
    /**
     * Returns an identifier for the represented device that is
     * persisted across sessions. It is un-guessable by other applications and
     * unique to the origin of the calling application. It is reset when the
     * user clears cookies (for Private Browsing, a different identifier is
     * used that is not persisted across sessions). Returns undefined when the
     * device is not open.
     */ get deviceId() {
        if (this._device) return this._device.deviceId;
        else return undefined;
    }
    /**
     * Returns a group identifier. Two devices have the
     * same group identifier if they belong to the same physical device.
     * Returns null  when the device is not open.
     */ get groupId() {
        if (this._device) return this._device.groupId;
        else return undefined;
    }
    /**
     * Returns a label describing this device (for example "Built-in Microphone").
     * Returns undefined when the device is not open or label is not available
     * because of permissions.
     */ get label() {
        if (this._device) return this._device.label;
        else return undefined;
    }
    /**
     * Mute the output.
     * @example
     * const mic = new Tone.UserMedia();
     * mic.open().then(() => {
     * 	// promise resolves when input is available
     * });
     * // mute the output
     * mic.mute = true;
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    dispose() {
        super.dispose();
        this.close();
        this._volume.dispose();
        this.volume.dispose();
        return this;
    }
    /**
     * If getUserMedia is supported by the browser.
     */ static get supported() {
        return _typeCheck.isDefined(navigator.mediaDevices) && _typeCheck.isDefined(navigator.mediaDevices.getUserMedia);
    }
}

},{"tslib":"bjkXk","../core/context/ToneAudioNode":"iT1SZ","../component/channel/Volume":"j5Q9V","../core/util/Defaults":"kSyYt","../core/util/Debug":"bsxl9","../core/util/Interface":"fVoXs","../core/util/TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"715Gq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Oscillator supports a number of features including
 * phase rotation, multiple oscillator types (see Oscillator.type),
 * and Transport syncing (see Oscillator.syncFrequency).
 *
 * @example
 * // make and start a 440hz sine tone
 * const osc = new Tone.Oscillator(440, "sine").toDestination().start();
 * @category Source
 */ parcelHelpers.export(exports, "Oscillator", ()=>Oscillator
);
var _tslib = require("tslib");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _typeCheck = require("../../core/util/TypeCheck");
var _signal = require("../../signal/Signal");
var _source = require("../Source");
var _oscillatorInterface = require("./OscillatorInterface");
var _toneOscillatorNode = require("./ToneOscillatorNode");
var _debug = require("../../core/util/Debug");
var _math = require("../../core/util/Math");
class Oscillator extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(Oscillator.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "Oscillator";
        /**
         * the main oscillator
         */ this._oscillator = null;
        const options = _defaults.optionsFromArguments(Oscillator.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        _interface.readOnly(this, "frequency");
        this.detune = new _signal.Signal({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        _interface.readOnly(this, "detune");
        this._partials = options.partials;
        this._partialCount = options.partialCount;
        this._type = options.type;
        if (options.partialCount && options.type !== "custom") this._type = this.baseType + options.partialCount.toString();
        this.phase = options.phase;
    }
    static getDefaults() {
        return Object.assign(_source.Source.getDefaults(), {
            detune: 0,
            frequency: 440,
            partialCount: 0,
            partials: [],
            phase: 0,
            type: "sine"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        const computedTime = this.toSeconds(time);
        // new oscillator with previous values
        const oscillator = new _toneOscillatorNode.ToneOscillatorNode({
            context: this.context,
            onended: ()=>this.onstop(this)
        });
        this._oscillator = oscillator;
        if (this._wave) this._oscillator.setPeriodicWave(this._wave);
        else this._oscillator.type = this._type;
        // connect the control signal to the oscillator frequency & detune
        this._oscillator.connect(this.output);
        this.frequency.connect(this._oscillator.frequency);
        this.detune.connect(this._oscillator.detune);
        // start the oscillator
        this._oscillator.start(computedTime);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        const computedTime = this.toSeconds(time);
        if (this._oscillator) this._oscillator.stop(computedTime);
    }
    /**
     * Restart the oscillator. Does not stop the oscillator, but instead
     * just cancels any scheduled 'stop' from being invoked.
     */ _restart(time) {
        const computedTime = this.toSeconds(time);
        this.log("restart", computedTime);
        if (this._oscillator) this._oscillator.cancelStop();
        this._state.cancel(computedTime);
        return this;
    }
    /**
     * Sync the signal to the Transport's bpm. Any changes to the transports bpm,
     * will also affect the oscillators frequency.
     * @example
     * const osc = new Tone.Oscillator().toDestination().start();
     * osc.frequency.value = 440;
     * // the ratio between the bpm and the frequency will be maintained
     * osc.syncFrequency();
     * // double the tempo
     * Tone.Transport.bpm.value *= 2;
     * // the frequency of the oscillator is doubled to 880
     */ syncFrequency() {
        this.context.transport.syncSignal(this.frequency);
        return this;
    }
    /**
     * Unsync the oscillator's frequency from the Transport.
     * See Oscillator.syncFrequency
     */ unsyncFrequency() {
        this.context.transport.unsyncSignal(this.frequency);
        return this;
    }
    /**
     * Get a cached periodic wave. Avoids having to recompute
     * the oscillator values when they have already been computed
     * with the same values.
     */ _getCachedPeriodicWave() {
        if (this._type === "custom") {
            const oscProps = Oscillator._periodicWaveCache.find((description)=>{
                return description.phase === this._phase && _defaults.deepEquals(description.partials, this._partials);
            });
            return oscProps;
        } else {
            const oscProps = Oscillator._periodicWaveCache.find((description)=>{
                return description.type === this._type && description.phase === this._phase;
            });
            this._partialCount = oscProps ? oscProps.partialCount : this._partialCount;
            return oscProps;
        }
    }
    get type() {
        return this._type;
    }
    set type(type) {
        this._type = type;
        const isBasicType = [
            "sine",
            "square",
            "sawtooth",
            "triangle"
        ].indexOf(type) !== -1;
        if (this._phase === 0 && isBasicType) {
            this._wave = undefined;
            this._partialCount = 0;
            // just go with the basic approach
            if (this._oscillator !== null) // already tested that it's a basic type
            this._oscillator.type = type;
        } else {
            // first check if the value is cached
            const cache = this._getCachedPeriodicWave();
            if (_typeCheck.isDefined(cache)) {
                const { partials , wave  } = cache;
                this._wave = wave;
                this._partials = partials;
                if (this._oscillator !== null) this._oscillator.setPeriodicWave(this._wave);
            } else {
                const [real, imag] = this._getRealImaginary(type, this._phase);
                const periodicWave = this.context.createPeriodicWave(real, imag);
                this._wave = periodicWave;
                if (this._oscillator !== null) this._oscillator.setPeriodicWave(this._wave);
                // set the cache
                Oscillator._periodicWaveCache.push({
                    imag,
                    partialCount: this._partialCount,
                    partials: this._partials,
                    phase: this._phase,
                    real,
                    type: this._type,
                    wave: this._wave
                });
                if (Oscillator._periodicWaveCache.length > 100) Oscillator._periodicWaveCache.shift();
            }
        }
    }
    get baseType() {
        return this._type.replace(this.partialCount.toString(), "");
    }
    set baseType(baseType) {
        if (this.partialCount && this._type !== "custom" && baseType !== "custom") this.type = baseType + this.partialCount;
        else this.type = baseType;
    }
    get partialCount() {
        return this._partialCount;
    }
    set partialCount(p) {
        _debug.assertRange(p, 0);
        let type = this._type;
        const partial = /^(sine|triangle|square|sawtooth)(\d+)$/.exec(this._type);
        if (partial) type = partial[1];
        if (this._type !== "custom") {
            if (p === 0) this.type = type;
            else this.type = type + p.toString();
        } else {
            // extend or shorten the partials array
            const fullPartials = new Float32Array(p);
            // copy over the partials array
            this._partials.forEach((v, i)=>fullPartials[i] = v
            );
            this._partials = Array.from(fullPartials);
            this.type = this._type;
        }
    }
    /**
     * Returns the real and imaginary components based
     * on the oscillator type.
     * @returns [real: Float32Array, imaginary: Float32Array]
     */ _getRealImaginary(type, phase) {
        const fftSize = 4096;
        let periodicWaveSize = fftSize / 2;
        const real = new Float32Array(periodicWaveSize);
        const imag = new Float32Array(periodicWaveSize);
        let partialCount = 1;
        if (type === "custom") {
            partialCount = this._partials.length + 1;
            this._partialCount = this._partials.length;
            periodicWaveSize = partialCount;
            // if the partial count is 0, don't bother doing any computation
            if (this._partials.length === 0) return [
                real,
                imag
            ];
        } else {
            const partial = /^(sine|triangle|square|sawtooth)(\d+)$/.exec(type);
            if (partial) {
                partialCount = parseInt(partial[2], 10) + 1;
                this._partialCount = parseInt(partial[2], 10);
                type = partial[1];
                partialCount = Math.max(partialCount, 2);
                periodicWaveSize = partialCount;
            } else this._partialCount = 0;
            this._partials = [];
        }
        for(let n = 1; n < periodicWaveSize; ++n){
            const piFactor = 2 / (n * Math.PI);
            let b;
            switch(type){
                case "sine":
                    b = n <= partialCount ? 1 : 0;
                    this._partials[n - 1] = b;
                    break;
                case "square":
                    b = n & 1 ? 2 * piFactor : 0;
                    this._partials[n - 1] = b;
                    break;
                case "sawtooth":
                    b = piFactor * (n & 1 ? 1 : -1);
                    this._partials[n - 1] = b;
                    break;
                case "triangle":
                    if (n & 1) b = 2 * (piFactor * piFactor) * (n - 1 >> 1 & 1 ? -1 : 1);
                    else b = 0;
                    this._partials[n - 1] = b;
                    break;
                case "custom":
                    b = this._partials[n - 1];
                    break;
                default:
                    throw new TypeError("Oscillator: invalid type: " + type);
            }
            if (b !== 0) {
                real[n] = -b * Math.sin(phase * n);
                imag[n] = b * Math.cos(phase * n);
            } else {
                real[n] = 0;
                imag[n] = 0;
            }
        }
        return [
            real,
            imag
        ];
    }
    /**
     * Compute the inverse FFT for a given phase.
     */ _inverseFFT(real, imag, phase) {
        let sum = 0;
        const len = real.length;
        for(let i = 0; i < len; i++)sum += real[i] * Math.cos(i * phase) + imag[i] * Math.sin(i * phase);
        return sum;
    }
    /**
     * Returns the initial value of the oscillator when stopped.
     * E.g. a "sine" oscillator with phase = 90 would return an initial value of -1.
     */ getInitialValue() {
        const [real, imag] = this._getRealImaginary(this._type, 0);
        let maxValue = 0;
        const twoPi = Math.PI * 2;
        const testPositions = 32;
        // check for peaks in 16 places
        for(let i = 0; i < testPositions; i++)maxValue = Math.max(this._inverseFFT(real, imag, i / testPositions * twoPi), maxValue);
        return _math.clamp(-this._inverseFFT(real, imag, this._phase) / maxValue, -1, 1);
    }
    get partials() {
        return this._partials.slice(0, this.partialCount);
    }
    set partials(partials) {
        this._partials = partials;
        this._partialCount = this._partials.length;
        if (partials.length) this.type = "custom";
    }
    get phase() {
        return this._phase * (180 / Math.PI);
    }
    set phase(phase) {
        this._phase = phase * Math.PI / 180;
        // reset the type
        this.type = this._type;
    }
    asArray(length = 1024) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            return _oscillatorInterface.generateWaveform(this, length);
        });
    }
    dispose() {
        super.dispose();
        if (this._oscillator !== null) this._oscillator.dispose();
        this._wave = undefined;
        this.frequency.dispose();
        this.detune.dispose();
        return this;
    }
}
/**
 * Cache the periodic waves to avoid having to redo computations
 */ Oscillator._periodicWaveCache = [];

},{"tslib":"bjkXk","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../core/util/TypeCheck":"lCqGC","../../signal/Signal":"kfryg","../Source":"31KwW","./OscillatorInterface":"fWLBY","./ToneOscillatorNode":"ahlJc","../../core/util/Debug":"bsxl9","../../core/util/Math":"gdhOV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fWLBY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Render a segment of the oscillator to an offline context and return the results as an array
 */ parcelHelpers.export(exports, "generateWaveform", ()=>generateWaveform
);
var _tslib = require("tslib");
var _offlineContext = require("../../core/context/OfflineContext");
function generateWaveform(instance, length) {
    return _tslib.__awaiter(this, void 0, void 0, function*() {
        const duration = length / instance.context.sampleRate;
        const context = new _offlineContext.OfflineContext(1, duration, instance.context.sampleRate);
        const clone = new instance.constructor(Object.assign(instance.get(), {
            // should do 2 iterations
            frequency: 2 / duration,
            // zero out the detune
            detune: 0,
            context
        })).toDestination();
        clone.start(0);
        const buffer = yield context.render();
        return buffer.getChannelData(0);
    });
}

},{"tslib":"bjkXk","../../core/context/OfflineContext":"KYtWQ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ahlJc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native fire-and-forget OscillatorNode.
 * Adds the ability to reschedule the stop method.
 * ***[[Oscillator]] is better for most use-cases***
 * @category Source
 */ parcelHelpers.export(exports, "ToneOscillatorNode", ()=>ToneOscillatorNode
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _param = require("../../core/context/Param");
var _defaults = require("../../core/util/Defaults");
var _oneShotSource = require("../OneShotSource");
var _interface = require("../../core/util/Interface");
class ToneOscillatorNode extends _oneShotSource.OneShotSource {
    constructor(){
        super(_defaults.optionsFromArguments(ToneOscillatorNode.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "ToneOscillatorNode";
        /**
         * The oscillator
         */ this._oscillator = this.context.createOscillator();
        this._internalChannels = [
            this._oscillator
        ];
        const options = _defaults.optionsFromArguments(ToneOscillatorNode.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        _toneAudioNode.connect(this._oscillator, this._gainNode);
        this.type = options.type;
        this.frequency = new _param.Param({
            context: this.context,
            param: this._oscillator.frequency,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new _param.Param({
            context: this.context,
            param: this._oscillator.detune,
            units: "cents",
            value: options.detune
        });
        _interface.readOnly(this, [
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign(_oneShotSource.OneShotSource.getDefaults(), {
            detune: 0,
            frequency: 440,
            type: "sine"
        });
    }
    /**
     * Start the oscillator node at the given time
     * @param  time When to start the oscillator
     */ start(time) {
        const computedTime = this.toSeconds(time);
        this.log("start", computedTime);
        this._startGain(computedTime);
        this._oscillator.start(computedTime);
        return this;
    }
    _stopSource(time) {
        this._oscillator.stop(time);
    }
    /**
     * Sets an arbitrary custom periodic waveform given a PeriodicWave.
     * @param  periodicWave PeriodicWave should be created with context.createPeriodicWave
     */ setPeriodicWave(periodicWave) {
        this._oscillator.setPeriodicWave(periodicWave);
        return this;
    }
    /**
     * The oscillator type. Either 'sine', 'sawtooth', 'square', or 'triangle'
     */ get type() {
        return this._oscillator.type;
    }
    set type(type) {
        this._oscillator.type = type;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        if (this.state === "started") this.stop();
        this._oscillator.disconnect();
        this.frequency.dispose();
        this.detune.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/context/Param":"2qxaM","../../core/util/Defaults":"kSyYt","../OneShotSource":"hEB90","../../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dECQc":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * An amplitude modulated oscillator node. It is implemented with
 * two oscillators, one which modulators the other's amplitude
 * through a gain node.
 * ```
 *    +-------------+       +----------+
 *    | Carrier Osc +>------> GainNode |
 *    +-------------+       |          +--->Output
 *                      +---> gain     |
 * +---------------+    |   +----------+
 * | Modulator Osc +>---+
 * +---------------+
 * ```
 * @example
 * return Tone.Offline(() => {
 * 	const amOsc = new Tone.AMOscillator(30, "sine", "square").toDestination().start();
 * }, 0.2, 1);
 * @category Source
 */ parcelHelpers.export(exports, "AMOscillator", ()=>AMOscillator
);
var _tslib = require("tslib");
var _gain = require("../../core/context/Gain");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _audioToGain = require("../../signal/AudioToGain");
var _multiply = require("../../signal/Multiply");
var _source = require("../Source");
var _oscillator = require("./Oscillator");
var _oscillatorInterface = require("./OscillatorInterface");
class AMOscillator extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(AMOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]));
        this.name = "AMOscillator";
        /**
         * convert the -1,1 output to 0,1
         */ this._modulationScale = new _audioToGain.AudioToGain({
            context: this.context
        });
        /**
         * the node where the modulation happens
         */ this._modulationNode = new _gain.Gain({
            context: this.context
        });
        const options = _defaults.optionsFromArguments(AMOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]);
        this._carrier = new _oscillator.Oscillator({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this)
            ,
            phase: options.phase,
            type: options.type
        });
        this.frequency = this._carrier.frequency, this.detune = this._carrier.detune;
        this._modulator = new _oscillator.Oscillator({
            context: this.context,
            phase: options.phase,
            type: options.modulationType
        });
        this.harmonicity = new _multiply.Multiply({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        // connections
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this._modulator.chain(this._modulationScale, this._modulationNode.gain);
        this._carrier.chain(this._modulationNode, this.output);
        _interface.readOnly(this, [
            "frequency",
            "detune",
            "harmonicity"
        ]);
    }
    static getDefaults() {
        return Object.assign(_oscillator.Oscillator.getDefaults(), {
            harmonicity: 1,
            modulationType: "square"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._modulator.start(time);
        this._carrier.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        this._modulator.stop(time);
        this._carrier.stop(time);
    }
    _restart(time) {
        this._modulator.restart(time);
        this._carrier.restart(time);
    }
    /**
     * The type of the carrier oscillator
     */ get type() {
        return this._carrier.type;
    }
    set type(type) {
        this._carrier.type = type;
    }
    get baseType() {
        return this._carrier.baseType;
    }
    set baseType(baseType) {
        this._carrier.baseType = baseType;
    }
    get partialCount() {
        return this._carrier.partialCount;
    }
    set partialCount(partialCount) {
        this._carrier.partialCount = partialCount;
    }
    /**
     * The type of the modulator oscillator
     */ get modulationType() {
        return this._modulator.type;
    }
    set modulationType(type) {
        this._modulator.type = type;
    }
    get phase() {
        return this._carrier.phase;
    }
    set phase(phase) {
        this._carrier.phase = phase;
        this._modulator.phase = phase;
    }
    get partials() {
        return this._carrier.partials;
    }
    set partials(partials) {
        this._carrier.partials = partials;
    }
    asArray(length = 1024) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            return _oscillatorInterface.generateWaveform(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this.harmonicity.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this._modulationNode.dispose();
        this._modulationScale.dispose();
        return this;
    }
}

},{"tslib":"bjkXk","../../core/context/Gain":"7kpMn","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../signal/AudioToGain":"bwjzf","../../signal/Multiply":"bN8EY","../Source":"31KwW","./Oscillator":"715Gq","./OscillatorInterface":"fWLBY","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bwjzf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AudioToGain converts an input in AudioRange [-1,1] to NormalRange [0,1].
 * See [[GainToAudio]].
 * @category Signal
 */ parcelHelpers.export(exports, "AudioToGain", ()=>AudioToGain
);
var _signalOperator = require("./SignalOperator");
var _waveShaper = require("./WaveShaper");
class AudioToGain extends _signalOperator.SignalOperator {
    constructor(){
        super(...arguments);
        this.name = "AudioToGain";
        /**
         * The node which converts the audio ranges
         */ this._norm = new _waveShaper.WaveShaper({
            context: this.context,
            mapping: (x)=>(x + 1) / 2
        });
        /**
         * The AudioRange input [-1, 1]
         */ this.input = this._norm;
        /**
         * The GainRange output [0, 1]
         */ this.output = this._norm;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._norm.dispose();
        return this;
    }
}

},{"./SignalOperator":"bqDTZ","./WaveShaper":"4cjPf","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bqDTZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A signal operator has an input and output and modifies the signal.
 */ parcelHelpers.export(exports, "SignalOperator", ()=>SignalOperator
);
var _defaults = require("../core/util/Defaults");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _signal = require("./Signal");
class SignalOperator extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(SignalOperator.getDefaults(), arguments, [
            "context"
        ])));
    }
    connect(destination, outputNum = 0, inputNum = 0) {
        _signal.connectSignal(this, destination, outputNum, inputNum);
        return this;
    }
}

},{"../core/util/Defaults":"kSyYt","../core/context/ToneAudioNode":"iT1SZ","./Signal":"kfryg","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4cjPf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wraps the native Web Audio API
 * [WaveShaperNode](http://webaudio.github.io/web-audio-api/#the-waveshapernode-interface).
 *
 * @example
 * const osc = new Tone.Oscillator().toDestination().start();
 * // multiply the output of the signal by 2 using the waveshaper's function
 * const timesTwo = new Tone.WaveShaper((val) => val * 2, 2048).connect(osc.frequency);
 * const signal = new Tone.Signal(440).connect(timesTwo);
 * @category Signal
 */ parcelHelpers.export(exports, "WaveShaper", ()=>WaveShaper
);
var _defaults = require("../core/util/Defaults");
var _typeCheck = require("../core/util/TypeCheck");
var _debug = require("../core/util/Debug");
var _signal = require("./Signal");
var _signalOperator = require("./SignalOperator");
class WaveShaper extends _signalOperator.SignalOperator {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(WaveShaper.getDefaults(), arguments, [
            "mapping",
            "length"
        ])));
        this.name = "WaveShaper";
        /**
         * the waveshaper node
         */ this._shaper = this.context.createWaveShaper();
        /**
         * The input to the waveshaper node.
         */ this.input = this._shaper;
        /**
         * The output from the waveshaper node
         */ this.output = this._shaper;
        const options = _defaults.optionsFromArguments(WaveShaper.getDefaults(), arguments, [
            "mapping",
            "length"
        ]);
        if (_typeCheck.isArray(options.mapping) || options.mapping instanceof Float32Array) this.curve = Float32Array.from(options.mapping);
        else if (_typeCheck.isFunction(options.mapping)) this.setMap(options.mapping, options.length);
    }
    static getDefaults() {
        return Object.assign(_signal.Signal.getDefaults(), {
            length: 1024
        });
    }
    /**
     * Uses a mapping function to set the value of the curve.
     * @param mapping The function used to define the values.
     *                The mapping function take two arguments:
     *                the first is the value at the current position
     *                which goes from -1 to 1 over the number of elements
     *                in the curve array. The second argument is the array position.
     * @example
     * const shaper = new Tone.WaveShaper();
     * // map the input signal from [-1, 1] to [0, 10]
     * shaper.setMap((val, index) => (val + 1) * 5);
     */ setMap(mapping, length = 1024) {
        const array = new Float32Array(length);
        for(let i = 0, len = length; i < len; i++){
            const normalized = i / (len - 1) * 2 - 1;
            array[i] = mapping(normalized, i);
        }
        this.curve = array;
        return this;
    }
    /**
     * The array to set as the waveshaper curve. For linear curves
     * array length does not make much difference, but for complex curves
     * longer arrays will provide smoother interpolation.
     */ get curve() {
        return this._shaper.curve;
    }
    set curve(mapping) {
        this._shaper.curve = mapping;
    }
    /**
     * Specifies what type of oversampling (if any) should be used when
     * applying the shaping curve. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        const isOverSampleType = [
            "none",
            "2x",
            "4x"
        ].some((str)=>str.includes(oversampling)
        );
        _debug.assert(isOverSampleType, "oversampling must be either 'none', '2x', or '4x'");
        this._shaper.oversample = oversampling;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._shaper.disconnect();
        return this;
    }
}

},{"../core/util/Defaults":"kSyYt","../core/util/TypeCheck":"lCqGC","../core/util/Debug":"bsxl9","./Signal":"kfryg","./SignalOperator":"bqDTZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bN8EY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Multiply two incoming signals. Or, if a number is given in the constructor,
 * multiplies the incoming signal by that value.
 *
 * @example
 * // multiply two signals
 * const mult = new Tone.Multiply();
 * const sigA = new Tone.Signal(3);
 * const sigB = new Tone.Signal(4);
 * sigA.connect(mult);
 * sigB.connect(mult.factor);
 * // output of mult is 12.
 * @example
 * // multiply a signal and a number
 * const mult = new Tone.Multiply(10);
 * const sig = new Tone.Signal(2).connect(mult);
 * // the output of mult is 20.
 * @category Signal
 */ parcelHelpers.export(exports, "Multiply", ()=>Multiply
);
var _gain = require("../core/context/Gain");
var _defaults = require("../core/util/Defaults");
var _signal = require("./Signal");
class Multiply extends _signal.Signal {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Multiply.getDefaults(), arguments, [
            "value"
        ])));
        this.name = "Multiply";
        /**
         * Indicates if the value should be overridden on connection
         */ this.override = false;
        const options = _defaults.optionsFromArguments(Multiply.getDefaults(), arguments, [
            "value"
        ]);
        this._mult = this.input = this.output = new _gain.Gain({
            context: this.context,
            minValue: options.minValue,
            maxValue: options.maxValue
        });
        this.factor = this._param = this._mult.gain;
        this.factor.setValueAtTime(options.value, 0);
    }
    static getDefaults() {
        return Object.assign(_signal.Signal.getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._mult.dispose();
        return this;
    }
}

},{"../core/context/Gain":"7kpMn","../core/util/Defaults":"kSyYt","./Signal":"kfryg","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9a3wa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FMOscillator implements a frequency modulation synthesis
 * ```
 *                                              +-------------+
 * +---------------+        +-------------+     | Carrier Osc |
 * | Modulator Osc +>-------> GainNode    |     |             +--->Output
 * +---------------+        |             +>----> frequency   |
 *                       +--> gain        |     +-------------+
 *                       |  +-------------+
 * +-----------------+   |
 * | modulationIndex +>--+
 * +-----------------+
 * ```
 *
 * @example
 * return Tone.Offline(() => {
 * 	const fmOsc = new Tone.FMOscillator({
 * 		frequency: 200,
 * 		type: "square",
 * 		modulationType: "triangle",
 * 		harmonicity: 0.2,
 * 		modulationIndex: 3
 * 	}).toDestination().start();
 * }, 0.1, 1);
 * @category Source
 */ parcelHelpers.export(exports, "FMOscillator", ()=>FMOscillator
);
var _tslib = require("tslib");
var _gain = require("../../core/context/Gain");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _multiply = require("../../signal/Multiply");
var _signal = require("../../signal/Signal");
var _source = require("../Source");
var _oscillator = require("./Oscillator");
var _oscillatorInterface = require("./OscillatorInterface");
class FMOscillator extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(FMOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]));
        this.name = "FMOscillator";
        /**
         * the node where the modulation happens
         */ this._modulationNode = new _gain.Gain({
            context: this.context,
            gain: 0
        });
        const options = _defaults.optionsFromArguments(FMOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "modulationType"
        ]);
        this._carrier = new _oscillator.Oscillator({
            context: this.context,
            detune: options.detune,
            frequency: 0,
            onstop: ()=>this.onstop(this)
            ,
            phase: options.phase,
            type: options.type
        });
        this.detune = this._carrier.detune;
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this._modulator = new _oscillator.Oscillator({
            context: this.context,
            phase: options.phase,
            type: options.modulationType
        });
        this.harmonicity = new _multiply.Multiply({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        this.modulationIndex = new _multiply.Multiply({
            context: this.context,
            units: "positive",
            value: options.modulationIndex
        });
        // connections
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.frequency.chain(this.modulationIndex, this._modulationNode);
        this._modulator.connect(this._modulationNode.gain);
        this._modulationNode.connect(this._carrier.frequency);
        this._carrier.connect(this.output);
        this.detune.connect(this._modulator.detune);
        _interface.readOnly(this, [
            "modulationIndex",
            "frequency",
            "detune",
            "harmonicity"
        ]);
    }
    static getDefaults() {
        return Object.assign(_oscillator.Oscillator.getDefaults(), {
            harmonicity: 1,
            modulationIndex: 2,
            modulationType: "square"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._modulator.start(time);
        this._carrier.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        this._modulator.stop(time);
        this._carrier.stop(time);
    }
    _restart(time) {
        this._modulator.restart(time);
        this._carrier.restart(time);
        return this;
    }
    get type() {
        return this._carrier.type;
    }
    set type(type) {
        this._carrier.type = type;
    }
    get baseType() {
        return this._carrier.baseType;
    }
    set baseType(baseType) {
        this._carrier.baseType = baseType;
    }
    get partialCount() {
        return this._carrier.partialCount;
    }
    set partialCount(partialCount) {
        this._carrier.partialCount = partialCount;
    }
    /**
     * The type of the modulator oscillator
     */ get modulationType() {
        return this._modulator.type;
    }
    set modulationType(type) {
        this._modulator.type = type;
    }
    get phase() {
        return this._carrier.phase;
    }
    set phase(phase) {
        this._carrier.phase = phase;
        this._modulator.phase = phase;
    }
    get partials() {
        return this._carrier.partials;
    }
    set partials(partials) {
        this._carrier.partials = partials;
    }
    asArray(length = 1024) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            return _oscillatorInterface.generateWaveform(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.harmonicity.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this._modulationNode.dispose();
        this.modulationIndex.dispose();
        return this;
    }
}

},{"tslib":"bjkXk","../../core/context/Gain":"7kpMn","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../signal/Multiply":"bN8EY","../../signal/Signal":"kfryg","../Source":"31KwW","./Oscillator":"715Gq","./OscillatorInterface":"fWLBY","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aYxy9":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PulseOscillator is an oscillator with control over pulse width,
 * also known as the duty cycle. At 50% duty cycle (width = 0) the wave is
 * a square wave.
 * [Read more](https://wigglewave.wordpress.com/2014/08/16/pulse-waveforms-and-harmonics/).
 * ```
 *    width = -0.25        width = 0.0          width = 0.25
 *
 *   +-----+            +-------+       +    +-------+     +-+
 *   |     |            |       |       |            |     |
 *   |     |            |       |       |            |     |
 * +-+     +-------+    +       +-------+            +-----+
 *
 *
 *    width = -0.5                              width = 0.5
 *
 *     +---+                                 +-------+   +---+
 *     |   |                                         |   |
 *     |   |                                         |   |
 * +---+   +-------+                                 +---+
 *
 *
 *    width = -0.75                             width = 0.75
 *
 *       +-+                                 +-------+ +-----+
 *       | |                                         | |
 *       | |                                         | |
 * +-----+ +-------+                                 +-+
 * ```
 * @example
 * return Tone.Offline(() => {
 * 	const pulse = new Tone.PulseOscillator(50, 0.4).toDestination().start();
 * }, 0.1, 1);
 * @category Source
 */ parcelHelpers.export(exports, "PulseOscillator", ()=>PulseOscillator
);
var _tslib = require("tslib");
var _gain = require("../../core/context/Gain");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _signal = require("../../signal/Signal");
var _waveShaper = require("../../signal/WaveShaper");
var _source = require("../Source");
var _oscillator = require("./Oscillator");
var _oscillatorInterface = require("./OscillatorInterface");
class PulseOscillator extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(PulseOscillator.getDefaults(), arguments, [
            "frequency",
            "width"
        ]));
        this.name = "PulseOscillator";
        /**
         * gate the width amount
         */ this._widthGate = new _gain.Gain({
            context: this.context,
            gain: 0
        });
        /**
         * Threshold the signal to turn it into a square
         */ this._thresh = new _waveShaper.WaveShaper({
            context: this.context,
            mapping: (val)=>val <= 0 ? -1 : 1
        });
        const options = _defaults.optionsFromArguments(PulseOscillator.getDefaults(), arguments, [
            "frequency",
            "width"
        ]);
        this.width = new _signal.Signal({
            context: this.context,
            units: "audioRange",
            value: options.width
        });
        this._triangle = new _oscillator.Oscillator({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this)
            ,
            phase: options.phase,
            type: "triangle"
        });
        this.frequency = this._triangle.frequency;
        this.detune = this._triangle.detune;
        // connections
        this._triangle.chain(this._thresh, this.output);
        this.width.chain(this._widthGate, this._thresh);
        _interface.readOnly(this, [
            "width",
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign(_source.Source.getDefaults(), {
            detune: 0,
            frequency: 440,
            phase: 0,
            type: "pulse",
            width: 0.2
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._triangle.start(time);
        this._widthGate.gain.setValueAtTime(1, time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._triangle.stop(time);
        // the width is still connected to the output.
        // that needs to be stopped also
        this._widthGate.gain.cancelScheduledValues(time);
        this._widthGate.gain.setValueAtTime(0, time);
    }
    _restart(time) {
        this._triangle.restart(time);
        this._widthGate.gain.cancelScheduledValues(time);
        this._widthGate.gain.setValueAtTime(1, time);
    }
    /**
     * The phase of the oscillator in degrees.
     */ get phase() {
        return this._triangle.phase;
    }
    set phase(phase) {
        this._triangle.phase = phase;
    }
    /**
     * The type of the oscillator. Always returns "pulse".
     */ get type() {
        return "pulse";
    }
    /**
     * The baseType of the oscillator. Always returns "pulse".
     */ get baseType() {
        return "pulse";
    }
    /**
     * The partials of the waveform. Cannot set partials for this waveform type
     */ get partials() {
        return [];
    }
    /**
     * No partials for this waveform type.
     */ get partialCount() {
        return 0;
    }
    /**
     * *Internal use* The carrier oscillator type is fed through the
     * waveshaper node to create the pulse. Using different carrier oscillators
     * changes oscillator's behavior.
     */ set carrierType(type) {
        this._triangle.type = type;
    }
    asArray(length = 1024) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            return _oscillatorInterface.generateWaveform(this, length);
        });
    }
    /**
     * Clean up method.
     */ dispose() {
        super.dispose();
        this._triangle.dispose();
        this.width.dispose();
        this._widthGate.dispose();
        this._thresh.dispose();
        return this;
    }
}

},{"tslib":"bjkXk","../../core/context/Gain":"7kpMn","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../signal/Signal":"kfryg","../../signal/WaveShaper":"4cjPf","../Source":"31KwW","./Oscillator":"715Gq","./OscillatorInterface":"fWLBY","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fcPql":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FatOscillator is an array of oscillators with detune spread between the oscillators
 * @example
 * const fatOsc = new Tone.FatOscillator("Ab3", "sawtooth", 40).toDestination().start();
 * @category Source
 */ parcelHelpers.export(exports, "FatOscillator", ()=>FatOscillator
);
var _tslib = require("tslib");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _signal = require("../../signal/Signal");
var _source = require("../Source");
var _oscillator = require("./Oscillator");
var _oscillatorInterface = require("./OscillatorInterface");
var _debug = require("../../core/util/Debug");
class FatOscillator extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(FatOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "spread"
        ]));
        this.name = "FatOscillator";
        /**
         * The array of oscillators
         */ this._oscillators = [];
        const options = _defaults.optionsFromArguments(FatOscillator.getDefaults(), arguments, [
            "frequency",
            "type",
            "spread"
        ]);
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new _signal.Signal({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this._spread = options.spread;
        this._type = options.type;
        this._phase = options.phase;
        this._partials = options.partials;
        this._partialCount = options.partialCount;
        // set the count initially
        this.count = options.count;
        _interface.readOnly(this, [
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign(_oscillator.Oscillator.getDefaults(), {
            count: 3,
            spread: 20,
            type: "sawtooth"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._forEach((osc)=>osc.start(time)
        );
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._forEach((osc)=>osc.stop(time)
        );
    }
    _restart(time) {
        this._forEach((osc)=>osc.restart(time)
        );
    }
    /**
     * Iterate over all of the oscillators
     */ _forEach(iterator) {
        for(let i = 0; i < this._oscillators.length; i++)iterator(this._oscillators[i], i);
    }
    /**
     * The type of the oscillator
     */ get type() {
        return this._type;
    }
    set type(type) {
        this._type = type;
        this._forEach((osc)=>osc.type = type
        );
    }
    /**
     * The detune spread between the oscillators. If "count" is
     * set to 3 oscillators and the "spread" is set to 40,
     * the three oscillators would be detuned like this: [-20, 0, 20]
     * for a total detune spread of 40 cents.
     * @example
     * const fatOsc = new Tone.FatOscillator().toDestination().start();
     * fatOsc.spread = 70;
     */ get spread() {
        return this._spread;
    }
    set spread(spread) {
        this._spread = spread;
        if (this._oscillators.length > 1) {
            const start = -spread / 2;
            const step = spread / (this._oscillators.length - 1);
            this._forEach((osc, i)=>osc.detune.value = start + step * i
            );
        }
    }
    /**
     * The number of detuned oscillators. Must be an integer greater than 1.
     * @example
     * const fatOsc = new Tone.FatOscillator("C#3", "sawtooth").toDestination().start();
     * // use 4 sawtooth oscillators
     * fatOsc.count = 4;
     */ get count() {
        return this._oscillators.length;
    }
    set count(count) {
        _debug.assertRange(count, 1);
        if (this._oscillators.length !== count) {
            // dispose the previous oscillators
            this._forEach((osc)=>osc.dispose()
            );
            this._oscillators = [];
            for(let i = 0; i < count; i++){
                const osc = new _oscillator.Oscillator({
                    context: this.context,
                    volume: -6 - count * 1.1,
                    type: this._type,
                    phase: this._phase + i / count * 360,
                    partialCount: this._partialCount,
                    onstop: i === 0 ? ()=>this.onstop(this)
                     : _interface.noOp
                });
                if (this.type === "custom") osc.partials = this._partials;
                this.frequency.connect(osc.frequency);
                this.detune.connect(osc.detune);
                osc.detune.overridden = false;
                osc.connect(this.output);
                this._oscillators[i] = osc;
            }
            // set the spread
            this.spread = this._spread;
            if (this.state === "started") this._forEach((osc)=>osc.start()
            );
        }
    }
    get phase() {
        return this._phase;
    }
    set phase(phase) {
        this._phase = phase;
        this._forEach((osc, i)=>osc.phase = this._phase + i / this.count * 360
        );
    }
    get baseType() {
        return this._oscillators[0].baseType;
    }
    set baseType(baseType) {
        this._forEach((osc)=>osc.baseType = baseType
        );
        this._type = this._oscillators[0].type;
    }
    get partials() {
        return this._oscillators[0].partials;
    }
    set partials(partials) {
        this._partials = partials;
        this._partialCount = this._partials.length;
        if (partials.length) {
            this._type = "custom";
            this._forEach((osc)=>osc.partials = partials
            );
        }
    }
    get partialCount() {
        return this._oscillators[0].partialCount;
    }
    set partialCount(partialCount) {
        this._partialCount = partialCount;
        this._forEach((osc)=>osc.partialCount = partialCount
        );
        this._type = this._oscillators[0].type;
    }
    asArray(length = 1024) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            return _oscillatorInterface.generateWaveform(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this._forEach((osc)=>osc.dispose()
        );
        return this;
    }
}

},{"tslib":"bjkXk","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../signal/Signal":"kfryg","../Source":"31KwW","./Oscillator":"715Gq","./OscillatorInterface":"fWLBY","../../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"frnTW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PWMOscillator modulates the width of a Tone.PulseOscillator
 * at the modulationFrequency. This has the effect of continuously
 * changing the timbre of the oscillator by altering the harmonics
 * generated.
 * @example
 * return Tone.Offline(() => {
 * 	const pwm = new Tone.PWMOscillator(60, 0.3).toDestination().start();
 * }, 0.1, 1);
 * @category Source
 */ parcelHelpers.export(exports, "PWMOscillator", ()=>PWMOscillator
);
var _tslib = require("tslib");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _multiply = require("../../signal/Multiply");
var _source = require("../Source");
var _oscillator = require("./Oscillator");
var _oscillatorInterface = require("./OscillatorInterface");
var _pulseOscillator = require("./PulseOscillator");
class PWMOscillator extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(PWMOscillator.getDefaults(), arguments, [
            "frequency",
            "modulationFrequency"
        ]));
        this.name = "PWMOscillator";
        this.sourceType = "pwm";
        /**
         * Scale the oscillator so it doesn't go silent
         * at the extreme values.
         */ this._scale = new _multiply.Multiply({
            context: this.context,
            value: 2
        });
        const options = _defaults.optionsFromArguments(PWMOscillator.getDefaults(), arguments, [
            "frequency",
            "modulationFrequency"
        ]);
        this._pulse = new _pulseOscillator.PulseOscillator({
            context: this.context,
            frequency: options.modulationFrequency
        });
        // change the pulse oscillator type
        this._pulse.carrierType = "sine";
        this.modulationFrequency = this._pulse.frequency;
        this._modulator = new _oscillator.Oscillator({
            context: this.context,
            detune: options.detune,
            frequency: options.frequency,
            onstop: ()=>this.onstop(this)
            ,
            phase: options.phase
        });
        this.frequency = this._modulator.frequency;
        this.detune = this._modulator.detune;
        // connections
        this._modulator.chain(this._scale, this._pulse.width);
        this._pulse.connect(this.output);
        _interface.readOnly(this, [
            "modulationFrequency",
            "frequency",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign(_source.Source.getDefaults(), {
            detune: 0,
            frequency: 440,
            modulationFrequency: 0.4,
            phase: 0,
            type: "pwm"
        });
    }
    /**
     * start the oscillator
     */ _start(time) {
        time = this.toSeconds(time);
        this._modulator.start(time);
        this._pulse.start(time);
    }
    /**
     * stop the oscillator
     */ _stop(time) {
        time = this.toSeconds(time);
        this._modulator.stop(time);
        this._pulse.stop(time);
    }
    /**
     * restart the oscillator
     */ _restart(time) {
        this._modulator.restart(time);
        this._pulse.restart(time);
    }
    /**
     * The type of the oscillator. Always returns "pwm".
     */ get type() {
        return "pwm";
    }
    /**
     * The baseType of the oscillator. Always returns "pwm".
     */ get baseType() {
        return "pwm";
    }
    /**
     * The partials of the waveform. Cannot set partials for this waveform type
     */ get partials() {
        return [];
    }
    /**
     * No partials for this waveform type.
     */ get partialCount() {
        return 0;
    }
    /**
     * The phase of the oscillator in degrees.
     */ get phase() {
        return this._modulator.phase;
    }
    set phase(phase) {
        this._modulator.phase = phase;
    }
    asArray(length = 1024) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            return _oscillatorInterface.generateWaveform(this, length);
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._pulse.dispose();
        this._scale.dispose();
        this._modulator.dispose();
        return this;
    }
}

},{"tslib":"bjkXk","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../signal/Multiply":"bN8EY","../Source":"31KwW","./Oscillator":"715Gq","./OscillatorInterface":"fWLBY","./PulseOscillator":"aYxy9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fKqBe":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * OmniOscillator aggregates all of the oscillator types into one.
 * @example
 * return Tone.Offline(() => {
 * 	const omniOsc = new Tone.OmniOscillator("C#4", "pwm").toDestination().start();
 * }, 0.1, 1);
 * @category Source
 */ parcelHelpers.export(exports, "OmniOscillator", ()=>OmniOscillator
);
var _tslib = require("tslib");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _typeCheck = require("../../core/util/TypeCheck");
var _signal = require("../../signal/Signal");
var _source = require("../Source");
var _amoscillator = require("./AMOscillator");
var _fatOscillator = require("./FatOscillator");
var _fmoscillator = require("./FMOscillator");
var _oscillator = require("./Oscillator");
var _oscillatorInterface = require("./OscillatorInterface");
var _pulseOscillator = require("./PulseOscillator");
var _pwmoscillator = require("./PWMOscillator");
const OmniOscillatorSourceMap = {
    am: _amoscillator.AMOscillator,
    fat: _fatOscillator.FatOscillator,
    fm: _fmoscillator.FMOscillator,
    oscillator: _oscillator.Oscillator,
    pulse: _pulseOscillator.PulseOscillator,
    pwm: _pwmoscillator.PWMOscillator
};
class OmniOscillator extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(OmniOscillator.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "OmniOscillator";
        const options = _defaults.optionsFromArguments(OmniOscillator.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new _signal.Signal({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        _interface.readOnly(this, [
            "frequency",
            "detune"
        ]);
        // set the options
        this.set(options);
    }
    static getDefaults() {
        return Object.assign(_oscillator.Oscillator.getDefaults(), _fmoscillator.FMOscillator.getDefaults(), _amoscillator.AMOscillator.getDefaults(), _fatOscillator.FatOscillator.getDefaults(), _pulseOscillator.PulseOscillator.getDefaults(), _pwmoscillator.PWMOscillator.getDefaults());
    }
    /**
     * start the oscillator
     */ _start(time) {
        this._oscillator.start(time);
    }
    /**
     * start the oscillator
     */ _stop(time) {
        this._oscillator.stop(time);
    }
    _restart(time) {
        this._oscillator.restart(time);
        return this;
    }
    /**
     * The type of the oscillator. Can be any of the basic types: sine, square, triangle, sawtooth. Or
     * prefix the basic types with "fm", "am", or "fat" to use the FMOscillator, AMOscillator or FatOscillator
     * types. The oscillator could also be set to "pwm" or "pulse". All of the parameters of the
     * oscillator's class are accessible when the oscillator is set to that type, but throws an error
     * when it's not.
     * @example
     * const omniOsc = new Tone.OmniOscillator().toDestination().start();
     * omniOsc.type = "pwm";
     * // modulationFrequency is parameter which is available
     * // only when the type is "pwm".
     * omniOsc.modulationFrequency.value = 0.5;
     */ get type() {
        let prefix = "";
        if ([
            "am",
            "fm",
            "fat"
        ].some((p)=>this._sourceType === p
        )) prefix = this._sourceType;
        return prefix + this._oscillator.type;
    }
    set type(type) {
        if (type.substr(0, 2) === "fm") {
            this._createNewOscillator("fm");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(2);
        } else if (type.substr(0, 2) === "am") {
            this._createNewOscillator("am");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(2);
        } else if (type.substr(0, 3) === "fat") {
            this._createNewOscillator("fat");
            this._oscillator = this._oscillator;
            this._oscillator.type = type.substr(3);
        } else if (type === "pwm") {
            this._createNewOscillator("pwm");
            this._oscillator = this._oscillator;
        } else if (type === "pulse") this._createNewOscillator("pulse");
        else {
            this._createNewOscillator("oscillator");
            this._oscillator = this._oscillator;
            this._oscillator.type = type;
        }
    }
    /**
     * The value is an empty array when the type is not "custom".
     * This is not available on "pwm" and "pulse" oscillator types.
     * See [[Oscillator.partials]]
     */ get partials() {
        return this._oscillator.partials;
    }
    set partials(partials) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm")) this._oscillator.partials = partials;
    }
    get partialCount() {
        return this._oscillator.partialCount;
    }
    set partialCount(partialCount) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm")) this._oscillator.partialCount = partialCount;
    }
    set(props) {
        // make sure the type is set first
        if (Reflect.has(props, "type") && props.type) this.type = props.type;
        // then set the rest
        super.set(props);
        return this;
    }
    /**
     * connect the oscillator to the frequency and detune signals
     */ _createNewOscillator(oscType) {
        if (oscType !== this._sourceType) {
            this._sourceType = oscType;
            const OscConstructor = OmniOscillatorSourceMap[oscType];
            // short delay to avoid clicks on the change
            const now = this.now();
            if (this._oscillator) {
                const oldOsc = this._oscillator;
                oldOsc.stop(now);
                // dispose the old one
                this.context.setTimeout(()=>oldOsc.dispose()
                , this.blockTime);
            }
            this._oscillator = new OscConstructor({
                context: this.context
            });
            this.frequency.connect(this._oscillator.frequency);
            this.detune.connect(this._oscillator.detune);
            this._oscillator.connect(this.output);
            this._oscillator.onstop = ()=>this.onstop(this)
            ;
            if (this.state === "started") this._oscillator.start(now);
        }
    }
    get phase() {
        return this._oscillator.phase;
    }
    set phase(phase) {
        this._oscillator.phase = phase;
    }
    /**
     * The source type of the oscillator.
     * @example
     * const omniOsc = new Tone.OmniOscillator(440, "fmsquare");
     * console.log(omniOsc.sourceType); // 'fm'
     */ get sourceType() {
        return this._sourceType;
    }
    set sourceType(sType) {
        // the basetype defaults to sine
        let baseType = "sine";
        if (this._oscillator.type !== "pwm" && this._oscillator.type !== "pulse") baseType = this._oscillator.type;
        // set the type
        if (sType === "fm") this.type = "fm" + baseType;
        else if (sType === "am") this.type = "am" + baseType;
        else if (sType === "fat") this.type = "fat" + baseType;
        else if (sType === "oscillator") this.type = baseType;
        else if (sType === "pulse") this.type = "pulse";
        else if (sType === "pwm") this.type = "pwm";
    }
    _getOscType(osc, sourceType) {
        return osc instanceof OmniOscillatorSourceMap[sourceType];
    }
    /**
     * The base type of the oscillator. See [[Oscillator.baseType]]
     * @example
     * const omniOsc = new Tone.OmniOscillator(440, "fmsquare4");
     * console.log(omniOsc.sourceType, omniOsc.baseType, omniOsc.partialCount);
     */ get baseType() {
        return this._oscillator.baseType;
    }
    set baseType(baseType) {
        if (!this._getOscType(this._oscillator, "pulse") && !this._getOscType(this._oscillator, "pwm") && baseType !== "pulse" && baseType !== "pwm") this._oscillator.baseType = baseType;
    }
    /**
     * The width of the oscillator when sourceType === "pulse".
     * See [[PWMOscillator.width]]
     */ get width() {
        if (this._getOscType(this._oscillator, "pulse")) return this._oscillator.width;
        else return undefined;
    }
    /**
     * The number of detuned oscillators when sourceType === "fat".
     * See [[FatOscillator.count]]
     */ get count() {
        if (this._getOscType(this._oscillator, "fat")) return this._oscillator.count;
        else return undefined;
    }
    set count(count) {
        if (this._getOscType(this._oscillator, "fat") && _typeCheck.isNumber(count)) this._oscillator.count = count;
    }
    /**
     * The detune spread between the oscillators when sourceType === "fat".
     * See [[FatOscillator.count]]
     */ get spread() {
        if (this._getOscType(this._oscillator, "fat")) return this._oscillator.spread;
        else return undefined;
    }
    set spread(spread) {
        if (this._getOscType(this._oscillator, "fat") && _typeCheck.isNumber(spread)) this._oscillator.spread = spread;
    }
    /**
     * The type of the modulator oscillator. Only if the oscillator is set to "am" or "fm" types.
     * See [[AMOscillator]] or [[FMOscillator]]
     */ get modulationType() {
        if (this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) return this._oscillator.modulationType;
        else return undefined;
    }
    set modulationType(mType) {
        if ((this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) && _typeCheck.isString(mType)) this._oscillator.modulationType = mType;
    }
    /**
     * The modulation index when the sourceType === "fm"
     * See [[FMOscillator]].
     */ get modulationIndex() {
        if (this._getOscType(this._oscillator, "fm")) return this._oscillator.modulationIndex;
        else return undefined;
    }
    /**
     * Harmonicity is the frequency ratio between the carrier and the modulator oscillators.
     * See [[AMOscillator]] or [[FMOscillator]]
     */ get harmonicity() {
        if (this._getOscType(this._oscillator, "fm") || this._getOscType(this._oscillator, "am")) return this._oscillator.harmonicity;
        else return undefined;
    }
    /**
     * The modulationFrequency Signal of the oscillator when sourceType === "pwm"
     * see [[PWMOscillator]]
     * @min 0.1
     * @max 5
     */ get modulationFrequency() {
        if (this._getOscType(this._oscillator, "pwm")) return this._oscillator.modulationFrequency;
        else return undefined;
    }
    asArray(length = 1024) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            return _oscillatorInterface.generateWaveform(this, length);
        });
    }
    dispose() {
        super.dispose();
        this.detune.dispose();
        this.frequency.dispose();
        this._oscillator.dispose();
        return this;
    }
}

},{"tslib":"bjkXk","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../core/util/TypeCheck":"lCqGC","../../signal/Signal":"kfryg","../Source":"31KwW","./AMOscillator":"dECQc","./FatOscillator":"fcPql","./FMOscillator":"9a3wa","./Oscillator":"715Gq","./OscillatorInterface":"fWLBY","./PulseOscillator":"aYxy9","./PWMOscillator":"frnTW","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d8Ivp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * LFO stands for low frequency oscillator. LFO produces an output signal
 * which can be attached to an AudioParam or Tone.Signal
 * in order to modulate that parameter with an oscillator. The LFO can
 * also be synced to the transport to start/stop and change when the tempo changes.
 * @example
 * return Tone.Offline(() => {
 * 	const lfo = new Tone.LFO("4n", 400, 4000).start().toDestination();
 * }, 0.5, 1);
 * @category Source
 */ parcelHelpers.export(exports, "LFO", ()=>LFO
);
var _gain = require("../../core/context/Gain");
var _param = require("../../core/context/Param");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _audioToGain = require("../../signal/AudioToGain");
var _scale = require("../../signal/Scale");
var _signal = require("../../signal/Signal");
var _zero = require("../../signal/Zero");
var _oscillator = require("./Oscillator");
class LFO extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(LFO.getDefaults(), arguments, [
            "frequency",
            "min",
            "max"
        ]));
        this.name = "LFO";
        /**
         * The value that the LFO outputs when it's stopped
         */ this._stoppedValue = 0;
        /**
         * A private placeholder for the units
         */ this._units = "number";
        /**
         * If the input value is converted using the [[units]]
         */ this.convert = true;
        /**
         * Private methods borrowed from Param
         */ // @ts-ignore
        this._fromType = _param.Param.prototype._fromType;
        // @ts-ignore
        this._toType = _param.Param.prototype._toType;
        // @ts-ignore
        this._is = _param.Param.prototype._is;
        // @ts-ignore
        this._clampValue = _param.Param.prototype._clampValue;
        const options = _defaults.optionsFromArguments(LFO.getDefaults(), arguments, [
            "frequency",
            "min",
            "max"
        ]);
        this._oscillator = new _oscillator.Oscillator(options);
        this.frequency = this._oscillator.frequency;
        this._amplitudeGain = new _gain.Gain({
            context: this.context,
            gain: options.amplitude,
            units: "normalRange"
        });
        this.amplitude = this._amplitudeGain.gain;
        this._stoppedSignal = new _signal.Signal({
            context: this.context,
            units: "audioRange",
            value: 0
        });
        this._zeros = new _zero.Zero({
            context: this.context
        });
        this._a2g = new _audioToGain.AudioToGain({
            context: this.context
        });
        this._scaler = this.output = new _scale.Scale({
            context: this.context,
            max: options.max,
            min: options.min
        });
        this.units = options.units;
        this.min = options.min;
        this.max = options.max;
        // connect it up
        this._oscillator.chain(this._amplitudeGain, this._a2g, this._scaler);
        this._zeros.connect(this._a2g);
        this._stoppedSignal.connect(this._a2g);
        _interface.readOnly(this, [
            "amplitude",
            "frequency"
        ]);
        this.phase = options.phase;
    }
    static getDefaults() {
        return Object.assign(_oscillator.Oscillator.getDefaults(), {
            amplitude: 1,
            frequency: "4n",
            max: 1,
            min: 0,
            type: "sine",
            units: "number"
        });
    }
    /**
     * Start the LFO.
     * @param time The time the LFO will start
     */ start(time) {
        time = this.toSeconds(time);
        this._stoppedSignal.setValueAtTime(0, time);
        this._oscillator.start(time);
        return this;
    }
    /**
     * Stop the LFO.
     * @param  time The time the LFO will stop
     */ stop(time) {
        time = this.toSeconds(time);
        this._stoppedSignal.setValueAtTime(this._stoppedValue, time);
        this._oscillator.stop(time);
        return this;
    }
    /**
     * Sync the start/stop/pause to the transport
     * and the frequency to the bpm of the transport
     * @example
     * const lfo = new Tone.LFO("8n");
     * lfo.sync().start(0);
     * // the rate of the LFO will always be an eighth note, even as the tempo changes
     */ sync() {
        this._oscillator.sync();
        this._oscillator.syncFrequency();
        return this;
    }
    /**
     * unsync the LFO from transport control
     */ unsync() {
        this._oscillator.unsync();
        this._oscillator.unsyncFrequency();
        return this;
    }
    /**
     * After the oscillator waveform is updated, reset the `_stoppedSignal` value to match the updated waveform
     */ _setStoppedValue() {
        this._stoppedValue = this._oscillator.getInitialValue();
        this._stoppedSignal.value = this._stoppedValue;
    }
    /**
     * The minimum output of the LFO.
     */ get min() {
        return this._toType(this._scaler.min);
    }
    set min(min) {
        min = this._fromType(min);
        this._scaler.min = min;
    }
    /**
     * The maximum output of the LFO.
     */ get max() {
        return this._toType(this._scaler.max);
    }
    set max(max) {
        max = this._fromType(max);
        this._scaler.max = max;
    }
    /**
     * The type of the oscillator: See [[Oscillator.type]]
     */ get type() {
        return this._oscillator.type;
    }
    set type(type) {
        this._oscillator.type = type;
        this._setStoppedValue();
    }
    /**
     * The oscillator's partials array: See [[Oscillator.partials]]
     */ get partials() {
        return this._oscillator.partials;
    }
    set partials(partials) {
        this._oscillator.partials = partials;
        this._setStoppedValue();
    }
    /**
     * The phase of the LFO.
     */ get phase() {
        return this._oscillator.phase;
    }
    set phase(phase) {
        this._oscillator.phase = phase;
        this._setStoppedValue();
    }
    /**
     * The output units of the LFO.
     */ get units() {
        return this._units;
    }
    set units(val) {
        const currentMin = this.min;
        const currentMax = this.max;
        // convert the min and the max
        this._units = val;
        this.min = currentMin;
        this.max = currentMax;
    }
    /**
     * Returns the playback state of the source, either "started" or "stopped".
     */ get state() {
        return this._oscillator.state;
    }
    /**
     * @param node the destination to connect to
     * @param outputNum the optional output number
     * @param inputNum the input number
     */ connect(node, outputNum, inputNum) {
        if (node instanceof _param.Param || node instanceof _signal.Signal) {
            this.convert = node.convert;
            this.units = node.units;
        }
        _signal.connectSignal(this, node, outputNum, inputNum);
        return this;
    }
    dispose() {
        super.dispose();
        this._oscillator.dispose();
        this._stoppedSignal.dispose();
        this._zeros.dispose();
        this._scaler.dispose();
        this._a2g.dispose();
        this._amplitudeGain.dispose();
        this.amplitude.dispose();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/Param":"2qxaM","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../signal/AudioToGain":"bwjzf","../../signal/Scale":"j7ETW","../../signal/Signal":"kfryg","../../signal/Zero":"hNiO3","./Oscillator":"715Gq","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j7ETW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Performs a linear scaling on an input signal.
 * Scales a NormalRange input to between
 * outputMin and outputMax.
 *
 * @example
 * const scale = new Tone.Scale(50, 100);
 * const signal = new Tone.Signal(0.5).connect(scale);
 * // the output of scale equals 75
 * @category Signal
 */ parcelHelpers.export(exports, "Scale", ()=>Scale
);
var _defaults = require("../core/util/Defaults");
var _add = require("./Add");
var _multiply = require("./Multiply");
var _signalOperator = require("./SignalOperator");
class Scale extends _signalOperator.SignalOperator {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Scale.getDefaults(), arguments, [
            "min",
            "max"
        ])));
        this.name = "Scale";
        const options = _defaults.optionsFromArguments(Scale.getDefaults(), arguments, [
            "min",
            "max"
        ]);
        this._mult = this.input = new _multiply.Multiply({
            context: this.context,
            value: options.max - options.min
        });
        this._add = this.output = new _add.Add({
            context: this.context,
            value: options.min
        });
        this._min = options.min;
        this._max = options.max;
        this.input.connect(this.output);
    }
    static getDefaults() {
        return Object.assign(_signalOperator.SignalOperator.getDefaults(), {
            max: 1,
            min: 0
        });
    }
    /**
     * The minimum output value. This number is output when the value input value is 0.
     */ get min() {
        return this._min;
    }
    set min(min) {
        this._min = min;
        this._setRange();
    }
    /**
     * The maximum output value. This number is output when the value input value is 1.
     */ get max() {
        return this._max;
    }
    set max(max) {
        this._max = max;
        this._setRange();
    }
    /**
     * set the values
     */ _setRange() {
        this._add.value = this._min;
        this._mult.value = this._max - this._min;
    }
    dispose() {
        super.dispose();
        this._add.dispose();
        this._mult.dispose();
        return this;
    }
}

},{"../core/util/Defaults":"kSyYt","./Add":"iRri4","./Multiply":"bN8EY","./SignalOperator":"bqDTZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iRri4":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Add a signal and a number or two signals. When no value is
 * passed into the constructor, Tone.Add will sum input and `addend`
 * If a value is passed into the constructor, the it will be added to the input.
 *
 * @example
 * return Tone.Offline(() => {
 * 	const add = new Tone.Add(2).toDestination();
 * 	add.addend.setValueAtTime(1, 0.2);
 * 	const signal = new Tone.Signal(2);
 * 	// add a signal and a scalar
 * 	signal.connect(add);
 * 	signal.setValueAtTime(1, 0.1);
 * }, 0.5, 1);
 * @category Signal
 */ parcelHelpers.export(exports, "Add", ()=>Add
);
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _gain = require("../core/context/Gain");
var _defaults = require("../core/util/Defaults");
var _signal = require("./Signal");
class Add extends _signal.Signal {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Add.getDefaults(), arguments, [
            "value"
        ])));
        this.override = false;
        this.name = "Add";
        /**
         * the summing node
         */ this._sum = new _gain.Gain({
            context: this.context
        });
        this.input = this._sum;
        this.output = this._sum;
        /**
         * The value which is added to the input signal
         */ this.addend = this._param;
        _toneAudioNode.connectSeries(this._constantSource, this._sum);
    }
    static getDefaults() {
        return Object.assign(_signal.Signal.getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._sum.dispose();
        return this;
    }
}

},{"../core/context/ToneAudioNode":"iT1SZ","../core/context/Gain":"7kpMn","../core/util/Defaults":"kSyYt","./Signal":"kfryg","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hNiO3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.Zero outputs 0's at audio-rate. The reason this has to be
 * it's own class is that many browsers optimize out Tone.Signal
 * with a value of 0 and will not process nodes further down the graph.
 * @category Signal
 */ parcelHelpers.export(exports, "Zero", ()=>Zero
);
var _gain = require("../core/context/Gain");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _defaults = require("../core/util/Defaults");
var _signalOperator = require("./SignalOperator");
class Zero extends _signalOperator.SignalOperator {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Zero.getDefaults(), arguments)));
        this.name = "Zero";
        /**
         * The gain node which connects the constant source to the output
         */ this._gain = new _gain.Gain({
            context: this.context
        });
        /**
         * Only outputs 0
         */ this.output = this._gain;
        /**
         * no input node
         */ this.input = undefined;
        _toneAudioNode.connect(this.context.getConstant(0), this._gain);
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        _toneAudioNode.disconnect(this.context.getConstant(0), this._gain);
        return this;
    }
}

},{"../core/context/Gain":"7kpMn","../core/context/ToneAudioNode":"iT1SZ","../core/util/Defaults":"kSyYt","./SignalOperator":"bqDTZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9Kbsu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Player is an audio file player with start, loop, and stop functions.
 * @example
 * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gong_1.mp3").toDestination();
 * // play as soon as the buffer is loaded
 * player.autostart = true;
 * @category Source
 */ parcelHelpers.export(exports, "Player", ()=>Player
);
var _tslib = require("tslib");
var _toneAudioBuffer = require("../../core/context/ToneAudioBuffer");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _typeCheck = require("../../core/util/TypeCheck");
var _source = require("../Source");
var _toneBufferSource = require("./ToneBufferSource");
var _debug = require("../../core/util/Debug");
var _decorator = require("../../core/util/Decorator");
class Player extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(Player.getDefaults(), arguments, [
            "url",
            "onload"
        ]));
        this.name = "Player";
        /**
         * All of the active buffer source nodes
         */ this._activeSources = new Set();
        const options = _defaults.optionsFromArguments(Player.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        this._buffer = new _toneAudioBuffer.ToneAudioBuffer({
            onload: this._onload.bind(this, options.onload),
            onerror: options.onerror,
            reverse: options.reverse,
            url: options.url
        });
        this.autostart = options.autostart;
        this._loop = options.loop;
        this._loopStart = options.loopStart;
        this._loopEnd = options.loopEnd;
        this._playbackRate = options.playbackRate;
        this.fadeIn = options.fadeIn;
        this.fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign(_source.Source.getDefaults(), {
            autostart: false,
            fadeIn: 0,
            fadeOut: 0,
            loop: false,
            loopEnd: 0,
            loopStart: 0,
            onload: _interface.noOp,
            onerror: _interface.noOp,
            playbackRate: 1,
            reverse: false
        });
    }
    /**
     * Load the audio file as an audio buffer.
     * Decodes the audio asynchronously and invokes
     * the callback once the audio buffer loads.
     * Note: this does not need to be called if a url
     * was passed in to the constructor. Only use this
     * if you want to manually load a new url.
     * @param url The url of the buffer to load. Filetype support depends on the browser.
     */ load(url) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            yield this._buffer.load(url);
            this._onload();
            return this;
        });
    }
    /**
     * Internal callback when the buffer is loaded.
     */ _onload(callback = _interface.noOp) {
        callback();
        if (this.autostart) this.start();
    }
    /**
     * Internal callback when the buffer is done playing.
     */ _onSourceEnd(source) {
        // invoke the onstop function
        this.onstop(this);
        // delete the source from the active sources
        this._activeSources.delete(source);
        if (this._activeSources.size === 0 && !this._synced && this._state.getValueAtTime(this.now()) === "started") {
            // remove the 'implicitEnd' event and replace with an explicit end
            this._state.cancel(this.now());
            this._state.setStateAtTime("stopped", this.now());
        }
    }
    /**
     * Play the buffer at the given startTime. Optionally add an offset
     * and/or duration which will play the buffer from a position
     * within the buffer for the given duration.
     *
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given, it will default to the full length of the sample (minus any offset)
     */ start(time, offset, duration) {
        super.start(time, offset, duration);
        return this;
    }
    /**
     * Internal start method
     */ _start(startTime, offset, duration) {
        // if it's a loop the default offset is the loopStart point
        if (this._loop) offset = _defaults.defaultArg(offset, this._loopStart);
        else // otherwise the default offset is 0
        offset = _defaults.defaultArg(offset, 0);
        // compute the values in seconds
        const computedOffset = this.toSeconds(offset);
        // compute the duration which is either the passed in duration of the buffer.duration - offset
        const origDuration = duration;
        duration = _defaults.defaultArg(duration, Math.max(this._buffer.duration - computedOffset, 0));
        let computedDuration = this.toSeconds(duration);
        // scale it by the playback rate
        computedDuration = computedDuration / this._playbackRate;
        // get the start time
        startTime = this.toSeconds(startTime);
        // make the source
        const source = new _toneBufferSource.ToneBufferSource({
            url: this._buffer,
            context: this.context,
            fadeIn: this.fadeIn,
            fadeOut: this.fadeOut,
            loop: this._loop,
            loopEnd: this._loopEnd,
            loopStart: this._loopStart,
            onended: this._onSourceEnd.bind(this),
            playbackRate: this._playbackRate
        }).connect(this.output);
        // set the looping properties
        if (!this._loop && !this._synced) {
            // cancel the previous stop
            this._state.cancel(startTime + computedDuration);
            // if it's not looping, set the state change at the end of the sample
            this._state.setStateAtTime("stopped", startTime + computedDuration, {
                implicitEnd: true
            });
        }
        // add it to the array of active sources
        this._activeSources.add(source);
        // start it
        if (this._loop && _typeCheck.isUndef(origDuration)) source.start(startTime, computedOffset);
        else // subtract the fade out time
        source.start(startTime, computedOffset, computedDuration - this.toSeconds(this.fadeOut));
    }
    /**
     * Stop playback.
     */ _stop(time) {
        const computedTime = this.toSeconds(time);
        this._activeSources.forEach((source)=>source.stop(computedTime)
        );
    }
    /**
     * Stop and then restart the player from the beginning (or offset)
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given,
     * 					it will default to the full length of the sample (minus any offset)
     */ restart(time, offset, duration) {
        super.restart(time, offset, duration);
        return this;
    }
    _restart(time, offset, duration) {
        this._stop(time);
        this._start(time, offset, duration);
    }
    /**
     * Seek to a specific time in the player's buffer. If the
     * source is no longer playing at that time, it will stop.
     * @param offset The time to seek to.
     * @param when The time for the seek event to occur.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/gurgling_theremin_1.mp3", () => {
     * 	player.start();
     * 	// seek to the offset in 1 second from now
     * 	player.seek(0.4, "+1");
     * }).toDestination();
     */ seek(offset, when) {
        const computedTime = this.toSeconds(when);
        if (this._state.getValueAtTime(computedTime) === "started") {
            const computedOffset = this.toSeconds(offset);
            // if it's currently playing, stop it
            this._stop(computedTime);
            // restart it at the given time
            this._start(computedTime, computedOffset);
        }
        return this;
    }
    /**
     * Set the loop start and end. Will only loop if loop is set to true.
     * @param loopStart The loop start time
     * @param loopEnd The loop end time
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/malevoices_aa2_F3.mp3").toDestination();
     * // loop between the given points
     * player.setLoopPoints(0.2, 0.3);
     * player.loop = true;
     * player.autostart = true;
     */ setLoopPoints(loopStart, loopEnd) {
        this.loopStart = loopStart;
        this.loopEnd = loopEnd;
        return this;
    }
    /**
     * If loop is true, the loop will start at this position.
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(loopStart) {
        this._loopStart = loopStart;
        if (this.buffer.loaded) _debug.assertRange(this.toSeconds(loopStart), 0, this.buffer.duration);
        // get the current source
        this._activeSources.forEach((source)=>{
            source.loopStart = loopStart;
        });
    }
    /**
     * If loop is true, the loop will end at this position.
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(loopEnd) {
        this._loopEnd = loopEnd;
        if (this.buffer.loaded) _debug.assertRange(this.toSeconds(loopEnd), 0, this.buffer.duration);
        // get the current source
        this._activeSources.forEach((source)=>{
            source.loopEnd = loopEnd;
        });
    }
    /**
     * The audio buffer belonging to the player.
     */ get buffer() {
        return this._buffer;
    }
    set buffer(buffer) {
        this._buffer.set(buffer);
    }
    /**
     * If the buffer should loop once it's over.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/drum-samples/breakbeat.mp3").toDestination();
     * player.loop = true;
     * player.autostart = true;
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        // if no change, do nothing
        if (this._loop === loop) return;
        this._loop = loop;
        // set the loop of all of the sources
        this._activeSources.forEach((source)=>{
            source.loop = loop;
        });
        if (loop) {
            // remove the next stopEvent
            const stopEvent = this._state.getNextState("stopped", this.now());
            if (stopEvent) this._state.cancel(stopEvent.time);
        }
    }
    /**
     * Normal speed is 1. The pitch will change with the playback rate.
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/femalevoices_aa2_A5.mp3").toDestination();
     * // play at 1/4 speed
     * player.playbackRate = 0.25;
     * // play as soon as the buffer is loaded
     * player.autostart = true;
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        const now = this.now();
        // cancel the stop event since it's at a different time now
        const stopEvent = this._state.getNextState("stopped", now);
        if (stopEvent && stopEvent.implicitEnd) {
            this._state.cancel(stopEvent.time);
            this._activeSources.forEach((source)=>source.cancelStop()
            );
        }
        // set all the sources
        this._activeSources.forEach((source)=>{
            source.playbackRate.setValueAtTime(rate, now);
        });
    }
    /**
     * If the buffer should be reversed
     * @example
     * const player = new Tone.Player("https://tonejs.github.io/audio/berklee/chime_1.mp3").toDestination();
     * player.autostart = true;
     * player.reverse = true;
     */ get reverse() {
        return this._buffer.reverse;
    }
    set reverse(rev) {
        this._buffer.reverse = rev;
    }
    /**
     * If the buffer is loaded
     */ get loaded() {
        return this._buffer.loaded;
    }
    dispose() {
        super.dispose();
        // disconnect all of the players
        this._activeSources.forEach((source)=>source.dispose()
        );
        this._activeSources.clear();
        this._buffer.dispose();
        return this;
    }
}
_tslib.__decorate([
    _decorator.timeRange(0)
], Player.prototype, "fadeIn", void 0);
_tslib.__decorate([
    _decorator.timeRange(0)
], Player.prototype, "fadeOut", void 0);

},{"tslib":"bjkXk","../../core/context/ToneAudioBuffer":"gpPIV","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../core/util/TypeCheck":"lCqGC","../Source":"31KwW","./ToneBufferSource":"6y7FM","../../core/util/Debug":"bsxl9","../../core/util/Decorator":"krpMw","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"krpMw":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Assert that the number is in the given range.
 */ parcelHelpers.export(exports, "range", ()=>range
);
/**
 * Convert the time to seconds and assert that the time is in between the two
 * values when being set.
 */ parcelHelpers.export(exports, "timeRange", ()=>timeRange
);
var _debug = require("./Debug");
function range(min, max = Infinity) {
    const valueMap = new WeakMap();
    return function(target, propertyKey) {
        Reflect.defineProperty(target, propertyKey, {
            configurable: true,
            enumerable: true,
            get: function() {
                return valueMap.get(this);
            },
            set: function(newValue) {
                _debug.assertRange(newValue, min, max);
                valueMap.set(this, newValue);
            }
        });
    };
}
function timeRange(min, max = Infinity) {
    const valueMap = new WeakMap();
    return function(target, propertyKey) {
        Reflect.defineProperty(target, propertyKey, {
            configurable: true,
            enumerable: true,
            get: function() {
                return valueMap.get(this);
            },
            set: function(newValue) {
                _debug.assertRange(this.toSeconds(newValue), min, max);
                valueMap.set(this, newValue);
            }
        });
    };
}

},{"./Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bKxBU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Players combines multiple [[Player]] objects.
 * @category Source
 */ parcelHelpers.export(exports, "Players", ()=>Players
);
var _volume = require("../../component/channel/Volume");
var _toneAudioBuffers = require("../../core/context/ToneAudioBuffers");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _debug = require("../../core/util/Debug");
var _interface = require("../../core/util/Interface");
var _source = require("../Source");
var _player = require("./Player");
class Players extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Players.getDefaults(), arguments, [
            "urls",
            "onload"
        ], "urls"));
        this.name = "Players";
        /**
         * Players has no input.
         */ this.input = undefined;
        /**
         * The container of all of the players
         */ this._players = new Map();
        const options = _defaults.optionsFromArguments(Players.getDefaults(), arguments, [
            "urls",
            "onload"
        ], "urls");
        /**
         * The output volume node
         */ this._volume = this.output = new _volume.Volume({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        _interface.readOnly(this, "volume");
        this._buffers = new _toneAudioBuffers.ToneAudioBuffers({
            urls: options.urls,
            onload: options.onload,
            baseUrl: options.baseUrl,
            onerror: options.onerror
        });
        // mute initially
        this.mute = options.mute;
        this._fadeIn = options.fadeIn;
        this._fadeOut = options.fadeOut;
    }
    static getDefaults() {
        return Object.assign(_source.Source.getDefaults(), {
            baseUrl: "",
            fadeIn: 0,
            fadeOut: 0,
            mute: false,
            onload: _interface.noOp,
            onerror: _interface.noOp,
            urls: {
            },
            volume: 0
        });
    }
    /**
     * Mute the output.
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    /**
     * The fadeIn time of the envelope applied to the source.
     */ get fadeIn() {
        return this._fadeIn;
    }
    set fadeIn(fadeIn) {
        this._fadeIn = fadeIn;
        this._players.forEach((player)=>{
            player.fadeIn = fadeIn;
        });
    }
    /**
     * The fadeOut time of the each of the sources.
     */ get fadeOut() {
        return this._fadeOut;
    }
    set fadeOut(fadeOut) {
        this._fadeOut = fadeOut;
        this._players.forEach((player)=>{
            player.fadeOut = fadeOut;
        });
    }
    /**
     * The state of the players object. Returns "started" if any of the players are playing.
     */ get state() {
        const playing = Array.from(this._players).some(([_, player])=>player.state === "started"
        );
        return playing ? "started" : "stopped";
    }
    /**
     * True if the buffers object has a buffer by that name.
     * @param name  The key or index of the buffer.
     */ has(name) {
        return this._buffers.has(name);
    }
    /**
     * Get a player by name.
     * @param  name  The players name as defined in the constructor object or `add` method.
     */ player(name) {
        _debug.assert(this.has(name), `No Player with the name ${name} exists on this object`);
        if (!this._players.has(name)) {
            const player = new _player.Player({
                context: this.context,
                fadeIn: this._fadeIn,
                fadeOut: this._fadeOut,
                url: this._buffers.get(name)
            }).connect(this.output);
            this._players.set(name, player);
        }
        return this._players.get(name);
    }
    /**
     * If all the buffers are loaded or not
     */ get loaded() {
        return this._buffers.loaded;
    }
    /**
     * Add a player by name and url to the Players
     * @param  name A unique name to give the player
     * @param  url  Either the url of the bufer or a buffer which will be added with the given name.
     * @param callback  The callback to invoke when the url is loaded.
     */ add(name, url, callback) {
        _debug.assert(!this._buffers.has(name), "A buffer with that name already exists on this object");
        this._buffers.add(name, url, callback);
        return this;
    }
    /**
     * Stop all of the players at the given time
     * @param time The time to stop all of the players.
     */ stopAll(time) {
        this._players.forEach((player)=>player.stop(time)
        );
        return this;
    }
    dispose() {
        super.dispose();
        this._volume.dispose();
        this.volume.dispose();
        this._players.forEach((player)=>player.dispose()
        );
        this._buffers.dispose();
        return this;
    }
}

},{"../../component/channel/Volume":"j5Q9V","../../core/context/ToneAudioBuffers":"g1eoF","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Debug":"bsxl9","../../core/util/Interface":"fVoXs","../Source":"31KwW","./Player":"9Kbsu","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6kdLY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * GrainPlayer implements [granular synthesis](https://en.wikipedia.org/wiki/Granular_synthesis).
 * Granular Synthesis enables you to adjust pitch and playback rate independently. The grainSize is the
 * amount of time each small chunk of audio is played for and the overlap is the
 * amount of crossfading transition time between successive grains.
 * @category Source
 */ parcelHelpers.export(exports, "GrainPlayer", ()=>GrainPlayer
);
var _source = require("../Source");
var _interface = require("../../core/util/Interface");
var _toneAudioBuffer = require("../../core/context/ToneAudioBuffer");
var _defaults = require("../../core/util/Defaults");
var _clock = require("../../core/clock/Clock");
var _toneBufferSource = require("./ToneBufferSource");
var _conversions = require("../../core/type/Conversions");
var _debug = require("../../core/util/Debug");
class GrainPlayer extends _source.Source {
    constructor(){
        super(_defaults.optionsFromArguments(GrainPlayer.getDefaults(), arguments, [
            "url",
            "onload"
        ]));
        this.name = "GrainPlayer";
        /**
         * Internal loopStart value
         */ this._loopStart = 0;
        /**
         * Internal loopStart value
         */ this._loopEnd = 0;
        /**
         * All of the currently playing BufferSources
         */ this._activeSources = [];
        const options = _defaults.optionsFromArguments(GrainPlayer.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        this.buffer = new _toneAudioBuffer.ToneAudioBuffer({
            onload: options.onload,
            onerror: options.onerror,
            reverse: options.reverse,
            url: options.url
        });
        this._clock = new _clock.Clock({
            context: this.context,
            callback: this._tick.bind(this),
            frequency: 1 / options.grainSize
        });
        this._playbackRate = options.playbackRate;
        this._grainSize = options.grainSize;
        this._overlap = options.overlap;
        this.detune = options.detune;
        // setup
        this.overlap = options.overlap;
        this.loop = options.loop;
        this.playbackRate = options.playbackRate;
        this.grainSize = options.grainSize;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this.reverse = options.reverse;
        this._clock.on("stop", this._onstop.bind(this));
    }
    static getDefaults() {
        return Object.assign(_source.Source.getDefaults(), {
            onload: _interface.noOp,
            onerror: _interface.noOp,
            overlap: 0.1,
            grainSize: 0.2,
            playbackRate: 1,
            detune: 0,
            loop: false,
            loopStart: 0,
            loopEnd: 0,
            reverse: false
        });
    }
    /**
     * Internal start method
     */ _start(time, offset, duration) {
        offset = _defaults.defaultArg(offset, 0);
        offset = this.toSeconds(offset);
        time = this.toSeconds(time);
        const grainSize = 1 / this._clock.frequency.getValueAtTime(time);
        this._clock.start(time, offset / grainSize);
        if (duration) this.stop(time + this.toSeconds(duration));
    }
    /**
     * Stop and then restart the player from the beginning (or offset)
     * @param  time When the player should start.
     * @param  offset The offset from the beginning of the sample to start at.
     * @param  duration How long the sample should play. If no duration is given,
     * 					it will default to the full length of the sample (minus any offset)
     */ restart(time, offset, duration) {
        super.restart(time, offset, duration);
        return this;
    }
    _restart(time, offset, duration) {
        this._stop(time);
        this._start(time, offset, duration);
    }
    /**
     * Internal stop method
     */ _stop(time) {
        this._clock.stop(time);
    }
    /**
     * Invoked when the clock is stopped
     */ _onstop(time) {
        // stop the players
        this._activeSources.forEach((source)=>{
            source.fadeOut = 0;
            source.stop(time);
        });
        this.onstop(this);
    }
    /**
     * Invoked on each clock tick. scheduled a new grain at this time.
     */ _tick(time) {
        // check if it should stop looping
        const ticks = this._clock.getTicksAtTime(time);
        const offset = ticks * this._grainSize;
        this.log("offset", offset);
        if (!this.loop && offset > this.buffer.duration) {
            this.stop(time);
            return;
        }
        // at the beginning of the file, the fade in should be 0
        const fadeIn = offset < this._overlap ? 0 : this._overlap;
        // create a buffer source
        const source = new _toneBufferSource.ToneBufferSource({
            context: this.context,
            url: this.buffer,
            fadeIn: fadeIn,
            fadeOut: this._overlap,
            loop: this.loop,
            loopStart: this._loopStart,
            loopEnd: this._loopEnd,
            // compute the playbackRate based on the detune
            playbackRate: _conversions.intervalToFrequencyRatio(this.detune / 100)
        }).connect(this.output);
        source.start(time, this._grainSize * ticks);
        source.stop(time + this._grainSize / this.playbackRate);
        // add it to the active sources
        this._activeSources.push(source);
        // remove it when it's done
        source.onended = ()=>{
            const index = this._activeSources.indexOf(source);
            if (index !== -1) this._activeSources.splice(index, 1);
        };
    }
    /**
     * The playback rate of the sample
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        _debug.assertRange(rate, 0.001);
        this._playbackRate = rate;
        this.grainSize = this._grainSize;
    }
    /**
     * The loop start time.
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(time) {
        if (this.buffer.loaded) _debug.assertRange(this.toSeconds(time), 0, this.buffer.duration);
        this._loopStart = this.toSeconds(time);
    }
    /**
     * The loop end time.
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(time) {
        if (this.buffer.loaded) _debug.assertRange(this.toSeconds(time), 0, this.buffer.duration);
        this._loopEnd = this.toSeconds(time);
    }
    /**
     * The direction the buffer should play in
     */ get reverse() {
        return this.buffer.reverse;
    }
    set reverse(rev) {
        this.buffer.reverse = rev;
    }
    /**
     * The size of each chunk of audio that the
     * buffer is chopped into and played back at.
     */ get grainSize() {
        return this._grainSize;
    }
    set grainSize(size) {
        this._grainSize = this.toSeconds(size);
        this._clock.frequency.setValueAtTime(this._playbackRate / this._grainSize, this.now());
    }
    /**
     * The duration of the cross-fade between successive grains.
     */ get overlap() {
        return this._overlap;
    }
    set overlap(time) {
        const computedTime = this.toSeconds(time);
        _debug.assertRange(computedTime, 0);
        this._overlap = computedTime;
    }
    /**
     * If all the buffer is loaded
     */ get loaded() {
        return this.buffer.loaded;
    }
    dispose() {
        super.dispose();
        this.buffer.dispose();
        this._clock.dispose();
        this._activeSources.forEach((source)=>source.dispose()
        );
        return this;
    }
}

},{"../Source":"31KwW","../../core/util/Interface":"fVoXs","../../core/context/ToneAudioBuffer":"gpPIV","../../core/util/Defaults":"kSyYt","../../core/clock/Clock":"2WJVT","./ToneBufferSource":"6y7FM","../../core/type/Conversions":"kOcnG","../../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"kD2C3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _add = require("./Add");
parcelHelpers.exportAll(_add, exports);
var _abs = require("./Abs");
parcelHelpers.exportAll(_abs, exports);
var _audioToGain = require("./AudioToGain");
parcelHelpers.exportAll(_audioToGain, exports);
var _gainToAudio = require("./GainToAudio");
parcelHelpers.exportAll(_gainToAudio, exports);
var _greaterThan = require("./GreaterThan");
parcelHelpers.exportAll(_greaterThan, exports);
var _greaterThanZero = require("./GreaterThanZero");
parcelHelpers.exportAll(_greaterThanZero, exports);
var _multiply = require("./Multiply");
parcelHelpers.exportAll(_multiply, exports);
var _negate = require("./Negate");
parcelHelpers.exportAll(_negate, exports);
var _pow = require("./Pow");
parcelHelpers.exportAll(_pow, exports);
var _signal = require("./Signal");
parcelHelpers.exportAll(_signal, exports);
var _scale = require("./Scale");
parcelHelpers.exportAll(_scale, exports);
var _scaleExp = require("./ScaleExp");
parcelHelpers.exportAll(_scaleExp, exports);
var _subtract = require("./Subtract");
parcelHelpers.exportAll(_subtract, exports);
var _syncedSignal = require("./SyncedSignal");
parcelHelpers.exportAll(_syncedSignal, exports);
var _waveShaper = require("./WaveShaper");
parcelHelpers.exportAll(_waveShaper, exports);
var _zero = require("./Zero");
parcelHelpers.exportAll(_zero, exports);

},{"./Add":"iRri4","./Abs":"h4HAb","./AudioToGain":"bwjzf","./GainToAudio":"5R2Lo","./GreaterThan":"hGVSg","./GreaterThanZero":"3Q5zA","./Multiply":"bN8EY","./Negate":"d15RF","./Pow":"69awp","./Signal":"kfryg","./Scale":"j7ETW","./ScaleExp":"2Xk6m","./Subtract":"hQpKf","./SyncedSignal":"3Q13z","./WaveShaper":"4cjPf","./Zero":"hNiO3","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"h4HAb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Return the absolute value of an incoming signal.
 *
 * @example
 * return Tone.Offline(() => {
 * 	const abs = new Tone.Abs().toDestination();
 * 	const signal = new Tone.Signal(1);
 * 	signal.rampTo(-1, 0.5);
 * 	signal.connect(abs);
 * }, 0.5, 1);
 * @category Signal
 */ parcelHelpers.export(exports, "Abs", ()=>Abs
);
var _signalOperator = require("./SignalOperator");
var _waveShaper = require("./WaveShaper");
class Abs extends _signalOperator.SignalOperator {
    constructor(){
        super(...arguments);
        this.name = "Abs";
        /**
         * The node which converts the audio ranges
         */ this._abs = new _waveShaper.WaveShaper({
            context: this.context,
            mapping: (val)=>{
                if (Math.abs(val) < 0.001) return 0;
                else return Math.abs(val);
            }
        });
        /**
         * The AudioRange input [-1, 1]
         */ this.input = this._abs;
        /**
         * The output range [0, 1]
         */ this.output = this._abs;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._abs.dispose();
        return this;
    }
}

},{"./SignalOperator":"bqDTZ","./WaveShaper":"4cjPf","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5R2Lo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * GainToAudio converts an input in NormalRange [0,1] to AudioRange [-1,1].
 * See [[AudioToGain]].
 * @category Signal
 */ parcelHelpers.export(exports, "GainToAudio", ()=>GainToAudio
);
var _signalOperator = require("./SignalOperator");
var _waveShaper = require("./WaveShaper");
class GainToAudio extends _signalOperator.SignalOperator {
    constructor(){
        super(...arguments);
        this.name = "GainToAudio";
        /**
         * The node which converts the audio ranges
         */ this._norm = new _waveShaper.WaveShaper({
            context: this.context,
            mapping: (x)=>Math.abs(x) * 2 - 1
        });
        /**
         * The NormalRange input [0, 1]
         */ this.input = this._norm;
        /**
         * The AudioRange output [-1, 1]
         */ this.output = this._norm;
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this._norm.dispose();
        return this;
    }
}

},{"./SignalOperator":"bqDTZ","./WaveShaper":"4cjPf","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hGVSg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Output 1 if the signal is greater than the value, otherwise outputs 0.
 * can compare two signals or a signal and a number.
 *
 * @example
 * return Tone.Offline(() => {
 * 	const gt = new Tone.GreaterThan(2).toDestination();
 * 	const sig = new Tone.Signal(4).connect(gt);
 * }, 0.1, 1);
 * @category Signal
 */ parcelHelpers.export(exports, "GreaterThan", ()=>GreaterThan
);
var _defaults = require("../core/util/Defaults");
var _subtract = require("./Subtract");
var _signal = require("./Signal");
var _greaterThanZero = require("./GreaterThanZero");
var _interface = require("../core/util/Interface");
class GreaterThan extends _signal.Signal {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(GreaterThan.getDefaults(), arguments, [
            "value"
        ])));
        this.name = "GreaterThan";
        this.override = false;
        const options = _defaults.optionsFromArguments(GreaterThan.getDefaults(), arguments, [
            "value"
        ]);
        this._subtract = this.input = new _subtract.Subtract({
            context: this.context,
            value: options.value
        });
        this._gtz = this.output = new _greaterThanZero.GreaterThanZero({
            context: this.context
        });
        this.comparator = this._param = this._subtract.subtrahend;
        _interface.readOnly(this, "comparator");
        // connect
        this._subtract.connect(this._gtz);
    }
    static getDefaults() {
        return Object.assign(_signal.Signal.getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._gtz.dispose();
        this._subtract.dispose();
        this.comparator.dispose();
        return this;
    }
}

},{"../core/util/Defaults":"kSyYt","./Subtract":"hQpKf","./Signal":"kfryg","./GreaterThanZero":"3Q5zA","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hQpKf":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Subtract the signal connected to the input is subtracted from the signal connected
 * The subtrahend.
 *
 * @example
 * // subtract a scalar from a signal
 * const sub = new Tone.Subtract(1);
 * const sig = new Tone.Signal(4).connect(sub);
 * // the output of sub is 3.
 * @example
 * // subtract two signals
 * const sub = new Tone.Subtract();
 * const sigA = new Tone.Signal(10);
 * const sigB = new Tone.Signal(2.5);
 * sigA.connect(sub);
 * sigB.connect(sub.subtrahend);
 * // output of sub is 7.5
 * @category Signal
 */ parcelHelpers.export(exports, "Subtract", ()=>Subtract
);
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _gain = require("../core/context/Gain");
var _defaults = require("../core/util/Defaults");
var _negate = require("../signal/Negate");
var _signal = require("../signal/Signal");
class Subtract extends _signal.Signal {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Subtract.getDefaults(), arguments, [
            "value"
        ])));
        this.override = false;
        this.name = "Subtract";
        /**
         * the summing node
         */ this._sum = new _gain.Gain({
            context: this.context
        });
        this.input = this._sum;
        this.output = this._sum;
        /**
         * Negate the input of the second input before connecting it to the summing node.
         */ this._neg = new _negate.Negate({
            context: this.context
        });
        /**
         * The value which is subtracted from the main signal
         */ this.subtrahend = this._param;
        _toneAudioNode.connectSeries(this._constantSource, this._neg, this._sum);
    }
    static getDefaults() {
        return Object.assign(_signal.Signal.getDefaults(), {
            value: 0
        });
    }
    dispose() {
        super.dispose();
        this._neg.dispose();
        this._sum.dispose();
        return this;
    }
}

},{"../core/context/ToneAudioNode":"iT1SZ","../core/context/Gain":"7kpMn","../core/util/Defaults":"kSyYt","../signal/Negate":"d15RF","../signal/Signal":"kfryg","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d15RF":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Negate the incoming signal. i.e. an input signal of 10 will output -10
 *
 * @example
 * const neg = new Tone.Negate();
 * const sig = new Tone.Signal(-2).connect(neg);
 * // output of neg is positive 2.
 * @category Signal
 */ parcelHelpers.export(exports, "Negate", ()=>Negate
);
var _multiply = require("./Multiply");
var _signalOperator = require("./SignalOperator");
class Negate extends _signalOperator.SignalOperator {
    constructor(){
        super(...arguments);
        this.name = "Negate";
        /**
         * negation is done by multiplying by -1
         */ this._multiply = new _multiply.Multiply({
            context: this.context,
            value: -1
        });
        /**
         * The input and output are equal to the multiply node
         */ this.input = this._multiply;
        this.output = this._multiply;
    }
    /**
     * clean up
     * @returns {Negate} this
     */ dispose() {
        super.dispose();
        this._multiply.dispose();
        return this;
    }
}

},{"./Multiply":"bN8EY","./SignalOperator":"bqDTZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3Q5zA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * GreaterThanZero outputs 1 when the input is strictly greater than zero
 * @example
 * return Tone.Offline(() => {
 * 	const gt0 = new Tone.GreaterThanZero().toDestination();
 * 	const sig = new Tone.Signal(0.5).connect(gt0);
 * 	sig.setValueAtTime(-1, 0.05);
 * }, 0.1, 1);
 * @category Signal
 */ parcelHelpers.export(exports, "GreaterThanZero", ()=>GreaterThanZero
);
var _signalOperator = require("./SignalOperator");
var _multiply = require("./Multiply");
var _waveShaper = require("./WaveShaper");
var _defaults = require("../core/util/Defaults");
class GreaterThanZero extends _signalOperator.SignalOperator {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(GreaterThanZero.getDefaults(), arguments)));
        this.name = "GreaterThanZero";
        this._thresh = this.output = new _waveShaper.WaveShaper({
            context: this.context,
            length: 127,
            mapping: (val)=>{
                if (val <= 0) return 0;
                else return 1;
            }
        });
        this._scale = this.input = new _multiply.Multiply({
            context: this.context,
            value: 10000
        });
        // connections
        this._scale.connect(this._thresh);
    }
    dispose() {
        super.dispose();
        this._scale.dispose();
        this._thresh.dispose();
        return this;
    }
}

},{"./SignalOperator":"bqDTZ","./Multiply":"bN8EY","./WaveShaper":"4cjPf","../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"69awp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Pow applies an exponent to the incoming signal. The incoming signal must be AudioRange [-1, 1]
 *
 * @example
 * const pow = new Tone.Pow(2);
 * const sig = new Tone.Signal(0.5).connect(pow);
 * // output of pow is 0.25.
 * @category Signal
 */ parcelHelpers.export(exports, "Pow", ()=>Pow
);
var _waveShaper = require("./WaveShaper");
var _defaults = require("../core/util/Defaults");
var _signalOperator = require("./SignalOperator");
class Pow extends _signalOperator.SignalOperator {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Pow.getDefaults(), arguments, [
            "value"
        ])));
        this.name = "Pow";
        const options = _defaults.optionsFromArguments(Pow.getDefaults(), arguments, [
            "value"
        ]);
        this._exponentScaler = this.input = this.output = new _waveShaper.WaveShaper({
            context: this.context,
            mapping: this._expFunc(options.value),
            length: 8192
        });
        this._exponent = options.value;
    }
    static getDefaults() {
        return Object.assign(_signalOperator.SignalOperator.getDefaults(), {
            value: 1
        });
    }
    /**
     * the function which maps the waveshaper
     * @param exponent exponent value
     */ _expFunc(exponent) {
        return (val)=>{
            return Math.pow(Math.abs(val), exponent);
        };
    }
    /**
     * The value of the exponent.
     */ get value() {
        return this._exponent;
    }
    set value(exponent) {
        this._exponent = exponent;
        this._exponentScaler.setMap(this._expFunc(this._exponent));
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._exponentScaler.dispose();
        return this;
    }
}

},{"./WaveShaper":"4cjPf","../core/util/Defaults":"kSyYt","./SignalOperator":"bqDTZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2Xk6m":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Performs an exponential scaling on an input signal.
 * Scales a NormalRange value [0,1] exponentially
 * to the output range of outputMin to outputMax.
 * @example
 * const scaleExp = new Tone.ScaleExp(0, 100, 2);
 * const signal = new Tone.Signal(0.5).connect(scaleExp);
 * @category Signal
 */ parcelHelpers.export(exports, "ScaleExp", ()=>ScaleExp
);
var _scale = require("./Scale");
var _defaults = require("../core/util/Defaults");
var _pow = require("./Pow");
class ScaleExp extends _scale.Scale {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(ScaleExp.getDefaults(), arguments, [
            "min",
            "max",
            "exponent"
        ])));
        this.name = "ScaleExp";
        const options = _defaults.optionsFromArguments(ScaleExp.getDefaults(), arguments, [
            "min",
            "max",
            "exponent"
        ]);
        this.input = this._exp = new _pow.Pow({
            context: this.context,
            value: options.exponent
        });
        this._exp.connect(this._mult);
    }
    static getDefaults() {
        return Object.assign(_scale.Scale.getDefaults(), {
            exponent: 1
        });
    }
    /**
     * Instead of interpolating linearly between the [[min]] and
     * [[max]] values, setting the exponent will interpolate between
     * the two values with an exponential curve.
     */ get exponent() {
        return this._exp.value;
    }
    set exponent(exp) {
        this._exp.value = exp;
    }
    dispose() {
        super.dispose();
        this._exp.dispose();
        return this;
    }
}

},{"./Scale":"j7ETW","../core/util/Defaults":"kSyYt","./Pow":"69awp","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3Q13z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Adds the ability to synchronize the signal to the [[Transport]]
 */ parcelHelpers.export(exports, "SyncedSignal", ()=>SyncedSignal
);
var _signal = require("./Signal");
var _defaults = require("../core/util/Defaults");
var _transportTime = require("../core/type/TransportTime");
var _toneConstantSource = require("./ToneConstantSource");
class SyncedSignal extends _signal.Signal {
    constructor(){
        super(_defaults.optionsFromArguments(_signal.Signal.getDefaults(), arguments, [
            "value",
            "units"
        ]));
        this.name = "SyncedSignal";
        /**
         * Don't override when something is connected to the input
         */ this.override = false;
        const options = _defaults.optionsFromArguments(_signal.Signal.getDefaults(), arguments, [
            "value",
            "units"
        ]);
        this._lastVal = options.value;
        this._synced = this.context.transport.scheduleRepeat(this._onTick.bind(this), "1i");
        this._syncedCallback = this._anchorValue.bind(this);
        this.context.transport.on("start", this._syncedCallback);
        this.context.transport.on("pause", this._syncedCallback);
        this.context.transport.on("stop", this._syncedCallback);
        // disconnect the constant source from the output and replace it with another one
        this._constantSource.disconnect();
        this._constantSource.stop(0);
        // create a new one
        this._constantSource = this.output = new _toneConstantSource.ToneConstantSource({
            context: this.context,
            offset: options.value,
            units: options.units
        }).start(0);
        this.setValueAtTime(options.value, 0);
    }
    /**
     * Callback which is invoked every tick.
     */ _onTick(time) {
        const val = super.getValueAtTime(this.context.transport.seconds);
        // approximate ramp curves with linear ramps
        if (this._lastVal !== val) {
            this._lastVal = val;
            this._constantSource.offset.setValueAtTime(val, time);
        }
    }
    /**
     * Anchor the value at the start and stop of the Transport
     */ _anchorValue(time) {
        const val = super.getValueAtTime(this.context.transport.seconds);
        this._lastVal = val;
        this._constantSource.offset.cancelAndHoldAtTime(time);
        this._constantSource.offset.setValueAtTime(val, time);
    }
    getValueAtTime(time) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, time).toSeconds();
        return super.getValueAtTime(computedTime);
    }
    setValueAtTime(value, time) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, time).toSeconds();
        super.setValueAtTime(value, computedTime);
        return this;
    }
    linearRampToValueAtTime(value, time) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, time).toSeconds();
        super.linearRampToValueAtTime(value, computedTime);
        return this;
    }
    exponentialRampToValueAtTime(value, time) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, time).toSeconds();
        super.exponentialRampToValueAtTime(value, computedTime);
        return this;
    }
    setTargetAtTime(value, startTime, timeConstant) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, startTime).toSeconds();
        super.setTargetAtTime(value, computedTime, timeConstant);
        return this;
    }
    cancelScheduledValues(startTime) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, startTime).toSeconds();
        super.cancelScheduledValues(computedTime);
        return this;
    }
    setValueCurveAtTime(values, startTime, duration, scaling) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, startTime).toSeconds();
        duration = this.toSeconds(duration);
        super.setValueCurveAtTime(values, computedTime, duration, scaling);
        return this;
    }
    cancelAndHoldAtTime(time) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, time).toSeconds();
        super.cancelAndHoldAtTime(computedTime);
        return this;
    }
    setRampPoint(time) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, time).toSeconds();
        super.setRampPoint(computedTime);
        return this;
    }
    exponentialRampTo(value, rampTime, startTime) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, startTime).toSeconds();
        super.exponentialRampTo(value, rampTime, computedTime);
        return this;
    }
    linearRampTo(value, rampTime, startTime) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, startTime).toSeconds();
        super.linearRampTo(value, rampTime, computedTime);
        return this;
    }
    targetRampTo(value, rampTime, startTime) {
        const computedTime = new _transportTime.TransportTimeClass(this.context, startTime).toSeconds();
        super.targetRampTo(value, rampTime, computedTime);
        return this;
    }
    dispose() {
        super.dispose();
        this.context.transport.clear(this._synced);
        this.context.transport.off("start", this._syncedCallback);
        this.context.transport.off("pause", this._syncedCallback);
        this.context.transport.off("stop", this._syncedCallback);
        this._constantSource.dispose();
        return this;
    }
}

},{"./Signal":"kfryg","../core/util/Defaults":"kSyYt","../core/type/TransportTime":"kcsdx","./ToneConstantSource":"iRz6E","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"13JoI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _amsynth = require("./AMSynth");
parcelHelpers.exportAll(_amsynth, exports);
var _duoSynth = require("./DuoSynth");
parcelHelpers.exportAll(_duoSynth, exports);
var _fmsynth = require("./FMSynth");
parcelHelpers.exportAll(_fmsynth, exports);
var _metalSynth = require("./MetalSynth");
parcelHelpers.exportAll(_metalSynth, exports);
var _membraneSynth = require("./MembraneSynth");
parcelHelpers.exportAll(_membraneSynth, exports);
var _monoSynth = require("./MonoSynth");
parcelHelpers.exportAll(_monoSynth, exports);
var _noiseSynth = require("./NoiseSynth");
parcelHelpers.exportAll(_noiseSynth, exports);
var _pluckSynth = require("./PluckSynth");
parcelHelpers.exportAll(_pluckSynth, exports);
var _polySynth = require("./PolySynth");
parcelHelpers.exportAll(_polySynth, exports);
var _sampler = require("./Sampler");
parcelHelpers.exportAll(_sampler, exports);
var _synth = require("./Synth");
parcelHelpers.exportAll(_synth, exports);

},{"./AMSynth":"cFra0","./DuoSynth":"jMF1u","./FMSynth":"77bnR","./MetalSynth":"1cKaV","./MembraneSynth":"hqDmG","./MonoSynth":"1Lpa8","./NoiseSynth":"c8hyC","./PluckSynth":"9QKPZ","./PolySynth":"1DZrk","./Sampler":"laPeI","./Synth":"1gImO","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cFra0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AMSynth uses the output of one Tone.Synth to modulate the
 * amplitude of another Tone.Synth. The harmonicity (the ratio between
 * the two signals) affects the timbre of the output signal greatly.
 * Read more about Amplitude Modulation Synthesis on
 * [SoundOnSound](https://web.archive.org/web/20160404103653/http://www.soundonsound.com:80/sos/mar00/articles/synthsecrets.htm).
 *
 * @example
 * const synth = new Tone.AMSynth().toDestination();
 * synth.triggerAttackRelease("C4", "4n");
 *
 * @category Instrument
 */ parcelHelpers.export(exports, "AMSynth", ()=>AMSynth
);
var _audioToGain = require("../signal/AudioToGain");
var _defaults = require("../core/util/Defaults");
var _modulationSynth = require("./ModulationSynth");
class AMSynth extends _modulationSynth.ModulationSynth {
    constructor(){
        super(_defaults.optionsFromArguments(AMSynth.getDefaults(), arguments));
        this.name = "AMSynth";
        this._modulationScale = new _audioToGain.AudioToGain({
            context: this.context
        });
        // control the two voices frequency
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.detune.fan(this._carrier.detune, this._modulator.detune);
        this._modulator.chain(this._modulationScale, this._modulationNode.gain);
        this._carrier.chain(this._modulationNode, this.output);
    }
    dispose() {
        super.dispose();
        this._modulationScale.dispose();
        return this;
    }
}

},{"../signal/AudioToGain":"bwjzf","../core/util/Defaults":"kSyYt","./ModulationSynth":"iXFri","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iXFri":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for both AM and FM synths
 */ parcelHelpers.export(exports, "ModulationSynth", ()=>ModulationSynth
);
var _signal = require("../signal/Signal");
var _multiply = require("../signal/Multiply");
var _gain = require("../core/context/Gain");
var _envelope = require("../component/envelope/Envelope");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _monophonic = require("./Monophonic");
var _omniOscillator = require("../source/oscillator/OmniOscillator");
var _source = require("../source/Source");
var _synth = require("./Synth");
var _interface = require("../core/util/Interface");
var _defaults = require("../core/util/Defaults");
class ModulationSynth extends _monophonic.Monophonic {
    constructor(){
        super(_defaults.optionsFromArguments(ModulationSynth.getDefaults(), arguments));
        this.name = "ModulationSynth";
        const options = _defaults.optionsFromArguments(ModulationSynth.getDefaults(), arguments);
        this._carrier = new _synth.Synth({
            context: this.context,
            oscillator: options.oscillator,
            envelope: options.envelope,
            onsilence: ()=>this.onsilence(this)
            ,
            volume: -10
        });
        this._modulator = new _synth.Synth({
            context: this.context,
            oscillator: options.modulation,
            envelope: options.modulationEnvelope,
            volume: -10
        });
        this.oscillator = this._carrier.oscillator;
        this.envelope = this._carrier.envelope;
        this.modulation = this._modulator.oscillator;
        this.modulationEnvelope = this._modulator.envelope;
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency"
        });
        this.detune = new _signal.Signal({
            context: this.context,
            value: options.detune,
            units: "cents"
        });
        this.harmonicity = new _multiply.Multiply({
            context: this.context,
            value: options.harmonicity,
            minValue: 0
        });
        this._modulationNode = new _gain.Gain({
            context: this.context,
            gain: 0
        });
        _interface.readOnly(this, [
            "frequency",
            "harmonicity",
            "oscillator",
            "envelope",
            "modulation",
            "modulationEnvelope",
            "detune"
        ]);
    }
    static getDefaults() {
        return Object.assign(_monophonic.Monophonic.getDefaults(), {
            harmonicity: 3,
            oscillator: Object.assign(_defaults.omitFromObject(_omniOscillator.OmniOscillator.getDefaults(), [
                ...Object.keys(_source.Source.getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "sine"
            }),
            envelope: Object.assign(_defaults.omitFromObject(_envelope.Envelope.getDefaults(), Object.keys(_toneAudioNode.ToneAudioNode.getDefaults())), {
                attack: 0.01,
                decay: 0.01,
                sustain: 1,
                release: 0.5
            }),
            modulation: Object.assign(_defaults.omitFromObject(_omniOscillator.OmniOscillator.getDefaults(), [
                ...Object.keys(_source.Source.getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "square"
            }),
            modulationEnvelope: Object.assign(_defaults.omitFromObject(_envelope.Envelope.getDefaults(), Object.keys(_toneAudioNode.ToneAudioNode.getDefaults())), {
                attack: 0.5,
                decay: 0,
                sustain: 1,
                release: 0.5
            })
        });
    }
    /**
     * Trigger the attack portion of the note
     */ _triggerEnvelopeAttack(time, velocity) {
        // @ts-ignore
        this._carrier._triggerEnvelopeAttack(time, velocity);
        // @ts-ignore
        this._modulator._triggerEnvelopeAttack(time, velocity);
    }
    /**
     * Trigger the release portion of the note
     */ _triggerEnvelopeRelease(time) {
        // @ts-ignore
        this._carrier._triggerEnvelopeRelease(time);
        // @ts-ignore
        this._modulator._triggerEnvelopeRelease(time);
        return this;
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    dispose() {
        super.dispose();
        this._carrier.dispose();
        this._modulator.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this.harmonicity.dispose();
        this._modulationNode.dispose();
        return this;
    }
}

},{"../signal/Signal":"kfryg","../signal/Multiply":"bN8EY","../core/context/Gain":"7kpMn","../component/envelope/Envelope":"91tjD","../core/context/ToneAudioNode":"iT1SZ","./Monophonic":"i6dl8","../source/oscillator/OmniOscillator":"fKqBe","../source/Source":"31KwW","./Synth":"1gImO","../core/util/Interface":"fVoXs","../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"91tjD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Envelope is an [ADSR](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope)
 * envelope generator. Envelope outputs a signal which
 * can be connected to an AudioParam or Tone.Signal.
 * ```
 *           /\
 *          /  \
 *         /    \
 *        /      \
 *       /        \___________
 *      /                     \
 *     /                       \
 *    /                         \
 *   /                           \
 * ```
 * @example
 * return Tone.Offline(() => {
 * 	const env = new Tone.Envelope({
 * 		attack: 0.1,
 * 		decay: 0.2,
 * 		sustain: 0.5,
 * 		release: 0.8,
 * 	}).toDestination();
 * 	env.triggerAttackRelease(0.5);
 * }, 1.5, 1);
 * @category Component
 */ parcelHelpers.export(exports, "Envelope", ()=>Envelope
);
var _tslib = require("tslib");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _typeCheck = require("../../core/util/TypeCheck");
var _signal = require("../../signal/Signal");
var _offlineContext = require("../../core/context/OfflineContext");
var _debug = require("../../core/util/Debug");
var _decorator = require("../../core/util/Decorator");
class Envelope extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Envelope.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]));
        this.name = "Envelope";
        /**
         * the signal which is output.
         */ this._sig = new _signal.Signal({
            context: this.context,
            value: 0
        });
        /**
         * The output signal of the envelope
         */ this.output = this._sig;
        /**
         * Envelope has no input
         */ this.input = undefined;
        const options = _defaults.optionsFromArguments(Envelope.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]);
        this.attack = options.attack;
        this.decay = options.decay;
        this.sustain = options.sustain;
        this.release = options.release;
        this.attackCurve = options.attackCurve;
        this.releaseCurve = options.releaseCurve;
        this.decayCurve = options.decayCurve;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            attack: 0.01,
            attackCurve: "linear",
            decay: 0.1,
            decayCurve: "exponential",
            release: 1,
            releaseCurve: "exponential",
            sustain: 0.5
        });
    }
    /**
     * Read the current value of the envelope. Useful for
     * synchronizing visual output to the envelope.
     */ get value() {
        return this.getValueAtTime(this.now());
    }
    /**
     * Get the curve
     * @param  curve
     * @param  direction  In/Out
     * @return The curve name
     */ _getCurve(curve, direction) {
        if (_typeCheck.isString(curve)) return curve;
        else {
            // look up the name in the curves array
            let curveName;
            for(curveName in EnvelopeCurves){
                if (EnvelopeCurves[curveName][direction] === curve) return curveName;
            }
            // return the custom curve
            return curve;
        }
    }
    /**
     * Assign a the curve to the given name using the direction
     * @param  name
     * @param  direction In/Out
     * @param  curve
     */ _setCurve(name, direction, curve) {
        // check if it's a valid type
        if (_typeCheck.isString(curve) && Reflect.has(EnvelopeCurves, curve)) {
            const curveDef = EnvelopeCurves[curve];
            if (_typeCheck.isObject(curveDef)) {
                if (name !== "_decayCurve") this[name] = curveDef[direction];
            } else this[name] = curveDef;
        } else if (_typeCheck.isArray(curve) && name !== "_decayCurve") this[name] = curve;
        else throw new Error("Envelope: invalid curve: " + curve);
    }
    /**
     * The shape of the attack.
     * Can be any of these strings:
     * * "linear"
     * * "exponential"
     * * "sine"
     * * "cosine"
     * * "bounce"
     * * "ripple"
     * * "step"
     *
     * Can also be an array which describes the curve. Values
     * in the array are evenly subdivided and linearly
     * interpolated over the duration of the attack.
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope(0.4).toDestination();
     * 	env.attackCurve = "linear";
     * 	env.triggerAttack();
     * }, 1, 1);
     */ get attackCurve() {
        return this._getCurve(this._attackCurve, "In");
    }
    set attackCurve(curve) {
        this._setCurve("_attackCurve", "In", curve);
    }
    /**
     * The shape of the release. See the attack curve types.
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope({
     * 		release: 0.8
     * 	}).toDestination();
     * 	env.triggerAttack();
     * 	// release curve could also be defined by an array
     * 	env.releaseCurve = [1, 0.3, 0.4, 0.2, 0.7, 0];
     * 	env.triggerRelease(0.2);
     * }, 1, 1);
     */ get releaseCurve() {
        return this._getCurve(this._releaseCurve, "Out");
    }
    set releaseCurve(curve) {
        this._setCurve("_releaseCurve", "Out", curve);
    }
    /**
     * The shape of the decay either "linear" or "exponential"
     * @example
     * return Tone.Offline(() => {
     * 	const env = new Tone.Envelope({
     * 		sustain: 0.1,
     * 		decay: 0.5
     * 	}).toDestination();
     * 	env.decayCurve = "linear";
     * 	env.triggerAttack();
     * }, 1, 1);
     */ get decayCurve() {
        return this._decayCurve;
    }
    set decayCurve(curve) {
        _debug.assert([
            "linear",
            "exponential"
        ].some((c)=>c === curve
        ), `Invalid envelope curve: ${curve}`);
        this._decayCurve = curve;
    }
    /**
     * Trigger the attack/decay portion of the ADSR envelope.
     * @param  time When the attack should start.
     * @param velocity The velocity of the envelope scales the vales.
     *                             number between 0-1
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator().connect(env).start();
     * // trigger the attack 0.5 seconds from now with a velocity of 0.2
     * env.triggerAttack("+0.5", 0.2);
     */ triggerAttack(time, velocity = 1) {
        this.log("triggerAttack", time, velocity);
        time = this.toSeconds(time);
        const originalAttack = this.toSeconds(this.attack);
        let attack = originalAttack;
        const decay = this.toSeconds(this.decay);
        // check if it's not a complete attack
        const currentValue = this.getValueAtTime(time);
        if (currentValue > 0) {
            // subtract the current value from the attack time
            const attackRate = 1 / attack;
            const remainingDistance = 1 - currentValue;
            // the attack is now the remaining time
            attack = remainingDistance / attackRate;
        }
        // attack
        if (attack < this.sampleTime) {
            this._sig.cancelScheduledValues(time);
            // case where the attack time is 0 should set instantly
            this._sig.setValueAtTime(velocity, time);
        } else if (this._attackCurve === "linear") this._sig.linearRampTo(velocity, attack, time);
        else if (this._attackCurve === "exponential") this._sig.targetRampTo(velocity, attack, time);
        else {
            this._sig.cancelAndHoldAtTime(time);
            let curve = this._attackCurve;
            // find the starting position in the curve
            for(let i = 1; i < curve.length; i++)// the starting index is between the two values
            if (curve[i - 1] <= currentValue && currentValue <= curve[i]) {
                curve = this._attackCurve.slice(i);
                // the first index is the current value
                curve[0] = currentValue;
                break;
            }
            this._sig.setValueCurveAtTime(curve, time, attack, velocity);
        }
        // decay
        if (decay && this.sustain < 1) {
            const decayValue = velocity * this.sustain;
            const decayStart = time + attack;
            this.log("decay", decayStart);
            if (this._decayCurve === "linear") this._sig.linearRampToValueAtTime(decayValue, decay + decayStart);
            else this._sig.exponentialApproachValueAtTime(decayValue, decayStart, decay);
        }
        return this;
    }
    /**
     * Triggers the release of the envelope.
     * @param  time When the release portion of the envelope should start.
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator({
     * 	type: "sawtooth"
     * }).connect(env).start();
     * env.triggerAttack();
     * // trigger the release half a second after the attack
     * env.triggerRelease("+0.5");
     */ triggerRelease(time) {
        this.log("triggerRelease", time);
        time = this.toSeconds(time);
        const currentValue = this.getValueAtTime(time);
        if (currentValue > 0) {
            const release = this.toSeconds(this.release);
            if (release < this.sampleTime) this._sig.setValueAtTime(0, time);
            else if (this._releaseCurve === "linear") this._sig.linearRampTo(0, release, time);
            else if (this._releaseCurve === "exponential") this._sig.targetRampTo(0, release, time);
            else {
                _debug.assert(_typeCheck.isArray(this._releaseCurve), "releaseCurve must be either 'linear', 'exponential' or an array");
                this._sig.cancelAndHoldAtTime(time);
                this._sig.setValueCurveAtTime(this._releaseCurve, time, release, currentValue);
            }
        }
        return this;
    }
    /**
     * Get the scheduled value at the given time. This will
     * return the unconverted (raw) value.
     * @example
     * const env = new Tone.Envelope(0.5, 1, 0.4, 2);
     * env.triggerAttackRelease(2);
     * setInterval(() => console.log(env.getValueAtTime(Tone.now())), 100);
     */ getValueAtTime(time) {
        return this._sig.getValueAtTime(time);
    }
    /**
     * triggerAttackRelease is shorthand for triggerAttack, then waiting
     * some duration, then triggerRelease.
     * @param duration The duration of the sustain.
     * @param time When the attack should be triggered.
     * @param velocity The velocity of the envelope.
     * @example
     * const env = new Tone.AmplitudeEnvelope().toDestination();
     * const osc = new Tone.Oscillator().connect(env).start();
     * // trigger the release 0.5 seconds after the attack
     * env.triggerAttackRelease(0.5);
     */ triggerAttackRelease(duration, time, velocity = 1) {
        time = this.toSeconds(time);
        this.triggerAttack(time, velocity);
        this.triggerRelease(time + this.toSeconds(duration));
        return this;
    }
    /**
     * Cancels all scheduled envelope changes after the given time.
     */ cancel(after) {
        this._sig.cancelScheduledValues(this.toSeconds(after));
        return this;
    }
    /**
     * Connect the envelope to a destination node.
     */ connect(destination, outputNumber = 0, inputNumber = 0) {
        _signal.connectSignal(this, destination, outputNumber, inputNumber);
        return this;
    }
    /**
     * Render the envelope curve to an array of the given length.
     * Good for visualizing the envelope curve. Rescales the duration of the
     * envelope to fit the length.
     */ asArray(length = 1024) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            const duration = length / this.context.sampleRate;
            const context = new _offlineContext.OfflineContext(1, duration, this.context.sampleRate);
            // normalize the ADSR for the given duration with 20% sustain time
            const attackPortion = this.toSeconds(this.attack) + this.toSeconds(this.decay);
            const envelopeDuration = attackPortion + this.toSeconds(this.release);
            const sustainTime = envelopeDuration * 0.1;
            const totalDuration = envelopeDuration + sustainTime;
            // @ts-ignore
            const clone = new this.constructor(Object.assign(this.get(), {
                attack: duration * this.toSeconds(this.attack) / totalDuration,
                decay: duration * this.toSeconds(this.decay) / totalDuration,
                release: duration * this.toSeconds(this.release) / totalDuration,
                context
            }));
            clone._sig.toDestination();
            clone.triggerAttackRelease(duration * (attackPortion + sustainTime) / totalDuration, 0);
            const buffer = yield context.render();
            return buffer.getChannelData(0);
        });
    }
    dispose() {
        super.dispose();
        this._sig.dispose();
        return this;
    }
}
_tslib.__decorate([
    _decorator.timeRange(0)
], Envelope.prototype, "attack", void 0);
_tslib.__decorate([
    _decorator.timeRange(0)
], Envelope.prototype, "decay", void 0);
_tslib.__decorate([
    _decorator.range(0, 1)
], Envelope.prototype, "sustain", void 0);
_tslib.__decorate([
    _decorator.timeRange(0)
], Envelope.prototype, "release", void 0);
/**
 * Generate some complex envelope curves.
 */ const EnvelopeCurves = (()=>{
    const curveLen = 128;
    let i;
    let k;
    // cosine curve
    const cosineCurve = [];
    for(i = 0; i < curveLen; i++)cosineCurve[i] = Math.sin(i / (curveLen - 1) * (Math.PI / 2));
    // ripple curve
    const rippleCurve = [];
    const rippleCurveFreq = 6.4;
    for(i = 0; i < curveLen - 1; i++){
        k = i / (curveLen - 1);
        const sineWave = Math.sin(k * (Math.PI * 2) * rippleCurveFreq - Math.PI / 2) + 1;
        rippleCurve[i] = sineWave / 10 + k * 0.83;
    }
    rippleCurve[curveLen - 1] = 1;
    // stairs curve
    const stairsCurve = [];
    const steps = 5;
    for(i = 0; i < curveLen; i++)stairsCurve[i] = Math.ceil(i / (curveLen - 1) * steps) / steps;
    // in-out easing curve
    const sineCurve = [];
    for(i = 0; i < curveLen; i++){
        k = i / (curveLen - 1);
        sineCurve[i] = 0.5 * (1 - Math.cos(Math.PI * k));
    }
    // a bounce curve
    const bounceCurve = [];
    for(i = 0; i < curveLen; i++){
        k = i / (curveLen - 1);
        const freq = Math.pow(k, 3) * 4 + 0.2;
        const val = Math.cos(freq * Math.PI * 2 * k);
        bounceCurve[i] = Math.abs(val * (1 - k));
    }
    /**
     * Invert a value curve to make it work for the release
     */ function invertCurve(curve) {
        const out = new Array(curve.length);
        for(let j = 0; j < curve.length; j++)out[j] = 1 - curve[j];
        return out;
    }
    /**
     * reverse the curve
     */ function reverseCurve(curve) {
        return curve.slice(0).reverse();
    }
    /**
     * attack and release curve arrays
     */ return {
        bounce: {
            In: invertCurve(bounceCurve),
            Out: bounceCurve
        },
        cosine: {
            In: cosineCurve,
            Out: reverseCurve(cosineCurve)
        },
        exponential: "exponential",
        linear: "linear",
        ripple: {
            In: rippleCurve,
            Out: invertCurve(rippleCurve)
        },
        sine: {
            In: sineCurve,
            Out: invertCurve(sineCurve)
        },
        step: {
            In: stairsCurve,
            Out: invertCurve(stairsCurve)
        }
    };
})();

},{"tslib":"bjkXk","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/TypeCheck":"lCqGC","../../signal/Signal":"kfryg","../../core/context/OfflineContext":"KYtWQ","../../core/util/Debug":"bsxl9","../../core/util/Decorator":"krpMw","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"i6dl8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Abstract base class for other monophonic instruments to extend.
 */ parcelHelpers.export(exports, "Monophonic", ()=>Monophonic
);
var _tslib = require("tslib");
var _frequency = require("../core/type/Frequency");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _instrument = require("../instrument/Instrument");
var _decorator = require("../core/util/Decorator");
class Monophonic extends _instrument.Instrument {
    constructor(){
        super(_defaults.optionsFromArguments(Monophonic.getDefaults(), arguments));
        const options = _defaults.optionsFromArguments(Monophonic.getDefaults(), arguments);
        this.portamento = options.portamento;
        this.onsilence = options.onsilence;
    }
    static getDefaults() {
        return Object.assign(_instrument.Instrument.getDefaults(), {
            detune: 0,
            onsilence: _interface.noOp,
            portamento: 0
        });
    }
    /**
     * Trigger the attack of the note optionally with a given velocity.
     * @param  note The note to trigger.
     * @param  time When the note should start.
     * @param  velocity The velocity scaler determines how "loud" the note will be triggered.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * // trigger the note a half second from now at half velocity
     * synth.triggerAttack("C4", "+0.5", 0.5);
     */ triggerAttack(note, time, velocity = 1) {
        this.log("triggerAttack", note, time, velocity);
        const seconds = this.toSeconds(time);
        this._triggerEnvelopeAttack(seconds, velocity);
        this.setNote(note, seconds);
        return this;
    }
    /**
     * Trigger the release portion of the envelope
     * @param  time If no time is given, the release happens immediatly
     * @example
     * const synth = new Tone.Synth().toDestination();
     * synth.triggerAttack("C4");
     * // trigger the release a second from now
     * synth.triggerRelease("+1");
     */ triggerRelease(time) {
        this.log("triggerRelease", time);
        const seconds = this.toSeconds(time);
        this._triggerEnvelopeRelease(seconds);
        return this;
    }
    /**
     * Set the note at the given time. If no time is given, the note
     * will set immediately.
     * @param note The note to change to.
     * @param  time The time when the note should be set.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * synth.triggerAttack("C4");
     * // change to F#6 in one quarter note from now.
     * synth.setNote("F#6", "+4n");
     */ setNote(note, time) {
        const computedTime = this.toSeconds(time);
        const computedFrequency = note instanceof _frequency.FrequencyClass ? note.toFrequency() : note;
        if (this.portamento > 0 && this.getLevelAtTime(computedTime) > 0.05) {
            const portTime = this.toSeconds(this.portamento);
            this.frequency.exponentialRampTo(computedFrequency, portTime, computedTime);
        } else this.frequency.setValueAtTime(computedFrequency, computedTime);
        return this;
    }
}
_tslib.__decorate([
    _decorator.timeRange(0)
], Monophonic.prototype, "portamento", void 0);

},{"tslib":"bjkXk","../core/type/Frequency":"b1aPl","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../instrument/Instrument":"iKEFd","../core/util/Decorator":"krpMw","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iKEFd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base-class for all instruments
 */ parcelHelpers.export(exports, "Instrument", ()=>Instrument
);
var _volume = require("../component/channel/Volume");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
class Instrument extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Instrument.getDefaults(), arguments));
        /**
         * Keep track of all events scheduled to the transport
         * when the instrument is 'synced'
         */ this._scheduledEvents = [];
        /**
         * If the instrument is currently synced
         */ this._synced = false;
        this._original_triggerAttack = this.triggerAttack;
        this._original_triggerRelease = this.triggerRelease;
        const options = _defaults.optionsFromArguments(Instrument.getDefaults(), arguments);
        this._volume = this.output = new _volume.Volume({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        _interface.readOnly(this, "volume");
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            volume: 0
        });
    }
    /**
     * Sync the instrument to the Transport. All subsequent calls of
     * [[triggerAttack]] and [[triggerRelease]] will be scheduled along the transport.
     * @example
     * const fmSynth = new Tone.FMSynth().toDestination();
     * fmSynth.volume.value = -6;
     * fmSynth.sync();
     * // schedule 3 notes when the transport first starts
     * fmSynth.triggerAttackRelease("C4", "8n", 0);
     * fmSynth.triggerAttackRelease("E4", "8n", "8n");
     * fmSynth.triggerAttackRelease("G4", "8n", "4n");
     * // start the transport to hear the notes
     * Tone.Transport.start();
     */ sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 0);
        }
        return this;
    }
    /**
     * set _sync
     */ _syncState() {
        let changed = false;
        if (!this._synced) {
            this._synced = true;
            changed = true;
        }
        return changed;
    }
    /**
     * Wrap the given method so that it can be synchronized
     * @param method Which method to wrap and sync
     * @param  timePosition What position the time argument appears in
     */ _syncMethod(method, timePosition) {
        const originalMethod = this["_original_" + method] = this[method];
        this[method] = (...args)=>{
            const time = args[timePosition];
            const id = this.context.transport.schedule((t)=>{
                args[timePosition] = t;
                originalMethod.apply(this, args);
            }, time);
            this._scheduledEvents.push(id);
        };
    }
    /**
     * Unsync the instrument from the Transport
     */ unsync() {
        this._scheduledEvents.forEach((id)=>this.context.transport.clear(id)
        );
        this._scheduledEvents = [];
        if (this._synced) {
            this._synced = false;
            this.triggerAttack = this._original_triggerAttack;
            this.triggerRelease = this._original_triggerRelease;
        }
        return this;
    }
    /**
     * Trigger the attack and then the release after the duration.
     * @param  note     The note to trigger.
     * @param  duration How long the note should be held for before
     *                         triggering the release. This value must be greater than 0.
     * @param time  When the note should be triggered.
     * @param  velocity The velocity the note should be triggered at.
     * @example
     * const synth = new Tone.Synth().toDestination();
     * // trigger "C4" for the duration of an 8th note
     * synth.triggerAttackRelease("C4", "8n");
     */ triggerAttackRelease(note, duration, time, velocity) {
        const computedTime = this.toSeconds(time);
        const computedDuration = this.toSeconds(duration);
        this.triggerAttack(note, computedTime, velocity);
        this.triggerRelease(computedTime + computedDuration);
        return this;
    }
    /**
     * clean up
     * @returns {Instrument} this
     */ dispose() {
        super.dispose();
        this._volume.dispose();
        this.unsync();
        this._scheduledEvents = [];
        return this;
    }
}

},{"../component/channel/Volume":"j5Q9V","../core/context/ToneAudioNode":"iT1SZ","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1gImO":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Synth is composed simply of a [[OmniOscillator]] routed through an [[AmplitudeEnvelope]].
 * ```
 * +----------------+   +-------------------+
 * | OmniOscillator +>--> AmplitudeEnvelope +>--> Output
 * +----------------+   +-------------------+
 * ```
 * @example
 * const synth = new Tone.Synth().toDestination();
 * synth.triggerAttackRelease("C4", "8n");
 * @category Instrument
 */ parcelHelpers.export(exports, "Synth", ()=>Synth
);
var _amplitudeEnvelope = require("../component/envelope/AmplitudeEnvelope");
var _envelope = require("../component/envelope/Envelope");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _omniOscillator = require("../source/oscillator/OmniOscillator");
var _source = require("../source/Source");
var _monophonic = require("./Monophonic");
class Synth extends _monophonic.Monophonic {
    constructor(){
        super(_defaults.optionsFromArguments(Synth.getDefaults(), arguments));
        this.name = "Synth";
        const options = _defaults.optionsFromArguments(Synth.getDefaults(), arguments);
        this.oscillator = new _omniOscillator.OmniOscillator(Object.assign({
            context: this.context,
            detune: options.detune,
            onstop: ()=>this.onsilence(this)
        }, options.oscillator));
        this.frequency = this.oscillator.frequency;
        this.detune = this.oscillator.detune;
        this.envelope = new _amplitudeEnvelope.AmplitudeEnvelope(Object.assign({
            context: this.context
        }, options.envelope));
        // connect the oscillators to the output
        this.oscillator.chain(this.envelope, this.output);
        _interface.readOnly(this, [
            "oscillator",
            "frequency",
            "detune",
            "envelope"
        ]);
    }
    static getDefaults() {
        return Object.assign(_monophonic.Monophonic.getDefaults(), {
            envelope: Object.assign(_defaults.omitFromObject(_envelope.Envelope.getDefaults(), Object.keys(_toneAudioNode.ToneAudioNode.getDefaults())), {
                attack: 0.005,
                decay: 0.1,
                release: 1,
                sustain: 0.3
            }),
            oscillator: Object.assign(_defaults.omitFromObject(_omniOscillator.OmniOscillator.getDefaults(), [
                ...Object.keys(_source.Source.getDefaults()),
                "frequency",
                "detune"
            ]), {
                type: "triangle"
            })
        });
    }
    /**
     * start the attack portion of the envelope
     * @param time the time the attack should start
     * @param velocity the velocity of the note (0-1)
     */ _triggerEnvelopeAttack(time, velocity) {
        // the envelopes
        this.envelope.triggerAttack(time, velocity);
        this.oscillator.start(time);
        // if there is no release portion, stop the oscillator
        if (this.envelope.sustain === 0) {
            const computedAttack = this.toSeconds(this.envelope.attack);
            const computedDecay = this.toSeconds(this.envelope.decay);
            this.oscillator.stop(time + computedAttack + computedDecay);
        }
    }
    /**
     * start the release portion of the envelope
     * @param time the time the release should start
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this.oscillator.stop(time + this.toSeconds(this.envelope.release));
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    /**
     * clean up
     */ dispose() {
        super.dispose();
        this.oscillator.dispose();
        this.envelope.dispose();
        return this;
    }
}

},{"../component/envelope/AmplitudeEnvelope":"j0uLP","../component/envelope/Envelope":"91tjD","../core/context/ToneAudioNode":"iT1SZ","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../source/oscillator/OmniOscillator":"fKqBe","../source/Source":"31KwW","./Monophonic":"i6dl8","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"j0uLP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AmplitudeEnvelope is a Tone.Envelope connected to a gain node.
 * Unlike Tone.Envelope, which outputs the envelope's value, AmplitudeEnvelope accepts
 * an audio signal as the input and will apply the envelope to the amplitude
 * of the signal.
 * Read more about ADSR Envelopes on [Wikipedia](https://en.wikipedia.org/wiki/Synthesizer#ADSR_envelope).
 *
 * @example
 * return Tone.Offline(() => {
 * 	const ampEnv = new Tone.AmplitudeEnvelope({
 * 		attack: 0.1,
 * 		decay: 0.2,
 * 		sustain: 1.0,
 * 		release: 0.8
 * 	}).toDestination();
 * 	// create an oscillator and connect it
 * 	const osc = new Tone.Oscillator().connect(ampEnv).start();
 * 	// trigger the envelopes attack and release "8t" apart
 * 	ampEnv.triggerAttackRelease("8t");
 * }, 1.5, 1);
 * @category Component
 */ parcelHelpers.export(exports, "AmplitudeEnvelope", ()=>AmplitudeEnvelope
);
var _gain = require("../../core/context/Gain");
var _defaults = require("../../core/util/Defaults");
var _envelope = require("./Envelope");
class AmplitudeEnvelope extends _envelope.Envelope {
    constructor(){
        super(_defaults.optionsFromArguments(AmplitudeEnvelope.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]));
        this.name = "AmplitudeEnvelope";
        this._gainNode = new _gain.Gain({
            context: this.context,
            gain: 0
        });
        this.output = this._gainNode;
        this.input = this._gainNode;
        this._sig.connect(this._gainNode.gain);
        this.output = this._gainNode;
        this.input = this._gainNode;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._gainNode.dispose();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/util/Defaults":"kSyYt","./Envelope":"91tjD","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jMF1u":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * DuoSynth is a monophonic synth composed of two [[MonoSynths]] run in parallel with control over the
 * frequency ratio between the two voices and vibrato effect.
 * @example
 * const duoSynth = new Tone.DuoSynth().toDestination();
 * duoSynth.triggerAttackRelease("C4", "2n");
 * @category Instrument
 */ parcelHelpers.export(exports, "DuoSynth", ()=>DuoSynth
);
var _monophonic = require("./Monophonic");
var _monoSynth = require("./MonoSynth");
var _signal = require("../signal/Signal");
var _interface = require("../core/util/Interface");
var _lfo = require("../source/oscillator/LFO");
var _gain = require("../core/context/Gain");
var _multiply = require("../signal/Multiply");
var _defaults = require("../core/util/Defaults");
class DuoSynth extends _monophonic.Monophonic {
    constructor(){
        super(_defaults.optionsFromArguments(DuoSynth.getDefaults(), arguments));
        this.name = "DuoSynth";
        const options = _defaults.optionsFromArguments(DuoSynth.getDefaults(), arguments);
        this.voice0 = new _monoSynth.MonoSynth(Object.assign(options.voice0, {
            context: this.context,
            onsilence: ()=>this.onsilence(this)
        }));
        this.voice1 = new _monoSynth.MonoSynth(Object.assign(options.voice1, {
            context: this.context
        }));
        this.harmonicity = new _multiply.Multiply({
            context: this.context,
            units: "positive",
            value: options.harmonicity
        });
        this._vibrato = new _lfo.LFO({
            frequency: options.vibratoRate,
            context: this.context,
            min: -50,
            max: 50
        });
        // start the vibrato immediately
        this._vibrato.start();
        this.vibratoRate = this._vibrato.frequency;
        this._vibratoGain = new _gain.Gain({
            context: this.context,
            units: "normalRange",
            gain: options.vibratoAmount
        });
        this.vibratoAmount = this._vibratoGain.gain;
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: 440
        });
        this.detune = new _signal.Signal({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        // control the two voices frequency
        this.frequency.connect(this.voice0.frequency);
        this.frequency.chain(this.harmonicity, this.voice1.frequency);
        this._vibrato.connect(this._vibratoGain);
        this._vibratoGain.fan(this.voice0.detune, this.voice1.detune);
        this.detune.fan(this.voice0.detune, this.voice1.detune);
        this.voice0.connect(this.output);
        this.voice1.connect(this.output);
        _interface.readOnly(this, [
            "voice0",
            "voice1",
            "frequency",
            "vibratoAmount",
            "vibratoRate"
        ]);
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.voice0.envelope.getValueAtTime(time) + this.voice1.envelope.getValueAtTime(time);
    }
    static getDefaults() {
        return _defaults.deepMerge(_monophonic.Monophonic.getDefaults(), {
            vibratoAmount: 0.5,
            vibratoRate: 5,
            harmonicity: 1.5,
            voice0: _defaults.deepMerge(_defaults.omitFromObject(_monoSynth.MonoSynth.getDefaults(), Object.keys(_monophonic.Monophonic.getDefaults())), {
                filterEnvelope: {
                    attack: 0.01,
                    decay: 0,
                    sustain: 1,
                    release: 0.5
                },
                envelope: {
                    attack: 0.01,
                    decay: 0,
                    sustain: 1,
                    release: 0.5
                }
            }),
            voice1: _defaults.deepMerge(_defaults.omitFromObject(_monoSynth.MonoSynth.getDefaults(), Object.keys(_monophonic.Monophonic.getDefaults())), {
                filterEnvelope: {
                    attack: 0.01,
                    decay: 0,
                    sustain: 1,
                    release: 0.5
                },
                envelope: {
                    attack: 0.01,
                    decay: 0,
                    sustain: 1,
                    release: 0.5
                }
            })
        });
    }
    /**
     * Trigger the attack portion of the note
     */ _triggerEnvelopeAttack(time, velocity) {
        // @ts-ignore
        this.voice0._triggerEnvelopeAttack(time, velocity);
        // @ts-ignore
        this.voice1._triggerEnvelopeAttack(time, velocity);
    }
    /**
     * Trigger the release portion of the note
     */ _triggerEnvelopeRelease(time) {
        // @ts-ignore
        this.voice0._triggerEnvelopeRelease(time);
        // @ts-ignore
        this.voice1._triggerEnvelopeRelease(time);
        return this;
    }
    dispose() {
        super.dispose();
        this.voice0.dispose();
        this.voice1.dispose();
        this.frequency.dispose();
        this.detune.dispose();
        this._vibrato.dispose();
        this.vibratoRate.dispose();
        this._vibratoGain.dispose();
        this.harmonicity.dispose();
        return this;
    }
}

},{"./Monophonic":"i6dl8","./MonoSynth":"1Lpa8","../signal/Signal":"kfryg","../core/util/Interface":"fVoXs","../source/oscillator/LFO":"d8Ivp","../core/context/Gain":"7kpMn","../signal/Multiply":"bN8EY","../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1Lpa8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * MonoSynth is composed of one `oscillator`, one `filter`, and two `envelopes`.
 * The amplitude of the Oscillator and the cutoff frequency of the
 * Filter are controlled by Envelopes.
 * <img src="https://docs.google.com/drawings/d/1gaY1DF9_Hzkodqf8JI1Cg2VZfwSElpFQfI94IQwad38/pub?w=924&h=240">
 * @example
 * const synth = new Tone.MonoSynth({
 * 	oscillator: {
 * 		type: "square"
 * 	},
 * 	envelope: {
 * 		attack: 0.1
 * 	}
 * }).toDestination();
 * synth.triggerAttackRelease("C4", "8n");
 * @category Instrument
 */ parcelHelpers.export(exports, "MonoSynth", ()=>MonoSynth
);
var _amplitudeEnvelope = require("../component/envelope/AmplitudeEnvelope");
var _envelope = require("../component/envelope/Envelope");
var _filter = require("../component/filter/Filter");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _monophonic = require("../instrument/Monophonic");
var _omniOscillator = require("../source/oscillator/OmniOscillator");
var _source = require("../source/Source");
var _frequencyEnvelope = require("../component/envelope/FrequencyEnvelope");
var _toneAudioNode = require("../core/context/ToneAudioNode");
class MonoSynth extends _monophonic.Monophonic {
    constructor(){
        super(_defaults.optionsFromArguments(MonoSynth.getDefaults(), arguments));
        this.name = "MonoSynth";
        const options = _defaults.optionsFromArguments(MonoSynth.getDefaults(), arguments);
        this.oscillator = new _omniOscillator.OmniOscillator(Object.assign(options.oscillator, {
            context: this.context,
            detune: options.detune,
            onstop: ()=>this.onsilence(this)
        }));
        this.frequency = this.oscillator.frequency;
        this.detune = this.oscillator.detune;
        this.filter = new _filter.Filter(Object.assign(options.filter, {
            context: this.context
        }));
        this.filterEnvelope = new _frequencyEnvelope.FrequencyEnvelope(Object.assign(options.filterEnvelope, {
            context: this.context
        }));
        this.envelope = new _amplitudeEnvelope.AmplitudeEnvelope(Object.assign(options.envelope, {
            context: this.context
        }));
        // connect the oscillators to the output
        this.oscillator.chain(this.filter, this.envelope, this.output);
        // connect the filter envelope
        this.filterEnvelope.connect(this.filter.frequency);
        _interface.readOnly(this, [
            "oscillator",
            "frequency",
            "detune",
            "filter",
            "filterEnvelope",
            "envelope"
        ]);
    }
    static getDefaults() {
        return Object.assign(_monophonic.Monophonic.getDefaults(), {
            envelope: Object.assign(_defaults.omitFromObject(_envelope.Envelope.getDefaults(), Object.keys(_toneAudioNode.ToneAudioNode.getDefaults())), {
                attack: 0.005,
                decay: 0.1,
                release: 1,
                sustain: 0.9
            }),
            filter: Object.assign(_defaults.omitFromObject(_filter.Filter.getDefaults(), Object.keys(_toneAudioNode.ToneAudioNode.getDefaults())), {
                Q: 1,
                rolloff: -12,
                type: "lowpass"
            }),
            filterEnvelope: Object.assign(_defaults.omitFromObject(_frequencyEnvelope.FrequencyEnvelope.getDefaults(), Object.keys(_toneAudioNode.ToneAudioNode.getDefaults())), {
                attack: 0.6,
                baseFrequency: 200,
                decay: 0.2,
                exponent: 2,
                octaves: 3,
                release: 2,
                sustain: 0.5
            }),
            oscillator: Object.assign(_defaults.omitFromObject(_omniOscillator.OmniOscillator.getDefaults(), Object.keys(_source.Source.getDefaults())), {
                type: "sawtooth"
            })
        });
    }
    /**
     * start the attack portion of the envelope
     * @param time the time the attack should start
     * @param velocity the velocity of the note (0-1)
     */ _triggerEnvelopeAttack(time, velocity = 1) {
        this.envelope.triggerAttack(time, velocity);
        this.filterEnvelope.triggerAttack(time);
        this.oscillator.start(time);
        if (this.envelope.sustain === 0) {
            const computedAttack = this.toSeconds(this.envelope.attack);
            const computedDecay = this.toSeconds(this.envelope.decay);
            this.oscillator.stop(time + computedAttack + computedDecay);
        }
    }
    /**
     * start the release portion of the envelope
     * @param time the time the release should start
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this.filterEnvelope.triggerRelease(time);
        this.oscillator.stop(time + this.toSeconds(this.envelope.release));
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    dispose() {
        super.dispose();
        this.oscillator.dispose();
        this.envelope.dispose();
        this.filterEnvelope.dispose();
        this.filter.dispose();
        return this;
    }
}

},{"../component/envelope/AmplitudeEnvelope":"j0uLP","../component/envelope/Envelope":"91tjD","../component/filter/Filter":"5lZpJ","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../instrument/Monophonic":"i6dl8","../source/oscillator/OmniOscillator":"fKqBe","../source/Source":"31KwW","../component/envelope/FrequencyEnvelope":"i9sZY","../core/context/ToneAudioNode":"iT1SZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5lZpJ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.Filter is a filter which allows for all of the same native methods
 * as the [BiquadFilterNode](http://webaudio.github.io/web-audio-api/#the-biquadfilternode-interface).
 * Tone.Filter has the added ability to set the filter rolloff at -12
 * (default), -24 and -48.
 * @example
 * const filter = new Tone.Filter(1500, "highpass").toDestination();
 * filter.frequency.rampTo(20000, 10);
 * const noise = new Tone.Noise().connect(filter).start();
 * @category Component
 */ parcelHelpers.export(exports, "Filter", ()=>Filter
);
var _gain = require("../../core/context/Gain");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _typeCheck = require("../../core/util/TypeCheck");
var _signal = require("../../signal/Signal");
var _debug = require("../../core/util/Debug");
var _biquadFilter = require("./BiquadFilter");
class Filter extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Filter.getDefaults(), arguments, [
            "frequency",
            "type",
            "rolloff"
        ]));
        this.name = "Filter";
        this.input = new _gain.Gain({
            context: this.context
        });
        this.output = new _gain.Gain({
            context: this.context
        });
        this._filters = [];
        const options = _defaults.optionsFromArguments(Filter.getDefaults(), arguments, [
            "frequency",
            "type",
            "rolloff"
        ]);
        this._filters = [];
        this.Q = new _signal.Signal({
            context: this.context,
            units: "positive",
            value: options.Q
        });
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: options.frequency
        });
        this.detune = new _signal.Signal({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this.gain = new _signal.Signal({
            context: this.context,
            units: "decibels",
            convert: false,
            value: options.gain
        });
        this._type = options.type;
        this.rolloff = options.rolloff;
        _interface.readOnly(this, [
            "detune",
            "frequency",
            "gain",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            Q: 1,
            detune: 0,
            frequency: 350,
            gain: 0,
            rolloff: -12,
            type: "lowpass"
        });
    }
    /**
     * The type of the filter. Types: "lowpass", "highpass",
     * "bandpass", "lowshelf", "highshelf", "notch", "allpass", or "peaking".
     */ get type() {
        return this._type;
    }
    set type(type) {
        const types = [
            "lowpass",
            "highpass",
            "bandpass",
            "lowshelf",
            "highshelf",
            "notch",
            "allpass",
            "peaking"
        ];
        _debug.assert(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);
        this._type = type;
        this._filters.forEach((filter)=>filter.type = type
        );
    }
    /**
     * The rolloff of the filter which is the drop in db
     * per octave. Implemented internally by cascading filters.
     * Only accepts the values -12, -24, -48 and -96.
     */ get rolloff() {
        return this._rolloff;
    }
    set rolloff(rolloff) {
        const rolloffNum = _typeCheck.isNumber(rolloff) ? rolloff : parseInt(rolloff, 10);
        const possibilities = [
            -12,
            -24,
            -48,
            -96
        ];
        let cascadingCount = possibilities.indexOf(rolloffNum);
        // check the rolloff is valid
        _debug.assert(cascadingCount !== -1, `rolloff can only be ${possibilities.join(", ")}`);
        cascadingCount += 1;
        this._rolloff = rolloffNum;
        this.input.disconnect();
        this._filters.forEach((filter)=>filter.disconnect()
        );
        this._filters = new Array(cascadingCount);
        for(let count = 0; count < cascadingCount; count++){
            const filter = new _biquadFilter.BiquadFilter({
                context: this.context
            });
            filter.type = this._type;
            this.frequency.connect(filter.frequency);
            this.detune.connect(filter.detune);
            this.Q.connect(filter.Q);
            this.gain.connect(filter.gain);
            this._filters[count] = filter;
        }
        this._internalChannels = this._filters;
        _toneAudioNode.connectSeries(this.input, ...this._internalChannels, this.output);
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        const filterClone = new _biquadFilter.BiquadFilter({
            frequency: this.frequency.value,
            gain: this.gain.value,
            Q: this.Q.value,
            type: this._type,
            detune: this.detune.value
        });
        // start with all 1s
        const totalResponse = new Float32Array(len).map(()=>1
        );
        this._filters.forEach(()=>{
            const response = filterClone.getFrequencyResponse(len);
            response.forEach((val, i)=>totalResponse[i] *= val
            );
        });
        filterClone.dispose();
        return totalResponse;
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._filters.forEach((filter)=>{
            filter.dispose();
        });
        _interface.writable(this, [
            "detune",
            "frequency",
            "gain",
            "Q"
        ]);
        this.frequency.dispose();
        this.Q.dispose();
        this.detune.dispose();
        this.gain.dispose();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../core/util/TypeCheck":"lCqGC","../../signal/Signal":"kfryg","../../core/util/Debug":"bsxl9","./BiquadFilter":"fCKNY","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fCKNY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Thin wrapper around the native Web Audio [BiquadFilterNode](https://webaudio.github.io/web-audio-api/#biquadfilternode).
 * BiquadFilter is similar to [[Filter]] but doesn't have the option to set the "rolloff" value.
 * @category Component
 */ parcelHelpers.export(exports, "BiquadFilter", ()=>BiquadFilter
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _param = require("../../core/context/Param");
var _debug = require("../../core/util/Debug");
class BiquadFilter extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(BiquadFilter.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "BiquadFilter";
        const options = _defaults.optionsFromArguments(BiquadFilter.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        this._filter = this.context.createBiquadFilter();
        this.input = this.output = this._filter;
        this.Q = new _param.Param({
            context: this.context,
            units: "number",
            value: options.Q,
            param: this._filter.Q
        });
        this.frequency = new _param.Param({
            context: this.context,
            units: "frequency",
            value: options.frequency,
            param: this._filter.frequency
        });
        this.detune = new _param.Param({
            context: this.context,
            units: "cents",
            value: options.detune,
            param: this._filter.detune
        });
        this.gain = new _param.Param({
            context: this.context,
            units: "decibels",
            convert: false,
            value: options.gain,
            param: this._filter.gain
        });
        this.type = options.type;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            Q: 1,
            type: "lowpass",
            frequency: 350,
            detune: 0,
            gain: 0
        });
    }
    /**
     * The type of this BiquadFilterNode. For a complete list of types and their attributes, see the
     * [Web Audio API](https://webaudio.github.io/web-audio-api/#dom-biquadfiltertype-lowpass)
     */ get type() {
        return this._filter.type;
    }
    set type(type) {
        const types = [
            "lowpass",
            "highpass",
            "bandpass",
            "lowshelf",
            "highshelf",
            "notch",
            "allpass",
            "peaking"
        ];
        _debug.assert(types.indexOf(type) !== -1, `Invalid filter type: ${type}`);
        this._filter.type = type;
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        // start with all 1s
        const freqValues = new Float32Array(len);
        for(let i = 0; i < len; i++){
            const norm = Math.pow(i / len, 2);
            const freq = norm * 19980 + 20;
            freqValues[i] = freq;
        }
        const magValues = new Float32Array(len);
        const phaseValues = new Float32Array(len);
        // clone the filter to remove any connections which may be changing the value
        const filterClone = this.context.createBiquadFilter();
        filterClone.type = this.type;
        filterClone.Q.value = this.Q.value;
        filterClone.frequency.value = this.frequency.value;
        filterClone.gain.value = this.gain.value;
        filterClone.getFrequencyResponse(freqValues, magValues, phaseValues);
        return magValues;
    }
    dispose() {
        super.dispose();
        this._filter.disconnect();
        this.Q.dispose();
        this.frequency.dispose();
        this.gain.dispose();
        this.detune.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/context/Param":"2qxaM","../../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"i9sZY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FrequencyEnvelope is an [[Envelope]] which ramps between [[baseFrequency]]
 * and [[octaves]]. It can also have an optional [[exponent]] to adjust the curve
 * which it ramps.
 * @example
 * const oscillator = new Tone.Oscillator().toDestination().start();
 * const freqEnv = new Tone.FrequencyEnvelope({
 * 	attack: 0.2,
 * 	baseFrequency: "C2",
 * 	octaves: 4
 * });
 * freqEnv.connect(oscillator.frequency);
 * freqEnv.triggerAttack();
 * @category Component
 */ parcelHelpers.export(exports, "FrequencyEnvelope", ()=>FrequencyEnvelope
);
var _defaults = require("../../core/util/Defaults");
var _envelope = require("./Envelope");
var _scale = require("../../signal/Scale");
var _pow = require("../../signal/Pow");
var _debug = require("../../core/util/Debug");
class FrequencyEnvelope extends _envelope.Envelope {
    constructor(){
        super(_defaults.optionsFromArguments(FrequencyEnvelope.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]));
        this.name = "FrequencyEnvelope";
        const options = _defaults.optionsFromArguments(FrequencyEnvelope.getDefaults(), arguments, [
            "attack",
            "decay",
            "sustain",
            "release"
        ]);
        this._octaves = options.octaves;
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._exponent = this.input = new _pow.Pow({
            context: this.context,
            value: options.exponent
        });
        this._scale = this.output = new _scale.Scale({
            context: this.context,
            min: this._baseFrequency,
            max: this._baseFrequency * Math.pow(2, this._octaves)
        });
        this._sig.chain(this._exponent, this._scale);
    }
    static getDefaults() {
        return Object.assign(_envelope.Envelope.getDefaults(), {
            baseFrequency: 200,
            exponent: 1,
            octaves: 4
        });
    }
    /**
     * The envelope's minimum output value. This is the value which it
     * starts at.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(min) {
        const freq = this.toFrequency(min);
        _debug.assertRange(freq, 0);
        this._baseFrequency = freq;
        this._scale.min = this._baseFrequency;
        // update the max value when the min changes
        this.octaves = this._octaves;
    }
    /**
     * The number of octaves above the baseFrequency that the
     * envelope will scale to.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        this._scale.max = this._baseFrequency * Math.pow(2, octaves);
    }
    /**
     * The envelope's exponent value.
     */ get exponent() {
        return this._exponent.value;
    }
    set exponent(exponent) {
        this._exponent.value = exponent;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._exponent.dispose();
        this._scale.dispose();
        return this;
    }
}

},{"../../core/util/Defaults":"kSyYt","./Envelope":"91tjD","../../signal/Scale":"j7ETW","../../signal/Pow":"69awp","../../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"77bnR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FMSynth is composed of two Tone.Synths where one Tone.Synth modulates
 * the frequency of a second Tone.Synth. A lot of spectral content
 * can be explored using the modulationIndex parameter. Read more about
 * frequency modulation synthesis on Sound On Sound: [Part 1](https://web.archive.org/web/20160403123704/http://www.soundonsound.com/sos/apr00/articles/synthsecrets.htm), [Part 2](https://web.archive.org/web/20160403115835/http://www.soundonsound.com/sos/may00/articles/synth.htm).
 *
 * @example
 * const fmSynth = new Tone.FMSynth().toDestination();
 * fmSynth.triggerAttackRelease("C5", "4n");
 *
 * @category Instrument
 */ parcelHelpers.export(exports, "FMSynth", ()=>FMSynth
);
var _defaults = require("../core/util/Defaults");
var _multiply = require("../signal/Multiply");
var _modulationSynth = require("./ModulationSynth");
class FMSynth extends _modulationSynth.ModulationSynth {
    constructor(){
        super(_defaults.optionsFromArguments(FMSynth.getDefaults(), arguments));
        this.name = "FMSynth";
        const options = _defaults.optionsFromArguments(FMSynth.getDefaults(), arguments);
        this.modulationIndex = new _multiply.Multiply({
            context: this.context,
            value: options.modulationIndex
        });
        // control the two voices frequency
        this.frequency.connect(this._carrier.frequency);
        this.frequency.chain(this.harmonicity, this._modulator.frequency);
        this.frequency.chain(this.modulationIndex, this._modulationNode);
        this.detune.fan(this._carrier.detune, this._modulator.detune);
        this._modulator.connect(this._modulationNode.gain);
        this._modulationNode.connect(this._carrier.frequency);
        this._carrier.connect(this.output);
    }
    static getDefaults() {
        return Object.assign(_modulationSynth.ModulationSynth.getDefaults(), {
            modulationIndex: 10
        });
    }
    dispose() {
        super.dispose();
        this.modulationIndex.dispose();
        return this;
    }
}

},{"../core/util/Defaults":"kSyYt","../signal/Multiply":"bN8EY","./ModulationSynth":"iXFri","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1cKaV":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A highly inharmonic and spectrally complex source with a highpass filter
 * and amplitude envelope which is good for making metallophone sounds.
 * Based on CymbalSynth by [@polyrhythmatic](https://github.com/polyrhythmatic).
 * Inspiration from [Sound on Sound](https://shorturl.at/rSZ12).
 * @category Instrument
 */ parcelHelpers.export(exports, "MetalSynth", ()=>MetalSynth
);
var _envelope = require("../component/envelope/Envelope");
var _filter = require("../component/filter/Filter");
var _gain = require("../core/context/Gain");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _multiply = require("../signal/Multiply");
var _scale = require("../signal/Scale");
var _signal = require("../signal/Signal");
var _fmoscillator = require("../source/oscillator/FMOscillator");
var _monophonic = require("./Monophonic");
/**
 * Inharmonic ratio of frequencies based on the Roland TR-808
 * Taken from https://ccrma.stanford.edu/papers/tr-808-cymbal-physically-informed-circuit-bendable-digital-model
 */ const inharmRatios = [
    1,
    1.483,
    1.932,
    2.546,
    2.63,
    3.897
];
class MetalSynth extends _monophonic.Monophonic {
    constructor(){
        super(_defaults.optionsFromArguments(MetalSynth.getDefaults(), arguments));
        this.name = "MetalSynth";
        /**
         * The array of FMOscillators
         */ this._oscillators = [];
        /**
         * The frequency multipliers
         */ this._freqMultipliers = [];
        const options = _defaults.optionsFromArguments(MetalSynth.getDefaults(), arguments);
        this.detune = new _signal.Signal({
            context: this.context,
            units: "cents",
            value: options.detune
        });
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency"
        });
        this._amplitude = new _gain.Gain({
            context: this.context,
            gain: 0
        }).connect(this.output);
        this._highpass = new _filter.Filter({
            // Q: -3.0102999566398125,
            Q: 0,
            context: this.context,
            type: "highpass"
        }).connect(this._amplitude);
        for(let i = 0; i < inharmRatios.length; i++){
            const osc = new _fmoscillator.FMOscillator({
                context: this.context,
                harmonicity: options.harmonicity,
                modulationIndex: options.modulationIndex,
                modulationType: "square",
                onstop: i === 0 ? ()=>this.onsilence(this)
                 : _interface.noOp,
                type: "square"
            });
            osc.connect(this._highpass);
            this._oscillators[i] = osc;
            const mult = new _multiply.Multiply({
                context: this.context,
                value: inharmRatios[i]
            });
            this._freqMultipliers[i] = mult;
            this.frequency.chain(mult, osc.frequency);
            this.detune.connect(osc.detune);
        }
        this._filterFreqScaler = new _scale.Scale({
            context: this.context,
            max: 7000,
            min: this.toFrequency(options.resonance)
        });
        this.envelope = new _envelope.Envelope({
            attack: options.envelope.attack,
            attackCurve: "linear",
            context: this.context,
            decay: options.envelope.decay,
            release: options.envelope.release,
            sustain: 0
        });
        this.envelope.chain(this._filterFreqScaler, this._highpass.frequency);
        this.envelope.connect(this._amplitude.gain);
        // set the octaves
        this._octaves = options.octaves;
        this.octaves = options.octaves;
    }
    static getDefaults() {
        return _defaults.deepMerge(_monophonic.Monophonic.getDefaults(), {
            envelope: Object.assign(_defaults.omitFromObject(_envelope.Envelope.getDefaults(), Object.keys(_toneAudioNode.ToneAudioNode.getDefaults())), {
                attack: 0.001,
                decay: 1.4,
                release: 0.2
            }),
            harmonicity: 5.1,
            modulationIndex: 32,
            octaves: 1.5,
            resonance: 4000
        });
    }
    /**
     * Trigger the attack.
     * @param time When the attack should be triggered.
     * @param velocity The velocity that the envelope should be triggered at.
     */ _triggerEnvelopeAttack(time, velocity = 1) {
        this.envelope.triggerAttack(time, velocity);
        this._oscillators.forEach((osc)=>osc.start(time)
        );
        if (this.envelope.sustain === 0) this._oscillators.forEach((osc)=>{
            osc.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));
        });
        return this;
    }
    /**
     * Trigger the release of the envelope.
     * @param time When the release should be triggered.
     */ _triggerEnvelopeRelease(time) {
        this.envelope.triggerRelease(time);
        this._oscillators.forEach((osc)=>osc.stop(time + this.toSeconds(this.envelope.release))
        );
        return this;
    }
    getLevelAtTime(time) {
        time = this.toSeconds(time);
        return this.envelope.getValueAtTime(time);
    }
    /**
     * The modulationIndex of the oscillators which make up the source.
     * see [[FMOscillator.modulationIndex]]
     * @min 1
     * @max 100
     */ get modulationIndex() {
        return this._oscillators[0].modulationIndex.value;
    }
    set modulationIndex(val) {
        this._oscillators.forEach((osc)=>osc.modulationIndex.value = val
        );
    }
    /**
     * The harmonicity of the oscillators which make up the source.
     * see Tone.FMOscillator.harmonicity
     * @min 0.1
     * @max 10
     */ get harmonicity() {
        return this._oscillators[0].harmonicity.value;
    }
    set harmonicity(val) {
        this._oscillators.forEach((osc)=>osc.harmonicity.value = val
        );
    }
    /**
     * The lower level of the highpass filter which is attached to the envelope.
     * This value should be between [0, 7000]
     * @min 0
     * @max 7000
     */ get resonance() {
        return this._filterFreqScaler.min;
    }
    set resonance(val) {
        this._filterFreqScaler.min = this.toFrequency(val);
        this.octaves = this._octaves;
    }
    /**
     * The number of octaves above the "resonance" frequency
     * that the filter ramps during the attack/decay envelope
     * @min 0
     * @max 8
     */ get octaves() {
        return this._octaves;
    }
    set octaves(val) {
        this._octaves = val;
        this._filterFreqScaler.max = this._filterFreqScaler.min * Math.pow(2, val);
    }
    dispose() {
        super.dispose();
        this._oscillators.forEach((osc)=>osc.dispose()
        );
        this._freqMultipliers.forEach((freqMult)=>freqMult.dispose()
        );
        this.frequency.dispose();
        this.detune.dispose();
        this._filterFreqScaler.dispose();
        this._amplitude.dispose();
        this.envelope.dispose();
        this._highpass.dispose();
        return this;
    }
}

},{"../component/envelope/Envelope":"91tjD","../component/filter/Filter":"5lZpJ","../core/context/Gain":"7kpMn","../core/context/ToneAudioNode":"iT1SZ","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../signal/Multiply":"bN8EY","../signal/Scale":"j7ETW","../signal/Signal":"kfryg","../source/oscillator/FMOscillator":"9a3wa","./Monophonic":"i6dl8","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hqDmG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * MembraneSynth makes kick and tom sounds using a single oscillator
 * with an amplitude envelope and frequency ramp. A Tone.OmniOscillator
 * is routed through a Tone.AmplitudeEnvelope to the output. The drum
 * quality of the sound comes from the frequency envelope applied
 * during MembraneSynth.triggerAttack(note). The frequency envelope
 * starts at <code>note * .octaves</code> and ramps to <code>note</code>
 * over the duration of <code>.pitchDecay</code>.
 * @example
 * const synth = new Tone.MembraneSynth().toDestination();
 * synth.triggerAttackRelease("C2", "8n");
 * @category Instrument
 */ parcelHelpers.export(exports, "MembraneSynth", ()=>MembraneSynth
);
var _tslib = require("tslib");
var _frequency = require("../core/type/Frequency");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _monophonic = require("./Monophonic");
var _synth = require("./Synth");
var _decorator = require("../core/util/Decorator");
class MembraneSynth extends _synth.Synth {
    constructor(){
        super(_defaults.optionsFromArguments(MembraneSynth.getDefaults(), arguments));
        this.name = "MembraneSynth";
        /**
         * Portamento is ignored in this synth. use pitch decay instead.
         */ this.portamento = 0;
        const options = _defaults.optionsFromArguments(MembraneSynth.getDefaults(), arguments);
        this.pitchDecay = options.pitchDecay;
        this.octaves = options.octaves;
        _interface.readOnly(this, [
            "oscillator",
            "envelope"
        ]);
    }
    static getDefaults() {
        return _defaults.deepMerge(_monophonic.Monophonic.getDefaults(), _synth.Synth.getDefaults(), {
            envelope: {
                attack: 0.001,
                attackCurve: "exponential",
                decay: 0.4,
                release: 1.4,
                sustain: 0.01
            },
            octaves: 10,
            oscillator: {
                type: "sine"
            },
            pitchDecay: 0.05
        });
    }
    setNote(note, time) {
        const seconds = this.toSeconds(time);
        const hertz = this.toFrequency(note instanceof _frequency.FrequencyClass ? note.toFrequency() : note);
        const maxNote = hertz * this.octaves;
        this.oscillator.frequency.setValueAtTime(maxNote, seconds);
        this.oscillator.frequency.exponentialRampToValueAtTime(hertz, seconds + this.toSeconds(this.pitchDecay));
        return this;
    }
    dispose() {
        super.dispose();
        return this;
    }
}
_tslib.__decorate([
    _decorator.range(0)
], MembraneSynth.prototype, "octaves", void 0);
_tslib.__decorate([
    _decorator.timeRange(0)
], MembraneSynth.prototype, "pitchDecay", void 0);

},{"tslib":"bjkXk","../core/type/Frequency":"b1aPl","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","./Monophonic":"i6dl8","./Synth":"1gImO","../core/util/Decorator":"krpMw","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"c8hyC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.NoiseSynth is composed of [[Noise]] through an [[AmplitudeEnvelope]].
 * ```
 * +-------+   +-------------------+
 * | Noise +>--> AmplitudeEnvelope +>--> Output
 * +-------+   +-------------------+
 * ```
 * @example
 * const noiseSynth = new Tone.NoiseSynth().toDestination();
 * noiseSynth.triggerAttackRelease("8n", 0.05);
 * @category Instrument
 */ parcelHelpers.export(exports, "NoiseSynth", ()=>NoiseSynth
);
var _amplitudeEnvelope = require("../component/envelope/AmplitudeEnvelope");
var _defaults = require("../core/util/Defaults");
var _noise = require("../source/Noise");
var _instrument = require("./Instrument");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _envelope = require("../component/envelope/Envelope");
var _source = require("../source/Source");
class NoiseSynth extends _instrument.Instrument {
    constructor(){
        super(_defaults.optionsFromArguments(NoiseSynth.getDefaults(), arguments));
        this.name = "NoiseSynth";
        const options = _defaults.optionsFromArguments(NoiseSynth.getDefaults(), arguments);
        this.noise = new _noise.Noise(Object.assign({
            context: this.context
        }, options.noise));
        this.envelope = new _amplitudeEnvelope.AmplitudeEnvelope(Object.assign({
            context: this.context
        }, options.envelope));
        // connect the noise to the output
        this.noise.chain(this.envelope, this.output);
    }
    static getDefaults() {
        return Object.assign(_instrument.Instrument.getDefaults(), {
            envelope: Object.assign(_defaults.omitFromObject(_envelope.Envelope.getDefaults(), Object.keys(_toneAudioNode.ToneAudioNode.getDefaults())), {
                decay: 0.1,
                sustain: 0
            }),
            noise: Object.assign(_defaults.omitFromObject(_noise.Noise.getDefaults(), Object.keys(_source.Source.getDefaults())), {
                type: "white"
            })
        });
    }
    /**
     * Start the attack portion of the envelopes. Unlike other
     * instruments, Tone.NoiseSynth doesn't have a note.
     * @example
     * const noiseSynth = new Tone.NoiseSynth().toDestination();
     * noiseSynth.triggerAttack();
     */ triggerAttack(time, velocity = 1) {
        time = this.toSeconds(time);
        // the envelopes
        this.envelope.triggerAttack(time, velocity);
        // start the noise
        this.noise.start(time);
        if (this.envelope.sustain === 0) this.noise.stop(time + this.toSeconds(this.envelope.attack) + this.toSeconds(this.envelope.decay));
        return this;
    }
    /**
     * Start the release portion of the envelopes.
     */ triggerRelease(time) {
        time = this.toSeconds(time);
        this.envelope.triggerRelease(time);
        this.noise.stop(time + this.toSeconds(this.envelope.release));
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 0);
            this._syncMethod("triggerRelease", 0);
        }
        return this;
    }
    triggerAttackRelease(duration, time, velocity = 1) {
        time = this.toSeconds(time);
        duration = this.toSeconds(duration);
        this.triggerAttack(time, velocity);
        this.triggerRelease(time + duration);
        return this;
    }
    dispose() {
        super.dispose();
        this.noise.dispose();
        this.envelope.dispose();
        return this;
    }
}

},{"../component/envelope/AmplitudeEnvelope":"j0uLP","../core/util/Defaults":"kSyYt","../source/Noise":"hF5D5","./Instrument":"iKEFd","../core/context/ToneAudioNode":"iT1SZ","../component/envelope/Envelope":"91tjD","../source/Source":"31KwW","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9QKPZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Karplus-String string synthesis.
 * @example
 * const plucky = new Tone.PluckSynth().toDestination();
 * plucky.triggerAttack("C4", "+0.5");
 * plucky.triggerAttack("C3", "+1");
 * plucky.triggerAttack("C2", "+1.5");
 * plucky.triggerAttack("C1", "+2");
 * @category Instrument
 */ parcelHelpers.export(exports, "PluckSynth", ()=>PluckSynth
);
var _lowpassCombFilter = require("../component/filter/LowpassCombFilter");
var _defaults = require("../core/util/Defaults");
var _noise = require("../source/Noise");
var _instrument = require("./Instrument");
class PluckSynth extends _instrument.Instrument {
    constructor(){
        super(_defaults.optionsFromArguments(PluckSynth.getDefaults(), arguments));
        this.name = "PluckSynth";
        const options = _defaults.optionsFromArguments(PluckSynth.getDefaults(), arguments);
        this._noise = new _noise.Noise({
            context: this.context,
            type: "pink"
        });
        this.attackNoise = options.attackNoise;
        this._lfcf = new _lowpassCombFilter.LowpassCombFilter({
            context: this.context,
            dampening: options.dampening,
            resonance: options.resonance
        });
        this.resonance = options.resonance;
        this.release = options.release;
        this._noise.connect(this._lfcf);
        this._lfcf.connect(this.output);
    }
    static getDefaults() {
        return _defaults.deepMerge(_instrument.Instrument.getDefaults(), {
            attackNoise: 1,
            dampening: 4000,
            resonance: 0.7,
            release: 1
        });
    }
    /**
     * The dampening control. i.e. the lowpass filter frequency of the comb filter
     * @min 0
     * @max 7000
     */ get dampening() {
        return this._lfcf.dampening;
    }
    set dampening(fq) {
        this._lfcf.dampening = fq;
    }
    triggerAttack(note, time) {
        const freq = this.toFrequency(note);
        time = this.toSeconds(time);
        const delayAmount = 1 / freq;
        this._lfcf.delayTime.setValueAtTime(delayAmount, time);
        this._noise.start(time);
        this._noise.stop(time + delayAmount * this.attackNoise);
        this._lfcf.resonance.cancelScheduledValues(time);
        this._lfcf.resonance.setValueAtTime(this.resonance, time);
        return this;
    }
    /**
     * Ramp down the [[resonance]] to 0 over the duration of the release time.
     */ triggerRelease(time) {
        this._lfcf.resonance.linearRampTo(0, this.release, time);
        return this;
    }
    dispose() {
        super.dispose();
        this._noise.dispose();
        this._lfcf.dispose();
        return this;
    }
}

},{"../component/filter/LowpassCombFilter":"ezloU","../core/util/Defaults":"kSyYt","../source/Noise":"hF5D5","./Instrument":"iKEFd","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ezloU":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A lowpass feedback comb filter. It is similar to
 * [[FeedbackCombFilter]], but includes a lowpass filter.
 * @category Component
 */ parcelHelpers.export(exports, "LowpassCombFilter", ()=>LowpassCombFilter
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _feedbackCombFilter = require("./FeedbackCombFilter");
var _onePoleFilter = require("./OnePoleFilter");
class LowpassCombFilter extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(LowpassCombFilter.getDefaults(), arguments, [
            "delayTime",
            "resonance",
            "dampening"
        ]));
        this.name = "LowpassCombFilter";
        const options = _defaults.optionsFromArguments(LowpassCombFilter.getDefaults(), arguments, [
            "delayTime",
            "resonance",
            "dampening"
        ]);
        this._combFilter = this.output = new _feedbackCombFilter.FeedbackCombFilter({
            context: this.context,
            delayTime: options.delayTime,
            resonance: options.resonance
        });
        this.delayTime = this._combFilter.delayTime;
        this.resonance = this._combFilter.resonance;
        this._lowpass = this.input = new _onePoleFilter.OnePoleFilter({
            context: this.context,
            frequency: options.dampening,
            type: "lowpass"
        });
        // connections
        this._lowpass.connect(this._combFilter);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            dampening: 3000,
            delayTime: 0.1,
            resonance: 0.5
        });
    }
    /**
     * The dampening control of the feedback
     */ get dampening() {
        return this._lowpass.frequency;
    }
    set dampening(fq) {
        this._lowpass.frequency = fq;
    }
    dispose() {
        super.dispose();
        this._combFilter.dispose();
        this._lowpass.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","./FeedbackCombFilter":"iTrd6","./OnePoleFilter":"6YRG8","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iTrd6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Comb filters are basic building blocks for physical modeling. Read more
 * about comb filters on [CCRMA's website](https://ccrma.stanford.edu/~jos/pasp/Feedback_Comb_Filters.html).
 *
 * This comb filter is implemented with the AudioWorkletNode which allows it to have feedback delays less than the
 * Web Audio processing block of 128 samples. There is a polyfill for browsers that don't yet support the
 * AudioWorkletNode, but it will add some latency and have slower performance than the AudioWorkletNode.
 * @category Component
 */ parcelHelpers.export(exports, "FeedbackCombFilter", ()=>FeedbackCombFilter
);
var _gain = require("../../core/context/Gain");
var _param = require("../../core/context/Param");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _toneAudioWorklet = require("../../core/worklet/ToneAudioWorklet");
var _feedbackCombFilterWorklet = require("./FeedbackCombFilter.worklet");
class FeedbackCombFilter extends _toneAudioWorklet.ToneAudioWorklet {
    constructor(){
        super(_defaults.optionsFromArguments(FeedbackCombFilter.getDefaults(), arguments, [
            "delayTime",
            "resonance"
        ]));
        this.name = "FeedbackCombFilter";
        const options = _defaults.optionsFromArguments(FeedbackCombFilter.getDefaults(), arguments, [
            "delayTime",
            "resonance"
        ]);
        this.input = new _gain.Gain({
            context: this.context
        });
        this.output = new _gain.Gain({
            context: this.context
        });
        this.delayTime = new _param.Param({
            context: this.context,
            value: options.delayTime,
            units: "time",
            minValue: 0,
            maxValue: 1,
            param: this._dummyParam,
            swappable: true
        });
        this.resonance = new _param.Param({
            context: this.context,
            value: options.resonance,
            units: "normalRange",
            param: this._dummyParam,
            swappable: true
        });
        _interface.readOnly(this, [
            "resonance",
            "delayTime"
        ]);
    }
    _audioWorkletName() {
        return _feedbackCombFilterWorklet.workletName;
    }
    /**
     * The default parameters
     */ static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            delayTime: 0.1,
            resonance: 0.5
        });
    }
    onReady(node) {
        _toneAudioNode.connectSeries(this.input, node, this.output);
        const delayTime = node.parameters.get("delayTime");
        this.delayTime.setParam(delayTime);
        const feedback = node.parameters.get("feedback");
        this.resonance.setParam(feedback);
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.delayTime.dispose();
        this.resonance.dispose();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/Param":"2qxaM","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../core/worklet/ToneAudioWorklet":"9RUwz","./FeedbackCombFilter.worklet":"aUZGg","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9RUwz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "ToneAudioWorklet", ()=>ToneAudioWorklet
);
var _toneAudioNode = require("../context/ToneAudioNode");
var _interface = require("../util/Interface");
var _workletGlobalScope = require("./WorkletGlobalScope");
class ToneAudioWorklet extends _toneAudioNode.ToneAudioNode {
    constructor(options){
        super(options);
        this.name = "ToneAudioWorklet";
        /**
         * The constructor options for the node
         */ this.workletOptions = {
        };
        /**
         * Callback which is invoked when there is an error in the processing
         */ this.onprocessorerror = _interface.noOp;
        const blobUrl = URL.createObjectURL(new Blob([
            _workletGlobalScope.getWorkletGlobalScope()
        ], {
            type: "text/javascript"
        }));
        const name = this._audioWorkletName();
        this._dummyGain = this.context.createGain();
        this._dummyParam = this._dummyGain.gain;
        // Register the processor
        this.context.addAudioWorkletModule(blobUrl, name).then(()=>{
            // create the worklet when it's read
            if (!this.disposed) {
                this._worklet = this.context.createAudioWorkletNode(name, this.workletOptions);
                this._worklet.onprocessorerror = this.onprocessorerror.bind(this);
                this.onReady(this._worklet);
            }
        });
    }
    dispose() {
        super.dispose();
        this._dummyGain.disconnect();
        if (this._worklet) {
            this._worklet.port.postMessage("dispose");
            this._worklet.disconnect();
        }
        return this;
    }
}

},{"../context/ToneAudioNode":"iT1SZ","../util/Interface":"fVoXs","./WorkletGlobalScope":"eDhav","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"eDhav":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Add a class to the AudioWorkletGlobalScope
 */ parcelHelpers.export(exports, "addToWorklet", ()=>addToWorklet
);
/**
 * Register a processor in the AudioWorkletGlobalScope with the given name
 */ parcelHelpers.export(exports, "registerProcessor", ()=>registerProcessor
);
/**
 * Get all of the modules which have been registered to the AudioWorkletGlobalScope
 */ parcelHelpers.export(exports, "getWorkletGlobalScope", ()=>getWorkletGlobalScope
);
/**
 * All of the classes or functions which are loaded into the AudioWorkletGlobalScope
 */ const workletContext = new Set();
function addToWorklet(classOrFunction) {
    workletContext.add(classOrFunction);
}
function registerProcessor(name, classDesc) {
    const processor = /* javascript */ `registerProcessor("${name}", ${classDesc})`;
    workletContext.add(processor);
}
function getWorkletGlobalScope() {
    return Array.from(workletContext).join("\n");
}

},{"@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aUZGg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "workletName", ()=>workletName
);
var _singleIOProcessorWorklet = require("../../core/worklet/SingleIOProcessor.worklet");
var _delayLineWorklet = require("../../core/worklet/DelayLine.worklet");
var _workletGlobalScope = require("../../core/worklet/WorkletGlobalScope");
const workletName = "feedback-comb-filter";
const feedbackCombFilter = /* javascript */ `\n	class FeedbackCombFilterWorklet extends SingleIOProcessor {\n\n		constructor(options) {\n			super(options);\n			this.delayLine = new DelayLine(this.sampleRate, options.channelCount || 2);\n		}\n\n		static get parameterDescriptors() {\n			return [{\n				name: "delayTime",\n				defaultValue: 0.1,\n				minValue: 0,\n				maxValue: 1,\n				automationRate: "k-rate"\n			}, {\n				name: "feedback",\n				defaultValue: 0.5,\n				minValue: 0,\n				maxValue: 0.9999,\n				automationRate: "k-rate"\n			}];\n		}\n\n		generate(input, channel, parameters) {\n			const delayedSample = this.delayLine.get(channel, parameters.delayTime * this.sampleRate);\n			this.delayLine.push(channel, input + delayedSample * parameters.feedback);\n			return delayedSample;\n		}\n	}\n`;
_workletGlobalScope.registerProcessor(workletName, feedbackCombFilter);

},{"../../core/worklet/SingleIOProcessor.worklet":"khtRN","../../core/worklet/DelayLine.worklet":"eBaxN","../../core/worklet/WorkletGlobalScope":"eDhav","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"khtRN":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "singleIOProcess", ()=>singleIOProcess
);
var _toneAudioWorkletProcessorWorklet = require("./ToneAudioWorkletProcessor.worklet");
var _workletGlobalScope = require("./WorkletGlobalScope");
const singleIOProcess = /* javascript */ `\n	/**\n	 * Abstract class for a single input/output processor. \n	 * has a 'generate' function which processes one sample at a time\n	 */\n	class SingleIOProcessor extends ToneAudioWorkletProcessor {\n\n		constructor(options) {\n			super(Object.assign(options, {\n				numberOfInputs: 1,\n				numberOfOutputs: 1\n			}));\n			/**\n			 * Holds the name of the parameter and a single value of that\n			 * parameter at the current sample\n			 * @type { [name: string]: number }\n			 */\n			this.params = {}\n		}\n\n		/**\n		 * Generate an output sample from the input sample and parameters\n		 * @abstract\n		 * @param input number\n		 * @param channel number\n		 * @param parameters { [name: string]: number }\n		 * @returns number\n		 */\n		generate(){}\n\n		/**\n		 * Update the private params object with the \n		 * values of the parameters at the given index\n		 * @param parameters { [name: string]: Float32Array },\n		 * @param index number\n		 */\n		updateParams(parameters, index) {\n			for (const paramName in parameters) {\n				const param = parameters[paramName];\n				if (param.length > 1) {\n					this.params[paramName] = parameters[paramName][index];\n				} else {\n					this.params[paramName] = parameters[paramName][0];\n				}\n			}\n		}\n\n		/**\n		 * Process a single frame of the audio\n		 * @param inputs Float32Array[][]\n		 * @param outputs Float32Array[][]\n		 */\n		process(inputs, outputs, parameters) {\n			const input = inputs[0];\n			const output = outputs[0];\n			// get the parameter values\n			const channelCount = Math.max(input && input.length || 0, output.length);\n			for (let sample = 0; sample < this.blockSize; sample++) {\n				this.updateParams(parameters, sample);\n				for (let channel = 0; channel < channelCount; channel++) {\n					const inputSample = input && input.length ? input[channel][sample] : 0;\n					output[channel][sample] = this.generate(inputSample, channel, this.params);\n				}\n			}\n			return !this.disposed;\n		}\n	};\n`;
_workletGlobalScope.addToWorklet(singleIOProcess);

},{"./ToneAudioWorkletProcessor.worklet":"19L6v","./WorkletGlobalScope":"eDhav","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"19L6v":[function(require,module,exports) {
var _workletGlobalScope = require("./WorkletGlobalScope");
const toneAudioWorkletProcessor = /* javascript */ `\n	/**\n	 * The base AudioWorkletProcessor for use in Tone.js. Works with the [[ToneAudioWorklet]]. \n	 */\n	class ToneAudioWorkletProcessor extends AudioWorkletProcessor {\n\n		constructor(options) {\n			\n			super(options);\n			/**\n			 * If the processor was disposed or not. Keep alive until it's disposed.\n			 */\n			this.disposed = false;\n		   	/** \n			 * The number of samples in the processing block\n			 */\n			this.blockSize = 128;\n			/**\n			 * the sample rate\n			 */\n			this.sampleRate = sampleRate;\n\n			this.port.onmessage = (event) => {\n				// when it receives a dispose \n				if (event.data === "dispose") {\n					this.disposed = true;\n				}\n			};\n		}\n	}\n`;
_workletGlobalScope.addToWorklet(toneAudioWorkletProcessor);

},{"./WorkletGlobalScope":"eDhav"}],"eBaxN":[function(require,module,exports) {
var _workletGlobalScope = require("./WorkletGlobalScope");
const delayLine = /* javascript */ `\n	/**\n	 * A multichannel buffer for use within an AudioWorkletProcessor as a delay line\n	 */\n	class DelayLine {\n		\n		constructor(size, channels) {\n			this.buffer = [];\n			this.writeHead = []\n			this.size = size;\n\n			// create the empty channels\n			for (let i = 0; i < channels; i++) {\n				this.buffer[i] = new Float32Array(this.size);\n				this.writeHead[i] = 0;\n			}\n		}\n\n		/**\n		 * Push a value onto the end\n		 * @param channel number\n		 * @param value number\n		 */\n		push(channel, value) {\n			this.writeHead[channel] += 1;\n			if (this.writeHead[channel] > this.size) {\n				this.writeHead[channel] = 0;\n			}\n			this.buffer[channel][this.writeHead[channel]] = value;\n		}\n\n		/**\n		 * Get the recorded value of the channel given the delay\n		 * @param channel number\n		 * @param delay number delay samples\n		 */\n		get(channel, delay) {\n			let readHead = this.writeHead[channel] - Math.floor(delay);\n			if (readHead < 0) {\n				readHead += this.size;\n			}\n			return this.buffer[channel][readHead];\n		}\n	}\n`;
_workletGlobalScope.addToWorklet(delayLine);

},{"./WorkletGlobalScope":"eDhav"}],"6YRG8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A one pole filter with 6db-per-octave rolloff. Either "highpass" or "lowpass".
 * Note that changing the type or frequency may result in a discontinuity which
 * can sound like a click or pop.
 * References:
 * * http://www.earlevel.com/main/2012/12/15/a-one-pole-filter/
 * * http://www.dspguide.com/ch19/2.htm
 * * https://github.com/vitaliy-bobrov/js-rocks/blob/master/src/app/audio/effects/one-pole-filters.ts
 * @category Component
 */ parcelHelpers.export(exports, "OnePoleFilter", ()=>OnePoleFilter
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _gain = require("../../core/context/Gain");
class OnePoleFilter extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(OnePoleFilter.getDefaults(), arguments, [
            "frequency",
            "type"
        ]));
        this.name = "OnePoleFilter";
        const options = _defaults.optionsFromArguments(OnePoleFilter.getDefaults(), arguments, [
            "frequency",
            "type"
        ]);
        this._frequency = options.frequency;
        this._type = options.type;
        this.input = new _gain.Gain({
            context: this.context
        });
        this.output = new _gain.Gain({
            context: this.context
        });
        this._createFilter();
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            frequency: 880,
            type: "lowpass"
        });
    }
    /**
     * Create a filter and dispose the old one
     */ _createFilter() {
        const oldFilter = this._filter;
        const freq = this.toFrequency(this._frequency);
        const t = 1 / (2 * Math.PI * freq);
        if (this._type === "lowpass") {
            const a0 = 1 / (t * this.context.sampleRate);
            const b1 = a0 - 1;
            this._filter = this.context.createIIRFilter([
                a0,
                0
            ], [
                1,
                b1
            ]);
        } else {
            const b1 = 1 / (t * this.context.sampleRate) - 1;
            this._filter = this.context.createIIRFilter([
                1,
                -1
            ], [
                1,
                b1
            ]);
        }
        this.input.chain(this._filter, this.output);
        if (oldFilter) // dispose it on the next block
        this.context.setTimeout(()=>{
            if (!this.disposed) {
                this.input.disconnect(oldFilter);
                oldFilter.disconnect();
            }
        }, this.blockTime);
    }
    /**
     * The frequency value.
     */ get frequency() {
        return this._frequency;
    }
    set frequency(fq) {
        this._frequency = fq;
        this._createFilter();
    }
    /**
     * The OnePole Filter type, either "highpass" or "lowpass"
     */ get type() {
        return this._type;
    }
    set type(t) {
        this._type = t;
        this._createFilter();
    }
    /**
     * Get the frequency response curve. This curve represents how the filter
     * responses to frequencies between 20hz-20khz.
     * @param  len The number of values to return
     * @return The frequency response curve between 20-20kHz
     */ getFrequencyResponse(len = 128) {
        const freqValues = new Float32Array(len);
        for(let i = 0; i < len; i++){
            const norm = Math.pow(i / len, 2);
            const freq = norm * 19980 + 20;
            freqValues[i] = freq;
        }
        const magValues = new Float32Array(len);
        const phaseValues = new Float32Array(len);
        this._filter.getFrequencyResponse(freqValues, magValues, phaseValues);
        return magValues;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this._filter.disconnect();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/context/Gain":"7kpMn","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"1DZrk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PolySynth handles voice creation and allocation for any
 * instruments passed in as the second paramter. PolySynth is
 * not a synthesizer by itself, it merely manages voices of
 * one of the other types of synths, allowing any of the
 * monophonic synthesizers to be polyphonic.
 *
 * @example
 * const synth = new Tone.PolySynth().toDestination();
 * // set the attributes across all the voices using 'set'
 * synth.set({ detune: -1200 });
 * // play a chord
 * synth.triggerAttackRelease(["C4", "E4", "A4"], 1);
 * @category Instrument
 */ parcelHelpers.export(exports, "PolySynth", ()=>PolySynth
);
var _midi = require("../core/type/Midi");
var _defaults = require("../core/util/Defaults");
var _typeCheck = require("../core/util/TypeCheck");
var _instrument = require("./Instrument");
var _synth = require("./Synth");
var _debug = require("../core/util/Debug");
class PolySynth extends _instrument.Instrument {
    constructor(){
        super(_defaults.optionsFromArguments(PolySynth.getDefaults(), arguments, [
            "voice",
            "options"
        ]));
        this.name = "PolySynth";
        /**
         * The voices which are not currently in use
         */ this._availableVoices = [];
        /**
         * The currently active voices
         */ this._activeVoices = [];
        /**
         * All of the allocated voices for this synth.
         */ this._voices = [];
        /**
         * The GC timeout. Held so that it could be cancelled when the node is disposed.
         */ this._gcTimeout = -1;
        /**
         * A moving average of the number of active voices
         */ this._averageActiveVoices = 0;
        const options1 = _defaults.optionsFromArguments(PolySynth.getDefaults(), arguments, [
            "voice",
            "options"
        ]);
        // check against the old API (pre 14.3.0)
        _debug.assert(!_typeCheck.isNumber(options1.voice), "DEPRECATED: The polyphony count is no longer the first argument.");
        const defaults = options1.voice.getDefaults();
        this.options = Object.assign(defaults, options1.options);
        this.voice = options1.voice;
        this.maxPolyphony = options1.maxPolyphony;
        // create the first voice
        this._dummyVoice = this._getNextAvailableVoice();
        // remove it from the voices list
        const index = this._voices.indexOf(this._dummyVoice);
        this._voices.splice(index, 1);
        // kick off the GC interval
        this._gcTimeout = this.context.setInterval(this._collectGarbage.bind(this), 1);
    }
    static getDefaults() {
        return Object.assign(_instrument.Instrument.getDefaults(), {
            maxPolyphony: 32,
            options: {
            },
            voice: _synth.Synth
        });
    }
    /**
     * The number of active voices.
     */ get activeVoices() {
        return this._activeVoices.length;
    }
    /**
     * Invoked when the source is done making sound, so that it can be
     * readded to the pool of available voices
     */ _makeVoiceAvailable(voice) {
        this._availableVoices.push(voice);
        // remove the midi note from 'active voices'
        const activeVoiceIndex = this._activeVoices.findIndex((e)=>e.voice === voice
        );
        this._activeVoices.splice(activeVoiceIndex, 1);
    }
    /**
     * Get an available voice from the pool of available voices.
     * If one is not available and the maxPolyphony limit is reached,
     * steal a voice, otherwise return null.
     */ _getNextAvailableVoice() {
        // if there are available voices, return the first one
        if (this._availableVoices.length) return this._availableVoices.shift();
        else if (this._voices.length < this.maxPolyphony) {
            // otherwise if there is still more maxPolyphony, make a new voice
            const voice = new this.voice(Object.assign(this.options, {
                context: this.context,
                onsilence: this._makeVoiceAvailable.bind(this)
            }));
            voice.connect(this.output);
            this._voices.push(voice);
            return voice;
        } else _debug.warn("Max polyphony exceeded. Note dropped.");
    }
    /**
     * Occasionally check if there are any allocated voices which can be cleaned up.
     */ _collectGarbage() {
        this._averageActiveVoices = Math.max(this._averageActiveVoices * 0.95, this.activeVoices);
        if (this._availableVoices.length && this._voices.length > Math.ceil(this._averageActiveVoices + 1)) {
            // take off an available note
            const firstAvail = this._availableVoices.shift();
            const index1 = this._voices.indexOf(firstAvail);
            this._voices.splice(index1, 1);
            if (!this.context.isOffline) firstAvail.dispose();
        }
    }
    /**
     * Internal method which triggers the attack
     */ _triggerAttack(notes, time, velocity) {
        notes.forEach((note)=>{
            const midiNote = new _midi.MidiClass(this.context, note).toMidi();
            const voice = this._getNextAvailableVoice();
            if (voice) {
                voice.triggerAttack(note, time, velocity);
                this._activeVoices.push({
                    midi: midiNote,
                    voice,
                    released: false
                });
                this.log("triggerAttack", note, time);
            }
        });
    }
    /**
     * Internal method which triggers the release
     */ _triggerRelease(notes, time) {
        notes.forEach((note)=>{
            const midiNote = new _midi.MidiClass(this.context, note).toMidi();
            const event = this._activeVoices.find(({ midi , released  })=>midi === midiNote && !released
            );
            if (event) {
                // trigger release on that note
                event.voice.triggerRelease(time);
                // mark it as released
                event.released = true;
                this.log("triggerRelease", note, time);
            }
        });
    }
    /**
     * Schedule the attack/release events. If the time is in the future, then it should set a timeout
     * to wait for just-in-time scheduling
     */ _scheduleEvent(type, notes, time, velocity) {
        _debug.assert(!this.disposed, "Synth was already disposed");
        // if the notes are greater than this amount of time in the future, they should be scheduled with setTimeout
        if (time <= this.now()) {
            // do it immediately
            if (type === "attack") this._triggerAttack(notes, time, velocity);
            else this._triggerRelease(notes, time);
        } else // schedule it to start in the future
        this.context.setTimeout(()=>{
            this._scheduleEvent(type, notes, time, velocity);
        }, time - this.now());
    }
    /**
     * Trigger the attack portion of the note
     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
     * @param  time  The start time of the note.
     * @param velocity The velocity of the note.
     * @example
     * const synth = new Tone.PolySynth(Tone.FMSynth).toDestination();
     * // trigger a chord immediately with a velocity of 0.2
     * synth.triggerAttack(["Ab3", "C4", "F5"], Tone.now(), 0.2);
     */ triggerAttack(notes, time, velocity) {
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        const computedTime = this.toSeconds(time);
        this._scheduleEvent("attack", notes, computedTime, velocity);
        return this;
    }
    /**
     * Trigger the release of the note. Unlike monophonic instruments,
     * a note (or array of notes) needs to be passed in as the first argument.
     * @param  notes The notes to play. Accepts a single Frequency or an array of frequencies.
     * @param  time  When the release will be triggered.
     * @example
     * @example
     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
     * poly.triggerAttack(["Ab3", "C4", "F5"]);
     * // trigger the release of the given notes.
     * poly.triggerRelease(["Ab3", "C4"], "+1");
     * poly.triggerRelease("F5", "+3");
     */ triggerRelease(notes, time) {
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        const computedTime = this.toSeconds(time);
        this._scheduleEvent("release", notes, computedTime);
        return this;
    }
    /**
     * Trigger the attack and release after the specified duration
     * @param  notes The notes to play. Accepts a single  Frequency or an array of frequencies.
     * @param  duration the duration of the note
     * @param  time  if no time is given, defaults to now
     * @param  velocity the velocity of the attack (0-1)
     * @example
     * const poly = new Tone.PolySynth(Tone.AMSynth).toDestination();
     * // can pass in an array of durations as well
     * poly.triggerAttackRelease(["Eb3", "G4", "Bb4", "D5"], [4, 3, 2, 1]);
     */ triggerAttackRelease(notes, duration, time, velocity) {
        const computedTime = this.toSeconds(time);
        this.triggerAttack(notes, computedTime, velocity);
        if (_typeCheck.isArray(duration)) {
            _debug.assert(_typeCheck.isArray(notes), "If the duration is an array, the notes must also be an array");
            for(let i = 0; i < notes.length; i++){
                const d = duration[Math.min(i, duration.length - 1)];
                const durationSeconds = this.toSeconds(d);
                _debug.assert(durationSeconds > 0, "The duration must be greater than 0");
                this.triggerRelease(notes[i], computedTime + durationSeconds);
            }
        } else {
            const durationSeconds = this.toSeconds(duration);
            _debug.assert(durationSeconds > 0, "The duration must be greater than 0");
            this.triggerRelease(notes, computedTime + durationSeconds);
        }
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 1);
        }
        return this;
    }
    /**
     * Set a member/attribute of the voices
     * @example
     * const poly = new Tone.PolySynth().toDestination();
     * // set all of the voices using an options object for the synth type
     * poly.set({
     * 	envelope: {
     * 		attack: 0.25
     * 	}
     * });
     * poly.triggerAttackRelease("Bb3", 0.2);
     */ set(options) {
        // remove options which are controlled by the PolySynth
        const sanitizedOptions = _defaults.omitFromObject(options, [
            "onsilence",
            "context"
        ]);
        // store all of the options
        this.options = _defaults.deepMerge(this.options, sanitizedOptions);
        this._voices.forEach((voice)=>voice.set(sanitizedOptions)
        );
        this._dummyVoice.set(sanitizedOptions);
        return this;
    }
    get() {
        return this._dummyVoice.get();
    }
    /**
     * Trigger the release portion of all the currently active voices immediately.
     * Useful for silencing the synth.
     */ releaseAll(time) {
        const computedTime = this.toSeconds(time);
        this._activeVoices.forEach(({ voice  })=>{
            voice.triggerRelease(computedTime);
        });
        return this;
    }
    dispose() {
        super.dispose();
        this._dummyVoice.dispose();
        this._voices.forEach((v)=>v.dispose()
        );
        this._activeVoices = [];
        this._availableVoices = [];
        this.context.clearInterval(this._gcTimeout);
        return this;
    }
}

},{"../core/type/Midi":"6VA3d","../core/util/Defaults":"kSyYt","../core/util/TypeCheck":"lCqGC","./Instrument":"iKEFd","./Synth":"1gImO","../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"laPeI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Pass in an object which maps the note's pitch or midi value to the url,
 * then you can trigger the attack and release of that note like other instruments.
 * By automatically repitching the samples, it is possible to play pitches which
 * were not explicitly included which can save loading time.
 *
 * For sample or buffer playback where repitching is not necessary,
 * use [[Player]].
 * @example
 * const sampler = new Tone.Sampler({
 * 	urls: {
 * 		A1: "A1.mp3",
 * 		A2: "A2.mp3",
 * 	},
 * 	baseUrl: "https://tonejs.github.io/audio/casio/",
 * 	onload: () => {
 * 		sampler.triggerAttackRelease(["C1", "E1", "G1", "B1"], 0.5);
 * 	}
 * }).toDestination();
 * @category Instrument
 */ parcelHelpers.export(exports, "Sampler", ()=>Sampler
);
var _tslib = require("tslib");
var _toneAudioBuffers = require("../core/context/ToneAudioBuffers");
var _conversions = require("../core/type/Conversions");
var _frequency = require("../core/type/Frequency");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _typeCheck = require("../core/util/TypeCheck");
var _instrument = require("../instrument/Instrument");
var _toneBufferSource = require("../source/buffer/ToneBufferSource");
var _decorator = require("../core/util/Decorator");
var _debug = require("../core/util/Debug");
class Sampler extends _instrument.Instrument {
    constructor(){
        super(_defaults.optionsFromArguments(Sampler.getDefaults(), arguments, [
            "urls",
            "onload",
            "baseUrl"
        ], "urls"));
        this.name = "Sampler";
        /**
         * The object of all currently playing BufferSources
         */ this._activeSources = new Map();
        const options = _defaults.optionsFromArguments(Sampler.getDefaults(), arguments, [
            "urls",
            "onload",
            "baseUrl"
        ], "urls");
        const urlMap = {
        };
        Object.keys(options.urls).forEach((note)=>{
            const noteNumber = parseInt(note, 10);
            _debug.assert(_typeCheck.isNote(note) || _typeCheck.isNumber(noteNumber) && isFinite(noteNumber), `url key is neither a note or midi pitch: ${note}`);
            if (_typeCheck.isNote(note)) {
                // convert the note name to MIDI
                const mid = new _frequency.FrequencyClass(this.context, note).toMidi();
                urlMap[mid] = options.urls[note];
            } else if (_typeCheck.isNumber(noteNumber) && isFinite(noteNumber)) // otherwise if it's numbers assume it's midi
            urlMap[noteNumber] = options.urls[noteNumber];
        });
        this._buffers = new _toneAudioBuffers.ToneAudioBuffers({
            urls: urlMap,
            onload: options.onload,
            baseUrl: options.baseUrl,
            onerror: options.onerror
        });
        this.attack = options.attack;
        this.release = options.release;
        this.curve = options.curve;
        // invoke the callback if it's already loaded
        if (this._buffers.loaded) // invoke onload deferred
        Promise.resolve().then(options.onload);
    }
    static getDefaults() {
        return Object.assign(_instrument.Instrument.getDefaults(), {
            attack: 0,
            baseUrl: "",
            curve: "exponential",
            onload: _interface.noOp,
            onerror: _interface.noOp,
            release: 0.1,
            urls: {
            }
        });
    }
    /**
     * Returns the difference in steps between the given midi note at the closets sample.
     */ _findClosest(midi) {
        // searches within 8 octaves of the given midi note
        const MAX_INTERVAL = 96;
        let interval = 0;
        while(interval < MAX_INTERVAL){
            // check above and below
            if (this._buffers.has(midi + interval)) return -interval;
            else if (this._buffers.has(midi - interval)) return interval;
            interval++;
        }
        throw new Error(`No available buffers for note: ${midi}`);
    }
    /**
     * @param  notes	The note to play, or an array of notes.
     * @param  time     When to play the note
     * @param  velocity The velocity to play the sample back.
     */ triggerAttack(notes, time, velocity = 1) {
        this.log("triggerAttack", notes, time, velocity);
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        notes.forEach((note)=>{
            const midiFloat = _conversions.ftomf(new _frequency.FrequencyClass(this.context, note).toFrequency());
            const midi = Math.round(midiFloat);
            const remainder = midiFloat - midi;
            // find the closest note pitch
            const difference = this._findClosest(midi);
            const closestNote = midi - difference;
            const buffer = this._buffers.get(closestNote);
            const playbackRate = _conversions.intervalToFrequencyRatio(difference + remainder);
            // play that note
            const source = new _toneBufferSource.ToneBufferSource({
                url: buffer,
                context: this.context,
                curve: this.curve,
                fadeIn: this.attack,
                fadeOut: this.release,
                playbackRate
            }).connect(this.output);
            source.start(time, 0, buffer.duration / playbackRate, velocity);
            // add it to the active sources
            if (!_typeCheck.isArray(this._activeSources.get(midi))) this._activeSources.set(midi, []);
            this._activeSources.get(midi).push(source);
            // remove it when it's done
            source.onended = ()=>{
                if (this._activeSources && this._activeSources.has(midi)) {
                    const sources = this._activeSources.get(midi);
                    const index = sources.indexOf(source);
                    if (index !== -1) sources.splice(index, 1);
                }
            };
        });
        return this;
    }
    /**
     * @param  notes	The note to release, or an array of notes.
     * @param  time     	When to release the note.
     */ triggerRelease(notes, time) {
        this.log("triggerRelease", notes, time);
        if (!Array.isArray(notes)) notes = [
            notes
        ];
        notes.forEach((note)=>{
            const midi = new _frequency.FrequencyClass(this.context, note).toMidi();
            // find the note
            if (this._activeSources.has(midi) && this._activeSources.get(midi).length) {
                const sources = this._activeSources.get(midi);
                time = this.toSeconds(time);
                sources.forEach((source)=>{
                    source.stop(time);
                });
                this._activeSources.set(midi, []);
            }
        });
        return this;
    }
    /**
     * Release all currently active notes.
     * @param  time     	When to release the notes.
     */ releaseAll(time) {
        const computedTime = this.toSeconds(time);
        this._activeSources.forEach((sources)=>{
            while(sources.length){
                const source = sources.shift();
                source.stop(computedTime);
            }
        });
        return this;
    }
    sync() {
        if (this._syncState()) {
            this._syncMethod("triggerAttack", 1);
            this._syncMethod("triggerRelease", 1);
        }
        return this;
    }
    /**
     * Invoke the attack phase, then after the duration, invoke the release.
     * @param  notes	The note to play and release, or an array of notes.
     * @param  duration The time the note should be held
     * @param  time     When to start the attack
     * @param  velocity The velocity of the attack
     */ triggerAttackRelease(notes, duration, time, velocity = 1) {
        const computedTime = this.toSeconds(time);
        this.triggerAttack(notes, computedTime, velocity);
        if (_typeCheck.isArray(duration)) {
            _debug.assert(_typeCheck.isArray(notes), "notes must be an array when duration is array");
            notes.forEach((note, index)=>{
                const d = duration[Math.min(index, duration.length - 1)];
                this.triggerRelease(note, computedTime + this.toSeconds(d));
            });
        } else this.triggerRelease(notes, computedTime + this.toSeconds(duration));
        return this;
    }
    /**
     * Add a note to the sampler.
     * @param  note      The buffer's pitch.
     * @param  url  Either the url of the buffer, or a buffer which will be added with the given name.
     * @param  callback  The callback to invoke when the url is loaded.
     */ add(note, url, callback) {
        _debug.assert(_typeCheck.isNote(note) || isFinite(note), `note must be a pitch or midi: ${note}`);
        if (_typeCheck.isNote(note)) {
            // convert the note name to MIDI
            const mid = new _frequency.FrequencyClass(this.context, note).toMidi();
            this._buffers.add(mid, url, callback);
        } else // otherwise if it's numbers assume it's midi
        this._buffers.add(note, url, callback);
        return this;
    }
    /**
     * If the buffers are loaded or not
     */ get loaded() {
        return this._buffers.loaded;
    }
    /**
     * Clean up
     */ dispose() {
        super.dispose();
        this._buffers.dispose();
        this._activeSources.forEach((sources)=>{
            sources.forEach((source)=>source.dispose()
            );
        });
        this._activeSources.clear();
        return this;
    }
}
_tslib.__decorate([
    _decorator.timeRange(0)
], Sampler.prototype, "attack", void 0);
_tslib.__decorate([
    _decorator.timeRange(0)
], Sampler.prototype, "release", void 0);

},{"tslib":"bjkXk","../core/context/ToneAudioBuffers":"g1eoF","../core/type/Conversions":"kOcnG","../core/type/Frequency":"b1aPl","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../core/util/TypeCheck":"lCqGC","../instrument/Instrument":"iKEFd","../source/buffer/ToneBufferSource":"6y7FM","../core/util/Decorator":"krpMw","../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"701IP":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _loop = require("./Loop");
parcelHelpers.exportAll(_loop, exports);
var _part = require("./Part");
parcelHelpers.exportAll(_part, exports);
var _pattern = require("./Pattern");
parcelHelpers.exportAll(_pattern, exports);
var _sequence = require("./Sequence");
parcelHelpers.exportAll(_sequence, exports);
var _toneEvent = require("./ToneEvent");
parcelHelpers.exportAll(_toneEvent, exports);

},{"./Loop":"2CJJq","./Part":"DtAJz","./Pattern":"3u9SD","./Sequence":"3CIFG","./ToneEvent":"2h1N6","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2CJJq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Loop creates a looped callback at the
 * specified interval. The callback can be
 * started, stopped and scheduled along
 * the Transport's timeline.
 * @example
 * const loop = new Tone.Loop((time) => {
 * 	// triggered every eighth note.
 * 	console.log(time);
 * }, "8n").start(0);
 * Tone.Transport.start();
 * @category Event
 */ parcelHelpers.export(exports, "Loop", ()=>Loop
);
var _toneEvent = require("./ToneEvent");
var _toneWithContext = require("../core/context/ToneWithContext");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
class Loop extends _toneWithContext.ToneWithContext {
    constructor(){
        super(_defaults.optionsFromArguments(Loop.getDefaults(), arguments, [
            "callback",
            "interval"
        ]));
        this.name = "Loop";
        const options = _defaults.optionsFromArguments(Loop.getDefaults(), arguments, [
            "callback",
            "interval"
        ]);
        this._event = new _toneEvent.ToneEvent({
            context: this.context,
            callback: this._tick.bind(this),
            loop: true,
            loopEnd: options.interval,
            playbackRate: options.playbackRate,
            probability: options.probability
        });
        this.callback = options.callback;
        // set the iterations
        this.iterations = options.iterations;
    }
    static getDefaults() {
        return Object.assign(_toneWithContext.ToneWithContext.getDefaults(), {
            interval: "4n",
            callback: _interface.noOp,
            playbackRate: 1,
            iterations: Infinity,
            probability: 1,
            mute: false,
            humanize: false
        });
    }
    /**
     * Start the loop at the specified time along the Transport's timeline.
     * @param  time  When to start the Loop.
     */ start(time) {
        this._event.start(time);
        return this;
    }
    /**
     * Stop the loop at the given time.
     * @param  time  When to stop the Loop.
     */ stop(time) {
        this._event.stop(time);
        return this;
    }
    /**
     * Cancel all scheduled events greater than or equal to the given time
     * @param  time  The time after which events will be cancel.
     */ cancel(time) {
        this._event.cancel(time);
        return this;
    }
    /**
     * Internal function called when the notes should be called
     * @param time  The time the event occurs
     */ _tick(time) {
        this.callback(time);
    }
    /**
     * The state of the Loop, either started or stopped.
     */ get state() {
        return this._event.state;
    }
    /**
     * The progress of the loop as a value between 0-1. 0, when the loop is stopped or done iterating.
     */ get progress() {
        return this._event.progress;
    }
    /**
     * The time between successive callbacks.
     * @example
     * const loop = new Tone.Loop();
     * loop.interval = "8n"; // loop every 8n
     */ get interval() {
        return this._event.loopEnd;
    }
    set interval(interval) {
        this._event.loopEnd = interval;
    }
    /**
     * The playback rate of the loop. The normal playback rate is 1 (no change).
     * A `playbackRate` of 2 would be twice as fast.
     */ get playbackRate() {
        return this._event.playbackRate;
    }
    set playbackRate(rate) {
        this._event.playbackRate = rate;
    }
    /**
     * Random variation +/-0.01s to the scheduled time.
     * Or give it a time value which it will randomize by.
     */ get humanize() {
        return this._event.humanize;
    }
    set humanize(variation) {
        this._event.humanize = variation;
    }
    /**
     * The probably of the callback being invoked.
     */ get probability() {
        return this._event.probability;
    }
    set probability(prob) {
        this._event.probability = prob;
    }
    /**
     * Muting the Loop means that no callbacks are invoked.
     */ get mute() {
        return this._event.mute;
    }
    set mute(mute) {
        this._event.mute = mute;
    }
    /**
     * The number of iterations of the loop. The default value is `Infinity` (loop forever).
     */ get iterations() {
        if (this._event.loop === true) return Infinity;
        else return this._event.loop;
    }
    set iterations(iters) {
        if (iters === Infinity) this._event.loop = true;
        else this._event.loop = iters;
    }
    dispose() {
        super.dispose();
        this._event.dispose();
        return this;
    }
}

},{"./ToneEvent":"2h1N6","../core/context/ToneWithContext":"ez5Mk","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2h1N6":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * ToneEvent abstracts away this.context.transport.schedule and provides a schedulable
 * callback for a single or repeatable events along the timeline.
 *
 * @example
 * const synth = new Tone.PolySynth().toDestination();
 * const chordEvent = new Tone.ToneEvent(((time, chord) => {
 * 	// the chord as well as the exact time of the event
 * 	// are passed in as arguments to the callback function
 * 	synth.triggerAttackRelease(chord, 0.5, time);
 * }), ["D4", "E4", "F4"]);
 * // start the chord at the beginning of the transport timeline
 * chordEvent.start();
 * // loop it every measure for 8 measures
 * chordEvent.loop = 8;
 * chordEvent.loopEnd = "1m";
 * @category Event
 */ parcelHelpers.export(exports, "ToneEvent", ()=>ToneEvent
);
var _transport = require("../core/clock/Transport");
var _toneWithContext = require("../core/context/ToneWithContext");
var _ticks = require("../core/type/Ticks");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _stateTimeline = require("../core/util/StateTimeline");
var _typeCheck = require("../core/util/TypeCheck");
class ToneEvent extends _toneWithContext.ToneWithContext {
    constructor(){
        super(_defaults.optionsFromArguments(ToneEvent.getDefaults(), arguments, [
            "callback",
            "value"
        ]));
        this.name = "ToneEvent";
        /**
         * Tracks the scheduled events
         */ this._state = new _stateTimeline.StateTimeline("stopped");
        /**
         * A delay time from when the event is scheduled to start
         */ this._startOffset = 0;
        const options = _defaults.optionsFromArguments(ToneEvent.getDefaults(), arguments, [
            "callback",
            "value"
        ]);
        this._loop = options.loop;
        this.callback = options.callback;
        this.value = options.value;
        this._loopStart = this.toTicks(options.loopStart);
        this._loopEnd = this.toTicks(options.loopEnd);
        this._playbackRate = options.playbackRate;
        this._probability = options.probability;
        this._humanize = options.humanize;
        this.mute = options.mute;
        this._playbackRate = options.playbackRate;
        this._state.increasing = true;
        // schedule the events for the first time
        this._rescheduleEvents();
    }
    static getDefaults() {
        return Object.assign(_toneWithContext.ToneWithContext.getDefaults(), {
            callback: _interface.noOp,
            humanize: false,
            loop: false,
            loopEnd: "1m",
            loopStart: 0,
            mute: false,
            playbackRate: 1,
            probability: 1,
            value: null
        });
    }
    /**
     * Reschedule all of the events along the timeline
     * with the updated values.
     * @param after Only reschedules events after the given time.
     */ _rescheduleEvents(after = -1) {
        // if no argument is given, schedules all of the events
        this._state.forEachFrom(after, (event)=>{
            let duration;
            if (event.state === "started") {
                if (event.id !== -1) this.context.transport.clear(event.id);
                const startTick = event.time + Math.round(this.startOffset / this._playbackRate);
                if (this._loop === true || _typeCheck.isNumber(this._loop) && this._loop > 1) {
                    duration = Infinity;
                    if (_typeCheck.isNumber(this._loop)) duration = this._loop * this._getLoopDuration();
                    const nextEvent = this._state.getAfter(startTick);
                    if (nextEvent !== null) duration = Math.min(duration, nextEvent.time - startTick);
                    if (duration !== Infinity) {
                        // schedule a stop since it's finite duration
                        this._state.setStateAtTime("stopped", startTick + duration + 1, {
                            id: -1
                        });
                        duration = new _ticks.TicksClass(this.context, duration);
                    }
                    const interval = new _ticks.TicksClass(this.context, this._getLoopDuration());
                    event.id = this.context.transport.scheduleRepeat(this._tick.bind(this), interval, new _ticks.TicksClass(this.context, startTick), duration);
                } else event.id = this.context.transport.schedule(this._tick.bind(this), new _ticks.TicksClass(this.context, startTick));
            }
        });
    }
    /**
     * Returns the playback state of the note, either "started" or "stopped".
     */ get state() {
        return this._state.getValueAtTime(this.context.transport.ticks);
    }
    /**
     * The start from the scheduled start time.
     */ get startOffset() {
        return this._startOffset;
    }
    set startOffset(offset) {
        this._startOffset = offset;
    }
    /**
     * The probability of the notes being triggered.
     */ get probability() {
        return this._probability;
    }
    set probability(prob) {
        this._probability = prob;
    }
    /**
     * If set to true, will apply small random variation
     * to the callback time. If the value is given as a time, it will randomize
     * by that amount.
     * @example
     * const event = new Tone.ToneEvent();
     * event.humanize = true;
     */ get humanize() {
        return this._humanize;
    }
    set humanize(variation) {
        this._humanize = variation;
    }
    /**
     * Start the note at the given time.
     * @param  time  When the event should start.
     */ start(time) {
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) === "stopped") {
            this._state.add({
                id: -1,
                state: "started",
                time: ticks
            });
            this._rescheduleEvents(ticks);
        }
        return this;
    }
    /**
     * Stop the Event at the given time.
     * @param  time  When the event should stop.
     */ stop(time) {
        this.cancel(time);
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) === "started") {
            this._state.setStateAtTime("stopped", ticks, {
                id: -1
            });
            const previousEvent = this._state.getBefore(ticks);
            let reschedulTime = ticks;
            if (previousEvent !== null) reschedulTime = previousEvent.time;
            this._rescheduleEvents(reschedulTime);
        }
        return this;
    }
    /**
     * Cancel all scheduled events greater than or equal to the given time
     * @param  time  The time after which events will be cancel.
     */ cancel(time) {
        time = _defaults.defaultArg(time, -Infinity);
        const ticks = this.toTicks(time);
        this._state.forEachFrom(ticks, (event)=>{
            this.context.transport.clear(event.id);
        });
        this._state.cancel(ticks);
        return this;
    }
    /**
     * The callback function invoker. Also
     * checks if the Event is done playing
     * @param  time  The time of the event in seconds
     */ _tick(time) {
        const ticks = this.context.transport.getTicksAtTime(time);
        if (!this.mute && this._state.getValueAtTime(ticks) === "started") {
            if (this.probability < 1 && Math.random() > this.probability) return;
            if (this.humanize) {
                let variation = 0.02;
                if (!_typeCheck.isBoolean(this.humanize)) variation = this.toSeconds(this.humanize);
                time += (Math.random() * 2 - 1) * variation;
            }
            this.callback(time, this.value);
        }
    }
    /**
     * Get the duration of the loop.
     */ _getLoopDuration() {
        return Math.round((this._loopEnd - this._loopStart) / this._playbackRate);
    }
    /**
     * If the note should loop or not
     * between ToneEvent.loopStart and
     * ToneEvent.loopEnd. If set to true,
     * the event will loop indefinitely,
     * if set to a number greater than 1
     * it will play a specific number of
     * times, if set to false, 0 or 1, the
     * part will only play once.
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        this._loop = loop;
        this._rescheduleEvents();
    }
    /**
     * The playback rate of the note. Defaults to 1.
     * @example
     * const note = new Tone.ToneEvent();
     * note.loop = true;
     * // repeat the note twice as fast
     * note.playbackRate = 2;
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        this._rescheduleEvents();
    }
    /**
     * The loopEnd point is the time the event will loop
     * if ToneEvent.loop is true.
     */ get loopEnd() {
        return new _ticks.TicksClass(this.context, this._loopEnd).toSeconds();
    }
    set loopEnd(loopEnd) {
        this._loopEnd = this.toTicks(loopEnd);
        if (this._loop) this._rescheduleEvents();
    }
    /**
     * The time when the loop should start.
     */ get loopStart() {
        return new _ticks.TicksClass(this.context, this._loopStart).toSeconds();
    }
    set loopStart(loopStart) {
        this._loopStart = this.toTicks(loopStart);
        if (this._loop) this._rescheduleEvents();
    }
    /**
     * The current progress of the loop interval.
     * Returns 0 if the event is not started yet or
     * it is not set to loop.
     */ get progress() {
        if (this._loop) {
            const ticks = this.context.transport.ticks;
            const lastEvent = this._state.get(ticks);
            if (lastEvent !== null && lastEvent.state === "started") {
                const loopDuration = this._getLoopDuration();
                const progress = (ticks - lastEvent.time) % loopDuration;
                return progress / loopDuration;
            } else return 0;
        } else return 0;
    }
    dispose() {
        super.dispose();
        this.cancel();
        this._state.dispose();
        return this;
    }
}

},{"../core/clock/Transport":"7Q4LA","../core/context/ToneWithContext":"ez5Mk","../core/type/Ticks":"8zKuk","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../core/util/StateTimeline":"am3qa","../core/util/TypeCheck":"lCqGC","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"DtAJz":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Part is a collection ToneEvents which can be started/stopped and looped as a single unit.
 *
 * @example
 * const synth = new Tone.Synth().toDestination();
 * const part = new Tone.Part(((time, note) => {
 * 	// the notes given as the second element in the array
 * 	// will be passed in as the second argument
 * 	synth.triggerAttackRelease(note, "8n", time);
 * }), [[0, "C2"], ["0:2", "C3"], ["0:3:2", "G2"]]);
 * Tone.Transport.start();
 * @example
 * const synth = new Tone.Synth().toDestination();
 * // use an array of objects as long as the object has a "time" attribute
 * const part = new Tone.Part(((time, value) => {
 * 	// the value is an object which contains both the note and the velocity
 * 	synth.triggerAttackRelease(value.note, "8n", time, value.velocity);
 * }), [{ time: 0, note: "C3", velocity: 0.9 },
 * 	{ time: "0:2", note: "C4", velocity: 0.5 }
 * ]).start(0);
 * Tone.Transport.start();
 * @category Event
 */ parcelHelpers.export(exports, "Part", ()=>Part
);
var _ticks = require("../core/type/Ticks");
var _transportTime = require("../core/type/TransportTime");
var _defaults = require("../core/util/Defaults");
var _stateTimeline = require("../core/util/StateTimeline");
var _typeCheck = require("../core/util/TypeCheck");
var _toneEvent = require("./ToneEvent");
class Part extends _toneEvent.ToneEvent {
    constructor(){
        super(_defaults.optionsFromArguments(Part.getDefaults(), arguments, [
            "callback",
            "events"
        ]));
        this.name = "Part";
        /**
         * Tracks the scheduled events
         */ this._state = new _stateTimeline.StateTimeline("stopped");
        /**
         * The events that belong to this part
         */ this._events = new Set();
        const options = _defaults.optionsFromArguments(Part.getDefaults(), arguments, [
            "callback",
            "events"
        ]);
        // make sure things are assigned in the right order
        this._state.increasing = true;
        // add the events
        options.events.forEach((event)=>{
            if (_typeCheck.isArray(event)) this.add(event[0], event[1]);
            else this.add(event);
        });
    }
    static getDefaults() {
        return Object.assign(_toneEvent.ToneEvent.getDefaults(), {
            events: []
        });
    }
    /**
     * Start the part at the given time.
     * @param  time    When to start the part.
     * @param  offset  The offset from the start of the part to begin playing at.
     */ start(time, offset) {
        const ticks = this.toTicks(time);
        if (this._state.getValueAtTime(ticks) !== "started") {
            offset = _defaults.defaultArg(offset, this._loop ? this._loopStart : 0);
            if (this._loop) offset = _defaults.defaultArg(offset, this._loopStart);
            else offset = _defaults.defaultArg(offset, 0);
            const computedOffset = this.toTicks(offset);
            this._state.add({
                id: -1,
                offset: computedOffset,
                state: "started",
                time: ticks
            });
            this._forEach((event)=>{
                this._startNote(event, ticks, computedOffset);
            });
        }
        return this;
    }
    /**
     * Start the event in the given event at the correct time given
     * the ticks and offset and looping.
     * @param  event
     * @param  ticks
     * @param  offset
     */ _startNote(event, ticks, offset) {
        ticks -= offset;
        if (this._loop) {
            if (event.startOffset >= this._loopStart && event.startOffset < this._loopEnd) {
                if (event.startOffset < offset) // start it on the next loop
                ticks += this._getLoopDuration();
                event.start(new _ticks.TicksClass(this.context, ticks));
            } else if (event.startOffset < this._loopStart && event.startOffset >= offset) {
                event.loop = false;
                event.start(new _ticks.TicksClass(this.context, ticks));
            }
        } else if (event.startOffset >= offset) event.start(new _ticks.TicksClass(this.context, ticks));
    }
    get startOffset() {
        return this._startOffset;
    }
    set startOffset(offset) {
        this._startOffset = offset;
        this._forEach((event)=>{
            event.startOffset += this._startOffset;
        });
    }
    /**
     * Stop the part at the given time.
     * @param  time  When to stop the part.
     */ stop(time) {
        const ticks = this.toTicks(time);
        this._state.cancel(ticks);
        this._state.setStateAtTime("stopped", ticks);
        this._forEach((event)=>{
            event.stop(time);
        });
        return this;
    }
    /**
     * Get/Set an Event's value at the given time.
     * If a value is passed in and no event exists at
     * the given time, one will be created with that value.
     * If two events are at the same time, the first one will
     * be returned.
     * @example
     * const part = new Tone.Part();
     * part.at("1m"); // returns the part at the first measure
     * part.at("2m", "C2"); // set the value at "2m" to C2.
     * // if an event didn't exist at that time, it will be created.
     * @param time The time of the event to get or set.
     * @param value If a value is passed in, the value of the event at the given time will be set to it.
     */ at(time, value) {
        const timeInTicks = new _transportTime.TransportTimeClass(this.context, time).toTicks();
        const tickTime = new _ticks.TicksClass(this.context, 1).toSeconds();
        const iterator = this._events.values();
        let result = iterator.next();
        while(!result.done){
            const event = result.value;
            if (Math.abs(timeInTicks - event.startOffset) < tickTime) {
                if (_typeCheck.isDefined(value)) event.value = value;
                return event;
            }
            result = iterator.next();
        }
        // if there was no event at that time, create one
        if (_typeCheck.isDefined(value)) {
            this.add(time, value);
            // return the new event
            return this.at(time);
        } else return null;
    }
    add(time, value) {
        // extract the parameters
        if (time instanceof Object && Reflect.has(time, "time")) {
            value = time;
            time = value.time;
        }
        const ticks = this.toTicks(time);
        let event;
        if (value instanceof _toneEvent.ToneEvent) {
            event = value;
            event.callback = this._tick.bind(this);
        } else event = new _toneEvent.ToneEvent({
            callback: this._tick.bind(this),
            context: this.context,
            value
        });
        // the start offset
        event.startOffset = ticks;
        // initialize the values
        event.set({
            humanize: this.humanize,
            loop: this.loop,
            loopEnd: this.loopEnd,
            loopStart: this.loopStart,
            playbackRate: this.playbackRate,
            probability: this.probability
        });
        this._events.add(event);
        // start the note if it should be played right now
        this._restartEvent(event);
        return this;
    }
    /**
     * Restart the given event
     */ _restartEvent(event) {
        this._state.forEach((stateEvent)=>{
            if (stateEvent.state === "started") this._startNote(event, stateEvent.time, stateEvent.offset);
            else // stop the note
            event.stop(new _ticks.TicksClass(this.context, stateEvent.time));
        });
    }
    remove(time, value) {
        // extract the parameters
        if (_typeCheck.isObject(time) && time.hasOwnProperty("time")) {
            value = time;
            time = value.time;
        }
        time = this.toTicks(time);
        this._events.forEach((event)=>{
            if (event.startOffset === time) {
                if (_typeCheck.isUndef(value) || _typeCheck.isDefined(value) && event.value === value) {
                    this._events.delete(event);
                    event.dispose();
                }
            }
        });
        return this;
    }
    /**
     * Remove all of the notes from the group.
     */ clear() {
        this._forEach((event)=>event.dispose()
        );
        this._events.clear();
        return this;
    }
    /**
     * Cancel scheduled state change events: i.e. "start" and "stop".
     * @param after The time after which to cancel the scheduled events.
     */ cancel(after) {
        this._forEach((event)=>event.cancel(after)
        );
        this._state.cancel(this.toTicks(after));
        return this;
    }
    /**
     * Iterate over all of the events
     */ _forEach(callback) {
        if (this._events) this._events.forEach((event)=>{
            if (event instanceof Part) event._forEach(callback);
            else callback(event);
        });
        return this;
    }
    /**
     * Set the attribute of all of the events
     * @param  attr  the attribute to set
     * @param  value      The value to set it to
     */ _setAll(attr, value) {
        this._forEach((event)=>{
            event[attr] = value;
        });
    }
    /**
     * Internal tick method
     * @param  time  The time of the event in seconds
     */ _tick(time, value) {
        if (!this.mute) this.callback(time, value);
    }
    /**
     * Determine if the event should be currently looping
     * given the loop boundries of this Part.
     * @param  event  The event to test
     */ _testLoopBoundries(event) {
        if (this._loop && (event.startOffset < this._loopStart || event.startOffset >= this._loopEnd)) event.cancel(0);
        else if (event.state === "stopped") // reschedule it if it's stopped
        this._restartEvent(event);
    }
    get probability() {
        return this._probability;
    }
    set probability(prob) {
        this._probability = prob;
        this._setAll("probability", prob);
    }
    get humanize() {
        return this._humanize;
    }
    set humanize(variation) {
        this._humanize = variation;
        this._setAll("humanize", variation);
    }
    /**
     * If the part should loop or not
     * between Part.loopStart and
     * Part.loopEnd. If set to true,
     * the part will loop indefinitely,
     * if set to a number greater than 1
     * it will play a specific number of
     * times, if set to false, 0 or 1, the
     * part will only play once.
     * @example
     * const part = new Tone.Part();
     * // loop the part 8 times
     * part.loop = 8;
     */ get loop() {
        return this._loop;
    }
    set loop(loop) {
        this._loop = loop;
        this._forEach((event)=>{
            event.loopStart = this.loopStart;
            event.loopEnd = this.loopEnd;
            event.loop = loop;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The loopEnd point determines when it will
     * loop if Part.loop is true.
     */ get loopEnd() {
        return new _ticks.TicksClass(this.context, this._loopEnd).toSeconds();
    }
    set loopEnd(loopEnd) {
        this._loopEnd = this.toTicks(loopEnd);
        if (this._loop) this._forEach((event)=>{
            event.loopEnd = loopEnd;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The loopStart point determines when it will
     * loop if Part.loop is true.
     */ get loopStart() {
        return new _ticks.TicksClass(this.context, this._loopStart).toSeconds();
    }
    set loopStart(loopStart) {
        this._loopStart = this.toTicks(loopStart);
        if (this._loop) this._forEach((event)=>{
            event.loopStart = this.loopStart;
            this._testLoopBoundries(event);
        });
    }
    /**
     * The playback rate of the part
     */ get playbackRate() {
        return this._playbackRate;
    }
    set playbackRate(rate) {
        this._playbackRate = rate;
        this._setAll("playbackRate", rate);
    }
    /**
     * The number of scheduled notes in the part.
     */ get length() {
        return this._events.size;
    }
    dispose() {
        super.dispose();
        this.clear();
        return this;
    }
}

},{"../core/type/Ticks":"8zKuk","../core/type/TransportTime":"kcsdx","../core/util/Defaults":"kSyYt","../core/util/StateTimeline":"am3qa","../core/util/TypeCheck":"lCqGC","./ToneEvent":"2h1N6","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3u9SD":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Pattern arpeggiates between the given notes
 * in a number of patterns.
 * @example
 * const pattern = new Tone.Pattern((time, note) => {
 * 	// the order of the notes passed in depends on the pattern
 * }, ["C2", "D4", "E5", "A6"], "upDown");
 * @category Event
 */ parcelHelpers.export(exports, "Pattern", ()=>Pattern
);
var _loop = require("./Loop");
var _patternGenerator = require("./PatternGenerator");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
class Pattern extends _loop.Loop {
    constructor(){
        super(_defaults.optionsFromArguments(Pattern.getDefaults(), arguments, [
            "callback",
            "values",
            "pattern"
        ]));
        this.name = "Pattern";
        const options = _defaults.optionsFromArguments(Pattern.getDefaults(), arguments, [
            "callback",
            "values",
            "pattern"
        ]);
        this.callback = options.callback;
        this._values = options.values;
        this._pattern = _patternGenerator.PatternGenerator(options.values, options.pattern);
        this._type = options.pattern;
    }
    static getDefaults() {
        return Object.assign(_loop.Loop.getDefaults(), {
            pattern: "up",
            values: [],
            callback: _interface.noOp
        });
    }
    /**
     * Internal function called when the notes should be called
     */ _tick(time) {
        const value = this._pattern.next();
        this._value = value.value;
        this.callback(time, this._value);
    }
    /**
     * The array of events.
     */ get values() {
        return this._values;
    }
    set values(val) {
        this._values = val;
        // reset the pattern
        this.pattern = this._type;
    }
    /**
     * The current value of the pattern.
     */ get value() {
        return this._value;
    }
    /**
     * The pattern type. See Tone.CtrlPattern for the full list of patterns.
     */ get pattern() {
        return this._type;
    }
    set pattern(pattern) {
        this._type = pattern;
        this._pattern = _patternGenerator.PatternGenerator(this._values, this._type);
    }
}

},{"./Loop":"2CJJq","./PatternGenerator":"jFWsQ","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jFWsQ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PatternGenerator returns a generator which will iterate over the given array
 * of values and yield the items according to the passed in pattern
 * @param values An array of values to iterate over
 * @param pattern The name of the pattern use when iterating over
 * @param index Where to start in the offset of the values array
 */ parcelHelpers.export(exports, "PatternGenerator", ()=>PatternGenerator
);
var _debug = require("../core/util/Debug");
var _math = require("../core/util/Math");
/**
 * Start at the first value and go up to the last
 */ function* upPatternGen(values) {
    let index = 0;
    while(index < values.length){
        index = clampToArraySize(index, values);
        yield values[index];
        index++;
    }
}
/**
 * Start at the last value and go down to 0
 */ function* downPatternGen(values) {
    let index = values.length - 1;
    while(index >= 0){
        index = clampToArraySize(index, values);
        yield values[index];
        index--;
    }
}
/**
 * Infinitely yield the generator
 */ function* infiniteGen(values, gen) {
    while(true)yield* gen(values);
}
/**
 * Make sure that the index is in the given range
 */ function clampToArraySize(index, values) {
    return _math.clamp(index, 0, values.length - 1);
}
/**
 * Alternate between two generators
 */ function* alternatingGenerator(values, directionUp) {
    let index = directionUp ? 0 : values.length - 1;
    while(true){
        index = clampToArraySize(index, values);
        yield values[index];
        if (directionUp) {
            index++;
            if (index >= values.length - 1) directionUp = false;
        } else {
            index--;
            if (index <= 0) directionUp = true;
        }
    }
}
/**
 * Starting from the bottom move up 2, down 1
 */ function* jumpUp(values) {
    let index = 0;
    let stepIndex = 0;
    while(index < values.length){
        index = clampToArraySize(index, values);
        yield values[index];
        stepIndex++;
        index += stepIndex % 2 ? 2 : -1;
    }
}
/**
 * Starting from the top move down 2, up 1
 */ function* jumpDown(values) {
    let index = values.length - 1;
    let stepIndex = 0;
    while(index >= 0){
        index = clampToArraySize(index, values);
        yield values[index];
        stepIndex++;
        index += stepIndex % 2 ? -2 : 1;
    }
}
/**
 * Choose a random index each time
 */ function* randomGen(values) {
    while(true){
        const randomIndex = Math.floor(Math.random() * values.length);
        yield values[randomIndex];
    }
}
/**
 * Randomly go through all of the values once before choosing a new random order
 */ function* randomOnce(values) {
    // create an array of indices
    const copy = [];
    for(let i = 0; i < values.length; i++)copy.push(i);
    while(copy.length > 0){
        // random choose an index, and then remove it so it's not chosen again
        const randVal = copy.splice(Math.floor(copy.length * Math.random()), 1);
        const index = clampToArraySize(randVal[0], values);
        yield values[index];
    }
}
/**
 * Randomly choose to walk up or down 1 index in the values array
 */ function* randomWalk(values) {
    // randomly choose a starting index in the values array
    let index = Math.floor(Math.random() * values.length);
    while(true){
        if (index === 0) index++; // at bottom of array, so force upward step
        else if (index === values.length - 1) index--; // at top of array, so force downward step
        else if (Math.random() < 0.5) index--;
        else index++;
        yield values[index];
    }
}
function* PatternGenerator(values, pattern = "up", index = 0) {
    // safeguards
    _debug.assert(values.length > 0, "The array must have more than one value in it");
    switch(pattern){
        case "up":
            yield* infiniteGen(values, upPatternGen);
        case "down":
            yield* infiniteGen(values, downPatternGen);
        case "upDown":
            yield* alternatingGenerator(values, true);
        case "downUp":
            yield* alternatingGenerator(values, false);
        case "alternateUp":
            yield* infiniteGen(values, jumpUp);
        case "alternateDown":
            yield* infiniteGen(values, jumpDown);
        case "random":
            yield* randomGen(values);
        case "randomOnce":
            yield* infiniteGen(values, randomOnce);
        case "randomWalk":
            yield* randomWalk(values);
    }
}

},{"../core/util/Debug":"bsxl9","../core/util/Math":"gdhOV","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3CIFG":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A sequence is an alternate notation of a part. Instead
 * of passing in an array of [time, event] pairs, pass
 * in an array of events which will be spaced at the
 * given subdivision. Sub-arrays will subdivide that beat
 * by the number of items are in the array.
 * Sequence notation inspiration from [Tidal](http://yaxu.org/tidal/)
 * @example
 * const synth = new Tone.Synth().toDestination();
 * const seq = new Tone.Sequence((time, note) => {
 * 	synth.triggerAttackRelease(note, 0.1, time);
 * 	// subdivisions are given as subarrays
 * }, ["C4", ["E4", "D4", "E4"], "G4", ["A4", "G4"]]).start(0);
 * Tone.Transport.start();
 * @category Event
 */ parcelHelpers.export(exports, "Sequence", ()=>Sequence
);
var _ticks = require("../core/type/Ticks");
var _defaults = require("../core/util/Defaults");
var _typeCheck = require("../core/util/TypeCheck");
var _part = require("./Part");
var _toneEvent = require("./ToneEvent");
class Sequence extends _toneEvent.ToneEvent {
    constructor(){
        super(_defaults.optionsFromArguments(Sequence.getDefaults(), arguments, [
            "callback",
            "events",
            "subdivision"
        ]));
        this.name = "Sequence";
        /**
         * The object responsible for scheduling all of the events
         */ this._part = new _part.Part({
            callback: this._seqCallback.bind(this),
            context: this.context
        });
        /**
         * private reference to all of the sequence proxies
         */ this._events = [];
        /**
         * The proxied array
         */ this._eventsArray = [];
        const options = _defaults.optionsFromArguments(Sequence.getDefaults(), arguments, [
            "callback",
            "events",
            "subdivision"
        ]);
        this._subdivision = this.toTicks(options.subdivision);
        this.events = options.events;
        // set all of the values
        this.loop = options.loop;
        this.loopStart = options.loopStart;
        this.loopEnd = options.loopEnd;
        this.playbackRate = options.playbackRate;
        this.probability = options.probability;
        this.humanize = options.humanize;
        this.mute = options.mute;
        this.playbackRate = options.playbackRate;
    }
    static getDefaults() {
        return Object.assign(_defaults.omitFromObject(_toneEvent.ToneEvent.getDefaults(), [
            "value"
        ]), {
            events: [],
            loop: true,
            loopEnd: 0,
            loopStart: 0,
            subdivision: "8n"
        });
    }
    /**
     * The internal callback for when an event is invoked
     */ _seqCallback(time, value) {
        if (value !== null) this.callback(time, value);
    }
    /**
     * The sequence
     */ get events() {
        return this._events;
    }
    set events(s) {
        this.clear();
        this._eventsArray = s;
        this._events = this._createSequence(this._eventsArray);
        this._eventsUpdated();
    }
    /**
     * Start the part at the given time.
     * @param  time    When to start the part.
     * @param  offset  The offset index to start at
     */ start(time, offset) {
        this._part.start(time, offset ? this._indexTime(offset) : offset);
        return this;
    }
    /**
     * Stop the part at the given time.
     * @param  time  When to stop the part.
     */ stop(time) {
        this._part.stop(time);
        return this;
    }
    /**
     * The subdivision of the sequence. This can only be
     * set in the constructor. The subdivision is the
     * interval between successive steps.
     */ get subdivision() {
        return new _ticks.TicksClass(this.context, this._subdivision).toSeconds();
    }
    /**
     * Create a sequence proxy which can be monitored to create subsequences
     */ _createSequence(array) {
        return new Proxy(array, {
            get: (target, property)=>{
                // property is index in this case
                return target[property];
            },
            set: (target, property, value)=>{
                if (_typeCheck.isString(property) && isFinite(parseInt(property, 10))) {
                    if (_typeCheck.isArray(value)) target[property] = this._createSequence(value);
                    else target[property] = value;
                } else target[property] = value;
                this._eventsUpdated();
                // return true to accept the changes
                return true;
            }
        });
    }
    /**
     * When the sequence has changed, all of the events need to be recreated
     */ _eventsUpdated() {
        this._part.clear();
        this._rescheduleSequence(this._eventsArray, this._subdivision, this.startOffset);
        // update the loopEnd
        this.loopEnd = this.loopEnd;
    }
    /**
     * reschedule all of the events that need to be rescheduled
     */ _rescheduleSequence(sequence, subdivision, startOffset) {
        sequence.forEach((value, index)=>{
            const eventOffset = index * subdivision + startOffset;
            if (_typeCheck.isArray(value)) this._rescheduleSequence(value, subdivision / value.length, eventOffset);
            else {
                const startTime = new _ticks.TicksClass(this.context, eventOffset, "i").toSeconds();
                this._part.add(startTime, value);
            }
        });
    }
    /**
     * Get the time of the index given the Sequence's subdivision
     * @param  index
     * @return The time of that index
     */ _indexTime(index) {
        return new _ticks.TicksClass(this.context, index * this._subdivision + this.startOffset).toSeconds();
    }
    /**
     * Clear all of the events
     */ clear() {
        this._part.clear();
        return this;
    }
    dispose() {
        super.dispose();
        this._part.dispose();
        return this;
    }
    //-------------------------------------
    // PROXY CALLS
    //-------------------------------------
    get loop() {
        return this._part.loop;
    }
    set loop(l) {
        this._part.loop = l;
    }
    /**
     * The index at which the sequence should start looping
     */ get loopStart() {
        return this._loopStart;
    }
    set loopStart(index) {
        this._loopStart = index;
        this._part.loopStart = this._indexTime(index);
    }
    /**
     * The index at which the sequence should end looping
     */ get loopEnd() {
        return this._loopEnd;
    }
    set loopEnd(index) {
        this._loopEnd = index;
        if (index === 0) this._part.loopEnd = this._indexTime(this._eventsArray.length);
        else this._part.loopEnd = this._indexTime(index);
    }
    get startOffset() {
        return this._part.startOffset;
    }
    set startOffset(start) {
        this._part.startOffset = start;
    }
    get playbackRate() {
        return this._part.playbackRate;
    }
    set playbackRate(rate) {
        this._part.playbackRate = rate;
    }
    get probability() {
        return this._part.probability;
    }
    set probability(prob) {
        this._part.probability = prob;
    }
    get progress() {
        return this._part.progress;
    }
    get humanize() {
        return this._part.humanize;
    }
    set humanize(variation) {
        this._part.humanize = variation;
    }
    /**
     * The number of scheduled events
     */ get length() {
        return this._part.length;
    }
}

},{"../core/type/Ticks":"8zKuk","../core/util/Defaults":"kSyYt","../core/util/TypeCheck":"lCqGC","./Part":"DtAJz","./ToneEvent":"2h1N6","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9Z6bM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _autoFilter = require("./AutoFilter");
parcelHelpers.exportAll(_autoFilter, exports);
var _autoPanner = require("./AutoPanner");
parcelHelpers.exportAll(_autoPanner, exports);
var _autoWah = require("./AutoWah");
parcelHelpers.exportAll(_autoWah, exports);
var _bitCrusher = require("./BitCrusher");
parcelHelpers.exportAll(_bitCrusher, exports);
var _chebyshev = require("./Chebyshev");
parcelHelpers.exportAll(_chebyshev, exports);
var _chorus = require("./Chorus");
parcelHelpers.exportAll(_chorus, exports);
var _distortion = require("./Distortion");
parcelHelpers.exportAll(_distortion, exports);
var _feedbackDelay = require("./FeedbackDelay");
parcelHelpers.exportAll(_feedbackDelay, exports);
var _frequencyShifter = require("./FrequencyShifter");
parcelHelpers.exportAll(_frequencyShifter, exports);
var _freeverb = require("./Freeverb");
parcelHelpers.exportAll(_freeverb, exports);
var _jcreverb = require("./JCReverb");
parcelHelpers.exportAll(_jcreverb, exports);
var _pingPongDelay = require("./PingPongDelay");
parcelHelpers.exportAll(_pingPongDelay, exports);
var _pitchShift = require("./PitchShift");
parcelHelpers.exportAll(_pitchShift, exports);
var _phaser = require("./Phaser");
parcelHelpers.exportAll(_phaser, exports);
var _reverb = require("./Reverb");
parcelHelpers.exportAll(_reverb, exports);
var _stereoWidener = require("./StereoWidener");
parcelHelpers.exportAll(_stereoWidener, exports);
var _tremolo = require("./Tremolo");
parcelHelpers.exportAll(_tremolo, exports);
var _vibrato = require("./Vibrato");
parcelHelpers.exportAll(_vibrato, exports);

},{"./AutoFilter":"01phv","./AutoPanner":"8mp50","./AutoWah":"hlzeE","./BitCrusher":"dlji0","./Chebyshev":"2Wred","./Chorus":"fEh3Z","./Distortion":"9ZFE2","./FeedbackDelay":"921Az","./FrequencyShifter":"2FcKB","./Freeverb":"jKkIp","./JCReverb":"5m0vd","./PingPongDelay":"9fqVT","./PitchShift":"aOCHY","./Phaser":"cbvFb","./Reverb":"51Gh7","./StereoWidener":"bEZDT","./Tremolo":"jyp9u","./Vibrato":"7wMcd","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"01phv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AutoFilter is a Tone.Filter with a Tone.LFO connected to the filter cutoff frequency.
 * Setting the LFO rate and depth allows for control over the filter modulation rate
 * and depth.
 *
 * @example
 * // create an autofilter and start it's LFO
 * const autoFilter = new Tone.AutoFilter("4n").toDestination().start();
 * // route an oscillator through the filter and start it
 * const oscillator = new Tone.Oscillator().connect(autoFilter).start();
 * @category Effect
 */ parcelHelpers.export(exports, "AutoFilter", ()=>AutoFilter
);
var _filter = require("../component/filter/Filter");
var _defaults = require("../core/util/Defaults");
var _lfoeffect = require("./LFOEffect");
class AutoFilter extends _lfoeffect.LFOEffect {
    constructor(){
        super(_defaults.optionsFromArguments(AutoFilter.getDefaults(), arguments, [
            "frequency",
            "baseFrequency",
            "octaves"
        ]));
        this.name = "AutoFilter";
        const options = _defaults.optionsFromArguments(AutoFilter.getDefaults(), arguments, [
            "frequency",
            "baseFrequency",
            "octaves"
        ]);
        this.filter = new _filter.Filter(Object.assign(options.filter, {
            context: this.context
        }));
        // connections
        this.connectEffect(this.filter);
        this._lfo.connect(this.filter.frequency);
        this.octaves = options.octaves;
        this.baseFrequency = options.baseFrequency;
    }
    static getDefaults() {
        return Object.assign(_lfoeffect.LFOEffect.getDefaults(), {
            baseFrequency: 200,
            octaves: 2.6,
            filter: {
                type: "lowpass",
                rolloff: -12,
                Q: 1
            }
        });
    }
    /**
     * The minimum value of the filter's cutoff frequency.
     */ get baseFrequency() {
        return this._lfo.min;
    }
    set baseFrequency(freq) {
        this._lfo.min = this.toFrequency(freq);
        // and set the max
        this.octaves = this._octaves;
    }
    /**
     * The maximum value of the filter's cutoff frequency.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(oct) {
        this._octaves = oct;
        this._lfo.max = this._lfo.min * Math.pow(2, oct);
    }
    dispose() {
        super.dispose();
        this.filter.dispose();
        return this;
    }
}

},{"../component/filter/Filter":"5lZpJ","../core/util/Defaults":"kSyYt","./LFOEffect":"khieK","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"khieK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for LFO-based effects.
 */ parcelHelpers.export(exports, "LFOEffect", ()=>LFOEffect
);
var _effect = require("../effect/Effect");
var _lfo = require("../source/oscillator/LFO");
var _interface = require("../core/util/Interface");
class LFOEffect extends _effect.Effect {
    constructor(options){
        super(options);
        this.name = "LFOEffect";
        this._lfo = new _lfo.LFO({
            context: this.context,
            frequency: options.frequency,
            amplitude: options.depth
        });
        this.depth = this._lfo.amplitude;
        this.frequency = this._lfo.frequency;
        this.type = options.type;
        _interface.readOnly(this, [
            "frequency",
            "depth"
        ]);
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            frequency: 1,
            type: "sine",
            depth: 1
        });
    }
    /**
     * Start the effect.
     */ start(time) {
        this._lfo.start(time);
        return this;
    }
    /**
     * Stop the lfo
     */ stop(time) {
        this._lfo.stop(time);
        return this;
    }
    /**
     * Sync the filter to the transport. See [[LFO.sync]]
     */ sync() {
        this._lfo.sync();
        return this;
    }
    /**
     * Unsync the filter from the transport.
     */ unsync() {
        this._lfo.unsync();
        return this;
    }
    /**
     * The type of the LFO's oscillator: See [[Oscillator.type]]
     * @example
     * const autoFilter = new Tone.AutoFilter().start().toDestination();
     * const noise = new Tone.Noise().start().connect(autoFilter);
     * autoFilter.type = "square";
     */ get type() {
        return this._lfo.type;
    }
    set type(type) {
        this._lfo.type = type;
    }
    dispose() {
        super.dispose();
        this._lfo.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}

},{"../effect/Effect":"k385z","../source/oscillator/LFO":"d8Ivp","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"k385z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Effect is the base class for effects. Connect the effect between
 * the effectSend and effectReturn GainNodes, then control the amount of
 * effect which goes to the output using the wet control.
 */ parcelHelpers.export(exports, "Effect", ()=>Effect
);
var _crossFade = require("../component/channel/CrossFade");
var _gain = require("../core/context/Gain");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _interface = require("../core/util/Interface");
class Effect extends _toneAudioNode.ToneAudioNode {
    constructor(options){
        super(options);
        this.name = "Effect";
        /**
         * the drywet knob to control the amount of effect
         */ this._dryWet = new _crossFade.CrossFade({
            context: this.context
        });
        /**
         * The wet control is how much of the effected
         * will pass through to the output. 1 = 100% effected
         * signal, 0 = 100% dry signal.
         */ this.wet = this._dryWet.fade;
        /**
         * connect the effectSend to the input of hte effect
         */ this.effectSend = new _gain.Gain({
            context: this.context
        });
        /**
         * connect the output of the effect to the effectReturn
         */ this.effectReturn = new _gain.Gain({
            context: this.context
        });
        /**
         * The effect input node
         */ this.input = new _gain.Gain({
            context: this.context
        });
        /**
         * The effect output
         */ this.output = this._dryWet;
        // connections
        this.input.fan(this._dryWet.a, this.effectSend);
        this.effectReturn.connect(this._dryWet.b);
        this.wet.setValueAtTime(options.wet, 0);
        this._internalChannels = [
            this.effectReturn,
            this.effectSend
        ];
        _interface.readOnly(this, "wet");
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            wet: 1
        });
    }
    /**
     * chains the effect in between the effectSend and effectReturn
     */ connectEffect(effect) {
        // add it to the internal channels
        this._internalChannels.push(effect);
        this.effectSend.chain(effect, this.effectReturn);
        return this;
    }
    dispose() {
        super.dispose();
        this._dryWet.dispose();
        this.effectSend.dispose();
        this.effectReturn.dispose();
        this.wet.dispose();
        return this;
    }
}

},{"../component/channel/CrossFade":"hj0PR","../core/context/Gain":"7kpMn","../core/context/ToneAudioNode":"iT1SZ","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hj0PR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.Crossfade provides equal power fading between two inputs.
 * More on crossfading technique [here](https://en.wikipedia.org/wiki/Fade_(audio_engineering)#Crossfading).
 * ```
 *                                             +---------+
 *                                            +> input a +>--+
 * +-----------+   +---------------------+     |         |   |
 * | 1s signal +>--> stereoPannerNode  L +>----> gain    |   |
 * +-----------+   |                     |     +---------+   |
 *               +-> pan               R +>-+                |   +--------+
 *               | +---------------------+  |                +---> output +>
 *  +------+     |                          |  +---------+   |   +--------+
 *  | fade +>----+                          | +> input b +>--+
 *  +------+                                |  |         |
 *                                          +--> gain    |
 *                                             +---------+
 * ```
 * @example
 * const crossFade = new Tone.CrossFade().toDestination();
 * // connect two inputs Tone.to a/b
 * const inputA = new Tone.Oscillator(440, "square").connect(crossFade.a).start();
 * const inputB = new Tone.Oscillator(440, "sine").connect(crossFade.b).start();
 * // use the fade to control the mix between the two
 * crossFade.fade.value = 0.5;
 * @category Component
 */ parcelHelpers.export(exports, "CrossFade", ()=>CrossFade
);
var _gain = require("../../core/context/Gain");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _gainToAudio = require("../../signal/GainToAudio");
var _signal = require("../../signal/Signal");
class CrossFade extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(CrossFade.getDefaults(), arguments, [
            "fade"
        ])));
        this.name = "CrossFade";
        /**
         * The crossfading is done by a StereoPannerNode
         */ this._panner = this.context.createStereoPanner();
        /**
         * Split the output of the panner node into two values used to control the gains.
         */ this._split = this.context.createChannelSplitter(2);
        /**
         * Convert the fade value into an audio range value so it can be connected
         * to the panner.pan AudioParam
         */ this._g2a = new _gainToAudio.GainToAudio({
            context: this.context
        });
        /**
         * The input which is at full level when fade = 0
         */ this.a = new _gain.Gain({
            context: this.context,
            gain: 0
        });
        /**
         * The input which is at full level when fade = 1
         */ this.b = new _gain.Gain({
            context: this.context,
            gain: 0
        });
        /**
         * The output is a mix between `a` and `b` at the ratio of `fade`
         */ this.output = new _gain.Gain({
            context: this.context
        });
        this._internalChannels = [
            this.a,
            this.b
        ];
        const options = _defaults.optionsFromArguments(CrossFade.getDefaults(), arguments, [
            "fade"
        ]);
        this.fade = new _signal.Signal({
            context: this.context,
            units: "normalRange",
            value: options.fade
        });
        _interface.readOnly(this, "fade");
        this.context.getConstant(1).connect(this._panner);
        this._panner.connect(this._split);
        // this is necessary for standardized-audio-context
        // doesn't make any difference for the native AudioContext
        // https://github.com/chrisguttandin/standardized-audio-context/issues/647
        this._panner.channelCount = 1;
        this._panner.channelCountMode = "explicit";
        _toneAudioNode.connect(this._split, this.a.gain, 0);
        _toneAudioNode.connect(this._split, this.b.gain, 1);
        this.fade.chain(this._g2a, this._panner.pan);
        this.a.connect(this.output);
        this.b.connect(this.output);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            fade: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.a.dispose();
        this.b.dispose();
        this.output.dispose();
        this.fade.dispose();
        this._g2a.dispose();
        this._panner.disconnect();
        this._split.disconnect();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../signal/GainToAudio":"5R2Lo","../../signal/Signal":"kfryg","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"8mp50":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AutoPanner is a [[Panner]] with an [[LFO]] connected to the pan amount.
 * [Related Reading](https://www.ableton.com/en/blog/autopan-chopper-effect-and-more-liveschool/).
 *
 * @example
 * // create an autopanner and start it
 * const autoPanner = new Tone.AutoPanner("4n").toDestination().start();
 * // route an oscillator through the panner and start it
 * const oscillator = new Tone.Oscillator().connect(autoPanner).start();
 * @category Effect
 */ parcelHelpers.export(exports, "AutoPanner", ()=>AutoPanner
);
var _panner = require("../component/channel/Panner");
var _defaults = require("../core/util/Defaults");
var _lfoeffect = require("./LFOEffect");
class AutoPanner extends _lfoeffect.LFOEffect {
    constructor(){
        super(_defaults.optionsFromArguments(AutoPanner.getDefaults(), arguments, [
            "frequency"
        ]));
        this.name = "AutoPanner";
        const options = _defaults.optionsFromArguments(AutoPanner.getDefaults(), arguments, [
            "frequency"
        ]);
        this._panner = new _panner.Panner({
            context: this.context,
            channelCount: options.channelCount
        });
        // connections
        this.connectEffect(this._panner);
        this._lfo.connect(this._panner.pan);
        this._lfo.min = -1;
        this._lfo.max = 1;
    }
    static getDefaults() {
        return Object.assign(_lfoeffect.LFOEffect.getDefaults(), {
            channelCount: 1
        });
    }
    dispose() {
        super.dispose();
        this._panner.dispose();
        return this;
    }
}

},{"../component/channel/Panner":"03e3W","../core/util/Defaults":"kSyYt","./LFOEffect":"khieK","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"03e3W":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Panner is an equal power Left/Right Panner. It is a wrapper around the StereoPannerNode.
 * @example
 * return Tone.Offline(() => {
 * // move the input signal from right to left
 * 	const panner = new Tone.Panner(1).toDestination();
 * 	panner.pan.rampTo(-1, 0.5);
 * 	const osc = new Tone.Oscillator(100).connect(panner).start();
 * }, 0.5, 2);
 * @category Component
 */ parcelHelpers.export(exports, "Panner", ()=>Panner
);
var _param = require("../../core/context/Param");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
class Panner extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Panner.getDefaults(), arguments, [
            "pan"
        ])));
        this.name = "Panner";
        /**
         * the panner node
         */ this._panner = this.context.createStereoPanner();
        this.input = this._panner;
        this.output = this._panner;
        const options = _defaults.optionsFromArguments(Panner.getDefaults(), arguments, [
            "pan"
        ]);
        this.pan = new _param.Param({
            context: this.context,
            param: this._panner.pan,
            value: options.pan,
            minValue: -1,
            maxValue: 1
        });
        // this is necessary for standardized-audio-context
        // doesn't make any difference for the native AudioContext
        // https://github.com/chrisguttandin/standardized-audio-context/issues/647
        this._panner.channelCount = options.channelCount;
        this._panner.channelCountMode = "explicit";
        // initial value
        _interface.readOnly(this, "pan");
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            pan: 0,
            channelCount: 1
        });
    }
    dispose() {
        super.dispose();
        this._panner.disconnect();
        this.pan.dispose();
        return this;
    }
}

},{"../../core/context/Param":"2qxaM","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"hlzeE":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * AutoWah connects a [[Follower]] to a [[Filter]].
 * The frequency of the filter, follows the input amplitude curve.
 * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna).
 *
 * @example
 * const autoWah = new Tone.AutoWah(50, 6, -30).toDestination();
 * // initialize the synth and connect to autowah
 * const synth = new Tone.Synth().connect(autoWah);
 * // Q value influences the effect of the wah - default is 2
 * autoWah.Q.value = 6;
 * // more audible on higher notes
 * synth.triggerAttackRelease("C4", "8n");
 * @category Effect
 */ parcelHelpers.export(exports, "AutoWah", ()=>AutoWah
);
var _effect = require("./Effect");
var _filter = require("../component/filter/Filter");
var _follower = require("../component/analysis/Follower");
var _defaults = require("../core/util/Defaults");
var _gain = require("../core/context/Gain");
var _conversions = require("../core/type/Conversions");
var _scaleExp = require("../signal/ScaleExp");
var _interface = require("../core/util/Interface");
class AutoWah extends _effect.Effect {
    constructor(){
        super(_defaults.optionsFromArguments(AutoWah.getDefaults(), arguments, [
            "baseFrequency",
            "octaves",
            "sensitivity"
        ]));
        this.name = "AutoWah";
        const options = _defaults.optionsFromArguments(AutoWah.getDefaults(), arguments, [
            "baseFrequency",
            "octaves",
            "sensitivity"
        ]);
        this._follower = new _follower.Follower({
            context: this.context,
            smoothing: options.follower
        });
        this._sweepRange = new _scaleExp.ScaleExp({
            context: this.context,
            min: 0,
            max: 1,
            exponent: 0.5
        });
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._octaves = options.octaves;
        this._inputBoost = new _gain.Gain({
            context: this.context
        });
        this._bandpass = new _filter.Filter({
            context: this.context,
            rolloff: -48,
            frequency: 0,
            Q: options.Q
        });
        this._peaking = new _filter.Filter({
            context: this.context,
            type: "peaking"
        });
        this._peaking.gain.value = options.gain;
        this.gain = this._peaking.gain;
        this.Q = this._bandpass.Q;
        // the control signal path
        this.effectSend.chain(this._inputBoost, this._follower, this._sweepRange);
        this._sweepRange.connect(this._bandpass.frequency);
        this._sweepRange.connect(this._peaking.frequency);
        // the filtered path
        this.effectSend.chain(this._bandpass, this._peaking, this.effectReturn);
        // set the initial value
        this._setSweepRange();
        this.sensitivity = options.sensitivity;
        _interface.readOnly(this, [
            "gain",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            baseFrequency: 100,
            octaves: 6,
            sensitivity: 0,
            Q: 2,
            gain: 2,
            follower: 0.2
        });
    }
    /**
     * The number of octaves that the filter will sweep above the baseFrequency.
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        this._setSweepRange();
    }
    /**
     * The follower's smoothing time
     */ get follower() {
        return this._follower.smoothing;
    }
    set follower(follower) {
        this._follower.smoothing = follower;
    }
    /**
     * The base frequency from which the sweep will start from.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(baseFreq) {
        this._baseFrequency = this.toFrequency(baseFreq);
        this._setSweepRange();
    }
    /**
     * The sensitivity to control how responsive to the input signal the filter is.
     */ get sensitivity() {
        return _conversions.gainToDb(1 / this._inputBoost.gain.value);
    }
    set sensitivity(sensitivity) {
        this._inputBoost.gain.value = 1 / _conversions.dbToGain(sensitivity);
    }
    /**
     * sets the sweep range of the scaler
     */ _setSweepRange() {
        this._sweepRange.min = this._baseFrequency;
        this._sweepRange.max = Math.min(this._baseFrequency * Math.pow(2, this._octaves), this.context.sampleRate / 2);
    }
    dispose() {
        super.dispose();
        this._follower.dispose();
        this._sweepRange.dispose();
        this._bandpass.dispose();
        this._peaking.dispose();
        this._inputBoost.dispose();
        return this;
    }
}

},{"./Effect":"k385z","../component/filter/Filter":"5lZpJ","../component/analysis/Follower":"4UVcI","../core/util/Defaults":"kSyYt","../core/context/Gain":"7kpMn","../core/type/Conversions":"kOcnG","../signal/ScaleExp":"2Xk6m","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4UVcI":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Follower is a simple envelope follower.
 * It's implemented by applying a lowpass filter to the absolute value of the incoming signal.
 * ```
 *          +-----+    +---------------+
 * Input +--> Abs +----> OnePoleFilter +--> Output
 *          +-----+    +---------------+
 * ```
 * @category Component
 */ parcelHelpers.export(exports, "Follower", ()=>Follower
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _onePoleFilter = require("../filter/OnePoleFilter");
var _abs = require("../../signal/Abs");
class Follower extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Follower.getDefaults(), arguments, [
            "smoothing"
        ]));
        this.name = "Follower";
        const options = _defaults.optionsFromArguments(Follower.getDefaults(), arguments, [
            "smoothing"
        ]);
        this._abs = this.input = new _abs.Abs({
            context: this.context
        });
        this._lowpass = this.output = new _onePoleFilter.OnePoleFilter({
            context: this.context,
            frequency: 1 / this.toSeconds(options.smoothing),
            type: "lowpass"
        });
        this._abs.connect(this._lowpass);
        this._smoothing = options.smoothing;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            smoothing: 0.05
        });
    }
    /**
     * The amount of time it takes a value change to arrive at the updated value.
     */ get smoothing() {
        return this._smoothing;
    }
    set smoothing(smoothing) {
        this._smoothing = smoothing;
        this._lowpass.frequency = 1 / this.toSeconds(this.smoothing);
    }
    dispose() {
        super.dispose();
        this._abs.dispose();
        this._lowpass.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../filter/OnePoleFilter":"6YRG8","../../signal/Abs":"h4HAb","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"dlji0":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * BitCrusher down-samples the incoming signal to a different bit depth.
 * Lowering the bit depth of the signal creates distortion. Read more about BitCrushing
 * on [Wikipedia](https://en.wikipedia.org/wiki/Bitcrusher).
 * @example
 * // initialize crusher and route a synth through it
 * const crusher = new Tone.BitCrusher(4).toDestination();
 * const synth = new Tone.Synth().connect(crusher);
 * synth.triggerAttackRelease("C2", 2);
 *
 * @category Effect
 */ parcelHelpers.export(exports, "BitCrusher", ()=>BitCrusher
);
var _toneAudioWorklet = require("../core/worklet/ToneAudioWorklet");
var _effect = require("./Effect");
var _gain = require("../core/context/Gain");
var _defaults = require("../core/util/Defaults");
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _param = require("../core/context/Param");
var _bitCrusherWorklet = require("./BitCrusher.worklet");
class BitCrusher extends _effect.Effect {
    constructor(){
        super(_defaults.optionsFromArguments(BitCrusher.getDefaults(), arguments, [
            "bits"
        ]));
        this.name = "BitCrusher";
        const options = _defaults.optionsFromArguments(BitCrusher.getDefaults(), arguments, [
            "bits"
        ]);
        this._bitCrusherWorklet = new BitCrusherWorklet({
            context: this.context,
            bits: options.bits
        });
        // connect it up
        this.connectEffect(this._bitCrusherWorklet);
        this.bits = this._bitCrusherWorklet.bits;
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            bits: 4
        });
    }
    dispose() {
        super.dispose();
        this._bitCrusherWorklet.dispose();
        return this;
    }
}
/**
 * Internal class which creates an AudioWorklet to do the bit crushing
 */ class BitCrusherWorklet extends _toneAudioWorklet.ToneAudioWorklet {
    constructor(){
        super(_defaults.optionsFromArguments(BitCrusherWorklet.getDefaults(), arguments));
        this.name = "BitCrusherWorklet";
        const options1 = _defaults.optionsFromArguments(BitCrusherWorklet.getDefaults(), arguments);
        this.input = new _gain.Gain({
            context: this.context
        });
        this.output = new _gain.Gain({
            context: this.context
        });
        this.bits = new _param.Param({
            context: this.context,
            value: options1.bits,
            units: "positive",
            minValue: 1,
            maxValue: 16,
            param: this._dummyParam,
            swappable: true
        });
    }
    static getDefaults() {
        return Object.assign(_toneAudioWorklet.ToneAudioWorklet.getDefaults(), {
            bits: 12
        });
    }
    _audioWorkletName() {
        return _bitCrusherWorklet.workletName;
    }
    onReady(node) {
        _toneAudioNode.connectSeries(this.input, node, this.output);
        const bits = node.parameters.get("bits");
        this.bits.setParam(bits);
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.bits.dispose();
        return this;
    }
}

},{"../core/worklet/ToneAudioWorklet":"9RUwz","./Effect":"k385z","../core/context/Gain":"7kpMn","../core/util/Defaults":"kSyYt","../core/context/ToneAudioNode":"iT1SZ","../core/context/Param":"2qxaM","./BitCrusher.worklet":"isiVm","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"isiVm":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
parcelHelpers.export(exports, "workletName", ()=>workletName
);
parcelHelpers.export(exports, "bitCrusherWorklet", ()=>bitCrusherWorklet
);
var _singleIOProcessorWorklet = require("../core/worklet/SingleIOProcessor.worklet");
var _workletGlobalScope = require("../core/worklet/WorkletGlobalScope");
const workletName = "bit-crusher";
const bitCrusherWorklet = /* javascript */ `\n	class BitCrusherWorklet extends SingleIOProcessor {\n\n		static get parameterDescriptors() {\n			return [{\n				name: "bits",\n				defaultValue: 12,\n				minValue: 1,\n				maxValue: 16,\n				automationRate: 'k-rate'\n			}];\n		}\n\n		generate(input, _channel, parameters) {\n			const step = Math.pow(0.5, parameters.bits - 1);\n			const val = step * Math.floor(input / step + 0.5);\n			return val;\n		}\n	}\n`;
_workletGlobalScope.registerProcessor(workletName, bitCrusherWorklet);

},{"../core/worklet/SingleIOProcessor.worklet":"khtRN","../core/worklet/WorkletGlobalScope":"eDhav","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2Wred":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Chebyshev is a waveshaper which is good
 * for making different types of distortion sounds.
 * Note that odd orders sound very different from even ones,
 * and order = 1 is no change.
 * Read more at [music.columbia.edu](http://music.columbia.edu/cmc/musicandcomputers/chapter4/04_06.php).
 * @example
 * // create a new cheby
 * const cheby = new Tone.Chebyshev(50).toDestination();
 * // create a monosynth connected to our cheby
 * const synth = new Tone.MonoSynth().connect(cheby);
 * synth.triggerAttackRelease("C2", 0.4);
 * @category Effect
 */ parcelHelpers.export(exports, "Chebyshev", ()=>Chebyshev
);
var _effect = require("./Effect");
var _defaults = require("../core/util/Defaults");
var _waveShaper = require("../signal/WaveShaper");
class Chebyshev extends _effect.Effect {
    constructor(){
        super(_defaults.optionsFromArguments(Chebyshev.getDefaults(), arguments, [
            "order"
        ]));
        this.name = "Chebyshev";
        const options = _defaults.optionsFromArguments(Chebyshev.getDefaults(), arguments, [
            "order"
        ]);
        this._shaper = new _waveShaper.WaveShaper({
            context: this.context,
            length: 4096
        });
        this._order = options.order;
        this.connectEffect(this._shaper);
        this.order = options.order;
        this.oversample = options.oversample;
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            order: 1,
            oversample: "none"
        });
    }
    /**
     * get the coefficient for that degree
     * @param  x the x value
     * @param  degree
     * @param  memo memoize the computed value. this speeds up computation greatly.
     */ _getCoefficient(x, degree, memo) {
        if (memo.has(degree)) return memo.get(degree);
        else if (degree === 0) memo.set(degree, 0);
        else if (degree === 1) memo.set(degree, x);
        else memo.set(degree, 2 * x * this._getCoefficient(x, degree - 1, memo) - this._getCoefficient(x, degree - 2, memo));
        return memo.get(degree);
    }
    /**
     * The order of the Chebyshev polynomial which creates the equation which is applied to the incoming
     * signal through a Tone.WaveShaper. The equations are in the form:
     * ```
     * order 2: 2x^2 + 1
     * order 3: 4x^3 + 3x
     * ```
     * @min 1
     * @max 100
     */ get order() {
        return this._order;
    }
    set order(order) {
        this._order = order;
        this._shaper.setMap((x)=>{
            return this._getCoefficient(x, order, new Map());
        });
    }
    /**
     * The oversampling of the effect. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        this._shaper.oversample = oversampling;
    }
    dispose() {
        super.dispose();
        this._shaper.dispose();
        return this;
    }
}

},{"./Effect":"k385z","../core/util/Defaults":"kSyYt","../signal/WaveShaper":"4cjPf","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fEh3Z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Chorus is a stereo chorus effect composed of a left and right delay with an [[LFO]] applied to the delayTime of each channel.
 * When [[feedback]] is set to a value larger than 0, you also get Flanger-type effects.
 * Inspiration from [Tuna.js](https://github.com/Dinahmoe/tuna/blob/master/tuna.js).
 * Read more on the chorus effect on [SoundOnSound](http://www.soundonsound.com/sos/jun04/articles/synthsecrets.htm).
 *
 * @example
 * const chorus = new Tone.Chorus(4, 2.5, 0.5).toDestination().start();
 * const synth = new Tone.PolySynth().connect(chorus);
 * synth.triggerAttackRelease(["C3", "E3", "G3"], "8n");
 *
 * @category Effect
 */ parcelHelpers.export(exports, "Chorus", ()=>Chorus
);
var _stereoFeedbackEffect = require("../effect/StereoFeedbackEffect");
var _defaults = require("../core/util/Defaults");
var _lfo = require("../source/oscillator/LFO");
var _delay = require("../core/context/Delay");
var _interface = require("../core/util/Interface");
class Chorus extends _stereoFeedbackEffect.StereoFeedbackEffect {
    constructor(){
        super(_defaults.optionsFromArguments(Chorus.getDefaults(), arguments, [
            "frequency",
            "delayTime",
            "depth"
        ]));
        this.name = "Chorus";
        const options = _defaults.optionsFromArguments(Chorus.getDefaults(), arguments, [
            "frequency",
            "delayTime",
            "depth"
        ]);
        this._depth = options.depth;
        this._delayTime = options.delayTime / 1000;
        this._lfoL = new _lfo.LFO({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1
        });
        this._lfoR = new _lfo.LFO({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1,
            phase: 180
        });
        this._delayNodeL = new _delay.Delay({
            context: this.context
        });
        this._delayNodeR = new _delay.Delay({
            context: this.context
        });
        this.frequency = this._lfoL.frequency;
        _interface.readOnly(this, [
            "frequency"
        ]);
        // have one LFO frequency control the other
        this._lfoL.frequency.connect(this._lfoR.frequency);
        // connections
        this.connectEffectLeft(this._delayNodeL);
        this.connectEffectRight(this._delayNodeR);
        // lfo setup
        this._lfoL.connect(this._delayNodeL.delayTime);
        this._lfoR.connect(this._delayNodeR.delayTime);
        // set the initial values
        this.depth = this._depth;
        this.type = options.type;
        this.spread = options.spread;
    }
    static getDefaults() {
        return Object.assign(_stereoFeedbackEffect.StereoFeedbackEffect.getDefaults(), {
            frequency: 1.5,
            delayTime: 3.5,
            depth: 0.7,
            type: "sine",
            spread: 180,
            feedback: 0,
            wet: 0.5
        });
    }
    /**
     * The depth of the effect. A depth of 1 makes the delayTime
     * modulate between 0 and 2*delayTime (centered around the delayTime).
     */ get depth() {
        return this._depth;
    }
    set depth(depth) {
        this._depth = depth;
        const deviation = this._delayTime * depth;
        this._lfoL.min = Math.max(this._delayTime - deviation, 0);
        this._lfoL.max = this._delayTime + deviation;
        this._lfoR.min = Math.max(this._delayTime - deviation, 0);
        this._lfoR.max = this._delayTime + deviation;
    }
    /**
     * The delayTime in milliseconds of the chorus. A larger delayTime
     * will give a more pronounced effect. Nominal range a delayTime
     * is between 2 and 20ms.
     */ get delayTime() {
        return this._delayTime * 1000;
    }
    set delayTime(delayTime) {
        this._delayTime = delayTime / 1000;
        this.depth = this._depth;
    }
    /**
     * The oscillator type of the LFO.
     */ get type() {
        return this._lfoL.type;
    }
    set type(type) {
        this._lfoL.type = type;
        this._lfoR.type = type;
    }
    /**
     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
     * When set to 180, LFO's will be panned hard left and right respectively.
     */ get spread() {
        return this._lfoR.phase - this._lfoL.phase;
    }
    set spread(spread) {
        this._lfoL.phase = 90 - spread / 2;
        this._lfoR.phase = spread / 2 + 90;
    }
    /**
     * Start the effect.
     */ start(time) {
        this._lfoL.start(time);
        this._lfoR.start(time);
        return this;
    }
    /**
     * Stop the lfo
     */ stop(time) {
        this._lfoL.stop(time);
        this._lfoR.stop(time);
        return this;
    }
    /**
     * Sync the filter to the transport. See [[LFO.sync]]
     */ sync() {
        this._lfoL.sync();
        this._lfoR.sync();
        return this;
    }
    /**
     * Unsync the filter from the transport.
     */ unsync() {
        this._lfoL.unsync();
        this._lfoR.unsync();
        return this;
    }
    dispose() {
        super.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._delayNodeL.dispose();
        this._delayNodeR.dispose();
        this.frequency.dispose();
        return this;
    }
}

},{"../effect/StereoFeedbackEffect":"fuoRv","../core/util/Defaults":"kSyYt","../source/oscillator/LFO":"d8Ivp","../core/context/Delay":"fGWul","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fuoRv":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for stereo feedback effects where the effectReturn is fed back into the same channel.
 */ parcelHelpers.export(exports, "StereoFeedbackEffect", ()=>StereoFeedbackEffect
);
var _stereoEffect = require("./StereoEffect");
var _signal = require("../signal/Signal");
var _gain = require("../core/context/Gain");
var _interface = require("../core/util/Interface");
var _split = require("../component/channel/Split");
var _merge = require("../component/channel/Merge");
class StereoFeedbackEffect extends _stereoEffect.StereoEffect {
    constructor(options){
        super(options);
        this.feedback = new _signal.Signal({
            context: this.context,
            value: options.feedback,
            units: "normalRange"
        });
        this._feedbackL = new _gain.Gain({
            context: this.context
        });
        this._feedbackR = new _gain.Gain({
            context: this.context
        });
        this._feedbackSplit = new _split.Split({
            context: this.context,
            channels: 2
        });
        this._feedbackMerge = new _merge.Merge({
            context: this.context,
            channels: 2
        });
        this._merge.connect(this._feedbackSplit);
        this._feedbackMerge.connect(this._split);
        // the left output connected to the left input
        this._feedbackSplit.connect(this._feedbackL, 0, 0);
        this._feedbackL.connect(this._feedbackMerge, 0, 0);
        // the right output connected to the right input
        this._feedbackSplit.connect(this._feedbackR, 1, 0);
        this._feedbackR.connect(this._feedbackMerge, 0, 1);
        // the feedback control
        this.feedback.fan(this._feedbackL.gain, this._feedbackR.gain);
        _interface.readOnly(this, [
            "feedback"
        ]);
    }
    static getDefaults() {
        return Object.assign(_stereoEffect.StereoEffect.getDefaults(), {
            feedback: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.feedback.dispose();
        this._feedbackL.dispose();
        this._feedbackR.dispose();
        this._feedbackSplit.dispose();
        this._feedbackMerge.dispose();
        return this;
    }
}

},{"./StereoEffect":"9c7Xr","../signal/Signal":"kfryg","../core/context/Gain":"7kpMn","../core/util/Interface":"fVoXs","../component/channel/Split":"fvmN8","../component/channel/Merge":"4QcRh","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9c7Xr":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Base class for Stereo effects.
 */ parcelHelpers.export(exports, "StereoEffect", ()=>StereoEffect
);
var _toneAudioNode = require("../core/context/ToneAudioNode");
var _crossFade = require("../component/channel/CrossFade");
var _split = require("../component/channel/Split");
var _gain = require("../core/context/Gain");
var _merge = require("../component/channel/Merge");
var _interface = require("../core/util/Interface");
class StereoEffect extends _toneAudioNode.ToneAudioNode {
    constructor(options){
        super(options);
        this.name = "StereoEffect";
        this.input = new _gain.Gain({
            context: this.context
        });
        // force mono sources to be stereo
        this.input.channelCount = 2;
        this.input.channelCountMode = "explicit";
        this._dryWet = this.output = new _crossFade.CrossFade({
            context: this.context,
            fade: options.wet
        });
        this.wet = this._dryWet.fade;
        this._split = new _split.Split({
            context: this.context,
            channels: 2
        });
        this._merge = new _merge.Merge({
            context: this.context,
            channels: 2
        });
        // connections
        this.input.connect(this._split);
        // dry wet connections
        this.input.connect(this._dryWet.a);
        this._merge.connect(this._dryWet.b);
        _interface.readOnly(this, [
            "wet"
        ]);
    }
    /**
     * Connect the left part of the effect
     */ connectEffectLeft(...nodes) {
        this._split.connect(nodes[0], 0, 0);
        _toneAudioNode.connectSeries(...nodes);
        _toneAudioNode.connect(nodes[nodes.length - 1], this._merge, 0, 0);
    }
    /**
     * Connect the right part of the effect
     */ connectEffectRight(...nodes) {
        this._split.connect(nodes[0], 1, 0);
        _toneAudioNode.connectSeries(...nodes);
        _toneAudioNode.connect(nodes[nodes.length - 1], this._merge, 0, 1);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            wet: 1
        });
    }
    dispose() {
        super.dispose();
        this._dryWet.dispose();
        this._split.dispose();
        this._merge.dispose();
        return this;
    }
}

},{"../core/context/ToneAudioNode":"iT1SZ","../component/channel/CrossFade":"hj0PR","../component/channel/Split":"fvmN8","../core/context/Gain":"7kpMn","../component/channel/Merge":"4QcRh","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"fvmN8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Split splits an incoming signal into the number of given channels.
 *
 * @example
 * const split = new Tone.Split();
 * // stereoSignal.connect(split);
 * @category Component
 */ parcelHelpers.export(exports, "Split", ()=>Split
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
class Split extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Split.getDefaults(), arguments, [
            "channels"
        ]));
        this.name = "Split";
        const options = _defaults.optionsFromArguments(Split.getDefaults(), arguments, [
            "channels"
        ]);
        this._splitter = this.input = this.output = this.context.createChannelSplitter(options.channels);
        this._internalChannels = [
            this._splitter
        ];
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            channels: 2
        });
    }
    dispose() {
        super.dispose();
        this._splitter.disconnect();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"4QcRh":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Merge brings multiple mono input channels into a single multichannel output channel.
 *
 * @example
 * const merge = new Tone.Merge().toDestination();
 * // routing a sine tone in the left channel
 * const osc = new Tone.Oscillator().connect(merge, 0, 0).start();
 * // and noise in the right channel
 * const noise = new Tone.Noise().connect(merge, 0, 1).start();;
 * @category Component
 */ parcelHelpers.export(exports, "Merge", ()=>Merge
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
class Merge extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Merge.getDefaults(), arguments, [
            "channels"
        ]));
        this.name = "Merge";
        const options = _defaults.optionsFromArguments(Merge.getDefaults(), arguments, [
            "channels"
        ]);
        this._merger = this.output = this.input = this.context.createChannelMerger(options.channels);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            channels: 2
        });
    }
    dispose() {
        super.dispose();
        this._merger.disconnect();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9ZFE2":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A simple distortion effect using Tone.WaveShaper.
 * Algorithm from [this stackoverflow answer](http://stackoverflow.com/a/22313408).
 *
 * @example
 * const dist = new Tone.Distortion(0.8).toDestination();
 * const fm = new Tone.FMSynth().connect(dist);
 * fm.triggerAttackRelease("A1", "8n");
 * @category Effect
 */ parcelHelpers.export(exports, "Distortion", ()=>Distortion
);
var _defaults = require("../core/util/Defaults");
var _waveShaper = require("../signal/WaveShaper");
var _effect = require("./Effect");
class Distortion extends _effect.Effect {
    constructor(){
        super(_defaults.optionsFromArguments(Distortion.getDefaults(), arguments, [
            "distortion"
        ]));
        this.name = "Distortion";
        const options = _defaults.optionsFromArguments(Distortion.getDefaults(), arguments, [
            "distortion"
        ]);
        this._shaper = new _waveShaper.WaveShaper({
            context: this.context,
            length: 4096
        });
        this._distortion = options.distortion;
        this.connectEffect(this._shaper);
        this.distortion = options.distortion;
        this.oversample = options.oversample;
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            distortion: 0.4,
            oversample: "none"
        });
    }
    /**
     * The amount of distortion. Nominal range is between 0 and 1.
     */ get distortion() {
        return this._distortion;
    }
    set distortion(amount) {
        this._distortion = amount;
        const k = amount * 100;
        const deg = Math.PI / 180;
        this._shaper.setMap((x)=>{
            if (Math.abs(x) < 0.001) // should output 0 when input is 0
            return 0;
            else return (3 + k) * x * 20 * deg / (Math.PI + k * Math.abs(x));
        });
    }
    /**
     * The oversampling of the effect. Can either be "none", "2x" or "4x".
     */ get oversample() {
        return this._shaper.oversample;
    }
    set oversample(oversampling) {
        this._shaper.oversample = oversampling;
    }
    dispose() {
        super.dispose();
        this._shaper.dispose();
        return this;
    }
}

},{"../core/util/Defaults":"kSyYt","../signal/WaveShaper":"4cjPf","./Effect":"k385z","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"921Az":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FeedbackDelay is a DelayNode in which part of output signal is fed back into the delay.
 *
 * @param delayTime The delay applied to the incoming signal.
 * @param feedback The amount of the effected signal which is fed back through the delay.
 * @example
 * const feedbackDelay = new Tone.FeedbackDelay("8n", 0.5).toDestination();
 * const tom = new Tone.MembraneSynth({
 * 	octaves: 4,
 * 	pitchDecay: 0.1
 * }).connect(feedbackDelay);
 * tom.triggerAttackRelease("A2", "32n");
 * @category Effect
 */ parcelHelpers.export(exports, "FeedbackDelay", ()=>FeedbackDelay
);
var _delay = require("../core/context/Delay");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _feedbackEffect = require("./FeedbackEffect");
class FeedbackDelay extends _feedbackEffect.FeedbackEffect {
    constructor(){
        super(_defaults.optionsFromArguments(FeedbackDelay.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]));
        this.name = "FeedbackDelay";
        const options = _defaults.optionsFromArguments(FeedbackDelay.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]);
        this._delayNode = new _delay.Delay({
            context: this.context,
            delayTime: options.delayTime,
            maxDelay: options.maxDelay
        });
        this.delayTime = this._delayNode.delayTime;
        // connect it up
        this.connectEffect(this._delayNode);
        _interface.readOnly(this, "delayTime");
    }
    static getDefaults() {
        return Object.assign(_feedbackEffect.FeedbackEffect.getDefaults(), {
            delayTime: 0.25,
            maxDelay: 1
        });
    }
    dispose() {
        super.dispose();
        this._delayNode.dispose();
        this.delayTime.dispose();
        return this;
    }
}

},{"../core/context/Delay":"fGWul","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","./FeedbackEffect":"7RXqA","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7RXqA":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FeedbackEffect provides a loop between an audio source and its own output.
 * This is a base-class for feedback effects.
 */ parcelHelpers.export(exports, "FeedbackEffect", ()=>FeedbackEffect
);
var _gain = require("../core/context/Gain");
var _interface = require("../core/util/Interface");
var _effect = require("./Effect");
class FeedbackEffect extends _effect.Effect {
    constructor(options){
        super(options);
        this.name = "FeedbackEffect";
        this._feedbackGain = new _gain.Gain({
            context: this.context,
            gain: options.feedback,
            units: "normalRange"
        });
        this.feedback = this._feedbackGain.gain;
        _interface.readOnly(this, "feedback");
        // the feedback loop
        this.effectReturn.chain(this._feedbackGain, this.effectSend);
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            feedback: 0.125
        });
    }
    dispose() {
        super.dispose();
        this._feedbackGain.dispose();
        this.feedback.dispose();
        return this;
    }
}

},{"../core/context/Gain":"7kpMn","../core/util/Interface":"fVoXs","./Effect":"k385z","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2FcKB":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * FrequencyShifter can be used to shift all frequencies of a signal by a fixed amount.
 * The amount can be changed at audio rate and the effect is applied in real time.
 * The frequency shifting is implemented with a technique called single side band modulation using a ring modulator.
 * Note: Contrary to pitch shifting, all frequencies are shifted by the same amount,
 * destroying the harmonic relationship between them. This leads to the classic ring modulator timbre distortion.
 * The algorithm will produces some aliasing towards the high end, especially if your source material
 * contains a lot of high frequencies. Unfortunatelly the webaudio API does not support resampling
 * buffers in real time, so it is not possible to fix it properly. Depending on the use case it might
 * be an option to low pass filter your input before frequency shifting it to get ride of the aliasing.
 * You can find a very detailed description of the algorithm here: https://larzeitlin.github.io/RMFS/
 *
 * @example
 * const input = new Tone.Oscillator(230, "sawtooth").start();
 * const shift = new Tone.FrequencyShifter(42).toDestination();
 * input.connect(shift);
 * @category Effect
 */ parcelHelpers.export(exports, "FrequencyShifter", ()=>FrequencyShifter
);
var _phaseShiftAllpass = require("../component/filter/PhaseShiftAllpass");
var _defaults = require("../core/util/Defaults");
var _effect = require("../effect/Effect");
var _add = require("../signal/Add");
var _multiply = require("../signal/Multiply");
var _negate = require("../signal/Negate");
var _signal = require("../signal/Signal");
var _oscillator = require("../source/oscillator/Oscillator");
var _toneOscillatorNode = require("../source/oscillator/ToneOscillatorNode");
class FrequencyShifter extends _effect.Effect {
    constructor(){
        super(_defaults.optionsFromArguments(FrequencyShifter.getDefaults(), arguments, [
            "frequency"
        ]));
        this.name = "FrequencyShifter";
        const options = _defaults.optionsFromArguments(FrequencyShifter.getDefaults(), arguments, [
            "frequency"
        ]);
        this.frequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: options.frequency,
            minValue: -this.context.sampleRate / 2,
            maxValue: this.context.sampleRate / 2
        });
        this._sine = new _toneOscillatorNode.ToneOscillatorNode({
            context: this.context,
            type: "sine"
        });
        this._cosine = new _oscillator.Oscillator({
            context: this.context,
            phase: -90,
            type: "sine"
        });
        this._sineMultiply = new _multiply.Multiply({
            context: this.context
        });
        this._cosineMultiply = new _multiply.Multiply({
            context: this.context
        });
        this._negate = new _negate.Negate({
            context: this.context
        });
        this._add = new _add.Add({
            context: this.context
        });
        this._phaseShifter = new _phaseShiftAllpass.PhaseShiftAllpass({
            context: this.context
        });
        this.effectSend.connect(this._phaseShifter);
        // connect the carrier frequency signal to the two oscillators
        this.frequency.fan(this._sine.frequency, this._cosine.frequency);
        this._phaseShifter.offset90.connect(this._cosineMultiply);
        this._cosine.connect(this._cosineMultiply.factor);
        this._phaseShifter.connect(this._sineMultiply);
        this._sine.connect(this._sineMultiply.factor);
        this._sineMultiply.connect(this._negate);
        this._cosineMultiply.connect(this._add);
        this._negate.connect(this._add.addend);
        this._add.connect(this.effectReturn);
        // start the oscillators at the same time
        const now = this.immediate();
        this._sine.start(now);
        this._cosine.start(now);
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            frequency: 0
        });
    }
    dispose() {
        super.dispose();
        this.frequency.dispose();
        this._add.dispose();
        this._cosine.dispose();
        this._cosineMultiply.dispose();
        this._negate.dispose();
        this._phaseShifter.dispose();
        this._sine.dispose();
        this._sineMultiply.dispose();
        return this;
    }
}

},{"../component/filter/PhaseShiftAllpass":"lHrr3","../core/util/Defaults":"kSyYt","../effect/Effect":"k385z","../signal/Add":"iRri4","../signal/Multiply":"bN8EY","../signal/Negate":"d15RF","../signal/Signal":"kfryg","../source/oscillator/Oscillator":"715Gq","../source/oscillator/ToneOscillatorNode":"ahlJc","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lHrr3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PhaseShiftAllpass is an very efficient implementation of a Hilbert Transform
 * using two Allpass filter banks whose outputs have a phase difference of 90°.
 * Here the `offset90` phase is offset by +90° in relation to `output`.
 * Coefficients and structure was developed by Olli Niemitalo.
 * For more details see: http://yehar.com/blog/?p=368
 * @category Component
 */ parcelHelpers.export(exports, "PhaseShiftAllpass", ()=>PhaseShiftAllpass
);
var _gain = require("../../core/context/Gain");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
class PhaseShiftAllpass extends _toneAudioNode.ToneAudioNode {
    constructor(options){
        super(options);
        this.name = "PhaseShiftAllpass";
        this.input = new _gain.Gain({
            context: this.context
        });
        /**
         * The phase shifted output
         */ this.output = new _gain.Gain({
            context: this.context
        });
        /**
         * The PhaseShifted allpass output
         */ this.offset90 = new _gain.Gain({
            context: this.context
        });
        const allpassBank1Values = [
            0.6923878,
            0.9360654322959,
            0.988229522686,
            0.9987488452737
        ];
        const allpassBank2Values = [
            0.4021921162426,
            0.856171088242,
            0.9722909545651,
            0.9952884791278
        ];
        this._bank0 = this._createAllPassFilterBank(allpassBank1Values);
        this._bank1 = this._createAllPassFilterBank(allpassBank2Values);
        this._oneSampleDelay = this.context.createIIRFilter([
            0,
            1
        ], [
            1,
            0
        ]);
        // connect Allpass filter banks
        _toneAudioNode.connectSeries(this.input, ...this._bank0, this._oneSampleDelay, this.output);
        _toneAudioNode.connectSeries(this.input, ...this._bank1, this.offset90);
    }
    /**
     * Create all of the IIR filters from an array of values using the coefficient calculation.
     */ _createAllPassFilterBank(bankValues) {
        const nodes = bankValues.map((value)=>{
            const coefficients = [
                [
                    value * value,
                    0,
                    -1
                ],
                [
                    1,
                    0,
                    -(value * value)
                ]
            ];
            return this.context.createIIRFilter(coefficients[0], coefficients[1]);
        });
        return nodes;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this.output.dispose();
        this.offset90.dispose();
        this._bank0.forEach((f)=>f.disconnect()
        );
        this._bank1.forEach((f)=>f.disconnect()
        );
        this._oneSampleDelay.disconnect();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/ToneAudioNode":"iT1SZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jKkIp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Freeverb is a reverb based on [Freeverb](https://ccrma.stanford.edu/~jos/pasp/Freeverb.html).
 * Read more on reverb on [Sound On Sound](https://web.archive.org/web/20160404083902/http://www.soundonsound.com:80/sos/feb01/articles/synthsecrets.asp).
 * Freeverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using [[Reverb]].
 * @example
 * const freeverb = new Tone.Freeverb().toDestination();
 * freeverb.dampening = 1000;
 * // routing synth through the reverb
 * const synth = new Tone.NoiseSynth().connect(freeverb);
 * synth.triggerAttackRelease(0.05);
 * @category Effect
 */ parcelHelpers.export(exports, "Freeverb", ()=>Freeverb
);
var _stereoEffect = require("./StereoEffect");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _signal = require("../signal/Signal");
var _lowpassCombFilter = require("../component/filter/LowpassCombFilter");
/**
 * An array of comb filter delay values from Freeverb implementation
 */ const combFilterTunings = [
    1557 / 44100,
    1617 / 44100,
    1491 / 44100,
    1422 / 44100,
    1277 / 44100,
    1356 / 44100,
    1188 / 44100,
    1116 / 44100
];
/**
 * An array of allpass filter frequency values from Freeverb implementation
 */ const allpassFilterFrequencies = [
    225,
    556,
    441,
    341
];
class Freeverb extends _stereoEffect.StereoEffect {
    constructor(){
        super(_defaults.optionsFromArguments(Freeverb.getDefaults(), arguments, [
            "roomSize",
            "dampening"
        ]));
        this.name = "Freeverb";
        /**
         * the comb filters
         */ this._combFilters = [];
        /**
         * the allpass filters on the left
         */ this._allpassFiltersL = [];
        /**
         * the allpass filters on the right
         */ this._allpassFiltersR = [];
        const options = _defaults.optionsFromArguments(Freeverb.getDefaults(), arguments, [
            "roomSize",
            "dampening"
        ]);
        this.roomSize = new _signal.Signal({
            context: this.context,
            value: options.roomSize,
            units: "normalRange"
        });
        // make the allpass filters on the right
        this._allpassFiltersL = allpassFilterFrequencies.map((freq)=>{
            const allpassL = this.context.createBiquadFilter();
            allpassL.type = "allpass";
            allpassL.frequency.value = freq;
            return allpassL;
        });
        // make the allpass filters on the left
        this._allpassFiltersR = allpassFilterFrequencies.map((freq)=>{
            const allpassR = this.context.createBiquadFilter();
            allpassR.type = "allpass";
            allpassR.frequency.value = freq;
            return allpassR;
        });
        // make the comb filters
        this._combFilters = combFilterTunings.map((delayTime, index)=>{
            const lfpf = new _lowpassCombFilter.LowpassCombFilter({
                context: this.context,
                dampening: options.dampening,
                delayTime
            });
            if (index < combFilterTunings.length / 2) this.connectEffectLeft(lfpf, ...this._allpassFiltersL);
            else this.connectEffectRight(lfpf, ...this._allpassFiltersR);
            this.roomSize.connect(lfpf.resonance);
            return lfpf;
        });
        _interface.readOnly(this, [
            "roomSize"
        ]);
    }
    static getDefaults() {
        return Object.assign(_stereoEffect.StereoEffect.getDefaults(), {
            roomSize: 0.7,
            dampening: 3000
        });
    }
    /**
     * The amount of dampening of the reverberant signal.
     */ get dampening() {
        return this._combFilters[0].dampening;
    }
    set dampening(d) {
        this._combFilters.forEach((c)=>c.dampening = d
        );
    }
    dispose() {
        super.dispose();
        this._allpassFiltersL.forEach((al)=>al.disconnect()
        );
        this._allpassFiltersR.forEach((ar)=>ar.disconnect()
        );
        this._combFilters.forEach((cf)=>cf.dispose()
        );
        this.roomSize.dispose();
        return this;
    }
}

},{"./StereoEffect":"9c7Xr","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../signal/Signal":"kfryg","../component/filter/LowpassCombFilter":"ezloU","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"5m0vd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * JCReverb is a simple [Schroeder Reverberator](https://ccrma.stanford.edu/~jos/pasp/Schroeder_Reverberators.html)
 * tuned by John Chowning in 1970.
 * It is made up of three allpass filters and four [[FeedbackCombFilter]].
 * JCReverb is now implemented with an AudioWorkletNode which may result on performance degradation on some platforms. Consider using [[Reverb]].
 * @example
 * const reverb = new Tone.JCReverb(0.4).toDestination();
 * const delay = new Tone.FeedbackDelay(0.5);
 * // connecting the synth to reverb through delay
 * const synth = new Tone.DuoSynth().chain(delay, reverb);
 * synth.triggerAttackRelease("A4", "8n");
 *
 * @category Effect
 */ parcelHelpers.export(exports, "JCReverb", ()=>JCReverb
);
var _stereoEffect = require("./StereoEffect");
var _defaults = require("../core/util/Defaults");
var _scale = require("../signal/Scale");
var _signal = require("../signal/Signal");
var _feedbackCombFilter = require("../component/filter/FeedbackCombFilter");
var _interface = require("../core/util/Interface");
/**
 * an array of the comb filter delay time values
 */ const combFilterDelayTimes = [
    0.06748,
    0.06404,
    0.08212,
    0.09004
];
/**
 * the resonances of each of the comb filters
 */ const combFilterResonances = [
    0.773,
    0.802,
    0.753,
    0.733
];
/**
 * the allpass filter frequencies
 */ const allpassFilterFreqs = [
    347,
    113,
    37
];
class JCReverb extends _stereoEffect.StereoEffect {
    constructor(){
        super(_defaults.optionsFromArguments(JCReverb.getDefaults(), arguments, [
            "roomSize"
        ]));
        this.name = "JCReverb";
        /**
         * a series of allpass filters
         */ this._allpassFilters = [];
        /**
         * parallel feedback comb filters
         */ this._feedbackCombFilters = [];
        const options = _defaults.optionsFromArguments(JCReverb.getDefaults(), arguments, [
            "roomSize"
        ]);
        this.roomSize = new _signal.Signal({
            context: this.context,
            value: options.roomSize,
            units: "normalRange"
        });
        this._scaleRoomSize = new _scale.Scale({
            context: this.context,
            min: -0.733,
            max: 0.197
        });
        // make the allpass filters
        this._allpassFilters = allpassFilterFreqs.map((freq)=>{
            const allpass = this.context.createBiquadFilter();
            allpass.type = "allpass";
            allpass.frequency.value = freq;
            return allpass;
        });
        // and the comb filters
        this._feedbackCombFilters = combFilterDelayTimes.map((delayTime, index)=>{
            const fbcf = new _feedbackCombFilter.FeedbackCombFilter({
                context: this.context,
                delayTime
            });
            this._scaleRoomSize.connect(fbcf.resonance);
            fbcf.resonance.value = combFilterResonances[index];
            if (index < combFilterDelayTimes.length / 2) this.connectEffectLeft(...this._allpassFilters, fbcf);
            else this.connectEffectRight(...this._allpassFilters, fbcf);
            return fbcf;
        });
        // chain the allpass filters together
        this.roomSize.connect(this._scaleRoomSize);
        _interface.readOnly(this, [
            "roomSize"
        ]);
    }
    static getDefaults() {
        return Object.assign(_stereoEffect.StereoEffect.getDefaults(), {
            roomSize: 0.5
        });
    }
    dispose() {
        super.dispose();
        this._allpassFilters.forEach((apf)=>apf.disconnect()
        );
        this._feedbackCombFilters.forEach((fbcf)=>fbcf.dispose()
        );
        this.roomSize.dispose();
        this._scaleRoomSize.dispose();
        return this;
    }
}

},{"./StereoEffect":"9c7Xr","../core/util/Defaults":"kSyYt","../signal/Scale":"j7ETW","../signal/Signal":"kfryg","../component/filter/FeedbackCombFilter":"iTrd6","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9fqVT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PingPongDelay is a feedback delay effect where the echo is heard
 * first in one channel and next in the opposite channel. In a stereo
 * system these are the right and left channels.
 * PingPongDelay in more simplified terms is two Tone.FeedbackDelays
 * with independent delay values. Each delay is routed to one channel
 * (left or right), and the channel triggered second will always
 * trigger at the same interval after the first.
 * @example
 * const pingPong = new Tone.PingPongDelay("4n", 0.2).toDestination();
 * const drum = new Tone.MembraneSynth().connect(pingPong);
 * drum.triggerAttackRelease("C4", "32n");
 * @category Effect
 */ parcelHelpers.export(exports, "PingPongDelay", ()=>PingPongDelay
);
var _stereoXFeedbackEffect = require("./StereoXFeedbackEffect");
var _defaults = require("../core/util/Defaults");
var _delay = require("../core/context/Delay");
var _signal = require("../signal/Signal");
var _interface = require("../core/util/Interface");
class PingPongDelay extends _stereoXFeedbackEffect.StereoXFeedbackEffect {
    constructor(){
        super(_defaults.optionsFromArguments(PingPongDelay.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]));
        this.name = "PingPongDelay";
        const options = _defaults.optionsFromArguments(PingPongDelay.getDefaults(), arguments, [
            "delayTime",
            "feedback"
        ]);
        this._leftDelay = new _delay.Delay({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this._rightDelay = new _delay.Delay({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this._rightPreDelay = new _delay.Delay({
            context: this.context,
            maxDelay: options.maxDelay
        });
        this.delayTime = new _signal.Signal({
            context: this.context,
            units: "time",
            value: options.delayTime
        });
        // connect it up
        this.connectEffectLeft(this._leftDelay);
        this.connectEffectRight(this._rightPreDelay, this._rightDelay);
        this.delayTime.fan(this._leftDelay.delayTime, this._rightDelay.delayTime, this._rightPreDelay.delayTime);
        // rearranged the feedback to be after the rightPreDelay
        this._feedbackL.disconnect();
        this._feedbackL.connect(this._rightDelay);
        _interface.readOnly(this, [
            "delayTime"
        ]);
    }
    static getDefaults() {
        return Object.assign(_stereoXFeedbackEffect.StereoXFeedbackEffect.getDefaults(), {
            delayTime: 0.25,
            maxDelay: 1
        });
    }
    dispose() {
        super.dispose();
        this._leftDelay.dispose();
        this._rightDelay.dispose();
        this._rightPreDelay.dispose();
        this.delayTime.dispose();
        return this;
    }
}

},{"./StereoXFeedbackEffect":"VLYIK","../core/util/Defaults":"kSyYt","../core/context/Delay":"fGWul","../signal/Signal":"kfryg","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"VLYIK":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Just like a [[StereoFeedbackEffect]], but the feedback is routed from left to right
 * and right to left instead of on the same channel.
 * ```
 * +--------------------------------+ feedbackL <-----------------------------------+
 * |                                                                                |
 * +-->                          +----->        +---->                          +-----+
 *      feedbackMerge +--> split        (EFFECT)       merge +--> feedbackSplit     | |
 * +-->                          +----->        +---->                          +---+ |
 * |                                                                                  |
 * +--------------------------------+ feedbackR <-------------------------------------+
 * ```
 */ parcelHelpers.export(exports, "StereoXFeedbackEffect", ()=>StereoXFeedbackEffect
);
var _stereoFeedbackEffect = require("./StereoFeedbackEffect");
var _interface = require("../core/util/Interface");
class StereoXFeedbackEffect extends _stereoFeedbackEffect.StereoFeedbackEffect {
    constructor(options){
        super(options);
        // the left output connected to the right input
        this._feedbackL.disconnect();
        this._feedbackL.connect(this._feedbackMerge, 0, 1);
        // the left output connected to the right input
        this._feedbackR.disconnect();
        this._feedbackR.connect(this._feedbackMerge, 0, 0);
        _interface.readOnly(this, [
            "feedback"
        ]);
    }
}

},{"./StereoFeedbackEffect":"fuoRv","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"aOCHY":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PitchShift does near-realtime pitch shifting to the incoming signal.
 * The effect is achieved by speeding up or slowing down the delayTime
 * of a DelayNode using a sawtooth wave.
 * Algorithm found in [this pdf](http://dsp-book.narod.ru/soundproc.pdf).
 * Additional reference by [Miller Pucket](http://msp.ucsd.edu/techniques/v0.11/book-html/node115.html).
 * @category Effect
 */ parcelHelpers.export(exports, "PitchShift", ()=>PitchShift
);
var _feedbackEffect = require("./FeedbackEffect");
var _defaults = require("../core/util/Defaults");
var _lfo = require("../source/oscillator/LFO");
var _delay = require("../core/context/Delay");
var _crossFade = require("../component/channel/CrossFade");
var _signal = require("../signal/Signal");
var _interface = require("../core/util/Interface");
var _conversions = require("../core/type/Conversions");
class PitchShift extends _feedbackEffect.FeedbackEffect {
    constructor(){
        super(_defaults.optionsFromArguments(PitchShift.getDefaults(), arguments, [
            "pitch"
        ]));
        this.name = "PitchShift";
        const options = _defaults.optionsFromArguments(PitchShift.getDefaults(), arguments, [
            "pitch"
        ]);
        this._frequency = new _signal.Signal({
            context: this.context
        });
        this._delayA = new _delay.Delay({
            maxDelay: 1,
            context: this.context
        });
        this._lfoA = new _lfo.LFO({
            context: this.context,
            min: 0,
            max: 0.1,
            type: "sawtooth"
        }).connect(this._delayA.delayTime);
        this._delayB = new _delay.Delay({
            maxDelay: 1,
            context: this.context
        });
        this._lfoB = new _lfo.LFO({
            context: this.context,
            min: 0,
            max: 0.1,
            type: "sawtooth",
            phase: 180
        }).connect(this._delayB.delayTime);
        this._crossFade = new _crossFade.CrossFade({
            context: this.context
        });
        this._crossFadeLFO = new _lfo.LFO({
            context: this.context,
            min: 0,
            max: 1,
            type: "triangle",
            phase: 90
        }).connect(this._crossFade.fade);
        this._feedbackDelay = new _delay.Delay({
            delayTime: options.delayTime,
            context: this.context
        });
        this.delayTime = this._feedbackDelay.delayTime;
        _interface.readOnly(this, "delayTime");
        this._pitch = options.pitch;
        this._windowSize = options.windowSize;
        // connect the two delay lines up
        this._delayA.connect(this._crossFade.a);
        this._delayB.connect(this._crossFade.b);
        // connect the frequency
        this._frequency.fan(this._lfoA.frequency, this._lfoB.frequency, this._crossFadeLFO.frequency);
        // route the input
        this.effectSend.fan(this._delayA, this._delayB);
        this._crossFade.chain(this._feedbackDelay, this.effectReturn);
        // start the LFOs at the same time
        const now = this.now();
        this._lfoA.start(now);
        this._lfoB.start(now);
        this._crossFadeLFO.start(now);
        // set the initial value
        this.windowSize = this._windowSize;
    }
    static getDefaults() {
        return Object.assign(_feedbackEffect.FeedbackEffect.getDefaults(), {
            pitch: 0,
            windowSize: 0.1,
            delayTime: 0,
            feedback: 0
        });
    }
    /**
     * Repitch the incoming signal by some interval (measured in semi-tones).
     * @example
     * const pitchShift = new Tone.PitchShift().toDestination();
     * const osc = new Tone.Oscillator().connect(pitchShift).start().toDestination();
     * pitchShift.pitch = -12; // down one octave
     * pitchShift.pitch = 7; // up a fifth
     */ get pitch() {
        return this._pitch;
    }
    set pitch(interval) {
        this._pitch = interval;
        let factor = 0;
        if (interval < 0) {
            this._lfoA.min = 0;
            this._lfoA.max = this._windowSize;
            this._lfoB.min = 0;
            this._lfoB.max = this._windowSize;
            factor = _conversions.intervalToFrequencyRatio(interval - 1) + 1;
        } else {
            this._lfoA.min = this._windowSize;
            this._lfoA.max = 0;
            this._lfoB.min = this._windowSize;
            this._lfoB.max = 0;
            factor = _conversions.intervalToFrequencyRatio(interval) - 1;
        }
        this._frequency.value = factor * (1.2 / this._windowSize);
    }
    /**
     * The window size corresponds roughly to the sample length in a looping sampler.
     * Smaller values are desirable for a less noticeable delay time of the pitch shifted
     * signal, but larger values will result in smoother pitch shifting for larger intervals.
     * A nominal range of 0.03 to 0.1 is recommended.
     */ get windowSize() {
        return this._windowSize;
    }
    set windowSize(size) {
        this._windowSize = this.toSeconds(size);
        this.pitch = this._pitch;
    }
    dispose() {
        super.dispose();
        this._frequency.dispose();
        this._delayA.dispose();
        this._delayB.dispose();
        this._lfoA.dispose();
        this._lfoB.dispose();
        this._crossFade.dispose();
        this._crossFadeLFO.dispose();
        this._feedbackDelay.dispose();
        return this;
    }
}

},{"./FeedbackEffect":"7RXqA","../core/util/Defaults":"kSyYt","../source/oscillator/LFO":"d8Ivp","../core/context/Delay":"fGWul","../component/channel/CrossFade":"hj0PR","../signal/Signal":"kfryg","../core/util/Interface":"fVoXs","../core/type/Conversions":"kOcnG","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cbvFb":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Phaser is a phaser effect. Phasers work by changing the phase
 * of different frequency components of an incoming signal. Read more on
 * [Wikipedia](https://en.wikipedia.org/wiki/Phaser_(effect)).
 * Inspiration for this phaser comes from [Tuna.js](https://github.com/Dinahmoe/tuna/).
 * @example
 * const phaser = new Tone.Phaser({
 * 	frequency: 15,
 * 	octaves: 5,
 * 	baseFrequency: 1000
 * }).toDestination();
 * const synth = new Tone.FMSynth().connect(phaser);
 * synth.triggerAttackRelease("E3", "2n");
 * @category Effect
 */ parcelHelpers.export(exports, "Phaser", ()=>Phaser
);
var _stereoEffect = require("./StereoEffect");
var _defaults = require("../core/util/Defaults");
var _lfo = require("../source/oscillator/LFO");
var _signal = require("../signal/Signal");
var _interface = require("../core/util/Interface");
class Phaser extends _stereoEffect.StereoEffect {
    constructor(){
        super(_defaults.optionsFromArguments(Phaser.getDefaults(), arguments, [
            "frequency",
            "octaves",
            "baseFrequency"
        ]));
        this.name = "Phaser";
        const options = _defaults.optionsFromArguments(Phaser.getDefaults(), arguments, [
            "frequency",
            "octaves",
            "baseFrequency"
        ]);
        this._lfoL = new _lfo.LFO({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1
        });
        this._lfoR = new _lfo.LFO({
            context: this.context,
            frequency: options.frequency,
            min: 0,
            max: 1,
            phase: 180
        });
        this._baseFrequency = this.toFrequency(options.baseFrequency);
        this._octaves = options.octaves;
        this.Q = new _signal.Signal({
            context: this.context,
            value: options.Q,
            units: "positive"
        });
        this._filtersL = this._makeFilters(options.stages, this._lfoL);
        this._filtersR = this._makeFilters(options.stages, this._lfoR);
        this.frequency = this._lfoL.frequency;
        this.frequency.value = options.frequency;
        // connect them up
        this.connectEffectLeft(...this._filtersL);
        this.connectEffectRight(...this._filtersR);
        // control the frequency with one LFO
        this._lfoL.frequency.connect(this._lfoR.frequency);
        // set the options
        this.baseFrequency = options.baseFrequency;
        this.octaves = options.octaves;
        // start the lfo
        this._lfoL.start();
        this._lfoR.start();
        _interface.readOnly(this, [
            "frequency",
            "Q"
        ]);
    }
    static getDefaults() {
        return Object.assign(_stereoEffect.StereoEffect.getDefaults(), {
            frequency: 0.5,
            octaves: 3,
            stages: 10,
            Q: 10,
            baseFrequency: 350
        });
    }
    _makeFilters(stages, connectToFreq) {
        const filters = [];
        // make all the filters
        for(let i = 0; i < stages; i++){
            const filter = this.context.createBiquadFilter();
            filter.type = "allpass";
            this.Q.connect(filter.Q);
            connectToFreq.connect(filter.frequency);
            filters.push(filter);
        }
        return filters;
    }
    /**
     * The number of octaves the phase goes above the baseFrequency
     */ get octaves() {
        return this._octaves;
    }
    set octaves(octaves) {
        this._octaves = octaves;
        const max = this._baseFrequency * Math.pow(2, octaves);
        this._lfoL.max = max;
        this._lfoR.max = max;
    }
    /**
     * The the base frequency of the filters.
     */ get baseFrequency() {
        return this._baseFrequency;
    }
    set baseFrequency(freq) {
        this._baseFrequency = this.toFrequency(freq);
        this._lfoL.min = this._baseFrequency;
        this._lfoR.min = this._baseFrequency;
        this.octaves = this._octaves;
    }
    dispose() {
        super.dispose();
        this.Q.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._filtersL.forEach((f)=>f.disconnect()
        );
        this._filtersR.forEach((f)=>f.disconnect()
        );
        this.frequency.dispose();
        return this;
    }
}

},{"./StereoEffect":"9c7Xr","../core/util/Defaults":"kSyYt","../source/oscillator/LFO":"d8Ivp","../signal/Signal":"kfryg","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"51Gh7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Simple convolution created with decaying noise.
 * Generates an Impulse Response Buffer
 * with Tone.Offline then feeds the IR into ConvolverNode.
 * The impulse response generation is async, so you have
 * to wait until [[ready]] resolves before it will make a sound.
 *
 * Inspiration from [ReverbGen](https://github.com/adelespinasse/reverbGen).
 * Copyright (c) 2014 Alan deLespinasse Apache 2.0 License.
 *
 * @category Effect
 */ parcelHelpers.export(exports, "Reverb", ()=>Reverb
);
var _tslib = require("tslib");
var _merge = require("../component/channel/Merge");
var _gain = require("../core/context/Gain");
var _defaults = require("../core/util/Defaults");
var _noise = require("../source/Noise");
var _effect = require("./Effect");
var _offlineContext = require("../core/context/OfflineContext");
var _interface = require("../core/util/Interface");
var _debug = require("../core/util/Debug");
class Reverb extends _effect.Effect {
    constructor(){
        super(_defaults.optionsFromArguments(Reverb.getDefaults(), arguments, [
            "decay"
        ]));
        this.name = "Reverb";
        /**
         * Convolver node
         */ this._convolver = this.context.createConvolver();
        /**
         * Resolves when the reverb buffer is generated. Whenever either [[decay]]
         * or [[preDelay]] are set, you have to wait until [[ready]] resolves
         * before the IR is generated with the latest values.
         */ this.ready = Promise.resolve();
        const options = _defaults.optionsFromArguments(Reverb.getDefaults(), arguments, [
            "decay"
        ]);
        this._decay = options.decay;
        this._preDelay = options.preDelay;
        this.generate();
        this.connectEffect(this._convolver);
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            decay: 1.5,
            preDelay: 0.01
        });
    }
    /**
     * The duration of the reverb.
     */ get decay() {
        return this._decay;
    }
    set decay(time) {
        time = this.toSeconds(time);
        _debug.assertRange(time, 0.001);
        this._decay = time;
        this.generate();
    }
    /**
     * The amount of time before the reverb is fully ramped in.
     */ get preDelay() {
        return this._preDelay;
    }
    set preDelay(time) {
        time = this.toSeconds(time);
        _debug.assertRange(time, 0);
        this._preDelay = time;
        this.generate();
    }
    /**
     * Generate the Impulse Response. Returns a promise while the IR is being generated.
     * @return Promise which returns this object.
     */ generate() {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            const previousReady = this.ready;
            // create a noise burst which decays over the duration in each channel
            const context = new _offlineContext.OfflineContext(2, this._decay + this._preDelay, this.context.sampleRate);
            const noiseL = new _noise.Noise({
                context
            });
            const noiseR = new _noise.Noise({
                context
            });
            const merge = new _merge.Merge({
                context
            });
            noiseL.connect(merge, 0, 0);
            noiseR.connect(merge, 0, 1);
            const gainNode = new _gain.Gain({
                context
            }).toDestination();
            merge.connect(gainNode);
            noiseL.start(0);
            noiseR.start(0);
            // predelay
            gainNode.gain.setValueAtTime(0, 0);
            gainNode.gain.setValueAtTime(1, this._preDelay);
            // decay
            gainNode.gain.exponentialApproachValueAtTime(0, this._preDelay, this.decay);
            // render the buffer
            const renderPromise = context.render();
            this.ready = renderPromise.then(_interface.noOp);
            // wait for the previous `ready` to resolve
            yield previousReady;
            // set the buffer
            this._convolver.buffer = (yield renderPromise).get();
            return this;
        });
    }
    dispose() {
        super.dispose();
        this._convolver.disconnect();
        return this;
    }
}

},{"tslib":"bjkXk","../component/channel/Merge":"4QcRh","../core/context/Gain":"7kpMn","../core/util/Defaults":"kSyYt","../source/Noise":"hF5D5","./Effect":"k385z","../core/context/OfflineContext":"KYtWQ","../core/util/Interface":"fVoXs","../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bEZDT":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Applies a width factor to the mid/side seperation.
 * 0 is all mid and 1 is all side.
 * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).
 * ```
 * Mid *= 2*(1-width)<br>
 * Side *= 2*width
 * ```
 * @category Effect
 */ parcelHelpers.export(exports, "StereoWidener", ()=>StereoWidener
);
var _midSideEffect = require("../effect/MidSideEffect");
var _signal = require("../signal/Signal");
var _multiply = require("../signal/Multiply");
var _subtract = require("../signal/Subtract");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
var _toneAudioNode = require("../core/context/ToneAudioNode");
class StereoWidener extends _midSideEffect.MidSideEffect {
    constructor(){
        super(_defaults.optionsFromArguments(StereoWidener.getDefaults(), arguments, [
            "width"
        ]));
        this.name = "StereoWidener";
        const options = _defaults.optionsFromArguments(StereoWidener.getDefaults(), arguments, [
            "width"
        ]);
        this.width = new _signal.Signal({
            context: this.context,
            value: options.width,
            units: "normalRange"
        });
        _interface.readOnly(this, [
            "width"
        ]);
        this._twoTimesWidthMid = new _multiply.Multiply({
            context: this.context,
            value: 2
        });
        this._twoTimesWidthSide = new _multiply.Multiply({
            context: this.context,
            value: 2
        });
        this._midMult = new _multiply.Multiply({
            context: this.context
        });
        this._twoTimesWidthMid.connect(this._midMult.factor);
        this.connectEffectMid(this._midMult);
        this._oneMinusWidth = new _subtract.Subtract({
            context: this.context
        });
        this._oneMinusWidth.connect(this._twoTimesWidthMid);
        _toneAudioNode.connect(this.context.getConstant(1), this._oneMinusWidth);
        this.width.connect(this._oneMinusWidth.subtrahend);
        this._sideMult = new _multiply.Multiply({
            context: this.context
        });
        this.width.connect(this._twoTimesWidthSide);
        this._twoTimesWidthSide.connect(this._sideMult.factor);
        this.connectEffectSide(this._sideMult);
    }
    static getDefaults() {
        return Object.assign(_midSideEffect.MidSideEffect.getDefaults(), {
            width: 0.5
        });
    }
    dispose() {
        super.dispose();
        this.width.dispose();
        this._midMult.dispose();
        this._sideMult.dispose();
        this._twoTimesWidthMid.dispose();
        this._twoTimesWidthSide.dispose();
        this._oneMinusWidth.dispose();
        return this;
    }
}

},{"../effect/MidSideEffect":"buBr8","../signal/Signal":"kfryg","../signal/Multiply":"bN8EY","../signal/Subtract":"hQpKf","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","../core/context/ToneAudioNode":"iT1SZ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"buBr8":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Mid/Side processing separates the the 'mid' signal
 * (which comes out of both the left and the right channel)
 * and the 'side' (which only comes out of the the side channels)
 * and effects them separately before being recombined.
 * Applies a Mid/Side seperation and recombination.
 * Algorithm found in [kvraudio forums](http://www.kvraudio.com/forum/viewtopic.php?t=212587).
 * This is a base-class for Mid/Side Effects.
 * @category Effect
 */ parcelHelpers.export(exports, "MidSideEffect", ()=>MidSideEffect
);
var _effect = require("./Effect");
var _midSideSplit = require("../component/channel/MidSideSplit");
var _midSideMerge = require("../component/channel/MidSideMerge");
class MidSideEffect extends _effect.Effect {
    constructor(options){
        super(options);
        this.name = "MidSideEffect";
        this._midSideMerge = new _midSideMerge.MidSideMerge({
            context: this.context
        });
        this._midSideSplit = new _midSideSplit.MidSideSplit({
            context: this.context
        });
        this._midSend = this._midSideSplit.mid;
        this._sideSend = this._midSideSplit.side;
        this._midReturn = this._midSideMerge.mid;
        this._sideReturn = this._midSideMerge.side;
        // the connections
        this.effectSend.connect(this._midSideSplit);
        this._midSideMerge.connect(this.effectReturn);
    }
    /**
     * Connect the mid chain of the effect
     */ connectEffectMid(...nodes) {
        this._midSend.chain(...nodes, this._midReturn);
    }
    /**
     * Connect the side chain of the effect
     */ connectEffectSide(...nodes) {
        this._sideSend.chain(...nodes, this._sideReturn);
    }
    dispose() {
        super.dispose();
        this._midSideSplit.dispose();
        this._midSideMerge.dispose();
        this._midSend.dispose();
        this._sideSend.dispose();
        this._midReturn.dispose();
        this._sideReturn.dispose();
        return this;
    }
}

},{"./Effect":"k385z","../component/channel/MidSideSplit":"9Dif7","../component/channel/MidSideMerge":"36SuM","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9Dif7":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Mid/Side processing separates the the 'mid' signal (which comes out of both the left and the right channel)
 * and the 'side' (which only comes out of the the side channels).
 * ```
 * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right
 * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right
 * ```
 * @category Component
 */ parcelHelpers.export(exports, "MidSideSplit", ()=>MidSideSplit
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _split = require("./Split");
var _add = require("../../signal/Add");
var _multiply = require("../../signal/Multiply");
var _subtract = require("../../signal/Subtract");
var _defaults = require("../../core/util/Defaults");
class MidSideSplit extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(MidSideSplit.getDefaults(), arguments));
        this.name = "MidSideSplit";
        this._split = this.input = new _split.Split({
            channels: 2,
            context: this.context
        });
        this._midAdd = new _add.Add({
            context: this.context
        });
        this.mid = new _multiply.Multiply({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._sideSubtract = new _subtract.Subtract({
            context: this.context
        });
        this.side = new _multiply.Multiply({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._split.connect(this._midAdd, 0);
        this._split.connect(this._midAdd.addend, 1);
        this._split.connect(this._sideSubtract, 0);
        this._split.connect(this._sideSubtract.subtrahend, 1);
        this._midAdd.connect(this.mid);
        this._sideSubtract.connect(this.side);
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._midAdd.dispose();
        this._sideSubtract.dispose();
        this._split.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","./Split":"fvmN8","../../signal/Add":"iRri4","../../signal/Multiply":"bN8EY","../../signal/Subtract":"hQpKf","../../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"36SuM":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * MidSideMerge merges the mid and side signal after they've been separated by [[MidSideSplit]]
 * ```
 * Mid = (Left+Right)/sqrt(2);   // obtain mid-signal from left and right
 * Side = (Left-Right)/sqrt(2);   // obtain side-signal from left and right
 * ```
 * @category Component
 */ parcelHelpers.export(exports, "MidSideMerge", ()=>MidSideMerge
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _merge = require("./Merge");
var _add = require("../../signal/Add");
var _multiply = require("../../signal/Multiply");
var _subtract = require("../../signal/Subtract");
var _gain = require("../../core/context/Gain");
var _defaults = require("../../core/util/Defaults");
class MidSideMerge extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(MidSideMerge.getDefaults(), arguments));
        this.name = "MidSideMerge";
        this.mid = new _gain.Gain({
            context: this.context
        });
        this.side = new _gain.Gain({
            context: this.context
        });
        this._left = new _add.Add({
            context: this.context
        });
        this._leftMult = new _multiply.Multiply({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._right = new _subtract.Subtract({
            context: this.context
        });
        this._rightMult = new _multiply.Multiply({
            context: this.context,
            value: Math.SQRT1_2
        });
        this._merge = this.output = new _merge.Merge({
            context: this.context
        });
        this.mid.fan(this._left);
        this.side.connect(this._left.addend);
        this.mid.connect(this._right);
        this.side.connect(this._right.subtrahend);
        this._left.connect(this._leftMult);
        this._right.connect(this._rightMult);
        this._leftMult.connect(this._merge, 0, 0);
        this._rightMult.connect(this._merge, 0, 1);
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._leftMult.dispose();
        this._rightMult.dispose();
        this._left.dispose();
        this._right.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","./Merge":"4QcRh","../../signal/Add":"iRri4","../../signal/Multiply":"bN8EY","../../signal/Subtract":"hQpKf","../../core/context/Gain":"7kpMn","../../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jyp9u":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tremolo modulates the amplitude of an incoming signal using an [[LFO]].
 * The effect is a stereo effect where the modulation phase is inverted in each channel.
 *
 * @example
 * // create a tremolo and start it's LFO
 * const tremolo = new Tone.Tremolo(9, 0.75).toDestination().start();
 * // route an oscillator through the tremolo and start it
 * const oscillator = new Tone.Oscillator().connect(tremolo).start();
 *
 * @category Effect
 */ parcelHelpers.export(exports, "Tremolo", ()=>Tremolo
);
var _stereoEffect = require("./StereoEffect");
var _lfo = require("../source/oscillator/LFO");
var _gain = require("../core/context/Gain");
var _signal = require("../signal/Signal");
var _defaults = require("../core/util/Defaults");
var _interface = require("../core/util/Interface");
class Tremolo extends _stereoEffect.StereoEffect {
    constructor(){
        super(_defaults.optionsFromArguments(Tremolo.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]));
        this.name = "Tremolo";
        const options = _defaults.optionsFromArguments(Tremolo.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]);
        this._lfoL = new _lfo.LFO({
            context: this.context,
            type: options.type,
            min: 1,
            max: 0
        });
        this._lfoR = new _lfo.LFO({
            context: this.context,
            type: options.type,
            min: 1,
            max: 0
        });
        this._amplitudeL = new _gain.Gain({
            context: this.context
        });
        this._amplitudeR = new _gain.Gain({
            context: this.context
        });
        this.frequency = new _signal.Signal({
            context: this.context,
            value: options.frequency,
            units: "frequency"
        });
        this.depth = new _signal.Signal({
            context: this.context,
            value: options.depth,
            units: "normalRange"
        });
        _interface.readOnly(this, [
            "frequency",
            "depth"
        ]);
        this.connectEffectLeft(this._amplitudeL);
        this.connectEffectRight(this._amplitudeR);
        this._lfoL.connect(this._amplitudeL.gain);
        this._lfoR.connect(this._amplitudeR.gain);
        this.frequency.fan(this._lfoL.frequency, this._lfoR.frequency);
        this.depth.fan(this._lfoR.amplitude, this._lfoL.amplitude);
        this.spread = options.spread;
    }
    static getDefaults() {
        return Object.assign(_stereoEffect.StereoEffect.getDefaults(), {
            frequency: 10,
            type: "sine",
            depth: 0.5,
            spread: 180
        });
    }
    /**
     * Start the tremolo.
     */ start(time) {
        this._lfoL.start(time);
        this._lfoR.start(time);
        return this;
    }
    /**
     * Stop the tremolo.
     */ stop(time) {
        this._lfoL.stop(time);
        this._lfoR.stop(time);
        return this;
    }
    /**
     * Sync the effect to the transport.
     */ sync() {
        this._lfoL.sync();
        this._lfoR.sync();
        this.context.transport.syncSignal(this.frequency);
        return this;
    }
    /**
     * Unsync the filter from the transport
     */ unsync() {
        this._lfoL.unsync();
        this._lfoR.unsync();
        this.context.transport.unsyncSignal(this.frequency);
        return this;
    }
    /**
     * The oscillator type.
     */ get type() {
        return this._lfoL.type;
    }
    set type(type) {
        this._lfoL.type = type;
        this._lfoR.type = type;
    }
    /**
     * Amount of stereo spread. When set to 0, both LFO's will be panned centrally.
     * When set to 180, LFO's will be panned hard left and right respectively.
     */ get spread() {
        return this._lfoR.phase - this._lfoL.phase; // 180
    }
    set spread(spread) {
        this._lfoL.phase = 90 - spread / 2;
        this._lfoR.phase = spread / 2 + 90;
    }
    dispose() {
        super.dispose();
        this._lfoL.dispose();
        this._lfoR.dispose();
        this._amplitudeL.dispose();
        this._amplitudeR.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}

},{"./StereoEffect":"9c7Xr","../source/oscillator/LFO":"d8Ivp","../core/context/Gain":"7kpMn","../signal/Signal":"kfryg","../core/util/Defaults":"kSyYt","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"7wMcd":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A Vibrato effect composed of a Tone.Delay and a Tone.LFO. The LFO
 * modulates the delayTime of the delay, causing the pitch to rise and fall.
 * @category Effect
 */ parcelHelpers.export(exports, "Vibrato", ()=>Vibrato
);
var _effect = require("./Effect");
var _defaults = require("../core/util/Defaults");
var _lfo = require("../source/oscillator/LFO");
var _delay = require("../core/context/Delay");
var _interface = require("../core/util/Interface");
class Vibrato extends _effect.Effect {
    constructor(){
        super(_defaults.optionsFromArguments(Vibrato.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]));
        this.name = "Vibrato";
        const options = _defaults.optionsFromArguments(Vibrato.getDefaults(), arguments, [
            "frequency",
            "depth"
        ]);
        this._delayNode = new _delay.Delay({
            context: this.context,
            delayTime: 0,
            maxDelay: options.maxDelay
        });
        this._lfo = new _lfo.LFO({
            context: this.context,
            type: options.type,
            min: 0,
            max: options.maxDelay,
            frequency: options.frequency,
            phase: -90 // offse the phase so the resting position is in the center
        }).start().connect(this._delayNode.delayTime);
        this.frequency = this._lfo.frequency;
        this.depth = this._lfo.amplitude;
        this.depth.value = options.depth;
        _interface.readOnly(this, [
            "frequency",
            "depth"
        ]);
        this.effectSend.chain(this._delayNode, this.effectReturn);
    }
    static getDefaults() {
        return Object.assign(_effect.Effect.getDefaults(), {
            maxDelay: 0.005,
            frequency: 5,
            depth: 0.1,
            type: "sine"
        });
    }
    /**
     * Type of oscillator attached to the Vibrato.
     */ get type() {
        return this._lfo.type;
    }
    set type(type) {
        this._lfo.type = type;
    }
    dispose() {
        super.dispose();
        this._delayNode.dispose();
        this._lfo.dispose();
        this.frequency.dispose();
        this.depth.dispose();
        return this;
    }
}

},{"./Effect":"k385z","../core/util/Defaults":"kSyYt","../source/oscillator/LFO":"d8Ivp","../core/context/Delay":"fGWul","../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"42PNa":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
var _analyser = require("./analysis/Analyser");
parcelHelpers.exportAll(_analyser, exports);
var _meter = require("./analysis/Meter");
parcelHelpers.exportAll(_meter, exports);
var _fft = require("./analysis/FFT");
parcelHelpers.exportAll(_fft, exports);
var _dcmeter = require("./analysis/DCMeter");
parcelHelpers.exportAll(_dcmeter, exports);
var _waveform = require("./analysis/Waveform");
parcelHelpers.exportAll(_waveform, exports);
var _follower = require("./analysis/Follower");
parcelHelpers.exportAll(_follower, exports);
var _channel = require("./channel/Channel");
parcelHelpers.exportAll(_channel, exports);
var _crossFade = require("./channel/CrossFade");
parcelHelpers.exportAll(_crossFade, exports);
var _merge = require("./channel/Merge");
parcelHelpers.exportAll(_merge, exports);
var _midSideMerge = require("./channel/MidSideMerge");
parcelHelpers.exportAll(_midSideMerge, exports);
var _midSideSplit = require("./channel/MidSideSplit");
parcelHelpers.exportAll(_midSideSplit, exports);
var _mono = require("./channel/Mono");
parcelHelpers.exportAll(_mono, exports);
var _multibandSplit = require("./channel/MultibandSplit");
parcelHelpers.exportAll(_multibandSplit, exports);
var _panner = require("./channel/Panner");
parcelHelpers.exportAll(_panner, exports);
var _panner3D = require("./channel/Panner3D");
parcelHelpers.exportAll(_panner3D, exports);
var _panVol = require("./channel/PanVol");
parcelHelpers.exportAll(_panVol, exports);
var _recorder = require("./channel/Recorder");
parcelHelpers.exportAll(_recorder, exports);
var _solo = require("./channel/Solo");
parcelHelpers.exportAll(_solo, exports);
var _split = require("./channel/Split");
parcelHelpers.exportAll(_split, exports);
var _volume = require("./channel/Volume");
parcelHelpers.exportAll(_volume, exports);
var _compressor = require("./dynamics/Compressor");
parcelHelpers.exportAll(_compressor, exports);
var _gate = require("./dynamics/Gate");
parcelHelpers.exportAll(_gate, exports);
var _limiter = require("./dynamics/Limiter");
parcelHelpers.exportAll(_limiter, exports);
var _midSideCompressor = require("./dynamics/MidSideCompressor");
parcelHelpers.exportAll(_midSideCompressor, exports);
var _multibandCompressor = require("./dynamics/MultibandCompressor");
parcelHelpers.exportAll(_multibandCompressor, exports);
var _amplitudeEnvelope = require("./envelope/AmplitudeEnvelope");
parcelHelpers.exportAll(_amplitudeEnvelope, exports);
var _envelope = require("./envelope/Envelope");
parcelHelpers.exportAll(_envelope, exports);
var _frequencyEnvelope = require("./envelope/FrequencyEnvelope");
parcelHelpers.exportAll(_frequencyEnvelope, exports);
var _eq3 = require("./filter/EQ3");
parcelHelpers.exportAll(_eq3, exports);
var _filter = require("./filter/Filter");
parcelHelpers.exportAll(_filter, exports);
var _onePoleFilter = require("./filter/OnePoleFilter");
parcelHelpers.exportAll(_onePoleFilter, exports);
var _feedbackCombFilter = require("./filter/FeedbackCombFilter");
parcelHelpers.exportAll(_feedbackCombFilter, exports);
var _lowpassCombFilter = require("./filter/LowpassCombFilter");
parcelHelpers.exportAll(_lowpassCombFilter, exports);
var _convolver = require("./filter/Convolver");
parcelHelpers.exportAll(_convolver, exports);
var _biquadFilter = require("./filter/BiquadFilter");
parcelHelpers.exportAll(_biquadFilter, exports);

},{"./analysis/Analyser":"alafR","./analysis/Meter":"d303z","./analysis/FFT":"jVHEH","./analysis/DCMeter":"h8SYp","./analysis/Waveform":"a03sk","./analysis/Follower":"4UVcI","./channel/Channel":"9okKL","./channel/CrossFade":"hj0PR","./channel/Merge":"4QcRh","./channel/MidSideMerge":"36SuM","./channel/MidSideSplit":"9Dif7","./channel/Mono":"jwmZZ","./channel/MultibandSplit":"6WZga","./channel/Panner":"03e3W","./channel/Panner3D":"3IgHy","./channel/PanVol":"lbLZg","./channel/Recorder":"gCtHo","./channel/Solo":"2XPtu","./channel/Split":"fvmN8","./channel/Volume":"j5Q9V","./dynamics/Compressor":"6zYlR","./dynamics/Gate":"6YClH","./dynamics/Limiter":"QBaiC","./dynamics/MidSideCompressor":"2Vu17","./dynamics/MultibandCompressor":"ibR3K","./envelope/AmplitudeEnvelope":"j0uLP","./envelope/Envelope":"91tjD","./envelope/FrequencyEnvelope":"i9sZY","./filter/EQ3":"bm4rq","./filter/Filter":"5lZpJ","./filter/OnePoleFilter":"6YRG8","./filter/FeedbackCombFilter":"iTrd6","./filter/LowpassCombFilter":"ezloU","./filter/Convolver":"cijNW","./filter/BiquadFilter":"fCKNY","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"alafR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Wrapper around the native Web Audio's [AnalyserNode](http://webaudio.github.io/web-audio-api/#idl-def-AnalyserNode).
 * Extracts FFT or Waveform data from the incoming signal.
 * @category Component
 */ parcelHelpers.export(exports, "Analyser", ()=>Analyser
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _split = require("../channel/Split");
var _gain = require("../../core/context/Gain");
var _debug = require("../../core/util/Debug");
class Analyser extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Analyser.getDefaults(), arguments, [
            "type",
            "size"
        ]));
        this.name = "Analyser";
        /**
         * The analyser node.
         */ this._analysers = [];
        /**
         * The buffer that the FFT data is written to
         */ this._buffers = [];
        const options = _defaults.optionsFromArguments(Analyser.getDefaults(), arguments, [
            "type",
            "size"
        ]);
        this.input = this.output = this._gain = new _gain.Gain({
            context: this.context
        });
        this._split = new _split.Split({
            context: this.context,
            channels: options.channels
        });
        this.input.connect(this._split);
        _debug.assertRange(options.channels, 1);
        // create the analysers
        for(let channel = 0; channel < options.channels; channel++){
            this._analysers[channel] = this.context.createAnalyser();
            this._split.connect(this._analysers[channel], channel, 0);
        }
        // set the values initially
        this.size = options.size;
        this.type = options.type;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            size: 1024,
            smoothing: 0.8,
            type: "fft",
            channels: 1
        });
    }
    /**
     * Run the analysis given the current settings. If [[channels]] = 1,
     * it will return a Float32Array. If [[channels]] > 1, it will
     * return an array of Float32Arrays where each index in the array
     * represents the analysis done on a channel.
     */ getValue() {
        this._analysers.forEach((analyser, index)=>{
            const buffer = this._buffers[index];
            if (this._type === "fft") analyser.getFloatFrequencyData(buffer);
            else if (this._type === "waveform") analyser.getFloatTimeDomainData(buffer);
        });
        if (this.channels === 1) return this._buffers[0];
        else return this._buffers;
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     */ get size() {
        return this._analysers[0].frequencyBinCount;
    }
    set size(size) {
        this._analysers.forEach((analyser, index)=>{
            analyser.fftSize = size * 2;
            this._buffers[index] = new Float32Array(size);
        });
    }
    /**
     * The number of channels the analyser does the analysis on. Channel
     * separation is done using [[Split]]
     */ get channels() {
        return this._analysers.length;
    }
    /**
     * The analysis function returned by analyser.getValue(), either "fft" or "waveform".
     */ get type() {
        return this._type;
    }
    set type(type) {
        _debug.assert(type === "waveform" || type === "fft", `Analyser: invalid type: ${type}`);
        this._type = type;
    }
    /**
     * 0 represents no time averaging with the last analysis frame.
     */ get smoothing() {
        return this._analysers[0].smoothingTimeConstant;
    }
    set smoothing(val) {
        this._analysers.forEach((a)=>a.smoothingTimeConstant = val
        );
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        this._analysers.forEach((a)=>a.disconnect()
        );
        this._split.dispose();
        this._gain.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../channel/Split":"fvmN8","../../core/context/Gain":"7kpMn","../../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"d303z":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Meter gets the [RMS](https://en.wikipedia.org/wiki/Root_mean_square)
 * of an input signal. It can also get the raw value of the input signal.
 *
 * @example
 * const meter = new Tone.Meter();
 * const mic = new Tone.UserMedia();
 * mic.open();
 * // connect mic to the meter
 * mic.connect(meter);
 * // the current level of the mic
 * setInterval(() => console.log(meter.getValue()), 100);
 * @category Component
 */ parcelHelpers.export(exports, "Meter", ()=>Meter
);
var _conversions = require("../../core/type/Conversions");
var _defaults = require("../../core/util/Defaults");
var _meterBase = require("./MeterBase");
var _debug = require("../../core/util/Debug");
var _analyser = require("./Analyser");
class Meter extends _meterBase.MeterBase {
    constructor(){
        super(_defaults.optionsFromArguments(Meter.getDefaults(), arguments, [
            "smoothing"
        ]));
        this.name = "Meter";
        /**
         * The previous frame's value
         */ this._rms = 0;
        const options = _defaults.optionsFromArguments(Meter.getDefaults(), arguments, [
            "smoothing"
        ]);
        this.input = this.output = this._analyser = new _analyser.Analyser({
            context: this.context,
            size: 256,
            type: "waveform",
            channels: options.channels
        });
        this.smoothing = options.smoothing, this.normalRange = options.normalRange;
    }
    static getDefaults() {
        return Object.assign(_meterBase.MeterBase.getDefaults(), {
            smoothing: 0.8,
            normalRange: false,
            channels: 1
        });
    }
    /**
     * Use [[getValue]] instead. For the previous getValue behavior, use DCMeter.
     * @deprecated
     */ getLevel() {
        _debug.warn("'getLevel' has been changed to 'getValue'");
        return this.getValue();
    }
    /**
     * Get the current value of the incoming signal.
     * Output is in decibels when [[normalRange]] is `false`.
     * If [[channels]] = 1, then the output is a single number
     * representing the value of the input signal. When [[channels]] > 1,
     * then each channel is returned as a value in a number array.
     */ getValue() {
        const aValues = this._analyser.getValue();
        const channelValues = this.channels === 1 ? [
            aValues
        ] : aValues;
        const vals = channelValues.map((values)=>{
            const totalSquared = values.reduce((total, current)=>total + current * current
            , 0);
            const rms = Math.sqrt(totalSquared / values.length);
            // the rms can only fall at the rate of the smoothing
            // but can jump up instantly
            this._rms = Math.max(rms, this._rms * this.smoothing);
            return this.normalRange ? this._rms : _conversions.gainToDb(this._rms);
        });
        if (this.channels === 1) return vals[0];
        else return vals;
    }
    /**
     * The number of channels of analysis.
     */ get channels() {
        return this._analyser.channels;
    }
    dispose() {
        super.dispose();
        this._analyser.dispose();
        return this;
    }
}

},{"../../core/type/Conversions":"kOcnG","../../core/util/Defaults":"kSyYt","./MeterBase":"iDym3","../../core/util/Debug":"bsxl9","./Analyser":"alafR","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"iDym3":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * The base class for Metering classes.
 */ parcelHelpers.export(exports, "MeterBase", ()=>MeterBase
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _analyser = require("./Analyser");
class MeterBase extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(MeterBase.getDefaults(), arguments));
        this.name = "MeterBase";
        this.input = this.output = this._analyser = new _analyser.Analyser({
            context: this.context,
            size: 256,
            type: "waveform"
        });
    }
    dispose() {
        super.dispose();
        this._analyser.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","./Analyser":"alafR","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jVHEH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Get the current frequency data of the connected audio source using a fast Fourier transform.
 * @category Component
 */ parcelHelpers.export(exports, "FFT", ()=>FFT
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _conversions = require("../../core/type/Conversions");
var _defaults = require("../../core/util/Defaults");
var _meterBase = require("./MeterBase");
var _debug = require("../../core/util/Debug");
class FFT extends _meterBase.MeterBase {
    constructor(){
        super(_defaults.optionsFromArguments(FFT.getDefaults(), arguments, [
            "size"
        ]));
        this.name = "FFT";
        const options = _defaults.optionsFromArguments(FFT.getDefaults(), arguments, [
            "size"
        ]);
        this.normalRange = options.normalRange;
        this._analyser.type = "fft";
        this.size = options.size;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            normalRange: false,
            size: 1024,
            smoothing: 0.8
        });
    }
    /**
     * Gets the current frequency data from the connected audio source.
     * Returns the frequency data of length [[size]] as a Float32Array of decibel values.
     */ getValue() {
        const values = this._analyser.getValue();
        return values.map((v)=>this.normalRange ? _conversions.dbToGain(v) : v
        );
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     * Determines the size of the array returned by [[getValue]] (i.e. the number of
     * frequency bins). Large FFT sizes may be costly to compute.
     */ get size() {
        return this._analyser.size;
    }
    set size(size) {
        this._analyser.size = size;
    }
    /**
     * 0 represents no time averaging with the last analysis frame.
     */ get smoothing() {
        return this._analyser.smoothing;
    }
    set smoothing(val) {
        this._analyser.smoothing = val;
    }
    /**
     * Returns the frequency value in hertz of each of the indices of the FFT's [[getValue]] response.
     * @example
     * const fft = new Tone.FFT(32);
     * console.log([0, 1, 2, 3, 4].map(index => fft.getFrequencyOfIndex(index)));
     */ getFrequencyOfIndex(index) {
        _debug.assert(0 <= index && index < this.size, `index must be greater than or equal to 0 and less than ${this.size}`);
        return index * this.context.sampleRate / (this.size * 2);
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/type/Conversions":"kOcnG","../../core/util/Defaults":"kSyYt","./MeterBase":"iDym3","../../core/util/Debug":"bsxl9","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"h8SYp":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * DCMeter gets the raw value of the input signal at the current time.
 *
 * @example
 * const meter = new Tone.DCMeter();
 * const mic = new Tone.UserMedia();
 * mic.open();
 * // connect mic to the meter
 * mic.connect(meter);
 * // the current level of the mic
 * const level = meter.getValue();
 * @category Component
 */ parcelHelpers.export(exports, "DCMeter", ()=>DCMeter
);
var _defaults = require("../../core/util/Defaults");
var _meterBase = require("./MeterBase");
class DCMeter extends _meterBase.MeterBase {
    constructor(){
        super(_defaults.optionsFromArguments(DCMeter.getDefaults(), arguments));
        this.name = "DCMeter";
        this._analyser.type = "waveform";
        this._analyser.size = 256;
    }
    /**
     * Get the signal value of the incoming signal
     */ getValue() {
        const value = this._analyser.getValue();
        return value[0];
    }
}

},{"../../core/util/Defaults":"kSyYt","./MeterBase":"iDym3","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"a03sk":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Get the current waveform data of the connected audio source.
 * @category Component
 */ parcelHelpers.export(exports, "Waveform", ()=>Waveform
);
var _defaults = require("../../core/util/Defaults");
var _meterBase = require("./MeterBase");
class Waveform extends _meterBase.MeterBase {
    constructor(){
        super(_defaults.optionsFromArguments(Waveform.getDefaults(), arguments, [
            "size"
        ]));
        this.name = "Waveform";
        const options = _defaults.optionsFromArguments(Waveform.getDefaults(), arguments, [
            "size"
        ]);
        this._analyser.type = "waveform";
        this.size = options.size;
    }
    static getDefaults() {
        return Object.assign(_meterBase.MeterBase.getDefaults(), {
            size: 1024
        });
    }
    /**
     * Return the waveform for the current time as a Float32Array where each value in the array
     * represents a sample in the waveform.
     */ getValue() {
        return this._analyser.getValue();
    }
    /**
     * The size of analysis. This must be a power of two in the range 16 to 16384.
     * Determines the size of the array returned by [[getValue]].
     */ get size() {
        return this._analyser.size;
    }
    set size(size) {
        this._analyser.size = size;
    }
}

},{"../../core/util/Defaults":"kSyYt","./MeterBase":"iDym3","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"9okKL":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Channel provides a channel strip interface with volume, pan, solo and mute controls.
 * See [[PanVol]] and [[Solo]]
 * @example
 * // pan the incoming signal left and drop the volume 12db
 * const channel = new Tone.Channel(-0.25, -12);
 * @category Component
 */ parcelHelpers.export(exports, "Channel", ()=>Channel
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _solo = require("./Solo");
var _panVol = require("./PanVol");
var _interface = require("../../core/util/Interface");
var _gain = require("../../core/context/Gain");
class Channel extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Channel.getDefaults(), arguments, [
            "volume",
            "pan"
        ]));
        this.name = "Channel";
        const options = _defaults.optionsFromArguments(Channel.getDefaults(), arguments, [
            "volume",
            "pan"
        ]);
        this._solo = this.input = new _solo.Solo({
            solo: options.solo,
            context: this.context
        });
        this._panVol = this.output = new _panVol.PanVol({
            context: this.context,
            pan: options.pan,
            volume: options.volume,
            mute: options.mute,
            channelCount: options.channelCount
        });
        this.pan = this._panVol.pan;
        this.volume = this._panVol.volume;
        this._solo.connect(this._panVol);
        _interface.readOnly(this, [
            "pan",
            "volume"
        ]);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            pan: 0,
            volume: 0,
            mute: false,
            solo: false,
            channelCount: 1
        });
    }
    /**
     * Solo/unsolo the channel. Soloing is only relative to other [[Channels]] and [[Solo]] instances
     */ get solo() {
        return this._solo.solo;
    }
    set solo(solo) {
        this._solo.solo = solo;
    }
    /**
     * If the current instance is muted, i.e. another instance is soloed,
     * or the channel is muted
     */ get muted() {
        return this._solo.muted || this.mute;
    }
    /**
     * Mute/unmute the volume
     */ get mute() {
        return this._panVol.mute;
    }
    set mute(mute) {
        this._panVol.mute = mute;
    }
    /**
     * Get the gain node belonging to the bus name. Create it if
     * it doesn't exist
     * @param name The bus name
     */ _getBus(name) {
        if (!Channel.buses.has(name)) Channel.buses.set(name, new _gain.Gain({
            context: this.context
        }));
        return Channel.buses.get(name);
    }
    /**
     * Send audio to another channel using a string. `send` is a lot like
     * [[connect]], except it uses a string instead of an object. This can
     * be useful in large applications to decouple sections since [[send]]
     * and [[receive]] can be invoked separately in order to connect an object
     * @param name The channel name to send the audio
     * @param volume The amount of the signal to send.
     * 	Defaults to 0db, i.e. send the entire signal
     * @returns Returns the gain node of this connection.
     */ send(name, volume = 0) {
        const bus = this._getBus(name);
        const sendKnob = new _gain.Gain({
            context: this.context,
            units: "decibels",
            gain: volume
        });
        this.connect(sendKnob);
        sendKnob.connect(bus);
        return sendKnob;
    }
    /**
     * Receive audio from a channel which was connected with [[send]].
     * @param name The channel name to receive audio from.
     */ receive(name) {
        const bus = this._getBus(name);
        bus.connect(this);
        return this;
    }
    dispose() {
        super.dispose();
        this._panVol.dispose();
        this.pan.dispose();
        this.volume.dispose();
        this._solo.dispose();
        return this;
    }
}
/**
 * Store the send/receive channels by name.
 */ Channel.buses = new Map();

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","./Solo":"2XPtu","./PanVol":"lbLZg","../../core/util/Interface":"fVoXs","../../core/context/Gain":"7kpMn","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2XPtu":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Solo lets you isolate a specific audio stream. When an instance is set to `solo=true`,
 * it will mute all other instances of Solo.
 * @example
 * const soloA = new Tone.Solo().toDestination();
 * const oscA = new Tone.Oscillator("C4", "sawtooth").connect(soloA);
 * const soloB = new Tone.Solo().toDestination();
 * const oscB = new Tone.Oscillator("E4", "square").connect(soloB);
 * soloA.solo = true;
 * // no audio will pass through soloB
 * @category Component
 */ parcelHelpers.export(exports, "Solo", ()=>Solo
);
var _gain = require("../../core/context/Gain");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
class Solo extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Solo.getDefaults(), arguments, [
            "solo"
        ]));
        this.name = "Solo";
        const options = _defaults.optionsFromArguments(Solo.getDefaults(), arguments, [
            "solo"
        ]);
        this.input = this.output = new _gain.Gain({
            context: this.context
        });
        if (!Solo._allSolos.has(this.context)) Solo._allSolos.set(this.context, new Set());
        Solo._allSolos.get(this.context).add(this);
        // set initially
        this.solo = options.solo;
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            solo: false
        });
    }
    /**
     * Isolates this instance and mutes all other instances of Solo.
     * Only one instance can be soloed at a time. A soloed
     * instance will report `solo=false` when another instance is soloed.
     */ get solo() {
        return this._isSoloed();
    }
    set solo(solo) {
        if (solo) this._addSolo();
        else this._removeSolo();
        Solo._allSolos.get(this.context).forEach((instance)=>instance._updateSolo()
        );
    }
    /**
     * If the current instance is muted, i.e. another instance is soloed
     */ get muted() {
        return this.input.gain.value === 0;
    }
    /**
     * Add this to the soloed array
     */ _addSolo() {
        if (!Solo._soloed.has(this.context)) Solo._soloed.set(this.context, new Set());
        Solo._soloed.get(this.context).add(this);
    }
    /**
     * Remove this from the soloed array
     */ _removeSolo() {
        if (Solo._soloed.has(this.context)) Solo._soloed.get(this.context).delete(this);
    }
    /**
     * Is this on the soloed array
     */ _isSoloed() {
        return Solo._soloed.has(this.context) && Solo._soloed.get(this.context).has(this);
    }
    /**
     * Returns true if no one is soloed
     */ _noSolos() {
        // either does not have any soloed added
        return !Solo._soloed.has(this.context) || Solo._soloed.has(this.context) && Solo._soloed.get(this.context).size === 0;
    }
    /**
     * Solo the current instance and unsolo all other instances.
     */ _updateSolo() {
        if (this._isSoloed()) this.input.gain.value = 1;
        else if (this._noSolos()) // no one is soloed
        this.input.gain.value = 1;
        else this.input.gain.value = 0;
    }
    dispose() {
        super.dispose();
        Solo._allSolos.get(this.context).delete(this);
        this._removeSolo();
        return this;
    }
}
/**
 * Hold all of the solo'ed tracks belonging to a specific context
 */ Solo._allSolos = new Map();
/**
 * Hold the currently solo'ed instance(s)
 */ Solo._soloed = new Map();

},{"../../core/context/Gain":"7kpMn","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"lbLZg":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * PanVol is a Tone.Panner and Tone.Volume in one.
 * @example
 * // pan the incoming signal left and drop the volume
 * const panVol = new Tone.PanVol(-0.25, -12).toDestination();
 * const osc = new Tone.Oscillator().connect(panVol).start();
 * @category Component
 */ parcelHelpers.export(exports, "PanVol", ()=>PanVol
);
var _interface = require("../../core/util/Interface");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _panner = require("./Panner");
var _volume = require("./Volume");
class PanVol extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(PanVol.getDefaults(), arguments, [
            "pan",
            "volume"
        ]));
        this.name = "PanVol";
        const options = _defaults.optionsFromArguments(PanVol.getDefaults(), arguments, [
            "pan",
            "volume"
        ]);
        this._panner = this.input = new _panner.Panner({
            context: this.context,
            pan: options.pan,
            channelCount: options.channelCount
        });
        this.pan = this._panner.pan;
        this._volume = this.output = new _volume.Volume({
            context: this.context,
            volume: options.volume
        });
        this.volume = this._volume.volume;
        // connections
        this._panner.connect(this._volume);
        this.mute = options.mute;
        _interface.readOnly(this, [
            "pan",
            "volume"
        ]);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            mute: false,
            pan: 0,
            volume: 0,
            channelCount: 1
        });
    }
    /**
     * Mute/unmute the volume
     */ get mute() {
        return this._volume.mute;
    }
    set mute(mute) {
        this._volume.mute = mute;
    }
    dispose() {
        super.dispose();
        this._panner.dispose();
        this.pan.dispose();
        this._volume.dispose();
        this.volume.dispose();
        return this;
    }
}

},{"../../core/util/Interface":"fVoXs","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","./Panner":"03e3W","./Volume":"j5Q9V","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"jwmZZ":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Mono coerces the incoming mono or stereo signal into a mono signal
 * where both left and right channels have the same value. This can be useful
 * for [stereo imaging](https://en.wikipedia.org/wiki/Stereo_imaging).
 * @category Component
 */ parcelHelpers.export(exports, "Mono", ()=>Mono
);
var _gain = require("../../core/context/Gain");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _merge = require("./Merge");
class Mono extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Mono.getDefaults(), arguments));
        this.name = "Mono";
        this.input = new _gain.Gain({
            context: this.context
        });
        this._merge = this.output = new _merge.Merge({
            channels: 2,
            context: this.context
        });
        this.input.connect(this._merge, 0, 0);
        this.input.connect(this._merge, 0, 1);
    }
    dispose() {
        super.dispose();
        this._merge.dispose();
        this.input.dispose();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","./Merge":"4QcRh","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6WZga":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Split the incoming signal into three bands (low, mid, high)
 * with two crossover frequency controls.
 * ```
 *            +----------------------+
 *          +-> input < lowFrequency +------------------> low
 *          | +----------------------+
 *          |
 *          | +--------------------------------------+
 * input ---+-> lowFrequency < input < highFrequency +--> mid
 *          | +--------------------------------------+
 *          |
 *          | +-----------------------+
 *          +-> highFrequency < input +-----------------> high
 *            +-----------------------+
 * ```
 * @category Component
 */ parcelHelpers.export(exports, "MultibandSplit", ()=>MultibandSplit
);
var _gain = require("../../core/context/Gain");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _signal = require("../../signal/Signal");
var _filter = require("../filter/Filter");
class MultibandSplit extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(MultibandSplit.getDefaults(), arguments, [
            "lowFrequency",
            "highFrequency"
        ]));
        this.name = "MultibandSplit";
        /**
         * the input
         */ this.input = new _gain.Gain({
            context: this.context
        });
        /**
         * no output node, use either low, mid or high outputs
         */ this.output = undefined;
        /**
         * The low band.
         */ this.low = new _filter.Filter({
            context: this.context,
            frequency: 0,
            type: "lowpass"
        });
        /**
         * the lower filter of the mid band
         */ this._lowMidFilter = new _filter.Filter({
            context: this.context,
            frequency: 0,
            type: "highpass"
        });
        /**
         * The mid band output.
         */ this.mid = new _filter.Filter({
            context: this.context,
            frequency: 0,
            type: "lowpass"
        });
        /**
         * The high band output.
         */ this.high = new _filter.Filter({
            context: this.context,
            frequency: 0,
            type: "highpass"
        });
        this._internalChannels = [
            this.low,
            this.mid,
            this.high
        ];
        const options = _defaults.optionsFromArguments(MultibandSplit.getDefaults(), arguments, [
            "lowFrequency",
            "highFrequency"
        ]);
        this.lowFrequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: options.lowFrequency
        });
        this.highFrequency = new _signal.Signal({
            context: this.context,
            units: "frequency",
            value: options.highFrequency
        });
        this.Q = new _signal.Signal({
            context: this.context,
            units: "positive",
            value: options.Q
        });
        this.input.fan(this.low, this.high);
        this.input.chain(this._lowMidFilter, this.mid);
        // the frequency control signal
        this.lowFrequency.fan(this.low.frequency, this._lowMidFilter.frequency);
        this.highFrequency.fan(this.mid.frequency, this.high.frequency);
        // the Q value
        this.Q.connect(this.low.Q);
        this.Q.connect(this._lowMidFilter.Q);
        this.Q.connect(this.mid.Q);
        this.Q.connect(this.high.Q);
        _interface.readOnly(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            Q: 1,
            highFrequency: 2500,
            lowFrequency: 400
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        _interface.writable(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
        this.low.dispose();
        this._lowMidFilter.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.lowFrequency.dispose();
        this.highFrequency.dispose();
        this.Q.dispose();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../../signal/Signal":"kfryg","../filter/Filter":"5lZpJ","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"3IgHy":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A spatialized panner node which supports equalpower or HRTF panning.
 * @category Component
 */ parcelHelpers.export(exports, "Panner3D", ()=>Panner3D
);
var _param = require("../../core/context/Param");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _listener = require("../../core/context/Listener");
class Panner3D extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Panner3D.getDefaults(), arguments, [
            "positionX",
            "positionY",
            "positionZ"
        ]));
        this.name = "Panner3D";
        const options = _defaults.optionsFromArguments(Panner3D.getDefaults(), arguments, [
            "positionX",
            "positionY",
            "positionZ"
        ]);
        this._panner = this.input = this.output = this.context.createPanner();
        // set some values
        this.panningModel = options.panningModel;
        this.maxDistance = options.maxDistance;
        this.distanceModel = options.distanceModel;
        this.coneOuterGain = options.coneOuterGain;
        this.coneOuterAngle = options.coneOuterAngle;
        this.coneInnerAngle = options.coneInnerAngle;
        this.refDistance = options.refDistance;
        this.rolloffFactor = options.rolloffFactor;
        this.positionX = new _param.Param({
            context: this.context,
            param: this._panner.positionX,
            value: options.positionX
        });
        this.positionY = new _param.Param({
            context: this.context,
            param: this._panner.positionY,
            value: options.positionY
        });
        this.positionZ = new _param.Param({
            context: this.context,
            param: this._panner.positionZ,
            value: options.positionZ
        });
        this.orientationX = new _param.Param({
            context: this.context,
            param: this._panner.orientationX,
            value: options.orientationX
        });
        this.orientationY = new _param.Param({
            context: this.context,
            param: this._panner.orientationY,
            value: options.orientationY
        });
        this.orientationZ = new _param.Param({
            context: this.context,
            param: this._panner.orientationZ,
            value: options.orientationZ
        });
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            coneInnerAngle: 360,
            coneOuterAngle: 360,
            coneOuterGain: 0,
            distanceModel: "inverse",
            maxDistance: 10000,
            orientationX: 0,
            orientationY: 0,
            orientationZ: 0,
            panningModel: "equalpower",
            positionX: 0,
            positionY: 0,
            positionZ: 0,
            refDistance: 1,
            rolloffFactor: 1
        });
    }
    /**
     * Sets the position of the source in 3d space.
     */ setPosition(x, y, z) {
        this.positionX.value = x;
        this.positionY.value = y;
        this.positionZ.value = z;
        return this;
    }
    /**
     * Sets the orientation of the source in 3d space.
     */ setOrientation(x, y, z) {
        this.orientationX.value = x;
        this.orientationY.value = y;
        this.orientationZ.value = z;
        return this;
    }
    /**
     * The panning model. Either "equalpower" or "HRTF".
     */ get panningModel() {
        return this._panner.panningModel;
    }
    set panningModel(val) {
        this._panner.panningModel = val;
    }
    /**
     * A reference distance for reducing volume as source move further from the listener
     */ get refDistance() {
        return this._panner.refDistance;
    }
    set refDistance(val) {
        this._panner.refDistance = val;
    }
    /**
     * Describes how quickly the volume is reduced as source moves away from listener.
     */ get rolloffFactor() {
        return this._panner.rolloffFactor;
    }
    set rolloffFactor(val) {
        this._panner.rolloffFactor = val;
    }
    /**
     * The distance model used by,  "linear", "inverse", or "exponential".
     */ get distanceModel() {
        return this._panner.distanceModel;
    }
    set distanceModel(val) {
        this._panner.distanceModel = val;
    }
    /**
     * The angle, in degrees, inside of which there will be no volume reduction
     */ get coneInnerAngle() {
        return this._panner.coneInnerAngle;
    }
    set coneInnerAngle(val) {
        this._panner.coneInnerAngle = val;
    }
    /**
     * The angle, in degrees, outside of which the volume will be reduced
     * to a constant value of coneOuterGain
     */ get coneOuterAngle() {
        return this._panner.coneOuterAngle;
    }
    set coneOuterAngle(val) {
        this._panner.coneOuterAngle = val;
    }
    /**
     * The gain outside of the coneOuterAngle
     */ get coneOuterGain() {
        return this._panner.coneOuterGain;
    }
    set coneOuterGain(val) {
        this._panner.coneOuterGain = val;
    }
    /**
     * The maximum distance between source and listener,
     * after which the volume will not be reduced any further.
     */ get maxDistance() {
        return this._panner.maxDistance;
    }
    set maxDistance(val) {
        this._panner.maxDistance = val;
    }
    dispose() {
        super.dispose();
        this._panner.disconnect();
        this.orientationX.dispose();
        this.orientationY.dispose();
        this.orientationZ.dispose();
        this.positionX.dispose();
        this.positionY.dispose();
        this.positionZ.dispose();
        return this;
    }
}

},{"../../core/context/Param":"2qxaM","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/context/Listener":"2ignj","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2ignj":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Tone.Listener is a thin wrapper around the AudioListener. Listener combined
 * with [[Panner3D]] makes up the Web Audio API's 3D panning system. Panner3D allows you
 * to place sounds in 3D and Listener allows you to navigate the 3D sound environment from
 * a first-person perspective. There is only one listener per audio context.
 */ parcelHelpers.export(exports, "Listener", ()=>Listener
);
var _toneAudioNode = require("./ToneAudioNode");
var _param = require("./Param");
var _contextInitialization = require("./ContextInitialization");
class Listener extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(...arguments);
        this.name = "Listener";
        this.positionX = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.positionX
        });
        this.positionY = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.positionY
        });
        this.positionZ = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.positionZ
        });
        this.forwardX = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.forwardX
        });
        this.forwardY = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.forwardY
        });
        this.forwardZ = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.forwardZ
        });
        this.upX = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.upX
        });
        this.upY = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.upY
        });
        this.upZ = new _param.Param({
            context: this.context,
            param: this.context.rawContext.listener.upZ
        });
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            positionX: 0,
            positionY: 0,
            positionZ: 0,
            forwardX: 0,
            forwardY: 0,
            forwardZ: -1,
            upX: 0,
            upY: 1,
            upZ: 0
        });
    }
    dispose() {
        super.dispose();
        this.positionX.dispose();
        this.positionY.dispose();
        this.positionZ.dispose();
        this.forwardX.dispose();
        this.forwardY.dispose();
        this.forwardZ.dispose();
        this.upX.dispose();
        this.upY.dispose();
        this.upZ.dispose();
        return this;
    }
}
//-------------------------------------
// 	INITIALIZATION
//-------------------------------------
_contextInitialization.onContextInit((context)=>{
    context.listener = new Listener({
        context
    });
});
_contextInitialization.onContextClose((context)=>{
    context.listener.dispose();
});

},{"./ToneAudioNode":"iT1SZ","./Param":"2qxaM","./ContextInitialization":"6PyHY","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"gCtHo":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A wrapper around the MediaRecorder API. Unlike the rest of Tone.js, this module does not offer
 * any sample-accurate scheduling because it is not a feature of the MediaRecorder API.
 * This is only natively supported in Chrome and Firefox.
 * For a cross-browser shim, install (audio-recorder-polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
 * @example
 * const recorder = new Tone.Recorder();
 * const synth = new Tone.Synth().connect(recorder);
 * // start recording
 * recorder.start();
 * // generate a few notes
 * synth.triggerAttackRelease("C3", 0.5);
 * synth.triggerAttackRelease("C4", 0.5, "+1");
 * synth.triggerAttackRelease("C5", 0.5, "+2");
 * // wait for the notes to end and stop the recording
 * setTimeout(async () => {
 * 	// the recorded audio is returned as a blob
 * 	const recording = await recorder.stop();
 * 	// download the recording by creating an anchor element and blob url
 * 	const url = URL.createObjectURL(recording);
 * 	const anchor = document.createElement("a");
 * 	anchor.download = "recording.webm";
 * 	anchor.href = url;
 * 	anchor.click();
 * }, 4000);
 * @category Component
 */ parcelHelpers.export(exports, "Recorder", ()=>Recorder
);
var _tslib = require("tslib");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _gain = require("../../core/context/Gain");
var _debug = require("../../core/util/Debug");
var _audioContext = require("../../core/context/AudioContext");
var _defaults = require("../../core/util/Defaults");
class Recorder extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Recorder.getDefaults(), arguments));
        this.name = "Recorder";
        const options = _defaults.optionsFromArguments(Recorder.getDefaults(), arguments);
        this.input = new _gain.Gain({
            context: this.context
        });
        _debug.assert(Recorder.supported, "Media Recorder API is not available");
        this._stream = this.context.createMediaStreamDestination();
        this.input.connect(this._stream);
        this._recorder = new MediaRecorder(this._stream.stream, {
            mimeType: options.mimeType
        });
    }
    static getDefaults() {
        return _toneAudioNode.ToneAudioNode.getDefaults();
    }
    /**
     * The mime type is the format that the audio is encoded in. For Chrome
     * that is typically webm encoded as "vorbis".
     */ get mimeType() {
        return this._recorder.mimeType;
    }
    /**
     * Test if your platform supports the Media Recorder API. If it's not available,
     * try installing this (polyfill)[https://www.npmjs.com/package/audio-recorder-polyfill].
     */ static get supported() {
        return _audioContext.theWindow !== null && Reflect.has(_audioContext.theWindow, "MediaRecorder");
    }
    /**
     * Get the playback state of the Recorder, either "started", "stopped" or "paused"
     */ get state() {
        if (this._recorder.state === "inactive") return "stopped";
        else if (this._recorder.state === "paused") return "paused";
        else return "started";
    }
    /**
     * Start the Recorder. Returns a promise which resolves
     * when the recorder has started.
     */ start() {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            _debug.assert(this.state !== "started", "Recorder is already started");
            const startPromise = new Promise((done)=>{
                const handleStart = ()=>{
                    this._recorder.removeEventListener("start", handleStart, false);
                    done();
                };
                this._recorder.addEventListener("start", handleStart, false);
            });
            this._recorder.start();
            return yield startPromise;
        });
    }
    /**
     * Stop the recorder. Returns a promise with the recorded content until this point
     * encoded as [[mimeType]]
     */ stop() {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            _debug.assert(this.state !== "stopped", "Recorder is not started");
            const dataPromise = new Promise((done)=>{
                const handleData = (e)=>{
                    this._recorder.removeEventListener("dataavailable", handleData, false);
                    done(e.data);
                };
                this._recorder.addEventListener("dataavailable", handleData, false);
            });
            this._recorder.stop();
            return yield dataPromise;
        });
    }
    /**
     * Pause the recorder
     */ pause() {
        _debug.assert(this.state === "started", "Recorder must be started");
        this._recorder.pause();
        return this;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this._stream.disconnect();
        return this;
    }
}

},{"tslib":"bjkXk","../../core/context/ToneAudioNode":"iT1SZ","../../core/context/Gain":"7kpMn","../../core/util/Debug":"bsxl9","../../core/context/AudioContext":"6cX1c","../../core/util/Defaults":"kSyYt","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6zYlR":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Compressor is a thin wrapper around the Web Audio
 * [DynamicsCompressorNode](http://webaudio.github.io/web-audio-api/#the-dynamicscompressornode-interface).
 * Compression reduces the volume of loud sounds or amplifies quiet sounds
 * by narrowing or "compressing" an audio signal's dynamic range.
 * Read more on [Wikipedia](https://en.wikipedia.org/wiki/Dynamic_range_compression).
 * @example
 * const comp = new Tone.Compressor(-30, 3);
 * @category Component
 */ parcelHelpers.export(exports, "Compressor", ()=>Compressor
);
var _param = require("../../core/context/Param");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
class Compressor extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Compressor.getDefaults(), arguments, [
            "threshold",
            "ratio"
        ]));
        this.name = "Compressor";
        /**
         * the compressor node
         */ this._compressor = this.context.createDynamicsCompressor();
        this.input = this._compressor;
        this.output = this._compressor;
        const options = _defaults.optionsFromArguments(Compressor.getDefaults(), arguments, [
            "threshold",
            "ratio"
        ]);
        this.threshold = new _param.Param({
            minValue: this._compressor.threshold.minValue,
            maxValue: this._compressor.threshold.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.threshold,
            units: "decibels",
            value: options.threshold
        });
        this.attack = new _param.Param({
            minValue: this._compressor.attack.minValue,
            maxValue: this._compressor.attack.maxValue,
            context: this.context,
            param: this._compressor.attack,
            units: "time",
            value: options.attack
        });
        this.release = new _param.Param({
            minValue: this._compressor.release.minValue,
            maxValue: this._compressor.release.maxValue,
            context: this.context,
            param: this._compressor.release,
            units: "time",
            value: options.release
        });
        this.knee = new _param.Param({
            minValue: this._compressor.knee.minValue,
            maxValue: this._compressor.knee.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.knee,
            units: "decibels",
            value: options.knee
        });
        this.ratio = new _param.Param({
            minValue: this._compressor.ratio.minValue,
            maxValue: this._compressor.ratio.maxValue,
            context: this.context,
            convert: false,
            param: this._compressor.ratio,
            units: "positive",
            value: options.ratio
        });
        // set the defaults
        _interface.readOnly(this, [
            "knee",
            "release",
            "attack",
            "ratio",
            "threshold"
        ]);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            attack: 0.003,
            knee: 30,
            ratio: 12,
            release: 0.25,
            threshold: -24
        });
    }
    /**
     * A read-only decibel value for metering purposes, representing the current amount of gain
     * reduction that the compressor is applying to the signal. If fed no signal the value will be 0 (no gain reduction).
     */ get reduction() {
        return this._compressor.reduction;
    }
    dispose() {
        super.dispose();
        this._compressor.disconnect();
        this.attack.dispose();
        this.release.dispose();
        this.threshold.dispose();
        this.ratio.dispose();
        this.knee.dispose();
        return this;
    }
}

},{"../../core/context/Param":"2qxaM","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"6YClH":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Gate only passes a signal through when the incoming
 * signal exceeds a specified threshold. It uses [[Follower]] to follow the ampltiude
 * of the incoming signal and compares it to the [[threshold]] value using [[GreaterThan]].
 *
 * @example
 * const gate = new Tone.Gate(-30, 0.2).toDestination();
 * const mic = new Tone.UserMedia().connect(gate);
 * // the gate will only pass through the incoming
 * // signal when it's louder than -30db
 * @category Component
 */ parcelHelpers.export(exports, "Gate", ()=>Gate
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _greaterThan = require("../../signal/GreaterThan");
var _gain = require("../../core/context/Gain");
var _follower = require("../analysis/Follower");
var _defaults = require("../../core/util/Defaults");
var _conversions = require("../../core/type/Conversions");
class Gate extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Gate.getDefaults(), arguments, [
            "threshold",
            "smoothing"
        ])));
        this.name = "Gate";
        const options = _defaults.optionsFromArguments(Gate.getDefaults(), arguments, [
            "threshold",
            "smoothing"
        ]);
        this._follower = new _follower.Follower({
            context: this.context,
            smoothing: options.smoothing
        });
        this._gt = new _greaterThan.GreaterThan({
            context: this.context,
            value: _conversions.dbToGain(options.threshold)
        });
        this.input = new _gain.Gain({
            context: this.context
        });
        this._gate = this.output = new _gain.Gain({
            context: this.context
        });
        // connections
        this.input.connect(this._gate);
        // the control signal
        this.input.chain(this._follower, this._gt, this._gate.gain);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            smoothing: 0.1,
            threshold: -40
        });
    }
    /**
     * The threshold of the gate in decibels
     */ get threshold() {
        return _conversions.gainToDb(this._gt.value);
    }
    set threshold(thresh) {
        this._gt.value = _conversions.dbToGain(thresh);
    }
    /**
     * The attack/decay speed of the gate. See [[Follower.smoothing]]
     */ get smoothing() {
        return this._follower.smoothing;
    }
    set smoothing(smoothingTime) {
        this._follower.smoothing = smoothingTime;
    }
    dispose() {
        super.dispose();
        this.input.dispose();
        this._follower.dispose();
        this._gt.dispose();
        this._gate.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../signal/GreaterThan":"hGVSg","../../core/context/Gain":"7kpMn","../analysis/Follower":"4UVcI","../../core/util/Defaults":"kSyYt","../../core/type/Conversions":"kOcnG","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"QBaiC":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Limiter will limit the loudness of an incoming signal.
 * Under the hood it's composed of a [[Compressor]] with a fast attack
 * and release and max compression ratio.
 *
 * @example
 * const limiter = new Tone.Limiter(-20).toDestination();
 * const oscillator = new Tone.Oscillator().connect(limiter);
 * oscillator.start();
 * @category Component
 */ parcelHelpers.export(exports, "Limiter", ()=>Limiter
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _compressor = require("./Compressor");
var _interface = require("../../core/util/Interface");
class Limiter extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(Limiter.getDefaults(), arguments, [
            "threshold"
        ])));
        this.name = "Limiter";
        const options = _defaults.optionsFromArguments(Limiter.getDefaults(), arguments, [
            "threshold"
        ]);
        this._compressor = this.input = this.output = new _compressor.Compressor({
            context: this.context,
            ratio: 20,
            attack: 0.003,
            release: 0.01,
            threshold: options.threshold
        });
        this.threshold = this._compressor.threshold;
        _interface.readOnly(this, "threshold");
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            threshold: -12
        });
    }
    /**
     * A read-only decibel value for metering purposes, representing the current amount of gain
     * reduction that the compressor is applying to the signal.
     */ get reduction() {
        return this._compressor.reduction;
    }
    dispose() {
        super.dispose();
        this._compressor.dispose();
        this.threshold.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","./Compressor":"6zYlR","../../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"2Vu17":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * MidSideCompressor applies two different compressors to the [[mid]]
 * and [[side]] signal components of the input. See [[MidSideSplit]] and [[MidSideMerge]].
 * @category Component
 */ parcelHelpers.export(exports, "MidSideCompressor", ()=>MidSideCompressor
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _compressor = require("./Compressor");
var _defaults = require("../../core/util/Defaults");
var _midSideSplit = require("../channel/MidSideSplit");
var _midSideMerge = require("../channel/MidSideMerge");
var _interface = require("../../core/util/Interface");
class MidSideCompressor extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(MidSideCompressor.getDefaults(), arguments)));
        this.name = "MidSideCompressor";
        const options = _defaults.optionsFromArguments(MidSideCompressor.getDefaults(), arguments);
        this._midSideSplit = this.input = new _midSideSplit.MidSideSplit({
            context: this.context
        });
        this._midSideMerge = this.output = new _midSideMerge.MidSideMerge({
            context: this.context
        });
        this.mid = new _compressor.Compressor(Object.assign(options.mid, {
            context: this.context
        }));
        this.side = new _compressor.Compressor(Object.assign(options.side, {
            context: this.context
        }));
        this._midSideSplit.mid.chain(this.mid, this._midSideMerge.mid);
        this._midSideSplit.side.chain(this.side, this._midSideMerge.side);
        _interface.readOnly(this, [
            "mid",
            "side"
        ]);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            mid: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            },
            side: {
                ratio: 6,
                threshold: -30,
                release: 0.25,
                attack: 0.03,
                knee: 10
            }
        });
    }
    dispose() {
        super.dispose();
        this.mid.dispose();
        this.side.dispose();
        this._midSideSplit.dispose();
        this._midSideMerge.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","./Compressor":"6zYlR","../../core/util/Defaults":"kSyYt","../channel/MidSideSplit":"9Dif7","../channel/MidSideMerge":"36SuM","../../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"ibR3K":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * A compressor with separate controls over low/mid/high dynamics. See [[Compressor]] and [[MultibandSplit]]
 *
 * @example
 * const multiband = new Tone.MultibandCompressor({
 * 	lowFrequency: 200,
 * 	highFrequency: 1300,
 * 	low: {
 * 		threshold: -12
 * 	}
 * });
 * @category Component
 */ parcelHelpers.export(exports, "MultibandCompressor", ()=>MultibandCompressor
);
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _compressor = require("./Compressor");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _multibandSplit = require("../channel/MultibandSplit");
var _gain = require("../../core/context/Gain");
class MultibandCompressor extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(Object.assign(_defaults.optionsFromArguments(MultibandCompressor.getDefaults(), arguments)));
        this.name = "MultibandCompressor";
        const options = _defaults.optionsFromArguments(MultibandCompressor.getDefaults(), arguments);
        this._splitter = this.input = new _multibandSplit.MultibandSplit({
            context: this.context,
            lowFrequency: options.lowFrequency,
            highFrequency: options.highFrequency
        });
        this.lowFrequency = this._splitter.lowFrequency;
        this.highFrequency = this._splitter.highFrequency;
        this.output = new _gain.Gain({
            context: this.context
        });
        this.low = new _compressor.Compressor(Object.assign(options.low, {
            context: this.context
        }));
        this.mid = new _compressor.Compressor(Object.assign(options.mid, {
            context: this.context
        }));
        this.high = new _compressor.Compressor(Object.assign(options.high, {
            context: this.context
        }));
        // connect the compressor
        this._splitter.low.chain(this.low, this.output);
        this._splitter.mid.chain(this.mid, this.output);
        this._splitter.high.chain(this.high, this.output);
        _interface.readOnly(this, [
            "high",
            "mid",
            "low",
            "highFrequency",
            "lowFrequency"
        ]);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            lowFrequency: 250,
            highFrequency: 2000,
            low: {
                ratio: 6,
                threshold: -30,
                release: 0.25,
                attack: 0.03,
                knee: 10
            },
            mid: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            },
            high: {
                ratio: 3,
                threshold: -24,
                release: 0.03,
                attack: 0.02,
                knee: 16
            }
        });
    }
    dispose() {
        super.dispose();
        this._splitter.dispose();
        this.low.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.output.dispose();
        return this;
    }
}

},{"../../core/context/ToneAudioNode":"iT1SZ","./Compressor":"6zYlR","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../channel/MultibandSplit":"6WZga","../../core/context/Gain":"7kpMn","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"bm4rq":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * EQ3 provides 3 equalizer bins: Low/Mid/High.
 * @category Component
 */ parcelHelpers.export(exports, "EQ3", ()=>EQ3
);
var _gain = require("../../core/context/Gain");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _defaults = require("../../core/util/Defaults");
var _interface = require("../../core/util/Interface");
var _multibandSplit = require("../channel/MultibandSplit");
class EQ3 extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(EQ3.getDefaults(), arguments, [
            "low",
            "mid",
            "high"
        ]));
        this.name = "EQ3";
        /**
         * the output
         */ this.output = new _gain.Gain({
            context: this.context
        });
        this._internalChannels = [];
        const options = _defaults.optionsFromArguments(EQ3.getDefaults(), arguments, [
            "low",
            "mid",
            "high"
        ]);
        this.input = this._multibandSplit = new _multibandSplit.MultibandSplit({
            context: this.context,
            highFrequency: options.highFrequency,
            lowFrequency: options.lowFrequency
        });
        this._lowGain = new _gain.Gain({
            context: this.context,
            gain: options.low,
            units: "decibels"
        });
        this._midGain = new _gain.Gain({
            context: this.context,
            gain: options.mid,
            units: "decibels"
        });
        this._highGain = new _gain.Gain({
            context: this.context,
            gain: options.high,
            units: "decibels"
        });
        this.low = this._lowGain.gain;
        this.mid = this._midGain.gain;
        this.high = this._highGain.gain;
        this.Q = this._multibandSplit.Q;
        this.lowFrequency = this._multibandSplit.lowFrequency;
        this.highFrequency = this._multibandSplit.highFrequency;
        // the frequency bands
        this._multibandSplit.low.chain(this._lowGain, this.output);
        this._multibandSplit.mid.chain(this._midGain, this.output);
        this._multibandSplit.high.chain(this._highGain, this.output);
        _interface.readOnly(this, [
            "low",
            "mid",
            "high",
            "lowFrequency",
            "highFrequency"
        ]);
        this._internalChannels = [
            this._multibandSplit
        ];
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            high: 0,
            highFrequency: 2500,
            low: 0,
            lowFrequency: 400,
            mid: 0
        });
    }
    /**
     * Clean up.
     */ dispose() {
        super.dispose();
        _interface.writable(this, [
            "low",
            "mid",
            "high",
            "lowFrequency",
            "highFrequency"
        ]);
        this._multibandSplit.dispose();
        this.lowFrequency.dispose();
        this.highFrequency.dispose();
        this._lowGain.dispose();
        this._midGain.dispose();
        this._highGain.dispose();
        this.low.dispose();
        this.mid.dispose();
        this.high.dispose();
        this.Q.dispose();
        return this;
    }
}

},{"../../core/context/Gain":"7kpMn","../../core/context/ToneAudioNode":"iT1SZ","../../core/util/Defaults":"kSyYt","../../core/util/Interface":"fVoXs","../channel/MultibandSplit":"6WZga","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}],"cijNW":[function(require,module,exports) {
var parcelHelpers = require("@parcel/transformer-js/src/esmodule-helpers.js");
parcelHelpers.defineInteropFlag(exports);
/**
 * Convolver is a wrapper around the Native Web Audio
 * [ConvolverNode](http://webaudio.github.io/web-audio-api/#the-convolvernode-interface).
 * Convolution is useful for reverb and filter emulation. Read more about convolution reverb on
 * [Wikipedia](https://en.wikipedia.org/wiki/Convolution_reverb).
 *
 * @example
 * // initializing the convolver with an impulse response
 * const convolver = new Tone.Convolver("./path/to/ir.wav").toDestination();
 * @category Component
 */ parcelHelpers.export(exports, "Convolver", ()=>Convolver
);
var _tslib = require("tslib");
var _toneAudioNode = require("../../core/context/ToneAudioNode");
var _toneAudioBuffer = require("../../core/context/ToneAudioBuffer");
var _defaults = require("../../core/util/Defaults");
var _gain = require("../../core/context/Gain");
var _interface = require("../../core/util/Interface");
class Convolver extends _toneAudioNode.ToneAudioNode {
    constructor(){
        super(_defaults.optionsFromArguments(Convolver.getDefaults(), arguments, [
            "url",
            "onload"
        ]));
        this.name = "Convolver";
        /**
         * The native ConvolverNode
         */ this._convolver = this.context.createConvolver();
        const options = _defaults.optionsFromArguments(Convolver.getDefaults(), arguments, [
            "url",
            "onload"
        ]);
        this._buffer = new _toneAudioBuffer.ToneAudioBuffer(options.url, (buffer)=>{
            this.buffer = buffer;
            options.onload();
        });
        this.input = new _gain.Gain({
            context: this.context
        });
        this.output = new _gain.Gain({
            context: this.context
        });
        // set if it's already loaded, set it immediately
        if (this._buffer.loaded) this.buffer = this._buffer;
        // initially set normalization
        this.normalize = options.normalize;
        // connect it up
        this.input.chain(this._convolver, this.output);
    }
    static getDefaults() {
        return Object.assign(_toneAudioNode.ToneAudioNode.getDefaults(), {
            normalize: true,
            onload: _interface.noOp
        });
    }
    /**
     * Load an impulse response url as an audio buffer.
     * Decodes the audio asynchronously and invokes
     * the callback once the audio buffer loads.
     * @param url The url of the buffer to load. filetype support depends on the browser.
     */ load(url) {
        return _tslib.__awaiter(this, void 0, void 0, function*() {
            this.buffer = yield this._buffer.load(url);
        });
    }
    /**
     * The convolver's buffer
     */ get buffer() {
        if (this._buffer.length) return this._buffer;
        else return null;
    }
    set buffer(buffer) {
        if (buffer) this._buffer.set(buffer);
        // if it's already got a buffer, create a new one
        if (this._convolver.buffer) {
            // disconnect the old one
            this.input.disconnect();
            this._convolver.disconnect();
            // create and connect a new one
            this._convolver = this.context.createConvolver();
            this.input.chain(this._convolver, this.output);
        }
        const buff = this._buffer.get();
        this._convolver.buffer = buff ? buff : null;
    }
    /**
     * The normalize property of the ConvolverNode interface is a boolean that
     * controls whether the impulse response from the buffer will be scaled by
     * an equal-power normalization when the buffer attribute is set, or not.
     */ get normalize() {
        return this._convolver.normalize;
    }
    set normalize(norm) {
        this._convolver.normalize = norm;
    }
    dispose() {
        super.dispose();
        this._buffer.dispose();
        this._convolver.disconnect();
        return this;
    }
}

},{"tslib":"bjkXk","../../core/context/ToneAudioNode":"iT1SZ","../../core/context/ToneAudioBuffer":"gpPIV","../../core/util/Defaults":"kSyYt","../../core/context/Gain":"7kpMn","../../core/util/Interface":"fVoXs","@parcel/transformer-js/src/esmodule-helpers.js":"3feM1"}]},["5mFkr","davKm"], "davKm", "parcelRequire097b")

//# sourceMappingURL=index.6a345035.js.map
